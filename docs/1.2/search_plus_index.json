{"./":{"url":"./","title":"Introduction","keywords":"","body":"PyTorch 1.0 中文文档 & 教程 PyTorch 是一个针对深度学习, 并且使用 GPU 和 CPU 来优化的 tensor library (张量库) 1.2 中文版本 1.0 中文版本 最新 英文教程 最新 英文文档 0.4 中文版本 0.3 中文版本 0.2 中文版本 欢迎任何人参与和完善：一个人可以走的很快，但是一群人却可以走的更远。 在线阅读 ApacheCN 学习资源 PyTorch 中文翻译组 | ApacheCN 713436582 目录结构 Introduction 中文教程 入门 PyTorch 深度学习: 60 分钟极速入门 数据加载和处理教程 用例子学习 PyTorch 迁移学习教程 部署与TorchScript一个Seq2Seq模型 可视化模型，数据，和与训练TensorBoard 保存和加载模型 torch.nn 到底是什么？ 图片 TorchVision对象检测教程细化和微调 微调Torchvision模型 空间变压器网络教程 使用PyTorch进行神经网络传递 对抗性示例生成 DCGAN教程 音频 torchaudio教程 文本 NLP从头：判断名称与字符级RNN NLP从头：生成名称与字符级RNN NLP从无到有：用序列到序列网络和翻译注意 文本分类与TorchText 语言翻译与TorchText 序列到序列与nn.Transformer和TorchText建模 强化学习 强化学习（DQN）教程 在生产部署PyTorch模型 1.部署PyTorch在Python经由REST API从Flask 2.介绍TorchScript 3.装载++一个TorchScript模型在C 4.（可选）从导出到PyTorch一个ONNX模型并使用ONNX运行时运行它 并行和分布式训练 1.型号并行最佳实践 2.入门分布式数据并行 3. PyTorch编写分布式应用 4.（高级）PyTorch 1.0分布式训练与Amazon AWS 扩展PyTorch 使用自定义 C++ 扩展算TorchScript 创建扩展使用numpy的和SciPy的 自定义 C++ 和CUDA扩展 PyTorch在其他语言 使用PyTorch C++ 前端 中文文档 注解 自动求导机制 广播语义 CPU线程和TorchScript推理 CUDA语义 扩展PyTorch 常见问题 对于大规模部署的特点 多处理最佳实践 重复性 序列化语义 Windows 常见问题 社区 PyTorch贡献说明书 PyTorch治理 PyTorch治|兴趣的人 封装参考文献 torch torch.Tensor Tensor Attributes Type Info torch.sparse torch.cuda torch.Storage torch.nn torch.nn.functional torch.nn.init torch.optim torch.autograd torch.distributed torch.distributions torch.hub torch.jit torch.multiprocessing torch.random torch.utils.bottleneck torch.utils.checkpoint torch.utils.cpp_extension torch.utils.data torch.utils.dlpack torch.utils.model_zoo torch.utils.tensorboard torch.onnx torch. config torchvision 参考文献 torchvision torchaudio Reference torchaudio torchtext Reference torchtext 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/deep_learning_60min_blitz.html":{"url":"beginner/deep_learning_60min_blitz.html","title":"PyTorch 深度学习: 60 分钟极速入门","keywords":"","body":"深度学习与PyTorch：60分钟的闪电战 作者 ： Soumith Chintala 本教程的目标： 了解PyTorch的张量库和神经网络在较高的水平。 培养一个小神经网络分类图片 本教程假设你有numpy的一个基本的了解 注意 请确保您有Torch 和 torchvision 安装的软件包。 什么是PyTorch？ Autograd：自动微分 神经网络 训练分类 可选：数据并行 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 深与PyTorch学习：60分钟闪电 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/data_loading_tutorial.html":{"url":"beginner/data_loading_tutorial.html","title":"数据加载和处理教程","keywords":"","body":"数据加载和处理教程 作者 ： Sasank Chilamkurthy 在解决任何机器学习问题的一个很大的功夫去到准备数据。 PyTorch提供了许多工具，使数据加载容易，希望，使你的代码更易读。在本教程中，我们将看到如何从一个不平凡的数据集加载和预处理/增强数据。 要运行本教程中，请确保以下软件包安装： scikit图像：用于图像IO和变换 大熊猫：为了方便CSV解析 from __future__ import print_function, division import os import torch import pandas as pd from skimage import io, transform import numpy as np import matplotlib.pyplot as plt from torch.utils.data import Dataset, DataLoader from torchvision import transforms, utils # Ignore warnings import warnings warnings.filterwarnings(\"ignore\") plt.ion() # interactive mode 我们要处理的数据集是面部姿态。这意味着，脸被注释是这样的： 总体而言，68个不同的标志点被注释为每个面。 Note 从下载数据集在这里，这样的图像是在一个名为“数据/面/”目录。此数据集实际上是由优秀的应用 DLIB的姿态估计从imagenet标记为“面子”一些图像生成。 数据集配有带注释，看起来像这样一个CSV文件： image_name,part_0_x,part_0_y,part_1_x,part_1_y,part_2_x, ... ,part_67_x,part_67_y 0805personali01.jpg,27,83,27,98, ... 84,134 1084239450_e76e00b7e7.jpg,70,236,71,257, ... ,128,312 让我们快速读取CSV并获得注释在（N，2）数组，其中N为标志的数量。 landmarks_frame = pd.read_csv('data/faces/face_landmarks.csv') n = 65 img_name = landmarks_frame.iloc[n, 0] landmarks = landmarks_frame.iloc[n, 1:].as_matrix() landmarks = landmarks.astype('float').reshape(-1, 2) print('Image name: {}'.format(img_name)) print('Landmarks shape: {}'.format(landmarks.shape)) print('First 4 Landmarks: {}'.format(landmarks[:4])) 日期： Image name: person-7.jpg Landmarks shape: (68, 2) First 4 Landmarks: [[32. 65.] [33. 76.] [34. 86.] [34. 97.]] 让我们写一个简单的辅助函数来显示的图象和标志性建筑，并用它来显示一个样本。 def show_landmarks(image, landmarks): \"\"\"Show image with landmarks\"\"\" plt.imshow(image) plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r') plt.pause(0.001) # pause a bit so that plots are updated plt.figure() show_landmarks(io.imread(os.path.join('data/faces/', img_name)), landmarks) plt.show() 数据集类 torch.utils.data.Dataset是表示数据集的抽象类。您的自定义数据集要继承数据集，并覆盖下列方法： __len__，使得LEN（数据集）返回数据集的大小。 __getitem__支持索引，使得数据集[I]可以被用来获得 \\（I \\）个样本 让我们创建一个DataSet类为我们的脸地标数据集。我们将读取__init__的CSV但留下的图像，以__getitem__读数。因为所有的图像没有存储在存储器中的一次，但根据需要读取，这是记忆效率。 我们的数据集中的样品将是一个字典{ '图像'： 图像， '标志'： 地标}。我们的数据集将采取一个可选的参数变换，使得可以在样品被施加任何所需的处理。我们将看到的用处变换在下一节。 class FaceLandmarksDataset(Dataset): \"\"\"Face Landmarks dataset.\"\"\" def __init__(self, csv_file, root_dir, transform=None): \"\"\" Args: csv_file (string): Path to the csv file with annotations. root_dir (string): Directory with all the images. transform (callable, optional): Optional transform to be applied on a sample. \"\"\" self.landmarks_frame = pd.read_csv(csv_file) self.root_dir = root_dir self.transform = transform def __len__(self): return len(self.landmarks_frame) def __getitem__(self, idx): if torch.is_tensor(idx): idx = idx.tolist() img_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, 0]) image = io.imread(img_name) landmarks = self.landmarks_frame.iloc[idx, 1:] landmarks = np.array([landmarks]) landmarks = landmarks.astype('float').reshape(-1, 2) sample = {'image': image, 'landmarks': landmarks} if self.transform: sample = self.transform(sample) return sample 让我们来实例化这个类，并通过数据样本进行迭代。我们将打印首4个样品的尺寸和展示自己的标志性建筑。 face_dataset = FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv', root_dir='data/faces/') fig = plt.figure() for i in range(len(face_dataset)): sample = face_dataset[i] print(i, sample['image'].shape, sample['landmarks'].shape) ax = plt.subplot(1, 4, i + 1) plt.tight_layout() ax.set_title('Sample #{}'.format(i)) ax.axis('off') show_landmarks(**sample) if i == 3: plt.show() break Out: 0 (324, 215, 3) (68, 2) 1 (500, 333, 3) (68, 2) 2 (250, 258, 3) (68, 2) 3 (434, 290, 3) (68, 2) 变换 有一个问题，我们可以从上面看到的是，样本大小相同的不行。大多数的神经网络指望一个固定大小的图像。因此，我们需要编写一些代码prepocessing。让我们创建三个变换： 重新缩放：将图像缩放 RandomCrop：从图像中随机裁剪。这是数据增强。 ToTensor：转换的numpy的图像焊枪图片（我们需要换轴）。 我们将它们写为可调用的类，而不是简单的功能，这样的变换参数不需要通过每次它叫。对于这一点，我们只需要实现__call__方法，如果需要，__init__方法。然后，我们可以使用转换是这样的： tsfm = Transform(params) transformed_sample = tsfm(sample) 注意下面这些变换怎么过的图像和标志性建筑上应用两者。 class Rescale(object): \"\"\"Rescale the image in a sample to a given size. Args: output_size (tuple or int): Desired output size. If tuple, output is matched to output_size. If int, smaller of image edges is matched to output_size keeping aspect ratio the same. \"\"\" def __init__(self, output_size): assert isinstance(output_size, (int, tuple)) self.output_size = output_size def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] h, w = image.shape[:2] if isinstance(self.output_size, int): if h > w: new_h, new_w = self.output_size * h / w, self.output_size else: new_h, new_w = self.output_size, self.output_size * w / h else: new_h, new_w = self.output_size new_h, new_w = int(new_h), int(new_w) img = transform.resize(image, (new_h, new_w)) # h and w are swapped for landmarks because for images, # x and y axes are axis 1 and 0 respectively landmarks = landmarks * [new_w / w, new_h / h] return {'image': img, 'landmarks': landmarks} class RandomCrop(object): \"\"\"Crop randomly the image in a sample. Args: output_size (tuple or int): Desired output size. If int, square crop is made. \"\"\" def __init__(self, output_size): assert isinstance(output_size, (int, tuple)) if isinstance(output_size, int): self.output_size = (output_size, output_size) else: assert len(output_size) == 2 self.output_size = output_size def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] h, w = image.shape[:2] new_h, new_w = self.output_size top = np.random.randint(0, h - new_h) left = np.random.randint(0, w - new_w) image = image[top: top + new_h, left: left + new_w] landmarks = landmarks - [left, top] return {'image': image, 'landmarks': landmarks} class ToTensor(object): \"\"\"Convert ndarrays in sample to Tensors.\"\"\" def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] # swap color axis because # numpy image: H x W x C # torch image: C X H X W image = image.transpose((2, 0, 1)) return {'image': torch.from_numpy(image), 'landmarks': torch.from_numpy(landmarks)} 构成变换 现在，我们应用在样品上的变换。 比方说，我们希望将图像的短边重新调整到256，然后随机地从它种植规模224的正方形。即，我们要组成重新调整和RandomCrop变换。 torchvision.transforms.Compose是一个简单的可调用的类，它使我们能够做到这一点。 scale = Rescale(256) crop = RandomCrop(128) composed = transforms.Compose([Rescale(256), RandomCrop(224)]) # Apply each of the above transforms on sample. fig = plt.figure() sample = face_dataset[65] for i, tsfrm in enumerate([scale, crop, composed]): transformed_sample = tsfrm(sample) ax = plt.subplot(1, 3, i + 1) plt.tight_layout() ax.set_title(type(tsfrm).__name__) show_landmarks(**transformed_sample) plt.show() 通过该数据集迭代 让我们把所有这一切共同创造与由变换的数据集。总之，每一个数据集被采样时间： 图像从上飞文件中读取 变换被应用于所读取的图像上 由于变换之一是随机的，数据被augmentated上采样 我们可以用一个在创建数据集迭代为 i的 在 范围环如前。 transformed_dataset = FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv', root_dir='data/faces/', transform=transforms.Compose([ Rescale(256), RandomCrop(224), ToTensor() ])) for i in range(len(transformed_dataset)): sample = transformed_dataset[i] print(i, sample['image'].size(), sample['landmarks'].size()) if i == 3: break Out: 0 torch.Size([3, 224, 224]) torch.Size([68, 2]) 1 torch.Size([3, 224, 224]) torch.Size([68, 2]) 2 torch.Size([3, 224, 224]) torch.Size([68, 2]) 3 torch.Size([3, 224, 224]) torch.Size([68, 2]) 但是，我们通过使用简单的对循环遍历数据丢失了很多功能。特别是，我们错过了： 配料数据 洗牌的数据 使用多处理工人负载并联的数据。 torch.utils.data.DataLoader为提供所有这些功能的迭代器。下面的参数应该是清楚的。感兴趣的一个参数是collat​​e_fn [HTG7。您可以指定样品需要究竟如何使用collat​​e_fn 进行批处理。然而，默认的整理应该正常工作对于大多数使用情况。 dataloader = DataLoader(transformed_dataset, batch_size=4, shuffle=True, num_workers=4) # Helper function to show a batch def show_landmarks_batch(sample_batched): \"\"\"Show image with landmarks for a batch of samples.\"\"\" images_batch, landmarks_batch = \\ sample_batched['image'], sample_batched['landmarks'] batch_size = len(images_batch) im_size = images_batch.size(2) grid_border_size = 2 grid = utils.make_grid(images_batch) plt.imshow(grid.numpy().transpose((1, 2, 0))) for i in range(batch_size): plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size + (i + 1) * grid_border_size, landmarks_batch[i, :, 1].numpy() + grid_border_size, s=10, marker='.', c='r') plt.title('Batch from dataloader') for i_batch, sample_batched in enumerate(dataloader): print(i_batch, sample_batched['image'].size(), sample_batched['landmarks'].size()) # observe 4th batch and stop. if i_batch == 3: plt.figure() show_landmarks_batch(sample_batched) plt.axis('off') plt.ioff() plt.show() break Out: 0 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2]) 1 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2]) 2 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2]) 3 torch.Size([4, 3, 224, 224]) torch.Size([4, 68, 2]) 后记：torchvision 在本教程中，我们已经看到了如何编写和使用的数据集，转换和的DataLoader。 torchvision包提供了一些常见的数据集和变换。你甚至可能没有编写自定义类。一个在torchvision提供更通用的数据集是ImageFolder [HTG7。它假定图像通过以下方式进行组织： root/ants/xxx.png root/ants/xxy.jpeg root/ants/xxz.png . . . root/bees/123.jpg root/bees/nsdf3.png root/bees/asd932_.png 其中，“蚂蚁”，“蜜蜂”等都是一流的标签。其上操作类似地通用变换PIL.Image如RandomHorizo​​ntalFlip，量表也可提供。您可以使用这些来写这样的的DataLoader： import torch from torchvision import transforms, datasets data_transform = transforms.Compose([ transforms.RandomSizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) hymenoptera_dataset = datasets.ImageFolder(root='hymenoptera_data/train', transform=data_transform) dataset_loader = torch.utils.data.DataLoader(hymenoptera_dataset, batch_size=4, shuffle=True, num_workers=4) 对于训练代码示例，请参见[ 迁移学习教程 HTG3。 脚本的总运行时间： （0分钟59.213秒） Download Python source code: data_loading_tutorial.py Download Jupyter notebook: data_loading_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 数据加载和处理教程 DataSet类 变换 撰写变换 通过数据集迭代 后记：torchvision ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/pytorch_with_examples.html":{"url":"beginner/pytorch_with_examples.html","title":"用例子学习 PyTorch","keywords":"","body":"与实施例学习PyTorch 作者 ：贾斯汀·约翰逊 这个教程通过自包含的实施例引入了的基本概念PyTorch 。 在其核心，PyTorch提供了两个主要特点： n维张量，类似于numpy的，但可以在GPU上运行 自动分化为建设和培训的神经网络 我们将使用全连接RELU网络我们当前实例。该网络将具有单个隐藏层，并且将与梯度下降来训练通过最小化网络输出和真实输出之间的欧几里得距离，以适应随机数据。 注意 您可以在此页面 的 年底浏览个别的例子。 目录 张量 热身：numpy的 PyTorch：张量 Autograd PyTorch：张量和autograd PyTorch：定义新autograd功能 TensorFlow：静态图形 NN 模块 PyTorch：NN PyTorch：的Optim PyTorch：自定义ン模块 PyTorch：控制流+重量共享 实施例 张量 Autograd NN 模块 张量 热身：numpy的 引入PyTorch之前，我们将使用numpy的第一个实施网络。 numpy的提供了一个n维阵列对象，并且许多功能用于操纵这些阵列。 NumPy的是科学计算的通用框架;不知道计算图形，或深学习，或渐变什么。然而，我们可以很容易地使用numpy的通过手动执行前进到适合的两层网络随机数据并通过网络使用numpy的操作向后传递： # -*- coding: utf-8 -*- import numpy as np # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random input and output data x = np.random.randn(N, D_in) y = np.random.randn(N, D_out) # Randomly initialize weights w1 = np.random.randn(D_in, H) w2 = np.random.randn(H, D_out) learning_rate = 1e-6 for t in range(500): # Forward pass: compute predicted y h = x.dot(w1) h_relu = np.maximum(h, 0) y_pred = h_relu.dot(w2) # Compute and print loss loss = np.square(y_pred - y).sum() print(t, loss) # Backprop to compute gradients of w1 and w2 with respect to loss grad_y_pred = 2.0 * (y_pred - y) grad_w2 = h_relu.T.dot(grad_y_pred) grad_h_relu = grad_y_pred.dot(w2.T) grad_h = grad_h_relu.copy() grad_h[h PyTorch：张量 numpy的是一个伟大的框架，但它不能利用GPU来加速其数值计算。对于现代的深层神经网络，图形处理器通常提供的 50倍以上的加速，所以很遗憾numpy的将是不够的现代深度学习。 在这里，我们介绍的最根本PyTorch概念： 张量[HTG1。甲PyTorch张量是概念性地等同于numpy的数组：一个张量是n维阵列，并且PyTorch关于这些张量的操作提供了许多功能。在幕后，张量可以跟踪的计算图表和渐变的，但他们也为科学计算的通用工具是有用的。 也不像numpy的，PyTorch张量可以利用GPU来加速他们的数值计算。要在GPU运行PyTorch张量，只需将它转换为新的数据类型。 这里我们使用PyTorch张量，以适应​​二层网络的随机数据。像numpy的上面的例子，我们需要手动执行向前和向后的通过网络： # -*- coding: utf-8 -*- import torch dtype = torch.float device = torch.device(\"cpu\") # device = torch.device(\"cuda:0\") # Uncomment this to run on GPU # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random input and output data x = torch.randn(N, D_in, device=device, dtype=dtype) y = torch.randn(N, D_out, device=device, dtype=dtype) # Randomly initialize weights w1 = torch.randn(D_in, H, device=device, dtype=dtype) w2 = torch.randn(H, D_out, device=device, dtype=dtype) learning_rate = 1e-6 for t in range(500): # Forward pass: compute predicted y h = x.mm(w1) h_relu = h.clamp(min=0) y_pred = h_relu.mm(w2) # Compute and print loss loss = (y_pred - y).pow(2).sum().item() if t % 100 == 99: print(t, loss) # Backprop to compute gradients of w1 and w2 with respect to loss grad_y_pred = 2.0 * (y_pred - y) grad_w2 = h_relu.t().mm(grad_y_pred) grad_h_relu = grad_y_pred.mm(w2.t()) grad_h = grad_h_relu.clone() grad_h[h Autograd PyTorch：张量和autograd 在上面的例子中，我们必须手动实现正向和我们的神经网络的落后通行证。手动实现后向通行是不是什么大不了的一个小二层网络，但可以迅速得到大型的复杂网络非常有毛。 幸运的是，我们可以使用自动分化自动化神经网络的向后传递的计算。在PyTorch的 autograd 包提供的正是这种功能。当使用autograd，网络的直传将定义一个 计算图表 ;图中的节点将是张量，并且边缘将是产生从输入输出张量张量的功能。通过这个图表Backpropagating然后让你轻松计算梯度。 这听起来很复杂，这是很简单的做法是使用。各张量表示在计算图中的节点。如果×是一个张量，其具有x.requires_grad =真然后x.grad的另一张量保持的×梯度相对于一些标量值。 这里我们使用PyTorch张量和autograd来实现我们的两层网络;现在我们不再需要手动实现通过网络向通行： # -*- coding: utf-8 -*- import torch dtype = torch.float device = torch.device(\"cpu\") # device = torch.device(\"cuda:0\") # Uncomment this to run on GPU # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random Tensors to hold input and outputs. # Setting requires_grad=False indicates that we do not need to compute gradients # with respect to these Tensors during the backward pass. x = torch.randn(N, D_in, device=device, dtype=dtype) y = torch.randn(N, D_out, device=device, dtype=dtype) # Create random Tensors for weights. # Setting requires_grad=True indicates that we want to compute gradients with # respect to these Tensors during the backward pass. w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True) w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True) learning_rate = 1e-6 for t in range(500): # Forward pass: compute predicted y using operations on Tensors; these # are exactly the same operations we used to compute the forward pass using # Tensors, but we do not need to keep references to intermediate values since # we are not implementing the backward pass by hand. y_pred = x.mm(w1).clamp(min=0).mm(w2) # Compute and print loss using operations on Tensors. # Now loss is a Tensor of shape (1,) # loss.item() gets the scalar value held in the loss. loss = (y_pred - y).pow(2).sum() if t % 100 == 99: print(t, loss.item()) # Use autograd to compute the backward pass. This call will compute the # gradient of loss with respect to all Tensors with requires_grad=True. # After this call w1.grad and w2.grad will be Tensors holding the gradient # of the loss with respect to w1 and w2 respectively. loss.backward() # Manually update weights using gradient descent. Wrap in torch.no_grad() # because weights have requires_grad=True, but we don't need to track this # in autograd. # An alternative way is to operate on weight.data and weight.grad.data. # Recall that tensor.data gives a tensor that shares the storage with # tensor, but doesn't track history. # You can also use torch.optim.SGD to achieve this. with torch.no_grad(): w1 -= learning_rate * w1.grad w2 -= learning_rate * w2.grad # Manually zero the gradients after updating weights w1.grad.zero_() w2.grad.zero_() PyTorch：定义新autograd功能 在内部，每个基元autograd操作者实际上是两个函数的张量进行操作。的 向前 函数从输入张量计算输出张量。的 向后 功能接收输出张量的梯度相对于一些标量值，并计算输入张量的梯度相对于该相同标量值。 在PyTorch我们可以很容易地通过定义torch.autograd.Function一个子类，并实现了转发和定义我们自己autograd操作向后功能。然后，我们可以通过构造一个实例，并调用它像一个函数，传递一个包含输入数据的张量使用我们的新autograd运营商。 在这个例子中，我们定义我们自己的自定义autograd功能进行RELU非线性，并用它来实现我们的两层网络： # -*- coding: utf-8 -*- import torch class MyReLU(torch.autograd.Function): \"\"\" We can implement our own custom autograd Functions by subclassing torch.autograd.Function and implementing the forward and backward passes which operate on Tensors. \"\"\" @staticmethod def forward(ctx, input): \"\"\" In the forward pass we receive a Tensor containing the input and return a Tensor containing the output. ctx is a context object that can be used to stash information for backward computation. You can cache arbitrary objects for use in the backward pass using the ctx.save_for_backward method. \"\"\" ctx.save_for_backward(input) return input.clamp(min=0) @staticmethod def backward(ctx, grad_output): \"\"\" In the backward pass we receive a Tensor containing the gradient of the loss with respect to the output, and we need to compute the gradient of the loss with respect to the input. \"\"\" input, = ctx.saved_tensors grad_input = grad_output.clone() grad_input[input TensorFlow：静态图形 PyTorch autograd看起来很像TensorFlow：在两个框架，我们定义的计算图表，并使用自动微分计算梯度。两者之间最大的区别是，TensorFlow的计算图是 静态 和PyTorch使用 动态 计算图表。 在TensorFlow，我们定义了计算图形一次，然后一遍一遍执行相同的曲线图，可能供给不同的输入数据提供给图。在PyTorch，每个直传定义了一个新的计算曲线图。 静态图是很好的，因为你可以在前面优化图形;例如框架可能决定一些融合图的运算效率，还是拿出了在许多的GPU或者多台机器分布图的策略。如果你一遍又一遍地重复使用同一张图上，那么这种潜在的昂贵的前期优化，可以摊销在同一张图中一遍又一遍地重新运行。 其中的静态和动态的曲线图不同的一个方面是控制流。对于某些型号我们可能希望对于每个数据点执行不同的计算;例如复发性网络可能被展开为不同数量的每个数据点的时间步;这样展开可以作为一个循环来实现。具有静态图中的循环结构需要是图形的一部分;为此TensorFlow为运营商提供如tf.scan嵌入循环到曲线图。随着动态图形的情况比较简单：因为我们建立在即时每个示例图，我们可以用正常的必要的流量控制来执行计算的是不同的每个输入。 为了与PyTorch对比上述autograd例子，这里我们使用TensorFlow，以适应一个简单的两层网： # -*- coding: utf-8 -*- import tensorflow as tf import numpy as np # First we set up the computational graph: # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create placeholders for the input and target data; these will be filled # with real data when we execute the graph. x = tf.placeholder(tf.float32, shape=(None, D_in)) y = tf.placeholder(tf.float32, shape=(None, D_out)) # Create Variables for the weights and initialize them with random data. # A TensorFlow Variable persists its value across executions of the graph. w1 = tf.Variable(tf.random_normal((D_in, H))) w2 = tf.Variable(tf.random_normal((H, D_out))) # Forward pass: Compute the predicted y using operations on TensorFlow Tensors. # Note that this code does not actually perform any numeric operations; it # merely sets up the computational graph that we will later execute. h = tf.matmul(x, w1) h_relu = tf.maximum(h, tf.zeros(1)) y_pred = tf.matmul(h_relu, w2) # Compute loss using operations on TensorFlow Tensors loss = tf.reduce_sum((y - y_pred) ** 2.0) # Compute gradient of the loss with respect to w1 and w2. grad_w1, grad_w2 = tf.gradients(loss, [w1, w2]) # Update the weights using gradient descent. To actually update the weights # we need to evaluate new_w1 and new_w2 when executing the graph. Note that # in TensorFlow the the act of updating the value of the weights is part of # the computational graph; in PyTorch this happens outside the computational # graph. learning_rate = 1e-6 new_w1 = w1.assign(w1 - learning_rate * grad_w1) new_w2 = w2.assign(w2 - learning_rate * grad_w2) # Now we have built our computational graph, so we enter a TensorFlow session to # actually execute the graph. with tf.Session() as sess: # Run the graph once to initialize the Variables w1 and w2. sess.run(tf.global_variables_initializer()) # Create numpy arrays holding the actual data for the inputs x and targets # y x_value = np.random.randn(N, D_in) y_value = np.random.randn(N, D_out) for t in range(500): # Execute the graph many times. Each time it executes we want to bind # x_value to x and y_value to y, specified with the feed_dict argument. # Each time we execute the graph we want to compute the values for loss, # new_w1, and new_w2; the values of these Tensors are returned as numpy # arrays. loss_value, _, _ = sess.run([loss, new_w1, new_w2], feed_dict={x: x_value, y: y_value}) if t % 100 == 99: print(t, loss_value) NN 模块 PyTorch：NN 计算图形和autograd是用于定义复杂的操作人员和自动采取衍生物一个非常强大的范例;然而，对于大的神经网络的原始autograd可以有点太级低。 当建立神经网络，我们经常想安排计算分成 图层 ，其中一些 学得的参数 将在学习过程中优化。 在TensorFlow，如包Keras ， TensorFlow修身和 TFLearn 通过原始的计算图表，是构建神经网络的有用提供更高层次的抽象。 在PyTorch时，NN包服务于这个相同的目的。的NN包定义了一组模块，它大致相当于神经网络层的 。一个模块接收输入张量，并且计算输出张量，而且还可以保持内部状态，如含有可以学习参数张量。的NN包还定义了一组训练神经网络时，通常使用的有用的损失函数。 在这个例子中，我们使用NN包来实现我们的两层网络： # -*- coding: utf-8 -*- import torch # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random Tensors to hold inputs and outputs x = torch.randn(N, D_in) y = torch.randn(N, D_out) # Use the nn package to define our model as a sequence of layers. nn.Sequential # is a Module which contains other Modules, and applies them in sequence to # produce its output. Each Linear Module computes output from input using a # linear function, and holds internal Tensors for its weight and bias. model = torch.nn.Sequential( torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out), ) # The nn package also contains definitions of popular loss functions; in this # case we will use Mean Squared Error (MSE) as our loss function. loss_fn = torch.nn.MSELoss(reduction='sum') learning_rate = 1e-4 for t in range(500): # Forward pass: compute predicted y by passing x to the model. Module objects # override the __call__ operator so you can call them like functions. When # doing so you pass a Tensor of input data to the Module and it produces # a Tensor of output data. y_pred = model(x) # Compute and print loss. We pass Tensors containing the predicted and true # values of y, and the loss function returns a Tensor containing the # loss. loss = loss_fn(y_pred, y) if t % 100 == 99: print(t, loss.item()) # Zero the gradients before running the backward pass. model.zero_grad() # Backward pass: compute gradient of the loss with respect to all the learnable # parameters of the model. Internally, the parameters of each Module are stored # in Tensors with requires_grad=True, so this call will compute gradients for # all learnable parameters in the model. loss.backward() # Update the weights using gradient descent. Each parameter is a Tensor, so # we can access its gradients like we did before. with torch.no_grad(): for param in model.parameters(): param -= learning_rate * param.grad PyTorch：的Optim 到现在为止，我们通过人工变异的张量保持可学习参数（torch.no_grad（）或。数据[HTG6更新了模型的重量]以避免在autograd跟踪历史）。这不是简单的优化算法，如随机梯度下降一个巨大的负担，但在实践中，我们经常使用更复杂的优化像AdaGrad，RMSProp，亚当等训练神经网络 的的Optim包在PyTorch夺取优化算法的思想，并提供了常用的优化算法的实施。 在这个例子中，我们将使用NN封装之前定义我们的模型，但是我们将使用由的Optim提供的亚当算法[HTG6优化模型]包： # -*- coding: utf-8 -*- import torch # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random Tensors to hold inputs and outputs x = torch.randn(N, D_in) y = torch.randn(N, D_out) # Use the nn package to define our model and loss function. model = torch.nn.Sequential( torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out), ) loss_fn = torch.nn.MSELoss(reduction='sum') # Use the optim package to define an Optimizer that will update the weights of # the model for us. Here we will use Adam; the optim package contains many other # optimization algoriths. The first argument to the Adam constructor tells the # optimizer which Tensors it should update. learning_rate = 1e-4 optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) for t in range(500): # Forward pass: compute predicted y by passing x to the model. y_pred = model(x) # Compute and print loss. loss = loss_fn(y_pred, y) if t % 100 == 99: print(t, loss.item()) # Before the backward pass, use the optimizer object to zero all of the # gradients for the variables it will update (which are the learnable # weights of the model). This is because by default, gradients are # accumulated in buffers( i.e, not overwritten) whenever .backward() # is called. Checkout docs of torch.autograd.backward for more details. optimizer.zero_grad() # Backward pass: compute gradient of the loss with respect to model # parameters loss.backward() # Calling the step function on an Optimizer makes an update to its # parameters optimizer.step() PyTorch：自定义ン模块 有时你会想指定型号是比现有模块的序列更加复杂;对于这些情况，你可以通过继承nn.Module和定义[定义你自己的模块HTG4] 向前 接收输入张量和使用的其他模块或其他张量运算autograd产生输出张量。 在这个例子中，我们实现我们的两层网络作为自定义模块的子类： # -*- coding: utf-8 -*- import torch class TwoLayerNet(torch.nn.Module): def __init__(self, D_in, H, D_out): \"\"\" In the constructor we instantiate two nn.Linear modules and assign them as member variables. \"\"\" super(TwoLayerNet, self).__init__() self.linear1 = torch.nn.Linear(D_in, H) self.linear2 = torch.nn.Linear(H, D_out) def forward(self, x): \"\"\" In the forward function we accept a Tensor of input data and we must return a Tensor of output data. We can use Modules defined in the constructor as well as arbitrary operators on Tensors. \"\"\" h_relu = self.linear1(x).clamp(min=0) y_pred = self.linear2(h_relu) return y_pred # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random Tensors to hold inputs and outputs x = torch.randn(N, D_in) y = torch.randn(N, D_out) # Construct our model by instantiating the class defined above model = TwoLayerNet(D_in, H, D_out) # Construct our loss function and an Optimizer. The call to model.parameters() # in the SGD constructor will contain the learnable parameters of the two # nn.Linear modules which are members of the model. criterion = torch.nn.MSELoss(reduction='sum') optimizer = torch.optim.SGD(model.parameters(), lr=1e-4) for t in range(500): # Forward pass: Compute predicted y by passing x to the model y_pred = model(x) # Compute and print loss loss = criterion(y_pred, y) if t % 100 == 99: print(t, loss.item()) # Zero gradients, perform a backward pass, and update the weights. optimizer.zero_grad() loss.backward() optimizer.step() PyTorch：控制流+重量共享 动态图形和重量共享的一个例子，我们实现一个很奇怪的模型：即在每个直传选择1和4之间的随机数，并使用该许多隐藏层，多次重复使用相同的权重全连接RELU网络计算隐藏最内层。 对于这个模型，我们可以使用普通的Python流量控制来实现循环，并且我们可以通过定义直传当多次简单地重复使用相同的模块实现最内层之间重量共享。 我们可以很容易地实现这个模型作为一个模块的子类： # -*- coding: utf-8 -*- import random import torch class DynamicNet(torch.nn.Module): def __init__(self, D_in, H, D_out): \"\"\" In the constructor we construct three nn.Linear instances that we will use in the forward pass. \"\"\" super(DynamicNet, self).__init__() self.input_linear = torch.nn.Linear(D_in, H) self.middle_linear = torch.nn.Linear(H, H) self.output_linear = torch.nn.Linear(H, D_out) def forward(self, x): \"\"\" For the forward pass of the model, we randomly choose either 0, 1, 2, or 3 and reuse the middle_linear Module that many times to compute hidden layer representations. Since each forward pass builds a dynamic computation graph, we can use normal Python control-flow operators like loops or conditional statements when defining the forward pass of the model. Here we also see that it is perfectly safe to reuse the same Module many times when defining a computational graph. This is a big improvement from Lua Torch, where each Module could be used only once. \"\"\" h_relu = self.input_linear(x).clamp(min=0) for _ in range(random.randint(0, 3)): h_relu = self.middle_linear(h_relu).clamp(min=0) y_pred = self.output_linear(h_relu) return y_pred # N is batch size; D_in is input dimension; # H is hidden dimension; D_out is output dimension. N, D_in, H, D_out = 64, 1000, 100, 10 # Create random Tensors to hold inputs and outputs x = torch.randn(N, D_in) y = torch.randn(N, D_out) # Construct our model by instantiating the class defined above model = DynamicNet(D_in, H, D_out) # Construct our loss function and an Optimizer. Training this strange model with # vanilla stochastic gradient descent is tough, so we use momentum criterion = torch.nn.MSELoss(reduction='sum') optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9) for t in range(500): # Forward pass: Compute predicted y by passing x to the model y_pred = model(x) # Compute and print loss loss = criterion(y_pred, y) if t % 100 == 99: print(t, loss.item()) # Zero gradients, perform a backward pass, and update the weights. optimizer.zero_grad() loss.backward() optimizer.step() 实施例 你可以在这里浏览上面的例子。 张量 热身：numpy的 PyTorch：张量 Autograd PyTorch：张量和autograd PyTorch：定义新autograd功能 TensorFlow：静态图形 NN 模块 PyTorch：NN PyTorch：的Optim PyTorch：自定义ン模块 PyTorch：控制流+重量共享 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 与实施例学习PyTorch 张量 热身：numpy的 PyTorch：张量 Autograd PyTorch：张量和autograd PyTorch：定义新autograd功能 TensorFlow：静态图形 NN 模块 PyTorch：NN PyTorch：的Optim PyTorch：自定义ン模块 PyTorch：控制流+重量共享 实施例 张量 Autograd NN 模块 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/transfer_learning_tutorial.html":{"url":"beginner/transfer_learning_tutorial.html","title":"迁移学习教程","keywords":"","body":"迁移学习教程 作者 ： Sasank Chilamkurthy 在本教程中，您将学习如何使用迁移学习训练网络。你可以阅读更多关于 cs231n票据转让学习 引用这些笔记， > [HTG0在实践中，很少有人训练的整个卷积网络从头开始（与随机初始化），因为它是比较少见到有足够大的数据集。相反，它是常见的pretrain上的非常大的数据集（例如ImageNet，其中包含与1000个类别1200000个图像）一个ConvNet，然后使用ConvNet无论是作为初始化或对于感兴趣的任务的固定特征提取。 这两大转移学习情境如下所示： 微调的convnet ：除了随机initializaion，我们初始化一个预训练的网络的网络，就像是在imagenet 1000集训练之一。培训的其余神色如常。 ConvNet为固定特征提取 ：在这里，我们将冻结的权重的所有不同的是最终的完全连接层的网络。这最后的完全连接层被替换为一个新的随机的权重也只有这层进行训练。 # License: BSD # Author: Sasank Chilamkurthy from __future__ import print_function, division import torch import torch.nn as nn import torch.optim as optim from torch.optim import lr_scheduler import numpy as np import torchvision from torchvision import datasets, models, transforms import matplotlib.pyplot as plt import time import os import copy plt.ion() # interactive mode 负载数据 我们将使用torchvision和torch.utils.data包加载数据。 我们今天要解决的问题是训练的模型进行分类 蚂蚁 和 蜜蜂HTG3。我们每次约120训练图像蚂蚁和蜜蜂。有75个每一类验证图像。通常情况下，这是一个非常小的数据集在一概而论，如果从头开始培训。由于我们使用的迁移学习，我们应该能够概括得相当好。 该数据集是imagenet的一个很小的子集。 Note 从此处下载数据，并将其解压到当前目录。 # Data augmentation and normalization for training # Just normalization for validation data_transforms = { 'train': transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), 'val': transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), } data_dir = 'data/hymenoptera_data' image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']} dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']} dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']} class_names = image_datasets['train'].classes device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") 可视化的几个图像 让我们想象一些训练图像，以便了解数据扩充。 def imshow(inp, title=None): \"\"\"Imshow for Tensor.\"\"\" inp = inp.numpy().transpose((1, 2, 0)) mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) inp = std * inp + mean inp = np.clip(inp, 0, 1) plt.imshow(inp) if title is not None: plt.title(title) plt.pause(0.001) # pause a bit so that plots are updated # Get a batch of training data inputs, classes = next(iter(dataloaders['train'])) # Make a grid from batch out = torchvision.utils.make_grid(inputs) imshow(out, title=[class_names[x] for x in classes]) 培养模式 现在，让我们写一个通用函数来训练模型。在这里，我们将说明： 安排学习率 保存最好的模式 在下文中，参数调度是从torch.optim.lr_scheduler的LR调度对象。 def train_model(model, criterion, optimizer, scheduler, num_epochs=25): since = time.time() best_model_wts = copy.deepcopy(model.state_dict()) best_acc = 0.0 for epoch in range(num_epochs): print('Epoch {}/{}'.format(epoch, num_epochs - 1)) print('-' * 10) # Each epoch has a training and validation phase for phase in ['train', 'val']: if phase == 'train': model.train() # Set model to training mode else: model.eval() # Set model to evaluate mode running_loss = 0.0 running_corrects = 0 # Iterate over data. for inputs, labels in dataloaders[phase]: inputs = inputs.to(device) labels = labels.to(device) # zero the parameter gradients optimizer.zero_grad() # forward # track history if only in train with torch.set_grad_enabled(phase == 'train'): outputs = model(inputs) _, preds = torch.max(outputs, 1) loss = criterion(outputs, labels) # backward + optimize only if in training phase if phase == 'train': loss.backward() optimizer.step() # statistics running_loss += loss.item() * inputs.size(0) running_corrects += torch.sum(preds == labels.data) if phase == 'train': scheduler.step() epoch_loss = running_loss / dataset_sizes[phase] epoch_acc = running_corrects.double() / dataset_sizes[phase] print('{} Loss: {:.4f} Acc: {:.4f}'.format( phase, epoch_loss, epoch_acc)) # deep copy the model if phase == 'val' and epoch_acc > best_acc: best_acc = epoch_acc best_model_wts = copy.deepcopy(model.state_dict()) print() time_elapsed = time.time() - since print('Training complete in {:.0f}m {:.0f}s'.format( time_elapsed // 60, time_elapsed % 60)) print('Best val Acc: {:4f}'.format(best_acc)) # load best model weights model.load_state_dict(best_model_wts) return model 可视化模型预测 泛型函数来显示一些图像预测 def visualize_model(model, num_images=6): was_training = model.training model.eval() images_so_far = 0 fig = plt.figure() with torch.no_grad(): for i, (inputs, labels) in enumerate(dataloaders['val']): inputs = inputs.to(device) labels = labels.to(device) outputs = model(inputs) _, preds = torch.max(outputs, 1) for j in range(inputs.size()[0]): images_so_far += 1 ax = plt.subplot(num_images//2, 2, images_so_far) ax.axis('off') ax.set_title('predicted: {}'.format(class_names[preds[j]])) imshow(inputs.cpu().data[j]) if images_so_far == num_images: model.train(mode=was_training) return model.train(mode=was_training) 微调修道院 加载一个预训练的模型和复位最终完全连接层。 model_ft = models.resnet18(pretrained=True) num_ftrs = model_ft.fc.in_features # Here the size of each output sample is set to 2. # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)). model_ft.fc = nn.Linear(num_ftrs, 2) model_ft = model_ft.to(device) criterion = nn.CrossEntropyLoss() # Observe that all parameters are being optimized optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9) # Decay LR by a factor of 0.1 every 7 epochs exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) 火车和评价 它应该承担CPU周围15-25分钟。在GPU的是，它需要不到一分钟。 model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25) 日期： Epoch 0/24 ---------- train Loss: 0.6751 Acc: 0.7049 val Loss: 0.1834 Acc: 0.9346 Epoch 1/24 ---------- train Loss: 0.5892 Acc: 0.7746 val Loss: 1.0048 Acc: 0.6667 Epoch 2/24 ---------- train Loss: 0.6568 Acc: 0.7459 val Loss: 0.6047 Acc: 0.8366 Epoch 3/24 ---------- train Loss: 0.4196 Acc: 0.8320 val Loss: 0.4388 Acc: 0.8562 Epoch 4/24 ---------- train Loss: 0.5883 Acc: 0.8033 val Loss: 0.4013 Acc: 0.8889 Epoch 5/24 ---------- train Loss: 0.6684 Acc: 0.7705 val Loss: 0.2666 Acc: 0.9412 Epoch 6/24 ---------- train Loss: 0.5308 Acc: 0.7787 val Loss: 0.4803 Acc: 0.8693 Epoch 7/24 ---------- train Loss: 0.3464 Acc: 0.8566 val Loss: 0.2385 Acc: 0.8954 Epoch 8/24 ---------- train Loss: 0.4586 Acc: 0.7910 val Loss: 0.2064 Acc: 0.9020 Epoch 9/24 ---------- train Loss: 0.3438 Acc: 0.8402 val Loss: 0.2336 Acc: 0.9020 Epoch 10/24 ---------- train Loss: 0.2405 Acc: 0.9016 val Loss: 0.1866 Acc: 0.9346 Epoch 11/24 ---------- train Loss: 0.2335 Acc: 0.8852 val Loss: 0.2152 Acc: 0.9216 Epoch 12/24 ---------- train Loss: 0.3441 Acc: 0.8402 val Loss: 0.2298 Acc: 0.9020 Epoch 13/24 ---------- train Loss: 0.2513 Acc: 0.9098 val Loss: 0.2204 Acc: 0.9020 Epoch 14/24 ---------- train Loss: 0.2745 Acc: 0.8934 val Loss: 0.2439 Acc: 0.8889 Epoch 15/24 ---------- train Loss: 0.2978 Acc: 0.8607 val Loss: 0.2817 Acc: 0.8497 Epoch 16/24 ---------- train Loss: 0.2560 Acc: 0.8975 val Loss: 0.1933 Acc: 0.9281 Epoch 17/24 ---------- train Loss: 0.2326 Acc: 0.9098 val Loss: 0.2176 Acc: 0.9085 Epoch 18/24 ---------- train Loss: 0.2274 Acc: 0.9016 val Loss: 0.2084 Acc: 0.9346 Epoch 19/24 ---------- train Loss: 0.3091 Acc: 0.8689 val Loss: 0.2270 Acc: 0.9150 Epoch 20/24 ---------- train Loss: 0.2540 Acc: 0.8975 val Loss: 0.1957 Acc: 0.9216 Epoch 21/24 ---------- train Loss: 0.3203 Acc: 0.8648 val Loss: 0.1969 Acc: 0.9216 Epoch 22/24 ---------- train Loss: 0.3048 Acc: 0.8443 val Loss: 0.1981 Acc: 0.9346 Epoch 23/24 ---------- train Loss: 0.2526 Acc: 0.9016 val Loss: 0.2415 Acc: 0.8889 Epoch 24/24 ---------- train Loss: 0.3041 Acc: 0.8689 val Loss: 0.1894 Acc: 0.9346 Training complete in 1m 7s Best val Acc: 0.941176 visualize_model(model_ft) ConvNet为固定特征提取 在这里，我们需要冻结所有网络，除了最后一层。我们需要设置requires_grad == 假冻结参数，使梯度不计算向后（）。 您可以将文档此处在阅读更多关于这一点。 model_conv = torchvision.models.resnet18(pretrained=True) for param in model_conv.parameters(): param.requires_grad = False # Parameters of newly constructed modules have requires_grad=True by default num_ftrs = model_conv.fc.in_features model_conv.fc = nn.Linear(num_ftrs, 2) model_conv = model_conv.to(device) criterion = nn.CrossEntropyLoss() # Observe that only parameters of final layer are being optimized as # opposed to before. optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9) # Decay LR by a factor of 0.1 every 7 epochs exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1) 火车和评价 在CPU这将需要大约一半的时间比以前的情况。这是预期的梯度不需要计算对于大多数网络。然而，前确实需要进行计算。 model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=25) Out: Epoch 0/24 ---------- train Loss: 0.6073 Acc: 0.6598 val Loss: 0.2511 Acc: 0.8954 Epoch 1/24 ---------- train Loss: 0.5457 Acc: 0.7459 val Loss: 0.5169 Acc: 0.7647 Epoch 2/24 ---------- train Loss: 0.4023 Acc: 0.8320 val Loss: 0.2361 Acc: 0.9150 Epoch 3/24 ---------- train Loss: 0.5150 Acc: 0.7869 val Loss: 0.5423 Acc: 0.8039 Epoch 4/24 ---------- train Loss: 0.4142 Acc: 0.8115 val Loss: 0.2257 Acc: 0.9216 Epoch 5/24 ---------- train Loss: 0.6364 Acc: 0.7418 val Loss: 0.3133 Acc: 0.8889 Epoch 6/24 ---------- train Loss: 0.5543 Acc: 0.7664 val Loss: 0.1959 Acc: 0.9412 Epoch 7/24 ---------- train Loss: 0.3552 Acc: 0.8443 val Loss: 0.2013 Acc: 0.9477 Epoch 8/24 ---------- train Loss: 0.3538 Acc: 0.8525 val Loss: 0.1825 Acc: 0.9542 Epoch 9/24 ---------- train Loss: 0.3954 Acc: 0.8402 val Loss: 0.1959 Acc: 0.9477 Epoch 10/24 ---------- train Loss: 0.3615 Acc: 0.8443 val Loss: 0.1779 Acc: 0.9542 Epoch 11/24 ---------- train Loss: 0.3951 Acc: 0.8320 val Loss: 0.1730 Acc: 0.9542 Epoch 12/24 ---------- train Loss: 0.4111 Acc: 0.8156 val Loss: 0.2573 Acc: 0.9150 Epoch 13/24 ---------- train Loss: 0.3073 Acc: 0.8525 val Loss: 0.1901 Acc: 0.9477 Epoch 14/24 ---------- train Loss: 0.3288 Acc: 0.8279 val Loss: 0.2114 Acc: 0.9346 Epoch 15/24 ---------- train Loss: 0.3472 Acc: 0.8525 val Loss: 0.1989 Acc: 0.9412 Epoch 16/24 ---------- train Loss: 0.3309 Acc: 0.8689 val Loss: 0.1757 Acc: 0.9412 Epoch 17/24 ---------- train Loss: 0.3963 Acc: 0.8197 val Loss: 0.1881 Acc: 0.9608 Epoch 18/24 ---------- train Loss: 0.3332 Acc: 0.8484 val Loss: 0.2175 Acc: 0.9412 Epoch 19/24 ---------- train Loss: 0.3419 Acc: 0.8320 val Loss: 0.1932 Acc: 0.9412 Epoch 20/24 ---------- train Loss: 0.3471 Acc: 0.8689 val Loss: 0.1851 Acc: 0.9477 Epoch 21/24 ---------- train Loss: 0.2843 Acc: 0.8811 val Loss: 0.1772 Acc: 0.9477 Epoch 22/24 ---------- train Loss: 0.4024 Acc: 0.8402 val Loss: 0.1818 Acc: 0.9542 Epoch 23/24 ---------- train Loss: 0.2409 Acc: 0.8975 val Loss: 0.2211 Acc: 0.9346 Epoch 24/24 ---------- train Loss: 0.3838 Acc: 0.8238 val Loss: 0.1918 Acc: 0.9412 Training complete in 0m 34s Best val Acc: 0.960784 visualize_model(model_conv) plt.ioff() plt.show() 脚本的总运行时间： （1分钟53.655秒） Download Python source code: transfer_learning_tutorial.py Download Jupyter notebook: transfer_learning_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 迁移学习教程 负载数据 可视化几个图像 训练模型 可视化模型预测 微调的convnet 火车和评价 ConvNet为固定特征提取 火车和评价 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/deploy_seq2seq_hybrid_frontend_tutorial.html":{"url":"beginner/deploy_seq2seq_hybrid_frontend_tutorial.html","title":"部署与TorchScript一个Seq2Seq模型","keywords":"","body":"部署具有TorchScript一个Seq2Seq模型 作者： [马修Inkawhich HTG3 1.2，本教程进行了更新与PyTorch 1.2工作 本教程将通过使用TorchScript API转换序列到序列模型TorchScript的过程中走。我们将转换的模型是从聊天机器人教程的聊天机器人模型。您可以把这个教程作为“第2部分”的聊天机器人教程和部署自己的预训练模型，或者你可以用这个文件开始，用我们举办的预训练模式。在后一种情况下，你可以参考的有关数据预处理，模型理论和定义，以及模型训练细节原来的聊天机器人教程。 什么是TorchScript？ 在深基础的学习项目的研究和开发阶段，有利的是，与 渴望 ，势在必行接口一样PyTorch的互动。这给用户写熟悉，地道的Python，允许使用Python的数据结构，控制流操作，打印报表，和调试事业的能力。虽然渴望接口是用于研究和实验应用的有利工具，当谈到时间部署在生产环境中的模型，有 图 基于模型的表示是非常有利的。一个延迟图表示允许优化，如乱序执行，并且目标高度优化的硬件架构的能力。此外，基于图的表示使得框架无关模型出口。 PyTorch提供了一种用于逐步转换渴望模式代码到TorchScript，Python中的静态分析的和优化的子集Torch 用来从Python运行时独立地表示深学习方案的机制。 用于转换渴望模式PyTorch方案纳入TorchScript的API的torch.jit模块中被发现。该模块具有用于急切模式模型转换为TorchScript图表示两个核心模式： 追踪 和 脚本 。的torch.jit.trace函数采用一个模块或功能和一组示例输入。然后，它贯穿功能或同时跟踪所遇到的计算步骤模块输入例子，并输出执行跟踪操作的基于图形的功能。 跟踪 是非常适合直接的模块和功能不涉及数据依赖控制流程，如标准的卷积神经网络。然而，如果与数据相关如果语句和循环被追踪，仅沿着由例如输入采取的路线执行调用的操作将被记录的功能。换句话说，控制流程本身不捕获。转换模块和包含的数据相关的控制流的功能，提供了一种 脚本 机制。的torch.jit.script功能/装饰需要一个模块或功能，并且不要求例如输入。脚本然后显式转换模块或功能码TorchScript，包括所有的控制流。使用脚本一个需要注意的是它只支持Python的一个子集，所以你可能需要重写代码，使其与TorchScript语法兼容。 要充分理解与支持的功能的所有细节，请参见[ TorchScript语言参考HTG1。为了提供最大的灵活性，也可以混合使用跟踪和脚本模式一起代表你的整个程序，并且这些技术可以逐步应用。 致谢 本教程的灵感来自以下来源： 袁阿贵吴pytorch - 聊天机器人实现： https://github.com/ywk991112/pytorch-chatbot 肖恩·罗伯逊的实际-pytorch seq2seq翻译例如： https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation FloydHub的康奈尔电影语料库预处理代码： https://github.com/floydhub/textutil-preprocess-cornell-movie-corpus 准备环境 首先，我们将导入所需的模块，并设置一些常量。如果您在使用自己的模型规划，是确保MAX_LENGTH 常数设置正确[HTG1。作为提醒，该恒定的训练和最大长度输出，该模型能够产生的过程中定义的最大允许句子长度。 from __future__ import absolute_import from __future__ import division from __future__ import print_function from __future__ import unicode_literals import torch import torch.nn as nn import torch.nn.functional as F import re import os import unicodedata import numpy as np device = torch.device(\"cpu\") MAX_LENGTH = 10 # Maximum sentence length # Default word tokens PAD_token = 0 # Used for padding short sentences SOS_token = 1 # Start-of-sentence token EOS_token = 2 # End-of-sentence token 模型概述 如所提到的，我们使用的模型是序列到序列（seq2seq）模型。这种类型的模型中的情况下使用时，我们的输入是一个可变长度的序列，而我们的输出也不一定是输入的一一对一映射的可变长度的序列。甲seq2seq模型由该协同工作，二期复发神经网络（RNNs）组成： 编码 和a 解码器 。 图像源： https://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_intro/ 编码器 通过输入句子一个令牌（例如字）编码器RNN迭代的时间，在每个时间步骤输出一个“输出”向量和“隐藏状态”载体。然后，将隐藏状态矢量被传递到下一个时间步长，而输出矢量被记录。该编码器将其转换看见在序列中的每个点为一组在高维空间中的点，其中解码器将使用以产生用于给定任务一个有意义的输出的情况下。 解码器 解码器RNN在令牌通过令牌方式产生响应句。它采用了编码器的上下文载体，以及内部隐藏的状态，以产生序列中的下一个单词。直到它输出 EOS_token ，表示句末它将继续产生字。我们使用注意机制在我们的解码器，以帮助它“注意”到输入的某些部分产生输出的时候。对于我们的模型，我们实现陈德良等人。 的‘全球关注’模块，并把它作为我们的解码模式的子模块。 数据处理 虽然我们的模型概念上的令牌序列的处理，在现实中，他们对付像所有的机器学习模型做数字。在这种情况下，模型中的词汇，这是训练之前建立的每一个字，被映射到一个整数索引。我们使用的Voc对象包含的映射从字索引，以及在所述词汇字的总数。我们运行模型之前，我们将在稍后加载对象。 此外，为了让我们能够运行的评估，我们必须为我们处理字符串输入的工具。的normalizeString函数的所有字符转换的字符串为小写，并删除所有非字母字符。的indexesFromSentence函数接受词的句子，并返回字索引的对应序列。 class Voc: def __init__(self, name): self.name = name self.trimmed = False self.word2index = {} self.word2count = {} self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"} self.num_words = 3 # Count SOS, EOS, PAD def addSentence(self, sentence): for word in sentence.split(' '): self.addWord(word) def addWord(self, word): if word not in self.word2index: self.word2index[word] = self.num_words self.word2count[word] = 1 self.index2word[self.num_words] = word self.num_words += 1 else: self.word2count[word] += 1 # Remove words below a certain count threshold def trim(self, min_count): if self.trimmed: return self.trimmed = True keep_words = [] for k, v in self.word2count.items(): if v >= min_count: keep_words.append(k) print('keep_words {} / {} = {:.4f}'.format( len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index) )) # Reinitialize dictionaries self.word2index = {} self.word2count = {} self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"} self.num_words = 3 # Count default tokens for word in keep_words: self.addWord(word) # Lowercase and remove non-letter characters def normalizeString(s): s = s.lower() s = re.sub(r\"([.!?])\", r\" \\1\", s) s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s) return s # Takes string sentence, returns sentence of word indexes def indexesFromSentence(voc, sentence): return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token] 定义编码器 我们以实现我们的编码器的RNN的torch.nn.GRU模块，我们一次仅进一批句子（字嵌入物的载体）和它在内部遍历句子一个令牌计算隐藏状态。我们初始化这个模块是双向的，这意味着我们有两个独立的灰鹤：一个按照时间顺序的序列进行迭代，并以相反的顺序另一种迭代。我们最终退掉这两丹顶鹤输出的总和。由于我们的模型是用配料的训练，我们的EncoderRNN模型转发函数需要填充输入批次。批量可变长度的句子，我们允许最多 MAX_LENGTH 在一个句子中的令牌，并在一批具有比 减去所有句子MAX_LENGTH 令牌在我们的专用年底补齐 PAD_token 令牌。要使用与PyTorch RNN模块填充批次，我们必须缠上torch.nn.utils.rnn.pack_padded_sequence和torch.nn直传通话。 utils.rnn.pad_packed_sequence数据转换。请注意，向前功能还需要一个input_lengths列表，其中包含的每个句子的在批处理的长度。此输入由torch.nn.utils.rnn.pack_padded_sequence功能时的填充使用。 TorchScript备注： 由于编码器的转发功能不包含任何数据有关的控制流程，我们将使用 追踪 将其转换为脚本模式。当跟踪模块，我们可以把模块定义原样。我们运行评估之前，我们将初始化所有车型对这一文件的末尾。 class EncoderRNN(nn.Module): def __init__(self, hidden_size, embedding, n_layers=1, dropout=0): super(EncoderRNN, self).__init__() self.n_layers = n_layers self.hidden_size = hidden_size self.embedding = embedding # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size' # because our input size is a word embedding with number of features == hidden_size self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout), bidirectional=True) def forward(self, input_seq, input_lengths, hidden=None): # type: (Tensor, Tensor, Optional[Tensor]) -> Tuple[Tensor, Tensor] # Convert word indexes to embeddings embedded = self.embedding(input_seq) # Pack padded batch of sequences for RNN module packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths) # Forward pass through GRU outputs, hidden = self.gru(packed, hidden) # Unpack padding outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs) # Sum bidirectional GRU outputs outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Return output and final hidden state return outputs, hidden 定义解码器的注意模块 接下来，我们将定义我们的注意力模块（经办人）。请注意，此模块将被用来作为我们的解码器模型的子模块。陈德良等人。综合考虑各种“得分函数”，其取当前解码器输出RNN和整个编码器的输出，并返回注意“能量”。这种关注能量张量的大小与编码器输出相同，并且两个最终相乘，产生一个加权的张量，其最大的值表示查询句子的最重要的部分在解码的特定时间步长。 # Luong attention layer class Attn(nn.Module): def __init__(self, method, hidden_size): super(Attn, self).__init__() self.method = method if self.method not in ['dot', 'general', 'concat']: raise ValueError(self.method, \"is not an appropriate attention method.\") self.hidden_size = hidden_size if self.method == 'general': self.attn = nn.Linear(self.hidden_size, hidden_size) elif self.method == 'concat': self.attn = nn.Linear(self.hidden_size * 2, hidden_size) self.v = nn.Parameter(torch.FloatTensor(hidden_size)) def dot_score(self, hidden, encoder_output): return torch.sum(hidden * encoder_output, dim=2) def general_score(self, hidden, encoder_output): energy = self.attn(encoder_output) return torch.sum(hidden * energy, dim=2) def concat_score(self, hidden, encoder_output): energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh() return torch.sum(self.v * energy, dim=2) def forward(self, hidden, encoder_outputs): # Calculate the attention weights (energies) based on the given method if self.method == 'general': attn_energies = self.general_score(hidden, encoder_outputs) elif self.method == 'concat': attn_energies = self.concat_score(hidden, encoder_outputs) elif self.method == 'dot': attn_energies = self.dot_score(hidden, encoder_outputs) # Transpose max_length and batch_size dimensions attn_energies = attn_energies.t() # Return the softmax normalized probability scores (with added dimension) return F.softmax(attn_energies, dim=1).unsqueeze(1) 定义解码器 类似于EncoderRNN，我们用我们的解码器的RNN的torch.nn.GRU模块。然而这一次，我们使用了单向GRU。需要注意的是不同的编码器，我们将饲料解码器RNN一个词在一个时间是很重要的。我们通过获取当前单词的嵌入和应用降启动。接下来，我们转发的嵌入和最后的隐藏状态的GRU和获取当前GRU输出和隐藏状态。然后，我们用我们的经办人模块作为一个层，以获得关注的权重，这是我们通过编码器的输出，以获得我们的出席编码器输出繁殖。我们使用这个出席编码器输出作为我们的背景张量，它代表的加权和指出哪些编码器的输出的部分要注意。从这里，我们使用线性层和SOFTMAX正常化选择在输出序列中的下一个单词。 # TorchScript Notes: # ~~~~~~~~~~~~~~~~~~~~~~ # # Similarly to the ``EncoderRNN``, this module does not contain any # data-dependent control flow. Therefore, we can once again use # **tracing** to convert this model to TorchScript after it # is initialized and its parameters are loaded. # class LuongAttnDecoderRNN(nn.Module): def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1): super(LuongAttnDecoderRNN, self).__init__() # Keep for reference self.attn_model = attn_model self.hidden_size = hidden_size self.output_size = output_size self.n_layers = n_layers self.dropout = dropout # Define layers self.embedding = embedding self.embedding_dropout = nn.Dropout(dropout) self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout)) self.concat = nn.Linear(hidden_size * 2, hidden_size) self.out = nn.Linear(hidden_size, output_size) self.attn = Attn(attn_model, hidden_size) def forward(self, input_step, last_hidden, encoder_outputs): # Note: we run this one step (word) at a time # Get embedding of current input word embedded = self.embedding(input_step) embedded = self.embedding_dropout(embedded) # Forward through unidirectional GRU rnn_output, hidden = self.gru(embedded, last_hidden) # Calculate attention weights from the current GRU output attn_weights = self.attn(rnn_output, encoder_outputs) # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # Concatenate weighted context vector and GRU output using Luong eq. 5 rnn_output = rnn_output.squeeze(0) context = context.squeeze(1) concat_input = torch.cat((rnn_output, context), 1) concat_output = torch.tanh(self.concat(concat_input)) # Predict next word using Luong eq. 6 output = self.out(concat_output) output = F.softmax(output, dim=1) # Return output and final hidden state return output, hidden 定义评价 贪婪搜索解码器 正如在聊天机器人教程中，我们使用了GreedySearchDecoder模块以便于实际解码处理。该模块具有经训练的编码器和解码器模型作为属性，并驱动编码输入句子（字索引的矢量），并且迭代一次进行解码的输出响应序列中的一个字（字索引）的过程。 编码输入序列是直接的：简单地转发在整个序列张量及其相应的长度向量到编码。要注意，此模块一次仅与一个输入序列涉及这一点很重要， NOT 序列的批次。因此，当恒定 1 用于声明张量的尺寸，这对应于1批量大小为解码给定解码器的输出，必须反复地向前运行通过我们的解码器模型，其输出SOFTMAX分数对应于每个字是所述解码序列以正确的下一个单词的概率。我们初始化decoder_input一种含有 SOS_token 的张量。每个后通过解码器，我们 贪婪 具有最高SOFTMAX可能性的单词追加到decoded_words名单。我们也用这个词作为decoder_input为下一次迭代。解码过程终止于：如果所述decoded_words列表已经达到的 MAX_LENGTH 的长度，或者如果所预测的单词是 EOS_token 。 TorchScript备注： 的向前该模块的方法，在一个解码输出序列中的一个字时涉及迭代过的 \\（[0，最大值\\ _length）的范围\\）时间。正因为如此，我们应该用 脚本 这个模块转换为TorchScript。不像我们的编码器和解码器模型，我们可以追踪，我们必须为了没有错误初始化对象到GreedySearchDecoder模块的一些必要的修改。换句话说，我们必须确保我们的模块附着在TorchScript机制的规则，不使用的Python的子集TorchScript包含之外的任何语言功能。 为了获得可能需要一些操作的想法，我们将在从聊天机器人教程GreedySearchDecoder执行和实施，我们在下面的电池使用之间的差异列表。请注意，行以红色突出显示从原来实行删除，线条突出显示为绿色线是新的。 变更： 新增decoder_n_layers在构造函数的参数 这种变化从这样一个事实，我们通过给此模块的编码器和解码器模型将是TracedModule（未模块 [HTG7子]）。因此，我们不能与decoder.n_layers访问层的解码器的数量。相反，我们考虑这一点，并在模块施工过程中通过此值。 保存好新的属性为常数 在最初的实现，我们是自由的，我们的GreedySearchDecoder的转发方法使用变量从周围的（全球）范围。然而，现在我们正在使用的脚本，我们没有这样的自由，与脚本的假设是，我们不一定能坚持到Python对象，出口时尤其如此。一个简单的解决方法是将这些值从全球范围的属性在构造函数中的模块存储，并把它们添加到一个名为一个特殊列表__constants__，使他们可以使用在向前方法构建图时作为文字值。这种用法的一个例子是在新行19，在那里，而不是使用装置和SOS_token全局值，我们使用我们的恒定属性self._device和self._SOS_token。 执行类型的向前方法参数 默认情况下，在TorchScript函数的所有参数都假定为张量。如果我们需要通过不同类型的参数，我们可以使用函数类型注释如 PEP 3107 引入。此外，也可以使用声明MyPy风格类型注释不同类型的参数（见 DOC ）。 的更改初始化decoder_input 在最初的实现，我们初始化我们的decoder_input与torch.LongTensor（[SOS_token]）张量。脚本时，我们是不允许的字面这样初始化张量。相反，我们可以初始化我们有一个明确的Torch 函数张量，如torch.ones [HTG11。在这种情况下，我们可以很容易地通过由存储在我们的SOS_token值乘以1复制标量decoder_input张量的常数self._SOS_token。 class GreedySearchDecoder(nn.Module): def __init__(self, encoder, decoder, decoder_n_layers): super(GreedySearchDecoder, self).__init__() self.encoder = encoder self.decoder = decoder self._device = device self._SOS_token = SOS_token self._decoder_n_layers = decoder_n_layers __constants__ = ['_device', '_SOS_token', '_decoder_n_layers'] def forward(self, input_seq : torch.Tensor, input_length : torch.Tensor, max_length : int): # Forward input through encoder model encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length) # Prepare encoder's final hidden layer to be first hidden input to the decoder decoder_hidden = encoder_hidden[:self._decoder_n_layers] # Initialize decoder input with SOS_token decoder_input = torch.ones(1, 1, device=self._device, dtype=torch.long) * self._SOS_token # Initialize tensors to append decoded words to all_tokens = torch.zeros([0], device=self._device, dtype=torch.long) all_scores = torch.zeros([0], device=self._device) # Iteratively decode one word token at a time for _ in range(max_length): # Forward pass through decoder decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs) # Obtain most likely word token and its softmax score decoder_scores, decoder_input = torch.max(decoder_output, dim=1) # Record token and score all_tokens = torch.cat((all_tokens, decoder_input), dim=0) all_scores = torch.cat((all_scores, decoder_scores), dim=0) # Prepare current token to be next decoder input (add a dimension) decoder_input = torch.unsqueeze(decoder_input, 0) # Return collections of word tokens and scores return all_tokens, all_scores 评价输入 接下来，我们定义用于评价输入某些功能。的评价函数将归一化的字符串的句子，它处理到其对应的字索引的张量（以1批量大小），并通过这个张量的GreedySearchDecoder实例调用搜索者来处理的编码/解码处理。搜索器返回输出字索引向量和对应于SOFTMAX分数为每个解码字令牌的得分张量。最后的步骤是使用voc.index2word到每个字索引转换回它的字符串表示。 我们还定义了用于评价输入句子两种功能。的evaluateInput函数提示的输入的用户，并且评估它。它会继续下去，直到用户输入“Q”或“退出”，要求另一输入。 的evaluateExample功能简单地采用一个字符串输入句子作为一个参数，它归一化，计算它，并打印的响应。 def evaluate(searcher, voc, sentence, max_length=MAX_LENGTH): ### Format input sentence as a batch # words -> indexes indexes_batch = [indexesFromSentence(voc, sentence)] # Create lengths tensor lengths = torch.tensor([len(indexes) for indexes in indexes_batch]) # Transpose dimensions of batch to match models' expectations input_batch = torch.LongTensor(indexes_batch).transpose(0, 1) # Use appropriate device input_batch = input_batch.to(device) lengths = lengths.to(device) # Decode sentence with searcher tokens, scores = searcher(input_batch, lengths, max_length) # indexes -> words decoded_words = [voc.index2word[token.item()] for token in tokens] return decoded_words # Evaluate inputs from user input (stdin) def evaluateInput(searcher, voc): input_sentence = '' while(1): try: # Get input sentence input_sentence = input('> ') # Check if it is quit case if input_sentence == 'q' or input_sentence == 'quit': break # Normalize sentence input_sentence = normalizeString(input_sentence) # Evaluate sentence output_words = evaluate(searcher, voc, input_sentence) # Format and print response sentence output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')] print('Bot:', ' '.join(output_words)) except KeyError: print(\"Error: Encountered unknown word.\") # Normalize input sentence and call evaluate() def evaluateExample(sentence, searcher, voc): print(\"> \" + sentence) # Normalize sentence input_sentence = normalizeString(sentence) # Evaluate sentence output_words = evaluate(searcher, voc, input_sentence) output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')] print('Bot:', ' '.join(output_words)) 加载预训练参数 好了，它的时间来加载我们的模型！ 使用托管模式 要加载托管模式： 下载模型[此处HTG1。 在loadFilename变量设置为路径下载的检查点文件。 离开检查点 = torch.load（loadFilename）线路未注释，因为托管模型上CPU训练。 使用您自己的模型 加载您自己的预先训练模式： 在loadFilename变量设置为路径，要加载检查点文件。请注意，如果您是用于保存从聊天机器人教程模型中的约定，这可能涉及更改MODEL_NAME，encoder_n_layers，decoder_n_layers，hidden_​​size和checkpoint_iter（因为这些值在模型中使用路径）。 如果你培养了CPU的型号，请确保您正在使用检查点 = torch.load（loadFilename）HTG6] [HTG7打开检查站]线。如果你训练了GPU的模式，在CPU上运行本教程中，取消注释检查点 = torch.load（loadFilename， map_location = torch.device（ 'CPU'）） 线。 TorchScript备注： 请注意，我们初始化和负载参数到我们的编码器和解码器模组如常。如果您使用的跟踪模式（ torch.jit.trace ）为你的模型的某些部分，则必须调用。要（设备）设置模式和设备选项.eval（）来设置漏失层，以测试模式 之前 跟踪模型。 TracedModule 对象不继承至或EVAL的方法。由于在本教程中，我们仅使用脚本，而不是跟踪，我们只需要做到这一点，我们之前做评价（这是与我们在急切模式通常做的）。 save_dir = os.path.join(\"data\", \"save\") corpus_name = \"cornell movie-dialogs corpus\" # Configure models model_name = 'cb_model' attn_model = 'dot' #attn_model = 'general' #attn_model = 'concat' hidden_size = 500 encoder_n_layers = 2 decoder_n_layers = 2 dropout = 0.1 batch_size = 64 # If you're loading your own model # Set checkpoint to load from checkpoint_iter = 4000 # loadFilename = os.path.join(save_dir, model_name, corpus_name, # '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size), # '{}_checkpoint.tar'.format(checkpoint_iter)) # If you're loading the hosted model loadFilename = 'data/4000_checkpoint.tar' # Load model # Force CPU device options (to match tensors in this tutorial) checkpoint = torch.load(loadFilename, map_location=torch.device('cpu')) encoder_sd = checkpoint['en'] decoder_sd = checkpoint['de'] encoder_optimizer_sd = checkpoint['en_opt'] decoder_optimizer_sd = checkpoint['de_opt'] embedding_sd = checkpoint['embedding'] voc = Voc(corpus_name) voc.__dict__ = checkpoint['voc_dict'] print('Building encoder and decoder ...') # Initialize word embeddings embedding = nn.Embedding(voc.num_words, hidden_size) embedding.load_state_dict(embedding_sd) # Initialize encoder & decoder models encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout) decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout) # Load trained model params encoder.load_state_dict(encoder_sd) decoder.load_state_dict(decoder_sd) # Use appropriate device encoder = encoder.to(device) decoder = decoder.to(device) # Set dropout layers to eval mode encoder.eval() decoder.eval() print('Models built and ready to go!') 日期： Building encoder and decoder ... Models built and ready to go! 转换模型TorchScript 编码器 正如前面提到的，到编码器模型TorchScript转换，我们使用 脚本[HTG1。编码器模型接受一个输入序列和相应的长度张量。因此，我们创建一个示例输入序列张量test_seq，这是适当的尺寸（MAX_LENGTH，1），包含在适当范围内 \\（[0，VOC号码。 NUM \\ _words）\\），并且是适当的类型（int64类型）的。我们还创建了一个test_seq_length标量，它真实地包含对应于有多少话是在test_seq的值。下一个步骤是使用torch.jit.trace函数来追踪模型。请注意，我们传递的第一个参数是我们要跟踪的模块，第二是参数模块的转发方法的元组。 解码器 我们进行追踪解码器，因为我们没有编码器相同的过程。请注意，我们称之为前一组随机输入到traced_encoder得到我们需要的解码器的输出。这不是必须的，因为我们也可以简单地制作正确的形状，类型和值范围的张量。因为在我们的例子中，我们没有对张量的值，任何约束，因为我们没有可能在故障超出范围的输入的任何操作此方法是可行的。 GreedySearchDecoder 回想一下，我们照本宣科我们的搜索模块由于数据相关控制流的存在。在脚本的情况下，我们做必要的语言更改以确保落实与TorchScript规定。我们初始化脚本搜索，我们将初始化一个未脚本变种同样的方式。 ### Compile the whole greedy search model to TorchScript model # Create artificial inputs test_seq = torch.LongTensor(MAX_LENGTH, 1).random_(0, voc.num_words).to(device) test_seq_length = torch.LongTensor([test_seq.size()[0]]).to(device) # Trace the model traced_encoder = torch.jit.trace(encoder, (test_seq, test_seq_length)) ### Convert decoder model # Create and generate artificial inputs test_encoder_outputs, test_encoder_hidden = traced_encoder(test_seq, test_seq_length) test_decoder_hidden = test_encoder_hidden[:decoder.n_layers] test_decoder_input = torch.LongTensor(1, 1).random_(0, voc.num_words) # Trace the model traced_decoder = torch.jit.trace(decoder, (test_decoder_input, test_decoder_hidden, test_encoder_outputs)) ### Initialize searcher module by wrapping ``torch.jit.script``call scripted_searcher = torch.jit.script(GreedySearchDecoder(traced_encoder, traced_decoder, decoder.n_layers)) 打印图形 现在，我们的模型在TorchScript形式，我们可以打印的每一个曲线图，以确保我们适当地捕获的计算图表。由于TorchScript让我们递归编译整个模型的层次结构和内联编码器和解码器图到一个图，我们只需要打印 scripted_searcher 图 print('scripted_searcher graph:\\n', scripted_searcher.graph) Out: scripted_searcher graph: graph(%self : ClassType, %input_seq.1 : Tensor, %input_length.1 : Tensor, %max_length.1 : int): %23 : bool? = prim::Constant() %21 : int? = prim::Constant() %161 : int = prim::Constant[value=9223372036854775807](), scope: EncoderRNN # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:310:0 %156 : float = prim::Constant[value=0](), scope: EncoderRNN # /opt/conda/lib/python3.6/site-packages/torch/nn/utils/rnn.py:322:0 %146 : float = prim::Constant[value=0.1](), scope: EncoderRNN/GRU[gru] # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:682:0 %145 : int = prim::Constant[value=2](), scope: EncoderRNN/GRU[gru] # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:682:0 %144 : bool = prim::Constant[value=1](), scope: EncoderRNN/GRU[gru] # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:682:0 %138 : int = prim::Constant[value=6](), scope: EncoderRNN/GRU[gru] # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:691:0 %136 : int = prim::Constant[value=500](), scope: EncoderRNN/GRU[gru] # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:691:0 %127 : int = prim::Constant[value=4](), scope: EncoderRNN # /opt/conda/lib/python3.6/site-packages/torch/nn/utils/rnn.py:265:0 %126 : Device = prim::Constant[value=\"cpu\"](), scope: EncoderRNN # /opt/conda/lib/python3.6/site-packages/torch/nn/utils/rnn.py:265:0 %123 : bool = prim::Constant[value=0](), scope: EncoderRNN/Embedding[embedding] # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1467:0 %122 : int = prim::Constant[value=-1](), scope: EncoderRNN/Embedding[embedding] # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1467:0 %12 : int = prim::Constant[value=0]() # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:560:26 %14 : int = prim::Constant[value=1]() # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:560:26 %4 : ClassType = prim::GetAttr[name=\"encoder\"](%self) %103 : ClassType = prim::GetAttr[name=\"embedding\"](%4) %weight.3 : Tensor = prim::GetAttr[name=\"weight\"](%103) %105 : ClassType = prim::GetAttr[name=\"gru\"](%4) %106 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%105) %107 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%105) %108 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%105) %109 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%105) %110 : Tensor = prim::GetAttr[name=\"weight_ih_l0_reverse\"](%105) %111 : Tensor = prim::GetAttr[name=\"weight_hh_l0_reverse\"](%105) %112 : Tensor = prim::GetAttr[name=\"bias_ih_l0_reverse\"](%105) %113 : Tensor = prim::GetAttr[name=\"bias_hh_l0_reverse\"](%105) %114 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%105) %115 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%105) %116 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%105) %117 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%105) %118 : Tensor = prim::GetAttr[name=\"weight_ih_l1_reverse\"](%105) %119 : Tensor = prim::GetAttr[name=\"weight_hh_l1_reverse\"](%105) %120 : Tensor = prim::GetAttr[name=\"bias_ih_l1_reverse\"](%105) %121 : Tensor = prim::GetAttr[name=\"bias_hh_l1_reverse\"](%105) %input.7 : Float(10, 1, 500) = aten::embedding(%weight.3, %input_seq.1, %122, %123, %123), scope: EncoderRNN/Embedding[embedding] # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1467:0 %lengths : Long(1) = aten::to(%input_length.1, %126, %127, %123, %123), scope: EncoderRNN # /opt/conda/lib/python3.6/site-packages/torch/nn/utils/rnn.py:265:0 %input.1 : Float(10, 500), %batch_sizes : Long(10) = aten::_pack_padded_sequence(%input.7, %lengths, %123), scope: EncoderRNN # /opt/conda/lib/python3.6/site-packages/torch/nn/utils/rnn.py:275:0 %137 : int[] = prim::ListConstruct(%127, %14, %136), scope: EncoderRNN/GRU[gru] %hx : Float(4, 1, 500) = aten::zeros(%137, %138, %12, %126, %123), scope: EncoderRNN/GRU[gru] # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:691:0 %143 : Tensor[] = prim::ListConstruct(%106, %107, %108, %109, %110, %111, %112, %113, %114, %115, %116, %117, %118, %119, %120, %121), scope: EncoderRNN/GRU[gru] %149 : Float(10, 1000), %150 : Float(4, 1, 500) = aten::gru(%input.1, %batch_sizes, %hx, %143, %144, %145, %146, %123, %144), scope: EncoderRNN/GRU[gru] # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:682:0 %152 : int = aten::size(%batch_sizes, %12), scope: EncoderRNN # /opt/conda/lib/python3.6/site-packages/torch/nn/utils/rnn.py:313:0 %max_seq_length : Long() = prim::NumToTensor(%152), scope: EncoderRNN %154 : int = aten::Int(%max_seq_length), scope: EncoderRNN %outputs : Float(10, 1, 1000), %158 : Long(1) = aten::_pad_packed_sequence(%149, %batch_sizes, %123, %156, %154), scope: EncoderRNN # /opt/conda/lib/python3.6/site-packages/torch/nn/utils/rnn.py:322:0 %163 : Float(10, 1, 1000) = aten::slice(%outputs, %12, %12, %161, %14), scope: EncoderRNN # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:310:0 %168 : Float(10, 1, 1000) = aten::slice(%163, %14, %12, %161, %14), scope: EncoderRNN # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:310:0 %173 : Float(10, 1!, 500) = aten::slice(%168, %145, %12, %136, %14), scope: EncoderRNN # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:310:0 %178 : Float(10, 1, 1000) = aten::slice(%outputs, %12, %12, %161, %14), scope: EncoderRNN # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:310:0 %183 : Float(10, 1, 1000) = aten::slice(%178, %14, %12, %161, %14), scope: EncoderRNN # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:310:0 %188 : Float(10, 1!, 500) = aten::slice(%183, %145, %136, %161, %14), scope: EncoderRNN # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:310:0 %190 : Float(10, 1, 500) = aten::add(%173, %188, %14), scope: EncoderRNN # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:310:0 %decoder_hidden.1 : Tensor = aten::slice(%150, %12, %12, %145, %14) # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:560:26 %19 : int[] = prim::ListConstruct(%14, %14) %24 : Tensor = aten::ones(%19, %127, %21, %126, %23) # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:562:25 %decoder_input.1 : Tensor = aten::mul(%24, %14) # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:562:25 %27 : int[] = prim::ListConstruct(%12) %all_tokens.1 : Tensor = aten::zeros(%27, %127, %21, %126, %23) # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:564:22 %35 : int[] = prim::ListConstruct(%12) %all_scores.1 : Tensor = aten::zeros(%35, %21, %21, %126, %23) # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:565:22 %all_tokens : Tensor, %all_scores : Tensor, %decoder_hidden : Tensor, %decoder_input : Tensor = prim::Loop(%max_length.1, %144, %all_tokens.1, %all_scores.1, %decoder_hidden.1, %decoder_input.1) # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:567:9 block0(%48 : int, %all_tokens.6 : Tensor, %all_scores.6 : Tensor, %decoder_hidden.5 : Tensor, %decoder_input.9 : Tensor): %49 : ClassType = prim::GetAttr[name=\"decoder\"](%self) %192 : ClassType = prim::GetAttr[name=\"embedding\"](%49) %weight.1 : Tensor = prim::GetAttr[name=\"weight\"](%192) %194 : ClassType = prim::GetAttr[name=\"gru\"](%49) %195 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%194) %196 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%194) %197 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%194) %198 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%194) %199 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%194) %200 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%194) %201 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%194) %202 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%194) %203 : ClassType = prim::GetAttr[name=\"concat\"](%49) %weight.2 : Tensor = prim::GetAttr[name=\"weight\"](%203) %bias.1 : Tensor = prim::GetAttr[name=\"bias\"](%203) %206 : ClassType = prim::GetAttr[name=\"out\"](%49) %weight : Tensor = prim::GetAttr[name=\"weight\"](%206) %bias : Tensor = prim::GetAttr[name=\"bias\"](%206) %input.2 : Float(1, 1, 500) = aten::embedding(%weight.1, %decoder_input.9, %122, %123, %123), scope: LuongAttnDecoderRNN/Embedding[embedding] # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1467:0 %input.3 : Float(1, 1, 500) = aten::dropout(%input.2, %146, %123), scope: LuongAttnDecoderRNN/Dropout[embedding_dropout] # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:806:0 %216 : Tensor[] = prim::ListConstruct(%195, %196, %197, %198, %199, %200, %201, %202), scope: LuongAttnDecoderRNN/GRU[gru] %hidden : Float(1, 1, 500), %224 : Float(2, 1, 500) = aten::gru(%input.3, %decoder_hidden.5, %216, %144, %145, %146, %123, %123, %123), scope: LuongAttnDecoderRNN/GRU[gru] # /opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:679:0 %225 : Float(10, 1, 500) = aten::mul(%hidden, %190), scope: LuongAttnDecoderRNN/Attn[attn] # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:344:0 %227 : int[] = prim::ListConstruct(%145), scope: LuongAttnDecoderRNN/Attn[attn] %attn_energies : Float(10, 1) = aten::sum(%225, %227, %123, %21), scope: LuongAttnDecoderRNN/Attn[attn] # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:344:0 %input.4 : Float(1!, 10) = aten::t(%attn_energies), scope: LuongAttnDecoderRNN/Attn[attn] # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:364:0 %234 : Float(1, 10) = aten::softmax(%input.4, %14, %21), scope: LuongAttnDecoderRNN/Attn[attn] # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1230:0 %attn_weights : Float(1, 1, 10) = aten::unsqueeze(%234, %14), scope: LuongAttnDecoderRNN/Attn[attn] # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:367:0 %239 : Float(1!, 10, 500) = aten::transpose(%190, %12, %14), scope: LuongAttnDecoderRNN # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:428:0 %context.1 : Float(1, 1, 500) = aten::bmm(%attn_weights, %239), scope: LuongAttnDecoderRNN # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:428:0 %rnn_output : Float(1, 500) = aten::squeeze(%hidden, %12), scope: LuongAttnDecoderRNN # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:430:0 %context : Float(1, 500) = aten::squeeze(%context.1, %14), scope: LuongAttnDecoderRNN # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:431:0 %245 : Tensor[] = prim::ListConstruct(%rnn_output, %context), scope: LuongAttnDecoderRNN %input.5 : Float(1, 1000) = aten::cat(%245, %14), scope: LuongAttnDecoderRNN # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:432:0 %248 : Float(1000!, 500!) = aten::t(%weight.2), scope: LuongAttnDecoderRNN/Linear[concat] # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1369:0 %251 : Float(1, 500) = aten::addmm(%bias.1, %input.5, %248, %14, %14), scope: LuongAttnDecoderRNN/Linear[concat] # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1369:0 %input.6 : Float(1, 500) = aten::tanh(%251), scope: LuongAttnDecoderRNN # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:433:0 %253 : Float(500!, 7826!) = aten::t(%weight), scope: LuongAttnDecoderRNN/Linear[out] # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1369:0 %input : Float(1, 7826) = aten::addmm(%bias, %input.6, %253, %14, %14), scope: LuongAttnDecoderRNN/Linear[out] # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1369:0 %259 : Float(1, 7826) = aten::softmax(%input, %14, %21), scope: LuongAttnDecoderRNN # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1230:0 %decoder_scores.1 : Tensor, %decoder_input.3 : Tensor = aten::max(%259, %14, %123) # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:571:45 %66 : Tensor[] = prim::ListConstruct(%all_tokens.6, %decoder_input.3) %all_tokens.3 : Tensor = aten::cat(%66, %12) # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:573:26 %72 : Tensor[] = prim::ListConstruct(%all_scores.6, %decoder_scores.1) %all_scores.3 : Tensor = aten::cat(%72, %12) # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:574:26 %decoder_input.7 : Tensor = aten::unsqueeze(%decoder_input.3, %12) # /var/lib/jenkins/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:576:29 -> (%144, %all_tokens.3, %all_scores.3, %224, %decoder_input.7) %80 : (Tensor, Tensor) = prim::TupleConstruct(%all_tokens, %all_scores) return (%80) 运行评价 最后，我们将运行使用TorchScript模型的聊天机器人模型的评价。如果正确地转换，该机型的行为，正是因为他们会在他们的渴望模式表示。 默认情况下，我们评估了几个常见的查询语句。如果你想与机器人聊天自己，取消对evaluateInput行，并给它一个旋转。 # Use appropriate device scripted_searcher.to(device) # Set dropout layers to eval mode scripted_searcher.eval() # Evaluate examples sentences = [\"hello\", \"what's up?\", \"who are you?\", \"where am I?\", \"where are you from?\"] for s in sentences: evaluateExample(s, scripted_searcher, voc) # Evaluate your input #evaluateInput(traced_encoder, traced_decoder, scripted_searcher, voc) Out: > hello Bot: hello . > what's up? Bot: i m going to get my car . > who are you? Bot: i m the owner . > where am I? Bot: in the house . > where are you from? Bot: south america . 保存模型 现在，我们已经成功地转换我们的模型TorchScript，我们将连载它在非Python的部署环境中使用。要做到这一点，我们可以简单地保存我们的scripted_searcher模块，因为这是运行推论反对聊天机器人模型面向用户的界面。当保存脚本模块，使用script_module.save（PATH），而不是torch.save（模型，PATH）。 scripted_searcher.save(\"scripted_chatbot.pth\") 脚本的总运行时间： （0分钟0.862秒） Download Python source code: deploy_seq2seq_hybrid_frontend_tutorial.py Download Jupyter notebook: deploy_seq2seq_hybrid_frontend_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 部署与TorchScript一个Seq2Seq模型 什么是TorchScript？ 致谢 准备环境 模型概述 编码 解码器 数据处理 定义编码器 TorchScript备注： 定义解码器的注意模块 定义解码器 定义评价 贪婪搜索解码器 TorchScript备注： 变更： 评价输入 载入预训练的参数 使用托管模式 使用自己的模型 TorchScript备注： 转换模型TorchScript 编码 解码器 GreedySearchDecoder 打印图形 运行评价 保存模型 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"intermediate/tensorboard_tutorial.html":{"url":"intermediate/tensorboard_tutorial.html","title":"可视化模型，数据，和与训练TensorBoard","keywords":"","body":"可视化模型，数据，并与TensorBoard培训 在 60分钟闪电战，我们向您展示如何在数据加载，通过我们定义为nn.Module一个子类的模型给它，这个训练模型训练数据，并测试它的测试数据。要看到发生了什么，我们打印出一些统计数据，该模型训练得到一个有意义的培训是进展。但是，我们可以做的比这更好：PyTorch与TensorBoard，设计可视化神经网络训练运行结果的工具集成。这个教程说明了一些它的功能，使用时装- MNIST数据集可使用 torchvision.datasets 读入PyTorch。 在本教程中，我们将学习如何： 读入数据，并用适当的变换（几乎等同于现有教程）。 设置TensorBoard。 写到TensorBoard。 使用TensorBoard检查的模型体系结构。 使用TensorBoard创建我们在上一个教程中创建可视化的互动形式，用更少的代码 > 具体来说，在点＃5，我们会看到： 一对夫妇的方式来检查我们的训练数据 因为训练 如何，一旦被训练评估我们的模型中的表现如何跟踪我们的模型的性能。 > 我们将与类似的样板代码在 CIFAR-10教程开始： # imports import matplotlib.pyplot as plt import numpy as np import torch import torchvision import torchvision.transforms as transforms import torch.nn as nn import torch.nn.functional as F import torch.optim as optim # transforms transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) # datasets trainset = torchvision.datasets.FashionMNIST('./data', download=True, train=True, transform=transform) testset = torchvision.datasets.FashionMNIST('./data', download=True, train=False, transform=transform) # dataloaders trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2) # constant for classes classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot') # helper function to show an image # (used in the `plot_classes_preds`function below) def matplotlib_imshow(img, one_channel=False): if one_channel: img = img.mean(dim=0) img = img / 2 + 0.5 # unnormalize npimg = img.numpy() if one_channel: plt.imshow(npimg, cmap=\"Greys\") else: plt.imshow(np.transpose(npimg, (1, 2, 0))) 我们将从教程定义了一个类似的模型架构，使细微的修改考虑到一个事实，即图像是现在一个通道，而不是三个和28x28，而不是32×32： class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 4 * 4, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 4 * 4) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() 我们将定义相同优化和标准从之前： criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) 1. TensorBoard设置 现在，我们将建立TensorBoard，导入tensorboard从torch.utils和定义SummaryWriter，我们已经对TensorBoard写入信息的关键对象。 from torch.utils.tensorboard import SummaryWriter # default `log_dir`is \"runs\" - we'll be more specific here writer = SummaryWriter('runs/fashion_mnist_experiment_1') 请注意，这条线单独创建一个运行/ fashion_mnist_experiment_1文件夹中。 2.写入TensorBoard 现在，让我们写一个像我们TensorBoard - 具体而言，一个网格 - 使用[ make_grid HTG1。 # get some random training images dataiter = iter(trainloader) images, labels = dataiter.next() # create grid of images img_grid = torchvision.utils.make_grid(images) # show images matplotlib_imshow(img_grid, one_channel=True) # write to tensorboard writer.add_image('four_fashion_mnist_images', img_grid) 现在运行 tensorboard --logdir=runs 在命令行，然后导航到的https：//本地主机：6006 应该显示如下。 现在你知道如何使用TensorBoard！其中TensorBoard的确有过人之处是创建交互式可视化 - 这个例子，但是，可以在Jupyter笔记本电脑来完成。我们接下来将介绍，还有几个由教程结束的一个。 3.使用检查模型TensorBoard 一个TensorBoard的优势之一是它的可视化复杂的模型结构的能力。让我们想象，我们构建的模型。 writer.add_graph(net, images) writer.close() 现在，在刷新TensorBoard你应该会看到一个“图形”选项卡，看起来像这样： 来吧，在“网络”双击看到它扩大，看到单独的操作组成模型的详细视图。 TensorBoard具有可视化，如在低维空间中的图像数据的高维数据的非常方便的功能;我们将讨论这个未来。 4.添加一个“投影”到TensorBoard 我们可以通过 add_embedding 方法可视化高维数据的低维表示 # helper function def select_n_random(data, labels, n=100): ''' Selects n random datapoints and their corresponding labels from a dataset ''' assert len(data) == len(labels) perm = torch.randperm(len(data)) return data[perm][:n], labels[perm][:n] # select random images and their target indices images, labels = select_n_random(trainset.data, trainset.targets) # get the class labels for each image class_labels = [classes[lab] for lab in labels] # log embeddings features = images.view(-1, 28 * 28) writer.add_embedding(features, metadata=class_labels, label_img=images.unsqueeze(1)) writer.close() 现在TensorBoard的“投影机”选项卡，可以看到这些100张图像 - 每一个都是784维 - 投射分解成三维空间。此外，这是互动的：你可以点击并拖动旋转三维投影。最后，一对夫妇的提示，使可视化更容易看到：选择“颜色：标签”的左上角，以及使“夜间模式”，这将使得图像更容易看到，因为他们的背景是白色的： 现在我们已经彻底检查我们的数据，让我们向TensorBoard如何才能使跟踪模型的训练和评估更清晰，开始训练。 5.跟踪模型训练TensorBoard 在前面的例子中，我们简单地 印刷 模型的运行每2000次迭代的损失。现在，我们将代替登录运行损失TensorBoard，以期到模型可通过plot_classes_preds功能使得预测一起。 # helper functions def images_to_probs(net, images): ''' Generates predictions and corresponding probabilities from a trained network and a list of images ''' output = net(images) # convert output probabilities to predicted class _, preds_tensor = torch.max(output, 1) preds = np.squeeze(preds_tensor.numpy()) return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)] def plot_classes_preds(net, images, labels): ''' Generates matplotlib Figure using a trained network, along with images and labels from a batch, that shows the network's top prediction along with its probability, alongside the actual label, coloring this information based on whether the prediction was correct or not. Uses the \"images_to_probs\" function. ''' preds, probs = images_to_probs(net, images) # plot the images in the batch, along with predicted and true labels fig = plt.figure(figsize=(12, 48)) for idx in np.arange(4): ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[]) matplotlib_imshow(images[idx], one_channel=True) ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format( classes[preds[idx]], probs[idx] * 100.0, classes[labels[idx]]), color=(\"green\" if preds[idx]==labels[idx].item() else \"red\")) return fig 最后，让我们使用相同的模型训练码从之前的教程训练模型，但是写结果TensorBoard每1000个批次，而不是打印到控制台;这是使用 add_scalar 函数来完成。 此外，我们训练，我们将生成展示模型的预测与包含在该批次的四个图像的实际效果的图像。 running_loss = 0.0 for epoch in range(1): # loop over the dataset multiple times for i, data in enumerate(trainloader, 0): # get the inputs; data is a list of [inputs, labels] inputs, labels = data # zero the parameter gradients optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() if i % 1000 == 999: # every 1000 mini-batches... # ...log the running loss writer.add_scalar('training loss', running_loss / 1000, epoch * len(trainloader) + i) # ...log a Matplotlib Figure showing the model's predictions on a # random mini-batch writer.add_figure('predictions vs. actuals', plot_classes_preds(net, inputs, labels), global_step=epoch * len(trainloader) + i) running_loss = 0.0 print('Finished Training') 现在，您可以看看标量选项卡查看正在运行的损失在绘制培训15000次迭代： 此外，我们可以看看预测在整个学习任意批量制造的模型。请参阅“图像”选项卡，然后向下滚动在“预测与实际数据”可视化看到这个;这告诉我们，例如，仅仅3000的训练迭代后，该模型已经能够视觉上不同的类，区分衬衫，运动鞋，和外套，虽然它，因为它在训练之后变成上是不是有信心： 在现有的教程中，我们看到每个类的准确性，一旦模型被训练;在这里，我们将使用TensorBoard绘制精确召回曲线（很好的解释此处）为每个类。 6.评估训练的模型与TensorBoard # 1. gets the probability predictions in a test_size x num_classes Tensor # 2. gets the preds in a test_size Tensor # takes ~10 seconds to run class_probs = [] class_preds = [] with torch.no_grad(): for data in testloader: images, labels = data output = net(images) class_probs_batch = [F.softmax(el, dim=0) for el in output] _, class_preds_batch = torch.max(output, 1) class_probs.append(class_probs_batch) class_preds.append(class_preds_batch) test_probs = torch.cat([torch.stack(batch) for batch in class_probs]) test_preds = torch.cat(class_preds) # helper function def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0): ''' Takes in a \"class_index\" from 0 to 9 and plots the corresponding precision-recall curve ''' tensorboard_preds = test_preds == class_index tensorboard_probs = test_probs[:, class_index] writer.add_pr_curve(classes[class_index], tensorboard_preds, tensorboard_probs, global_step=global_step) writer.close() # plot all the pr curves for i in range(len(classes)): add_pr_curve_tensorboard(i, test_probs, test_preds) 现在，您将看到一个包含每个类的精确召回曲线的“公关曲线”选项卡。来吧，闲逛;你会看到，在一些类模型具有“曲线下面积”近100％，而对别人这方面是下： 这是一个介绍到TensorBoard和PyTorch与它集成。当然，你可以做一切TensorBoard确实在Jupyter笔记本电脑，但TensorBoard，你得到了默认情况下交互的视觉效果。 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 可视化模型，数据，和与训练TensorBoard [HTG0 1. TensorBoard设置 [HTG0 2.写入TensorBoard 3.检查使用TensorBoard模型 4.添加一个“投影”到TensorBoard [HTG0 5.跟踪模型训练TensorBoard 6.评估训练的模型与TensorBoard ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/saving_loading_models.html":{"url":"beginner/saving_loading_models.html","title":"保存和加载模型","keywords":"","body":"保存和加载模型 作者： 马修Inkawhich 本文档提供解决方案，以各种关于PyTorch模型的保存和加载使用情况。随时阅读整个文档，或者只是跳到你需要一个期望的使用情况下的代码。 当涉及到保存和加载模型，有三个核心功能熟悉： torch.save ：保存一个序列化的对象到磁盘。此功能使用Python的泡菜实用程序进行序列化。模型，张量，以及各类对象的字典可以使用该功能进行保存。 torch.load ：使用泡菜的在unpickle设施到腌对象文件反序列化到存储器。该功能也有助于该装置加载数据到（见保存&安培;荷载模型跨设备）。 torch.nn.Module.load_state_dict ：使用反序列化 state_dict 加载一个模型的参数字典。有关 更多信息state_dict 参见什么是state_dict？ 。 内容： 什么是state_dict？ 保存&安培;为推理荷载模型 保存&安培;载入通用检查点 在一个文件中保存多个模型 Warmstarting模型从一个不同的模型使用参数 保存&安培;荷载模型跨设备 什么是state_dict？ 在PyTorch中，可学习的参数（即重量和偏见）的torch.nn.Module模型中包含的模型 参数 （带有访问model.parameters（））。 A state_dict 仅仅是每一层映射到其参数张量Python字典对象。注意与可学习参数（卷积层，线性层等）和注册缓冲器（batchnorm的runningmean），只有层具有在条目模型的 _state_dict 。优化器对象（torch.optim）也有一个 state_dict ，它包含有关该优化程序的状态的信息，以及所使用的超参数。 因为 state_dict 对象是Python字典，它们可以方便地保存，更新，修改和恢复，加上模块化的大量工作PyTorch模型和优化。 例如： 让我们来看看从训练分类教程中使用的简单模型 state_dict [HTG1。 # Define model class TheModelClass(nn.Module): def __init__(self): super(TheModelClass, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x # Initialize model model = TheModelClass() # Initialize optimizer optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # Print model's state_dict print(\"Model's state_dict:\") for param_tensor in model.state_dict(): print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size()) # Print optimizer's state_dict print(\"Optimizer's state_dict:\") for var_name in optimizer.state_dict(): print(var_name, \"\\t\", optimizer.state_dict()[var_name]) 输出： Model's state_dict: conv1.weight torch.Size([6, 3, 5, 5]) conv1.bias torch.Size([6]) conv2.weight torch.Size([16, 6, 5, 5]) conv2.bias torch.Size([16]) fc1.weight torch.Size([120, 400]) fc1.bias torch.Size([120]) fc2.weight torch.Size([84, 120]) fc2.bias torch.Size([84]) fc3.weight torch.Size([10, 84]) fc3.bias torch.Size([10]) Optimizer's state_dict: state {} param_groups [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [4675713712, 4675713784, 4675714000, 4675714072, 4675714216, 4675714288, 4675714432, 4675714504, 4675714648, 4675714720]}] 节省&安培;为荷载模型推断 保存/加载state_dict（推荐） 保存： torch.save(model.state_dict(), PATH) 负载： model = TheModelClass(*args, **kwargs) model.load_state_dict(torch.load(PATH)) model.eval() 当节省推理模型，只需要保存训练模型的参数得知。保存模型 state_dict 与torch.save（）功能会给你最大的灵活性后恢复模型，这就是为什么它是推荐的方法为保存模型。 一个常见的PyTorch惯例是使用一个.PT或.pth文件扩展名来保存模式。 请记住，你必须调用model.eval（）运行推论之前设置辍学率和批标准化层为评估模式。如果不这样做会产生不一致的推断结果。 Note 注意，load_state_dict（）函数采用一个字典对象，而不是路径保存的对象。这意味着你必须反序列化保存 state_dict 你将它传递给load_state_dict前（）功能。例如，你不能加载使用model.load_state_dict（PATH）。 SAVE / LOAD整个模型 Save: torch.save(model, PATH) Load: # Model class must be defined somewhere model = torch.load(PATH) model.eval() 此保存/加载处理使用最直观的语法和涉及的代码量最少。以这种方式保存的模型将使用Python的泡菜模块保存整个模块。这种方法的缺点是串行数据绑定到特定的类和在保存的模型中使用的精确的目录结构。这样做的原因是因为泡菜不保存模型类本身。相反，它保存到包含类，这是在负载时所使用的文件的路径。正因为如此，你的代码可以在其他项目或refactors后使用时，以各种方式突破。 A common PyTorch convention is to save models using either a .ptor .pth file extension. Remember that you must call model.eval()to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results. 保存&放;加载一般检查点推断和/或恢复训练 保存： torch.save({ 'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'loss': loss, ... }, PATH) 负载： model = TheModelClass(*args, **kwargs) optimizer = TheOptimizerClass(*args, **kwargs) checkpoint = torch.load(PATH) model.load_state_dict(checkpoint['model_state_dict']) optimizer.load_state_dict(checkpoint['optimizer_state_dict']) epoch = checkpoint['epoch'] loss = checkpoint['loss'] model.eval() # - or - model.train() 当保存一般的检查点，以用于任何推理或恢复训练，你必须保存不仅仅是模型的 state_dict [HTG1。它也保存重要的是优化的 _state_dict ，因为这包含了更新的模型火车缓冲区和参数。你可能希望保存其他项目，你离开时，最新的培训记录丢失，外部torch.nn.Embedding层等时代_ 保存多个组件，但在一个字典组织它们，并使用torch.save（）序列化的词典。一个常见的PyTorch约定是为了节省使用的.tar文件扩展名，这些检查站。 要装入的物品，首先初始化模型和优化器，然后装入词典本地使用torch.load（）。从这里，你可以很容易地通过简单的查询你所期望的字典访问保存的项目。 请记住，你必须调用model.eval（）运行推论之前设置辍学率和批标准化层为评估模式。如果不这样做会产生不一致的推断结果。如果你想恢复训练，调用model.train（），以确保这些层在训练模式。 在一个文件中保存多个模型 保存： torch.save({ 'modelA_state_dict': modelA.state_dict(), 'modelB_state_dict': modelB.state_dict(), 'optimizerA_state_dict': optimizerA.state_dict(), 'optimizerB_state_dict': optimizerB.state_dict(), ... }, PATH) 负载： modelA = TheModelAClass(*args, **kwargs) modelB = TheModelBClass(*args, **kwargs) optimizerA = TheOptimizerAClass(*args, **kwargs) optimizerB = TheOptimizerBClass(*args, **kwargs) checkpoint = torch.load(PATH) modelA.load_state_dict(checkpoint['modelA_state_dict']) modelB.load_state_dict(checkpoint['modelB_state_dict']) optimizerA.load_state_dict(checkpoint['optimizerA_state_dict']) optimizerB.load_state_dict(checkpoint['optimizerB_state_dict']) modelA.eval() modelB.eval() # - or - modelA.train() modelB.train() 当保存由多个torch.nn.Modules，例如GAN，序列到序列模型或模型的集合的模型，就按照同样的方法，因为当您要保存一般的检查点。换言之，保存每个模型的 state_dict 和相应的优化的字典。正如前面提到的，你可以保存可以通过简单地追加他们的字典帮助您恢复训练其他任何物品。 一个常见的PyTorch约定是为了节省使用的.tar文件扩展名，这些检查站。 要加载模型中，首先初始化模型和优化器，然后装入词典本地使用torch.load（）。从这里，你可以很容易地通过简单的查询你所期望的字典访问保存的项目。 请记住，你必须调用model.eval（）运行推论之前设置辍学率和批标准化层为评估模式。如果不这样做会产生不一致的推断结果。如果你想恢复训练，调用model.train（）设置这些层的培训模式。 Warmstarting模型中使用的参数从一个不同的模型 保存： torch.save(modelA.state_dict(), PATH) 负载： modelB = TheModelBClass(*args, **kwargs) modelB.load_state_dict(torch.load(PATH), strict=False) 部分加载模型或加载局部模型常见的场景时，转移学习或培训新的复杂的模型。凭借训练有素的参数，即使只有少数是可用的，将有助于WARMSTART训练过程，并希望能帮助你的模型收敛比从头训练快得多。 无论您是从装载部分 state_dict ，它缺少一些键，或加载 state_dict 与比要装载到模型更加按键，可以设置严格参数为 假 在load_state_dict（）函数忽略非匹配密钥。 如果你想从一个层对其他负载参数，但有些键不匹配，只需更改 参数键的名称state_dict 您加载以匹配你是模型的关键装入。 节省&安培;荷载模型跨设备 保存在GPU上，加载在CPU Save: torch.save(model.state_dict(), PATH) Load: device = torch.device('cpu') model = TheModelClass(*args, **kwargs) model.load_state_dict(torch.load(PATH, map_location=device)) 当加载，将其与一个GPU培养了CPU上的模型，通过torch.device（ 'CPU'）到map_location在torch.load参数（）功能。在这种情况下，张量基础的存储器使用map_location参数动态地重新映射到CPU的设备。 保存在GPU上，加载在GPU Save: torch.save(model.state_dict(), PATH) Load: device = torch.device(\"cuda\") model = TheModelClass(*args, **kwargs) model.load_state_dict(torch.load(PATH)) model.to(device) # Make sure to call input = input.to(device) on any input tensors that you feed to the model 当加载上进行训练，并且保存在GPU上GPU的模型，简单地转换初始化模型，用model.to（Torch CUDA优化模型。设备（ 'CUDA'））。另外，一定使用。要（torch.device（ 'CUDA'））功能上的所有模型输入到该模型准备数据。请注意，调用my_tensor.to（设备）HTG14]返回GPU的my_tensor新副本。它不会覆盖my_tensor [HTG23。因此，记得手动改写张量：my_tensor = my_tensor.to（torch.device（ 'CUDA'）） 。 节省CPU，装载在GPU Save: torch.save(model.state_dict(), PATH) Load: device = torch.device(\"cuda\") model = TheModelClass(*args, **kwargs) model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\")) # Choose whatever GPU device number you want model.to(device) # Make sure to call input = input.to(device) on any input tensors that you feed to the model 当加载上进行训练，并且保存在CPU一个GPU的模型，将map_location参数在torch.load（）函数为 CUDA：DEVICE_ID 。这将加载模型给定的GPU设备。其次，一定要打电话model.to（torch.device（ 'CUDA'））对模型的参数张量转换为CUDA张量。最后，一定要使用。要（torch.device（ 'CUDA'））功能上的所有模型输入为CUDA优化模型准备数据。请注意，调用my_tensor.to（设备）HTG20]返回GPU的my_tensor新副本。它不会覆盖my_tensor [HTG29。因此，记得手动改写张量：my_tensor = my_tensor.to（torch.device（ 'CUDA'）） 。 节省torch.nn.DataParallel模型 Save: torch.save(model.module.state_dict(), PATH) Load: # Load to whatever device you want torch.nn.DataParallel是一个模型包装，可以并行GPU利用率。要保存数据并行模型一般，保存model.module.state_dict（）。这样，您可以灵活地加载模型要你想要的任何设备的任何方式。 脚本的总运行时间： （0分钟0.000秒） Download Python source code: saving_loading_models.py Download Jupyter notebook: saving_loading_models.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 保存和加载模型 什么是state_dict？ [HTG0例： 保存&安培;为推理荷载模型 保存/加载state_dict（推荐） 保存/加载整个模型 保存&安培;载入通用检查点用于推断和/或恢复训练 保存： 负载： 在一个文件中保存多个模型 保存： 负载： Warmstarting模型从一个不同的模型使用参数 保存： 负载： 保存&安培;荷载模型跨设备 保存在GPU，CPU负荷 节省GPU，GPU的负载 保存在CPU，GPU上负载 保存torch.nn.DataParallel模型 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/nn_tutorial.html":{"url":"beginner/nn_tutorial.html","title":"torch.nn 到底是什么？","keywords":"","body":"torch.nn 到底是什么？ 杰里米·霍华德，[ fast.ai HTG1。由于雷切尔·托马斯和弗朗西斯科英厄姆。 我们建议运行本教程为笔记本电脑，而不是一个脚本。要下载笔记本（.ipynb）文件，请点击页面顶部的链接。 PyTorch提供了优雅的设计模块和类 torch.nn ， torch.optim ，数据集和的DataLoader ，以帮助您创建和火车神经网络。为了充分利用他们的权力和它们进行自定义你的问题，你需要真正了解他们在做什么。为了开发这样的认识，我们将第一列火车在MNIST数据，而无需使用来自这些模型的任何功能设置基本的神经网络;我们最初将只使用最基本的PyTorch张量的功能。然后，我们将逐步增加一个功能可以从torch.nn，torch.optim，数据集或的DataLoader的时间，正好显示每一块做什么，以及它如何使代码或者更简洁，更灵活。 本教程假设你已经安装PyTorch，并熟悉操作张的基础。 （如果你熟悉numpy的数组操作，你会发现这里使用几乎相同的PyTorch张量操作）。 MNIST数据建立 我们将使用经典 MNIST 数据集，它由手绘数字黑色和白色图像（0至9）的。 我们将使用 pathlib 与路径处理（Python的3标准库的一部分），并使用请求下载数据集。当我们使用它们，我们将只导入模块，这样你就可以清楚地看到什么是在每个点被使用。 from pathlib import Path import requests DATA_PATH = Path(\"data\") PATH = DATA_PATH / \"mnist\" PATH.mkdir(parents=True, exist_ok=True) URL = \"http://deeplearning.net/data/mnist/\" FILENAME = \"mnist.pkl.gz\" if not (PATH / FILENAME).exists(): content = requests.get(URL + FILENAME).content (PATH / FILENAME).open(\"wb\").write(content) 此数据集是在numpy的阵列格式，以及使用泡菜，用于序列数据的特定蟒格式已经被存储。 import pickle import gzip with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\") 每个图像是28×28，并且被存储为784长度（= 28x28）的扁平行。让我们来看看一个[]我们需要重塑它首先到2d。 from matplotlib import pyplot import numpy as np pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\") print(x_train.shape) 日期： (50000, 784) PyTorch使用torch.tensor，而不是numpy的阵列，因此我们需要我们的数据转换。 import torch x_train, y_train, x_valid, y_valid = map( torch.tensor, (x_train, y_train, x_valid, y_valid) ) n, c = x_train.shape x_train, x_train.shape, y_train.min(), y_train.max() print(x_train, y_train) print(x_train.shape) print(y_train.min(), y_train.max()) Out: tensor([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], ..., [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]]) tensor([5, 0, 4, ..., 8, 4, 8]) torch.Size([50000, 784]) tensor(0) tensor(9) 从头（无torch.nn）神经网络 让我们先创建一个使用无非是PyTorch张量操作的模式。我们假设你已经熟悉了神经网络的基本知识。 （如果你没有，你可以在 course.fast.ai 学习他们）。 PyTorch提供方法来创建随机或零填充的张量，我们将用它来创建我们的权重和偏见一个简单的线性模型。这些只是普通的张量，一个非常特殊的另外：我们告诉PyTorch，他们需要一个梯度。这将导致PyTorch记录所有对张进行操作的，所以它可以反向传播 自动 在计算梯度！ 对于权重，我们设定requires_grad后 初始化，因为我们不希望包含在梯度一步。 （请注意，一个trailling _在PyTorch表示该操作是在就地进行。） Note 我们正在与泽维尔初始化这里初始化权重（通过用1 / SQRT（N乘以））。 import math weights = torch.randn(784, 10) / math.sqrt(784) weights.requires_grad_() bias = torch.zeros(10, requires_grad=True) 由于PyTorch的自动计算梯度，我们可以使用任何标准的Python函数（或可调用对象）作为模型的能力！所以让我们只写一个简单的矩阵乘法和广播除了创建一个简单的线性模型。我们还需要一个激活的功能，所以我们写 log_softmax 并使用它。记住：虽然PyTorch提供了大量的预先书面挂失功能，激活功能，等等，你可以很容易地编写自己的使用普通蟒蛇。 PyTorch甚至会为你的函数自动创建快速的GPU或CPU矢量代码。 def log_softmax(x): return x - x.exp().sum(-1).log().unsqueeze(-1) def model(xb): return log_softmax(xb @ weights + bias) 另外，在上述中，@代表点积操作。我们将调用数据的一个批次（在这种情况下，64个图像）我们的函数。这是一个 直传 。请注意，我们的预测会不会比随机更好的在这个阶段，因为我们开始与随机权。 bs = 64 # batch size xb = x_train[0:bs] # a mini-batch from x preds = model(xb) # predictions preds[0], preds.shape print(preds[0], preds.shape) Out: tensor([-2.4595, -1.9240, -1.9316, -2.6839, -2.5857, -1.9705, -2.4925, -2.4569, -2.2955, -2.6387], grad_fn=) torch.Size([64, 10]) 正如你看到的，preds张量不仅包含了张量的值，也是一个渐变的功能。我们将利用这个做以后backprop。 让我们来实现负对数似然的损失函数（同样，我们可以用标准的Python）使用方法： def nll(input, target): return -input[range(target.shape[0]), target].mean() loss_func = nll 让我们来看看我们的损失与我们的随机模型，所以我们可以看到，如果我们提高后backprop后通过。 yb = y_train[0:bs] print(loss_func(preds, yb)) Out: tensor(2.3762, grad_fn=) 我们还要实现一个函数来计算我们模型的准确性。对于每一个预测，如果与最大值的指标目标值相匹配，那么预测是正确的。 def accuracy(out, yb): preds = torch.argmax(out, dim=1) return (preds == yb).float().mean() 让我们来看看我们的随机模型的准确性，所以我们可以看到，如果我们的准确度随着我们的损失得到改善。 print(accuracy(preds, yb)) Out: tensor(0.0625) 现在，我们可以运行一个训练循环。对于每次迭代，我们将： 选择迷你一批数据（大小BS的） 使用模型进行预测 计算损失 loss.backward（）更新模型的梯度，在这种情况下，权重和偏压。 我们现在使用这些梯度更新权重和偏见。我们这样做的torch.no_grad内（）上下文管理，因为我们不希望被记录为我们的下一个梯度的计算这些操作。你可以阅读更多关于PyTorch的Autograd如何记录操作[此处HTG5。 然后，我们设置渐变到零，让我们准备下一个循环。否则，我们的梯度将记录这一切已经发生的业务流水账（即loss.backward（）增加 梯度到任何已存储的，而不是取代它们）。 小费 您可以使用标准的Python调试器分步PyTorch代码，让您在每一步检查各种变量值。取消注释set_trace（）下面尝试一下。 from IPython.core.debugger import set_trace lr = 0.5 # learning rate epochs = 2 # how many epochs to train for for epoch in range(epochs): for i in range((n - 1) // bs + 1): # set_trace() start_i = i * bs end_i = start_i + bs xb = x_train[start_i:end_i] yb = y_train[start_i:end_i] pred = model(xb) loss = loss_func(pred, yb) loss.backward() with torch.no_grad(): weights -= weights.grad * lr bias -= bias.grad * lr weights.grad.zero_() bias.grad.zero_() 就是这样：我们创建和培养了极少的神经网络（在这种情况下，逻辑回归，因为我们没有隐藏层）完全从头开始！ 让我们来看看损失，准确性和比较那些我们前面了。我们预计，损失将有所减少和准确性都有所增加，并且他们有。 print(loss_func(model(xb), yb), accuracy(model(xb), yb)) Out: tensor(0.0824, grad_fn=) tensor(1.) 使用torch.nn.functional 现在，我们将重构我们的代码，以便它像以前一样做同样的事情，只有我们将开始利用PyTorch的NN类，使其更加简洁和灵活。在这里，从每一步，我们应该使我们的代码的一个或多个：更短，更容易理解，和/或更灵活。 第一和最容易的步骤是使我们的代码越短由与那些从代替我们的手写激活和损耗函数torch.nn.functional（其通常导入到命名空间F [HTG7按照惯例]）。该模块包含在torch.nn 库中的所有功能（而库的其它部分包含类）。除了各种各样的损失和激活功能，你会也在这里找到有关创建神经网络，如池功能的一些方便的功能。 （也有做卷积，线性层等功能，但正如我们所看到的，这些通常是使用该库的其他部分更好地处理。） 如果您在使用负对数似然损失和日志SOFTMAX激活，然后Pytorch提供了一个单一的功能F.cross_entropy，结合了两个。因此，我们甚至可以删除从我们的模型激活功能。 import torch.nn.functional as F loss_func = F.cross_entropy def model(xb): return xb @ weights + bias 请注意，我们不再调用log_softmax中的模型功能。让我们确认，我们的损失和准确度都和以前一样： print(loss_func(model(xb), yb), accuracy(model(xb), yb)) Out: tensor(0.0824, grad_fn=) tensor(1.) 使用重构nn.Module 接下来，我们将使用nn.Module和nn.Parameter，更清晰和更简洁的训练循环。我们继承nn.Module（这本身是一类，并能跟踪状态）。在这种情况下，我们要创建一个保存我们的砝码，偏置和方法向前台阶的类。 nn.Module具有许多属性和方法（如.parameters的（）和.zero_grad （）），我们将使用。 Note nn.Module（大写的M）是PyTorch具体的概念，是我们将要使用大量的类。 nn.Module不与的Python的概念混淆（小写M）模块这是Python代码的文件可以导入。 from torch import nn class Mnist_Logistic(nn.Module): def __init__(self): super().__init__() self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784)) self.bias = nn.Parameter(torch.zeros(10)) def forward(self, xb): return xb @ self.weights + self.bias 因为现在我们使用的对象，而不是只使用一个功能，我们首先必须初始化我们的模型： model = Mnist_Logistic() 现在，我们可以计算出之前以相同方式的损失。需要注意的是nn.Module使用的对象，就好像它们是函数（即它们 调用 ），但幕后Pytorch会打电话给我们的向前自动方法。 print(loss_func(model(xb), yb)) Out: tensor(2.2882, grad_fn=) 以前我们的训练循环，我们必须更新值按名称各参数，并分别手动清零每个参数的梯度，这样的： with torch.no_grad(): weights -= weights.grad * lr bias -= bias.grad * lr weights.grad.zero_() bias.grad.zero_() 现在，我们可以利用model.parameters（）和model.zero_grad（），以使这些步骤更简洁，不容易（这两者都是由PyTorch为nn.Module中定义）遗忘我们的一些参数，特别是如果我们有一个更复杂的模型的错误： with torch.no_grad(): for p in model.parameters(): p -= p.grad * lr model.zero_grad() 我们将包裹我们的小训练循环在适合功能，所以我们可以稍后再运行它。 def fit(): for epoch in range(epochs): for i in range((n - 1) // bs + 1): start_i = i * bs end_i = start_i + bs xb = x_train[start_i:end_i] yb = y_train[start_i:end_i] pred = model(xb) loss = loss_func(pred, yb) loss.backward() with torch.no_grad(): for p in model.parameters(): p -= p.grad * lr model.zero_grad() fit() 让我们仔细检查，我们的损失已经下降： print(loss_func(model(xb), yb)) Out: tensor(0.0795, grad_fn=) 使用重构nn.Linear 我们继续重构我们的代码。代替手动定义和初始化self.weights和self.bias，并计算XB @ self.weights + self.bias，我们将改用Pytorch类 nn.Linear 为线性层，它确实所有的我们。 Pytorch有许多类型的预定义层，可以大大简化我们的代码，而且往往使得它更快了。 class Mnist_Logistic(nn.Module): def __init__(self): super().__init__() self.lin = nn.Linear(784, 10) def forward(self, xb): return self.lin(xb) 我们实例模型和计算以同样的方式和以前的损失： model = Mnist_Logistic() print(loss_func(model(xb), yb)) Out: tensor(2.3549, grad_fn=) 我们仍然能够像以前一样使用我们同样适合方法。 fit() print(loss_func(model(xb), yb)) Out: tensor(0.0820, grad_fn=) 使用重构的Optim Pytorch还具有与各种优化算法的软件包，torch.optim。我们可以使用步骤方法从我们的优化器作为一个前步骤，而不是手动更新各参数。 这将让我们取代我们以前的手工编码的优化步骤： with torch.no_grad(): for p in model.parameters(): p -= p.grad * lr model.zero_grad() 而是只需使用： opt.step() opt.zero_grad() （optim.zero_grad（）复位梯度为0，我们需要计算用于下一minibatch梯度之前调用它。） from torch import optim 我们将定义一个小功能来创建我们的模型和优化，所以我们可以在未来重复使用。 def get_model(): model = Mnist_Logistic() return model, optim.SGD(model.parameters(), lr=lr) model, opt = get_model() print(loss_func(model(xb), yb)) for epoch in range(epochs): for i in range((n - 1) // bs + 1): start_i = i * bs end_i = start_i + bs xb = x_train[start_i:end_i] yb = y_train[start_i:end_i] pred = model(xb) loss = loss_func(pred, yb) loss.backward() opt.step() opt.zero_grad() print(loss_func(model(xb), yb)) Out: tensor(2.3540, grad_fn=) tensor(0.0828, grad_fn=) 使用重构数据集 PyTorch有一个抽象的DataSet类。数据集可以是任何具有__len__函数（由Python的标准LEN函数调用）和__getitem__用作索引的一种方式进去。 本教程遍历创建自定义FacialLandmarkDataset类作为数据集的子类的一个很好的例子。 PyTorch的 TensorDataset 是一个数据集包装张量。通过定义索引的长度和方式，这也为我们提供了一种方式来遍历，指数，并沿张量的第一个维度切片。这将使它更容易访问两个自变量和因变量在同一行，因为我们训练。 from torch.utils.data import TensorDataset 既x_train和y_train可以以组合的单TensorDataset，这将更容易遍历，切片。 train_ds = TensorDataset(x_train, y_train) 以前，我们必须通过x的minibatches和y值分别进行迭代： xb = x_train[start_i:end_i] yb = y_train[start_i:end_i] 现在，我们可以做这两个步骤一起： xb,yb = train_ds[i*bs : i*bs+bs] model, opt = get_model() for epoch in range(epochs): for i in range((n - 1) // bs + 1): xb, yb = train_ds[i * bs: i * bs + bs] pred = model(xb) loss = loss_func(pred, yb) loss.backward() opt.step() opt.zero_grad() print(loss_func(model(xb), yb)) Out: tensor(0.0823, grad_fn=) 使用重构的DataLoader Pytorch的的DataLoader负责管理批次。您可以创建一个的DataLoader从任何数据集 [HTG11。 的DataLoader可以更容易地在批次迭代。而不必使用train_ds [I BS ： 我 BS + BS] 时，的DataLoader给我们每个自动minibatch。 from torch.utils.data import DataLoader train_ds = TensorDataset(x_train, y_train) train_dl = DataLoader(train_ds, batch_size=bs) 此前，我们的循环遍历批次（XB，YB）是这样的： for i in range((n-1)//bs + 1): xb,yb = train_ds[i*bs : i*bs+bs] pred = model(xb) 现在，我们的循环是更清洁，如（XB，YB）会自动从数据加载器加载： for xb,yb in train_dl: pred = model(xb) model, opt = get_model() for epoch in range(epochs): for xb, yb in train_dl: pred = model(xb) loss = loss_func(pred, yb) loss.backward() opt.step() opt.zero_grad() print(loss_func(model(xb), yb)) Out: tensor(0.0807, grad_fn=) 由于Pytorch的nn.Module，nn.Parameter，数据集，和的DataLoader，我们的训练循环现显着更小，更容易理解。现在，让我们尝试添加必要在实践中创造effecive模型的基本特征。 添加验证 在第1节，我们只是想获得一个合理的训练循环建立对我们的训练数据的使用。在现实中，你 总是 也应该有一个验证设置，以确定如果你过度拟合。 洗牌训练数据是重要为了防止批料和过拟合之间的相关性。在另一方面，确认损失将是相同的，我们是否洗牌验证设置与否。由于洗牌需要额外的时间，这是没有意义的洗牌验证数据。 我们将使用的批次数量为验证集是两倍，对于训练集。这是因为验证集不需要反向传播并且因此需要较少的存储器（它并不需要存储的梯度）。我们利用这一点来使用更大的批量大小和更迅速地计算损失。 train_ds = TensorDataset(x_train, y_train) train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True) valid_ds = TensorDataset(x_valid, y_valid) valid_dl = DataLoader(valid_ds, batch_size=bs * 2) 我们将计算，并在每个时代的结束打印确认损失。 （请注意，我们随时调用model.train（）训练前，和model.eval（）推理之前，因为这些都是通过层如nn.BatchNorm2d和nn.Dropout，以确保这些不同的阶段适当的行为使用）。 model, opt = get_model() for epoch in range(epochs): model.train() for xb, yb in train_dl: pred = model(xb) loss = loss_func(pred, yb) loss.backward() opt.step() opt.zero_grad() model.eval() with torch.no_grad(): valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl) print(epoch, valid_loss / len(valid_dl)) Out: 0 tensor(0.3543) 1 tensor(0.4185) 创建拟合（）和GET_DATA（） 现在，我们会尽自己的一点点重构。因为我们经历了类似的过程计算训练集和验证集既损失的两倍，让我们做的是为自己的功能，loss_batch，其计算为一个损失批量。 我们通过一个优化在训练集，并用它来执行backprop。对于验证集，我们没有通过优化，因此该方法不执行backprop。 def loss_batch(model, loss_func, xb, yb, opt=None): loss = loss_func(model(xb), yb) if opt is not None: loss.backward() opt.step() opt.zero_grad() return loss.item(), len(xb) 适合运行必要的操作来训练我们的模型和计算每个时期的训练和验证的损失。 import numpy as np def fit(epochs, model, loss_func, opt, train_dl, valid_dl): for epoch in range(epochs): model.train() for xb, yb in train_dl: loss_batch(model, loss_func, xb, yb, opt) model.eval() with torch.no_grad(): losses, nums = zip( *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl] ) val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums) print(epoch, val_loss) GET_DATA返回dataloaders用于训练和验证集。 def get_data(train_ds, valid_ds, bs): return ( DataLoader(train_ds, batch_size=bs, shuffle=True), DataLoader(valid_ds, batch_size=bs * 2), ) 现在，我们整个获取数据装载机和拟合模型的过程可在3行代码运行： train_dl, valid_dl = get_data(train_ds, valid_ds, bs) model, opt = get_model() fit(epochs, model, loss_func, opt, train_dl, valid_dl) Out: 0 0.29517731761932375 1 0.2856491837501526 您可以使用这些基本的3行代码，培养各种各样的模型。让我们来看看，如果我们可以用它们来训练卷积神经网络（CNN）！ 切换到CNN 现在，我们要建立我们的神经网络有三个卷积层。因为没有上一节中的功能，承担有关模型的形式什么，我们就可以用它们来训练CNN不作任何修改。 我们将使用Pytorch的预定义 Conv2d 类作为我们的卷积层。我们定义了一个CNN 3个卷积层。每一圈之后是RELU。最后，我们执行的平均池。 （请注意，视图时PyTorch的版本numpy的年代重塑） class Mnist_CNN(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1) self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1) self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1) def forward(self, xb): xb = xb.view(-1, 1, 28, 28) xb = F.relu(self.conv1(xb)) xb = F.relu(self.conv2(xb)) xb = F.relu(self.conv3(xb)) xb = F.avg_pool2d(xb, 4) return xb.view(-1, xb.size(1)) lr = 0.1 动量是采用以前的更新考虑以及和通常会导致更快的训练上随机梯度下降的变化。 model = Mnist_CNN() opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9) fit(epochs, model, loss_func, opt, train_dl, valid_dl) Out: 0 0.35516392378807066 1 0.25097596280574797 nn.Sequential torch.nn还有一个方便的类，我们可以用它来简单的我们的代码：[顺序HTG5。 A 序贯对象运行的每个包含在其内的模块的，以顺序的方式。这是我们写的神经网络的一个简单的方法。 要充分利用这一点，我们需要能够轻松地从一个给定函数定义 自定义层[HTG1。例如，PyTorch没有一个 查看层，我们需要创建一个为我们的网络。 LAMBDA将创建一个层，其限定与序贯网络时，我们可以再使用。 class Lambda(nn.Module): def __init__(self, func): super().__init__() self.func = func def forward(self, x): return self.func(x) def preprocess(x): return x.view(-1, 1, 28, 28) 与序贯创建的模型只是： model = nn.Sequential( Lambda(preprocess), nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(), nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(), nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(), nn.AvgPool2d(4), Lambda(lambda x: x.view(x.size(0), -1)), ) opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9) fit(epochs, model, loss_func, opt, train_dl, valid_dl) Out: 0 0.4354481062412262 1 0.23530314621925355 包裹的DataLoader Our CNN is fairly concise, but it only works with MNIST, because: 它假定输入是一个28 * 28长向量 它假定最终CNN格大小为4×4（因为这是平均 我们使用的池内核大小） 让我们摆脱这两个假设，因此我们的模型与任何2D单通道形象工程。首先，我们可以删除初始LAMBDA层但移动数据预处理成发生器： def preprocess(x, y): return x.view(-1, 1, 28, 28), y class WrappedDataLoader: def __init__(self, dl, func): self.dl = dl self.func = func def __len__(self): return len(self.dl) def __iter__(self): batches = iter(self.dl) for b in batches: yield (self.func(*b)) train_dl, valid_dl = get_data(train_ds, valid_ds, bs) train_dl = WrappedDataLoader(train_dl, preprocess) valid_dl = WrappedDataLoader(valid_dl, preprocess) 接下来，我们可以替换nn.AvgPool2d与nn.AdaptiveAvgPool2d，这使我们能够限定 输出的大小 张量我们想要的，而不是 输入 张量，我们有。其结果是，我们的模型将与任何大小的输入工作。 model = nn.Sequential( nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(), nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(), nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d(1), Lambda(lambda x: x.view(x.size(0), -1)), ) opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9) 让我们来尝试一下： fit(epochs, model, loss_func, opt, train_dl, valid_dl) Out: 0 0.427955148935318 1 0.2865892390727997 使用你的GPU 如果你足够幸运，有机会获得一个支持CUDA的GPU（你可以租一个大约$ 0.50 /小时，大多数云供应商），你可以用它来加速你的代码。首先检查你的GPU在Pytorch工作： print(torch.cuda.is_available()) Out: True 然后为它创建一个设备对象： dev = torch.device( \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") 让我们更新预处理以分批转移到GPU： def preprocess(x, y): return x.view(-1, 1, 28, 28).to(dev), y.to(dev) train_dl, valid_dl = get_data(train_ds, valid_ds, bs) train_dl = WrappedDataLoader(train_dl, preprocess) valid_dl = WrappedDataLoader(valid_dl, preprocess) 最后，我们可以把我们的模型转移到GPU。 model.to(dev) opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9) 你会发现，现在运行得更快： fit(epochs, model, loss_func, opt, train_dl, valid_dl) Out: 0 0.1994757580757141 1 0.1848785598754883 关闭的想法 我们现在有一个通用数据管道和训练循环，您可以使用训练多种类型的使用Pytorch模型。看样板可以训练多么简单，现在是，看看在 mnist_sample 样本笔记本。 当然，也有很多事情你需要添加，比如数据扩充，超参数调整，监控培训，迁移学习，等等。这些功能在fastai库，它已使用本教程中相同的设计方法研制，对从业人员提供希望进一步采取他们的模型的下一步可用。 我们承诺在本教程的开始，我们会通过例子来说明每种torch.nn，torch.optim，数据集和的DataLoader。因此，让我们总结一下，我们看到： torch.nn 模块：创建一个可调用的，其行为类似的功能，但也可以包含状态（如神经网络层的权重）它知道什么`参数 [HTG14（S）它包含并可以通过它们更新权重为零，他们的所有梯度，循环等HTG15] 参数：用于张量，告诉一个包装一模块，它具有需要backprop期间更新权重。只用 requires_grad 属性集张量被更新 官能：一个模块（通常导入到F按照惯例命名空间），其包含激活的功能，损失函数，等等，以及层的非状态版本，如卷积和线性层。 ` torch.optim：包含优化如SGD，它更新的权重的参数在向后步骤 数据集：对象的抽象接口与__len__状语从句一个__getitem__，包括设置有Pytorch类，如TensorDataset 的的DataLoader：取任何数据集并且创建返回数据的批量的迭代器。 > 脚本的总运行时间： （1分钟2.848秒） Download Python source code: nn_tutorial.py Download Jupyter notebook: nn_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 什么是 torch.nn 真的 ？ MNIST数据建立 从头神经网（无torch.nn） 使用torch.nn.functional 使用nn.Module重构 使用nn.Linear重构 使用重构的Optim 使用数据集重构 使用的DataLoader重构 添加验证 创建拟合（）和GET_DATA（） 转为CNN nn.Sequential 包装纸的DataLoader 使用你的GPU 合的想法 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"intermediate/torchvision_tutorial.html":{"url":"intermediate/torchvision_tutorial.html","title":"TorchVision对象检测教程细化和微调","keywords":"","body":"TorchVision对象检测教程细化和微调 小费 为了得到最本教程中，我们建议使用此[ Colab版本HTG1。这将让你与下面提供的信息进行试验。 在本教程中，我们将微调预训练面膜R-CNN 中的佩恩 - 复旦数据库行人检测与分割模式。它包含170倍的图像与行人345分的情况下，我们将用它来说明如何才能培养上的自定义数据集的实例细分模型使用torchvision的新功能。 定义数据集 培训对象检测，例如分割和人关键点检测的参考脚本允许容易地支持添加新的自定义数据集。数据集应该从标准torch.utils.data.Dataset类继承，实施__len__和__getitem__。 我们需要的唯一的特殊性在于，数据集__getitem__应该返回： 图像：尺寸（H， W）的PIL图像 目标：包含以下字段的一个字典 盒 （FloatTensor [N， 4]）：的N 的坐标在包围盒[X0， Y0， X 1， Y1]格式中，范围从0至W和0至H 标签 （Int64Tensor [N]）：对于每个边界框的标签 image_id （Int64Tensor [1]）：图像标识符。它应该是在数据集中的所有图像之间唯一的，评估过程中使用 面积 （张量[N]）：将边界框的面积。这是通过COCO度量评估过程中使用，以分离小，中，大箱之间的度量得分。 iscrowd （UInt8Tensor [N]）：用iscrowd =真实例将被评估期间忽略。 （可选地）掩模 （UInt8Tensor [N， H， W]）：本分割掩码的每个其中一个对象 （可选地）关键点 （FloatTensor [N， K， 3]）：对于每一个中的所述一个N个对象，它包含K个关键点[X， Y， 能见度]格式中，定义的对象。能见度= 0表示所述关键点是不可见的。请注意，数据增强，翻转关键点的概念是依赖于数据表示，你可能要适应引用/检测/ transforms.py为您的新关键点表示 如果你的模型返回上面的方法，他们将使其成为训练和评估工作，并会使用评估脚本，从pycocotools [HTG3。 此外，如果要训练期间要使用的纵横比的分组（以使每个批次仅包含具有类似的纵横比的图像），则建议也实现get_height_and_width的方法，其中返回的高度和图像的宽度。如果不提供这种方法，我们通过查询数据集的所有元素__getitem__，它加载在存储器中的图像，并且比如果提供一个自定义的方法慢。 编写自定义的数据集PennFudan 让我们写的PennFudan数据集的数据集。 下载并解压缩zip文件之后，我们有以下文件夹结构： PennFudanPed/ PedMasks/ FudanPed00001_mask.png FudanPed00002_mask.png FudanPed00003_mask.png FudanPed00004_mask.png ... PNGImages/ FudanPed00001.png FudanPed00002.png FudanPed00003.png FudanPed00004.png 这里是一对图像和分割掩码的一个实例 因此，每个图像具有对应的分割掩码，其中每个颜色对应于不同实例。让我们写一个torch.utils.data.Dataset类数据集。 import os import numpy as np import torch from PIL import Image class PennFudanDataset(object): def __init__(self, root, transforms): self.root = root self.transforms = transforms # load all image files, sorting them to # ensure that they are aligned self.imgs = list(sorted(os.listdir(os.path.join(root, \"PNGImages\")))) self.masks = list(sorted(os.listdir(os.path.join(root, \"PedMasks\")))) def __getitem__(self, idx): # load images ad masks img_path = os.path.join(self.root, \"PNGImages\", self.imgs[idx]) mask_path = os.path.join(self.root, \"PedMasks\", self.masks[idx]) img = Image.open(img_path).convert(\"RGB\") # note that we haven't converted the mask to RGB, # because each color corresponds to a different instance # with 0 being background mask = Image.open(mask_path) # convert the PIL Image into a numpy array mask = np.array(mask) # instances are encoded as different colors obj_ids = np.unique(mask) # first id is the background, so remove it obj_ids = obj_ids[1:] # split the color-encoded mask into a set # of binary masks masks = mask == obj_ids[:, None, None] # get bounding box coordinates for each mask num_objs = len(obj_ids) boxes = [] for i in range(num_objs): pos = np.where(masks[i]) xmin = np.min(pos[1]) xmax = np.max(pos[1]) ymin = np.min(pos[0]) ymax = np.max(pos[0]) boxes.append([xmin, ymin, xmax, ymax]) # convert everything into a torch.Tensor boxes = torch.as_tensor(boxes, dtype=torch.float32) # there is only one class labels = torch.ones((num_objs,), dtype=torch.int64) masks = torch.as_tensor(masks, dtype=torch.uint8) image_id = torch.tensor([idx]) area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]) # suppose all instances are not crowd iscrowd = torch.zeros((num_objs,), dtype=torch.int64) target = {} target[\"boxes\"] = boxes target[\"labels\"] = labels target[\"masks\"] = masks target[\"image_id\"] = image_id target[\"area\"] = area target[\"iscrowd\"] = iscrowd if self.transforms is not None: img, target = self.transforms(img, target) return img, target def __len__(self): return len(self.imgs) 这是所有的数据集。现在让我们来定义可以在这个数据集进行预测的模型。 自定义模型 在本文中，我们将使用面膜R-CNN ，它是基于更快R-CNN 顶部。更快的R-CNN是预测二者边界框和类得分为图像中的潜在对象的模型。 面膜R-CNN增加了额外的分支为更快R-CNN，这也预示分割掩码为每个实例。 有一个地方可能要修改torchvision modelzoo可用的车型之一两种常见的情况。第一种是当我们想从一个预先训练模型开始，只是微调的最后一层。另一种是当我们想用一个不同的替换机型的骨干（更快的预测，例如）。 让我们去看看我们会怎么做在下面的章节一种或另一种。 1 - 从一个预训练的模型微调 让我们假设你想从一个模型上COCO预先训练开始，并希望它微调您的特定类。下面是做这件事的一个可能的方式： import torchvision from torchvision.models.detection.faster_rcnn import FastRCNNPredictor # load a model pre-trained pre-trained on COCO model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True) # replace the classifier with a new one, that has # num_classes which is user-defined num_classes = 2 # 1 class (person) + background # get number of input features for the classifier in_features = model.roi_heads.box_predictor.cls_score.in_features # replace the pre-trained head with a new one model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) 2 - 修改模型添加不同的骨干 import torchvision from torchvision.models.detection import FasterRCNN from torchvision.models.detection.rpn import AnchorGenerator # load a pre-trained model for classification and return # only the features backbone = torchvision.models.mobilenet_v2(pretrained=True).features # FasterRCNN needs to know the number of # output channels in a backbone. For mobilenet_v2, it's 1280 # so we need to add it here backbone.out_channels = 1280 # let's make the RPN generate 5 x 3 anchors per spatial # location, with 5 different sizes and 3 different aspect # ratios. We have a Tuple[Tuple[int]] because each feature # map could potentially have different sizes and # aspect ratios anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),), aspect_ratios=((0.5, 1.0, 2.0),)) # let's define what are the feature maps that we will # use to perform the region of interest cropping, as well as # the size of the crop after rescaling. # if your backbone returns a Tensor, featmap_names is expected to # be [0]. More generally, the backbone should return an # OrderedDict[Tensor], and in featmap_names you can choose which # feature maps to use. roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0], output_size=7, sampling_ratio=2) # put the pieces together inside a FasterRCNN model model = FasterRCNN(backbone, num_classes=2, rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler) 对于实例分割模型PennFudan数据集 在我们的例子中，我们要微调从预先训练的模式，因为我们的数据是非常小的，所以我们将在下面的方法1号。 在这里，我们也想计算实例分割掩码，所以我们将使用面膜R-CNN： import torchvision from torchvision.models.detection.faster_rcnn import FastRCNNPredictor from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor def get_model_instance_segmentation(num_classes): # load an instance segmentation model pre-trained pre-trained on COCO model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True) # get number of input features for the classifier in_features = model.roi_heads.box_predictor.cls_score.in_features # replace the pre-trained head with a new one model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) # now get the number of input features for the mask classifier in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels hidden_layer = 256 # and replace the mask predictor with a new one model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes) return model 就是这样，这将使模型准备进行培训，并在您的自定义数据集进行评估。 将所有内容放在一起 在引用/检测/，我们有一些辅助功能，以简化培训和评估检测模型。在这里，我们将使用引用/检测/ engine.py，引用/检测/ utils.py和参考/检测/ transforms.py。把它们复制到你的文件夹，并在这里使用它们。 让我们来写数据增强/转换了一些辅助功能： import transforms as T def get_transform(train): transforms = [] transforms.append(T.ToTensor()) if train: transforms.append(T.RandomHorizontalFlip(0.5)) return T.Compose(transforms) 现在，让我们写一个执行训练和验证的主要功能： from engine import train_one_epoch, evaluate import utils def main(): # train on the GPU or on the CPU, if a GPU is not available device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') # our dataset has two classes only - background and person num_classes = 2 # use our dataset and defined transformations dataset = PennFudanDataset('PennFudanPed', get_transform(train=True)) dataset_test = PennFudanDataset('PennFudanPed', get_transform(train=False)) # split the dataset in train and test set indices = torch.randperm(len(dataset)).tolist() dataset = torch.utils.data.Subset(dataset, indices[:-50]) dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:]) # define training and validation data loaders data_loader = torch.utils.data.DataLoader( dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=utils.collate_fn) data_loader_test = torch.utils.data.DataLoader( dataset_test, batch_size=1, shuffle=False, num_workers=4, collate_fn=utils.collate_fn) # get the model using our helper function model = get_model_instance_segmentation(num_classes) # move model to the right device model.to(device) # construct an optimizer params = [p for p in model.parameters() if p.requires_grad] optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005) # and a learning rate scheduler lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1) # let's train it for 10 epochs num_epochs = 10 for epoch in range(num_epochs): # train for one epoch, printing every 10 iterations train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10) # update the learning rate lr_scheduler.step() # evaluate on the test dataset evaluate(model, data_loader_test, device=device) print(\"That's it!\") 你应该得到作为第一时期的输出： Epoch: [0] [ 0/60] eta: 0:01:18 lr: 0.000090 loss: 2.5213 (2.5213) loss_classifier: 0.8025 (0.8025) loss_box_reg: 0.2634 (0.2634) loss_mask: 1.4265 (1.4265) loss_objectness: 0.0190 (0.0190) loss_rpn_box_reg: 0.0099 (0.0099) time: 1.3121 data: 0.3024 max mem: 3485 Epoch: [0] [10/60] eta: 0:00:20 lr: 0.000936 loss: 1.3007 (1.5313) loss_classifier: 0.3979 (0.4719) loss_box_reg: 0.2454 (0.2272) loss_mask: 0.6089 (0.7953) loss_objectness: 0.0197 (0.0228) loss_rpn_box_reg: 0.0121 (0.0141) time: 0.4198 data: 0.0298 max mem: 5081 Epoch: [0] [20/60] eta: 0:00:15 lr: 0.001783 loss: 0.7567 (1.1056) loss_classifier: 0.2221 (0.3319) loss_box_reg: 0.2002 (0.2106) loss_mask: 0.2904 (0.5332) loss_objectness: 0.0146 (0.0176) loss_rpn_box_reg: 0.0094 (0.0123) time: 0.3293 data: 0.0035 max mem: 5081 Epoch: [0] [30/60] eta: 0:00:11 lr: 0.002629 loss: 0.4705 (0.8935) loss_classifier: 0.0991 (0.2517) loss_box_reg: 0.1578 (0.1957) loss_mask: 0.1970 (0.4204) loss_objectness: 0.0061 (0.0140) loss_rpn_box_reg: 0.0075 (0.0118) time: 0.3403 data: 0.0044 max mem: 5081 Epoch: [0] [40/60] eta: 0:00:07 lr: 0.003476 loss: 0.3901 (0.7568) loss_classifier: 0.0648 (0.2022) loss_box_reg: 0.1207 (0.1736) loss_mask: 0.1705 (0.3585) loss_objectness: 0.0018 (0.0113) loss_rpn_box_reg: 0.0075 (0.0112) time: 0.3407 data: 0.0044 max mem: 5081 Epoch: [0] [50/60] eta: 0:00:03 lr: 0.004323 loss: 0.3237 (0.6703) loss_classifier: 0.0474 (0.1731) loss_box_reg: 0.1109 (0.1561) loss_mask: 0.1658 (0.3201) loss_objectness: 0.0015 (0.0093) loss_rpn_box_reg: 0.0093 (0.0116) time: 0.3379 data: 0.0043 max mem: 5081 Epoch: [0] [59/60] eta: 0:00:00 lr: 0.005000 loss: 0.2540 (0.6082) loss_classifier: 0.0309 (0.1526) loss_box_reg: 0.0463 (0.1405) loss_mask: 0.1568 (0.2945) loss_objectness: 0.0012 (0.0083) loss_rpn_box_reg: 0.0093 (0.0123) time: 0.3489 data: 0.0042 max mem: 5081 Epoch: [0] Total time: 0:00:21 (0.3570 s / it) creating index... index created! Test: [ 0/50] eta: 0:00:19 model_time: 0.2152 (0.2152) evaluator_time: 0.0133 (0.0133) time: 0.4000 data: 0.1701 max mem: 5081 Test: [49/50] eta: 0:00:00 model_time: 0.0628 (0.0687) evaluator_time: 0.0039 (0.0064) time: 0.0735 data: 0.0022 max mem: 5081 Test: Total time: 0:00:04 (0.0828 s / it) Averaged stats: model_time: 0.0628 (0.0687) evaluator_time: 0.0039 (0.0064) Accumulating evaluation results... DONE (t=0.01s). Accumulating evaluation results... DONE (t=0.01s). IoU metric: bbox Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.606 Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.984 Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.780 Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313 Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.582 Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.612 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.270 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.672 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.672 Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.650 Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.755 Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664 IoU metric: segm Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.704 Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.979 Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.871 Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325 Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.488 Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.316 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.748 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.749 Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.650 Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.673 Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758 所以培训一个时期后，我们得到的60.6椰油风格的地图，以及70.4面具地图。 10个时代训练结束后，我得到了以下指标 IoU metric: bbox Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.799 Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.969 Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.935 Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.349 Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592 Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.831 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.324 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.844 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.844 Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400 Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.777 Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.870 IoU metric: segm Average Precision (AP) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.761 Average Precision (AP) @[ IoU=0.50 | area= all | maxDets=100 ] = 0.969 Average Precision (AP) @[ IoU=0.75 | area= all | maxDets=100 ] = 0.919 Average Precision (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.341 Average Precision (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.464 Average Precision (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.788 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 1 ] = 0.303 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets= 10 ] = 0.799 Average Recall (AR) @[ IoU=0.50:0.95 | area= all | maxDets=100 ] = 0.799 Average Recall (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400 Average Recall (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.769 Average Recall (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.818 但是什么预测样子的？让我们一个图像中的数据集和验证 训练的模型预测的9种人情况下，这种形象，让我们来看看他们夫妇： 结果看起来不错！ 结束语 在本教程中，你已经学会了如何创建例如分割模型自己训练的管道，在自定义的数据集。对于这一点，你写一个torch.utils.data.Dataset类，返回的图像和地面真值块和分割口罩。您还利用一个面具上COCO train2017 R-CNN模型预先训练，以这个新的数据集进行迁移学习。 对于更完整的示例，其包括多机/多GPU训练，检查引用/检测/ train.py，它是存在于torchvision回购。 你可以下载一个完整的源文件本教程[此处HTG1。 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 TorchVision对象检测教程细化和微调 定义数据集 编写自定义数据集PennFudan 自定义模型 1 - 从一个预训练的模型微调 2 - 修改模型添加不同的骨干 [HTG0用于PennFudan数据集的实例分割模型 将所有内容放在一起 结束语 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/finetuning_torchvision_models_tutorial.html":{"url":"beginner/finetuning_torchvision_models_tutorial.html","title":"微调Torchvision模型","keywords":"","body":"微调Torchvision模型 作者： 弥敦道Inkawhich 在本教程中，我们将采取在如何微调和特征提取 torchvision模型，所有这些都被预先训练的1000级Imagenet数据集更深入的了解。本教程将给予在如何与一些现代CNN架构工作的深入看，将建立一个直觉微调任何PyTorch模型。由于每个模型架构是不同的，没有样板代码细化和微调，将在所有情况下工作。相反，研究人员必须着眼于现有的架构，并为每个模型自定义调整。 在本文中，我们将执行两种类型的迁移学习的：和细化和微调特征提取。在 微调 ，我们先从预训练模式和更新 所有为我们的新任务模型的参数 ，在本质上再培训整个模型。在 特征提取 ，我们先从一个预训练的模型和仅更新从中我们推导预测最终的层的权重。这就是所谓的特征提取，因为我们使用预训练的CNN作为一个固定的功能提取，只改变输出层。有关迁移学习更多的技术信息，请参阅此处和[此处HTG9。 一般这两种传输的学习方法遵循相同的几个步骤： 初始化预训练模式 重塑最后的层（一个或多个），以具有相同的数量的输出作为类在新的数据集的数目 定义哪些参数，我们要在训练期间更新优化算法 运行训练步骤 from __future__ import print_function from __future__ import division import torch import torch.nn as nn import torch.optim as optim import numpy as np import torchvision from torchvision import datasets, models, transforms import matplotlib.pyplot as plt import time import os import copy print(\"PyTorch Version: \",torch.__version__) print(\"Torchvision Version: \",torchvision.__version__) 日期： PyTorch Version: 1.2.0 Torchvision Version: 0.4.0 输入 这里是所有的参数，为运行而改变。我们将使用 hymenoptera_data 数据集可以下载此处[HTG3。此数据集包含两类， 蜜蜂HTG5]和 蚂蚁 ，其结构是这样，我们可以使用 ImageFolder 数据集，而不是写自己的自定义数据集。下载数据和DATA_DIR输入设置为数据集的根目录下。在MODEL_NAME输入你想使用，必须从这个列表中选择模型的名称： [resnet, alexnet, vgg, squeezenet, densenet, inception] 其它输入如下：num_classes是类数据集中的数目，的batch_size是用于训练的批量大小和可根据您的机器的性能进行调整，num_epochs是我们要运行训练时期的编号，feature_extract是一个布尔值，定义，如果我们微调或特征提取。如果feature_extract = 假，模型被微调，并且所有模型参数被更新。如果feature_extract = 真，只有最后层参数被更新，其它的保持固定。 # Top level data directory. Here we assume the format of the directory conforms # to the ImageFolder structure data_dir = \"./data/hymenoptera_data\" # Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception] model_name = \"squeezenet\" # Number of classes in the dataset num_classes = 2 # Batch size for training (change depending on how much memory you have) batch_size = 8 # Number of epochs to train for num_epochs = 15 # Flag for feature extracting. When False, we finetune the whole model, # when True we only update the reshaped layer params feature_extract = True 辅助函数 之前我们写的代码，用于调整模型，让定义一些辅助功能。 模型训练和验证码 在train_model函数处理给定模型的训练和验证。作为输入，它需要一个PyTorch模型，dataloaders的词典，损失函数，优化器，一个指定数目的历元的训练和验证，和一个布尔标志，用于当模型是一个启模型。的 is_inception 标志用于以容纳 启V3 模型，因为该架构使用的辅助输出和整体模型损耗方面都辅助输出和最终的输出，如所描述的[此处HTG9。该功能用于训练历元的指定数目和每个时期后运行一个完整的验证步骤。它也跟踪性能最佳的模型（在验证准确性方面），并在训练结束返回表现最好的模型。每个历元之后，训练和验证的精度进行打印。 def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False): since = time.time() val_acc_history = [] best_model_wts = copy.deepcopy(model.state_dict()) best_acc = 0.0 for epoch in range(num_epochs): print('Epoch {}/{}'.format(epoch, num_epochs - 1)) print('-' * 10) # Each epoch has a training and validation phase for phase in ['train', 'val']: if phase == 'train': model.train() # Set model to training mode else: model.eval() # Set model to evaluate mode running_loss = 0.0 running_corrects = 0 # Iterate over data. for inputs, labels in dataloaders[phase]: inputs = inputs.to(device) labels = labels.to(device) # zero the parameter gradients optimizer.zero_grad() # forward # track history if only in train with torch.set_grad_enabled(phase == 'train'): # Get model outputs and calculate loss # Special case for inception because in training it has an auxiliary output. In train # mode we calculate the loss by summing the final output and the auxiliary output # but in testing we only consider the final output. if is_inception and phase == 'train': # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958 outputs, aux_outputs = model(inputs) loss1 = criterion(outputs, labels) loss2 = criterion(aux_outputs, labels) loss = loss1 + 0.4*loss2 else: outputs = model(inputs) loss = criterion(outputs, labels) _, preds = torch.max(outputs, 1) # backward + optimize only if in training phase if phase == 'train': loss.backward() optimizer.step() # statistics running_loss += loss.item() * inputs.size(0) running_corrects += torch.sum(preds == labels.data) epoch_loss = running_loss / len(dataloaders[phase].dataset) epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset) print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc)) # deep copy the model if phase == 'val' and epoch_acc > best_acc: best_acc = epoch_acc best_model_wts = copy.deepcopy(model.state_dict()) if phase == 'val': val_acc_history.append(epoch_acc) print() time_elapsed = time.time() - since print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) print('Best val Acc: {:4f}'.format(best_acc)) # load best model weights model.load_state_dict(best_model_wts) return model, val_acc_history 设置模型参数.requires_grad属性 这个辅助功能设置.requires_grad的参数模型中的属性设置为false，当我们特征提取。默认情况下，当我们加载预训练模型的所有参数都.requires_grad =真，这是很好的，如果我们从头开始或培训细化和微调。然而，如果我们特征提取，只要计算新初始化层梯度那么我们希望所有的其他参数不要求梯度。这将在后面更有意义。 def set_parameter_requires_grad(model, feature_extracting): if feature_extracting: for param in model.parameters(): param.requires_grad = False 初始化和重塑网络 现在到了最有趣的部分。这里我们处理每一个网络的重塑。请注意，这不是一个自动的过程，是唯一的每个模型。回想一下，CNN的模式，这是经常倍FC层的最终层，具有相同的数作为输出类别的数据集中的节点数量。由于所有的模型都被预先训练上Imagenet，它们都具有尺寸1000，为每个类一个节点的输出层。这样做的目的是为了重塑最后一层像以前一样有相同数量的输入，并拥有相同数量的输出作为类中的数据集数。在下面的章节中，我们将讨论如何单独改变每个模型的架构。但首先，有关于和细化和微调特征提取的区别一个重要的细节。 当特征提取，我们只希望更新的最后一层的参数，或者换句话说，我们只需要更新我们正在重塑层（一个或多个）的参数。因此，我们并不需要计算的参数，我们不改变梯度，所以效率，我们的.requires_grad属性设置为False。因为默认情况下，该属性设置为True，这是非常重要的。然后，当我们初始化新的层，并默认新参数有.requires_grad =真所以才有了新层的参数将被更新。当我们微调我们可以把所有的.required_grad的一套以真默认值。 最后，注意inception_v3需要输入的内容是（299299），而所有其他型号的预期（224224）。 RESNET RESNET在图像识别纸张深残余学习引入。有不同的尺寸，包括Resnet18，Resnet34，Resnet50，Resnet101和Resnet152，所有这些都可以从torchvision模型的几个变种。这里我们使用Resnet18，因为我们的数据集很小，只有两个班。当我们打印模式，我们看到，最后一层是完全连接层，如下图所示： (fc): Linear(in_features=512, out_features=1000, bias=True) 因此，我们必须重新初始化model.fc是一个线性层512点输入的特征和2层输出的功能： model.fc = nn.Linear(512, num_classes) Alexnet Alexnet是与深卷积神经网络纸 ImageNet分类介绍，是第一个非常成功的CNN在ImageNet数据集。当我们打印模型架构，我们可以看到模型输出来自分类的第6层 (classifier): Sequential( ... (6): Linear(in_features=4096, out_features=1000, bias=True) ) 要使用我们的数据使用的模型中，我们初始化该层 model.classifier[6] = nn.Linear(4096,num_classes) VGG VGG在文献[非常深卷积网络推出的大型图像识别HTG1。 Torchvision提供各种长度和一些有一批归一化层的8个版本VGG的。这里我们使用VGG-11批标准化。输出层类似于Alexnet，即 (classifier): Sequential( ... (6): Linear(in_features=4096, out_features=1000, bias=True) ) 因此，我们使用相同的技术来修改输出层 model.classifier[6] = nn.Linear(4096,num_classes) Squeezenet 所述Squeeznet体系结构在论文中描述 SqueezeNet：用50个更少的参数和AlexNet级精度& LT ; 0.5MB模型大小，并使用不同的输出结构比任何其他模型的这里显示。 Torchvision有Squeezenet的两个版本中，我们使用1.0版本。输出来自这是分类器的第一层是1x1卷积层： (classifier): Sequential( (0): Dropout(p=0.5) (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)) (2): ReLU(inplace) (3): AvgPool2d(kernel_size=13, stride=1, padding=0) ) 修改网络，我们重新初始化Conv2d层具有深度为2的输出特性图作为 model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1)) Densenet Densenet是在论文密集连接的卷积网络引入。 Torchvision有Densenet的四个变种，但在这里我们只使用Densenet-121。输出层是用1024个输入特征的线性层： (classifier): Linear(in_features=1024, out_features=1000, bias=True) 重塑网络，我们重新初始化分类的线性层 model.classifier = nn.Linear(1024, num_classes) 盗梦空间V3 最后，启V3在反思盗梦空间架构计算机视觉HTG1]首次描述。该网络是独一无二的，因为它有训练的时候两个输出层。第二输出被称为辅助输出，并且包含在该网络的AuxLogits一部分。初级输出是在网络的端部的线性层。请注意，测试我们只考虑主输出时。辅助输出和所加载的模型的主要输出被打印为： (AuxLogits): InceptionAux( ... (fc): Linear(in_features=768, out_features=1000, bias=True) ) ... (fc): Linear(in_features=2048, out_features=1000, bias=True) 微调该模块，我们必须重塑两层。这是通过下列步骤完成 model.AuxLogits.fc = nn.Linear(768, num_classes) model.fc = nn.Linear(2048, num_classes) 请注意，许多车型也有类似的输出结构，但每次都必须稍有不同的方式处理。此外，检查出重新成形网络的打印模型体系结构，并确保的输出特征的数量是相同的类中的数据集的数目。 def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True): # Initialize these variables which will be set in this if statement. Each of these # variables is model specific. model_ft = None input_size = 0 if model_name == \"resnet\": \"\"\" Resnet18 \"\"\" model_ft = models.resnet18(pretrained=use_pretrained) set_parameter_requires_grad(model_ft, feature_extract) num_ftrs = model_ft.fc.in_features model_ft.fc = nn.Linear(num_ftrs, num_classes) input_size = 224 elif model_name == \"alexnet\": \"\"\" Alexnet \"\"\" model_ft = models.alexnet(pretrained=use_pretrained) set_parameter_requires_grad(model_ft, feature_extract) num_ftrs = model_ft.classifier[6].in_features model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes) input_size = 224 elif model_name == \"vgg\": \"\"\" VGG11_bn \"\"\" model_ft = models.vgg11_bn(pretrained=use_pretrained) set_parameter_requires_grad(model_ft, feature_extract) num_ftrs = model_ft.classifier[6].in_features model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes) input_size = 224 elif model_name == \"squeezenet\": \"\"\" Squeezenet \"\"\" model_ft = models.squeezenet1_0(pretrained=use_pretrained) set_parameter_requires_grad(model_ft, feature_extract) model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1)) model_ft.num_classes = num_classes input_size = 224 elif model_name == \"densenet\": \"\"\" Densenet \"\"\" model_ft = models.densenet121(pretrained=use_pretrained) set_parameter_requires_grad(model_ft, feature_extract) num_ftrs = model_ft.classifier.in_features model_ft.classifier = nn.Linear(num_ftrs, num_classes) input_size = 224 elif model_name == \"inception\": \"\"\" Inception v3 Be careful, expects (299,299) sized images and has auxiliary output \"\"\" model_ft = models.inception_v3(pretrained=use_pretrained) set_parameter_requires_grad(model_ft, feature_extract) # Handle the auxilary net num_ftrs = model_ft.AuxLogits.fc.in_features model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes) # Handle the primary net num_ftrs = model_ft.fc.in_features model_ft.fc = nn.Linear(num_ftrs,num_classes) input_size = 299 else: print(\"Invalid model name, exiting...\") exit() return model_ft, input_size # Initialize the model for this run model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True) # Print the model we just instantiated print(model_ft) Out: SqueezeNet( (features): Sequential( (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2)) (1): ReLU(inplace=True) (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True) (3): Fire( (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1)) (squeeze_activation): ReLU(inplace=True) (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1)) (expand1x1_activation): ReLU(inplace=True) (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (expand3x3_activation): ReLU(inplace=True) ) (4): Fire( (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1)) (squeeze_activation): ReLU(inplace=True) (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1)) (expand1x1_activation): ReLU(inplace=True) (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (expand3x3_activation): ReLU(inplace=True) ) (5): Fire( (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1)) (squeeze_activation): ReLU(inplace=True) (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1)) (expand1x1_activation): ReLU(inplace=True) (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (expand3x3_activation): ReLU(inplace=True) ) (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True) (7): Fire( (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1)) (squeeze_activation): ReLU(inplace=True) (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1)) (expand1x1_activation): ReLU(inplace=True) (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (expand3x3_activation): ReLU(inplace=True) ) (8): Fire( (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1)) (squeeze_activation): ReLU(inplace=True) (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1)) (expand1x1_activation): ReLU(inplace=True) (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (expand3x3_activation): ReLU(inplace=True) ) (9): Fire( (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1)) (squeeze_activation): ReLU(inplace=True) (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1)) (expand1x1_activation): ReLU(inplace=True) (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (expand3x3_activation): ReLU(inplace=True) ) (10): Fire( (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1)) (squeeze_activation): ReLU(inplace=True) (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1)) (expand1x1_activation): ReLU(inplace=True) (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (expand3x3_activation): ReLU(inplace=True) ) (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True) (12): Fire( (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1)) (squeeze_activation): ReLU(inplace=True) (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1)) (expand1x1_activation): ReLU(inplace=True) (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (expand3x3_activation): ReLU(inplace=True) ) ) (classifier): Sequential( (0): Dropout(p=0.5, inplace=False) (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1)) (2): ReLU(inplace=True) (3): AdaptiveAvgPool2d(output_size=(1, 1)) ) ) 负载数据 现在我们知道输入的内容必须是什么，我们可以初始化数据变换，图像数据集，以及dataloaders。通知时，模型与硬编码正常化值预训练的，如所描述的这里。 # Data augmentation and normalization for training # Just normalization for validation data_transforms = { 'train': transforms.Compose([ transforms.RandomResizedCrop(input_size), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), 'val': transforms.Compose([ transforms.Resize(input_size), transforms.CenterCrop(input_size), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), } print(\"Initializing Datasets and Dataloaders...\") # Create training and validation datasets image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']} # Create training and validation dataloaders dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']} # Detect if we have a GPU available device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") Out: Initializing Datasets and Dataloaders... 创建优化 现在，该模型的结构是正确的，对于微调和特征提取的最后一步是创建一个优化，仅更新所需的参数。回想一下，在加载预训练模式后，却重塑之前，如果feature_extract =真我们手动设置所有参数的.requires_grad属性为False。然后，重新初始化层的参数有.requires_grad =真缺省。所以，现在我们知道， 已.requires_grad = true的参数应优化。 [HTG13接下来，我们做这个名单的SGD算法构造这样的参数和输入的列表。 为了验证这一点，请查看打印参数学习。微调时，该名单应该是长期的，包括所有的模型参数。然而，当特征提取这个名单应该简短，并且仅包括重塑层的权重和偏见。 # Send the model to GPU model_ft = model_ft.to(device) # Gather the parameters to be optimized/updated in this run. If we are # finetuning we will be updating all parameters. However, if we are # doing feature extract method, we will only update the parameters # that we have just initialized, i.e. the parameters with requires_grad # is True. params_to_update = model_ft.parameters() print(\"Params to learn:\") if feature_extract: params_to_update = [] for name,param in model_ft.named_parameters(): if param.requires_grad == True: params_to_update.append(param) print(\"\\t\",name) else: for name,param in model_ft.named_parameters(): if param.requires_grad == True: print(\"\\t\",name) # Observe that all parameters are being optimized optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9) Out: Params to learn: classifier.1.weight classifier.1.bias 跑训练和验证步骤 最后，最后一步就是设置为模型的损失，然后运行时期的设定次数，培训和验证功能。通知，取决于历元的数目这个步骤可能需要在CPU上一会儿。此外，默认的学习速度是不是最佳的所有车型，所以要实现有必要调整每个型号分别最高的精度。 # Setup the loss fxn criterion = nn.CrossEntropyLoss() # Train and evaluate model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\")) Out: Epoch 0/14 ---------- train Loss: 0.5200 Acc: 0.7336 val Loss: 0.3895 Acc: 0.8366 Epoch 1/14 ---------- train Loss: 0.3361 Acc: 0.8566 val Loss: 0.3015 Acc: 0.8954 Epoch 2/14 ---------- train Loss: 0.2721 Acc: 0.8770 val Loss: 0.2938 Acc: 0.8954 Epoch 3/14 ---------- train Loss: 0.2776 Acc: 0.8770 val Loss: 0.2774 Acc: 0.9150 Epoch 4/14 ---------- train Loss: 0.1881 Acc: 0.9139 val Loss: 0.2715 Acc: 0.9150 Epoch 5/14 ---------- train Loss: 0.1561 Acc: 0.9467 val Loss: 0.3201 Acc: 0.9150 Epoch 6/14 ---------- train Loss: 0.2536 Acc: 0.9016 val Loss: 0.3474 Acc: 0.9150 Epoch 7/14 ---------- train Loss: 0.1781 Acc: 0.9303 val Loss: 0.3262 Acc: 0.9150 Epoch 8/14 ---------- train Loss: 0.2321 Acc: 0.8811 val Loss: 0.3197 Acc: 0.8889 Epoch 9/14 ---------- train Loss: 0.1616 Acc: 0.9344 val Loss: 0.3161 Acc: 0.9346 Epoch 10/14 ---------- train Loss: 0.1510 Acc: 0.9262 val Loss: 0.3199 Acc: 0.9216 Epoch 11/14 ---------- train Loss: 0.1485 Acc: 0.9385 val Loss: 0.3198 Acc: 0.9216 Epoch 12/14 ---------- train Loss: 0.1098 Acc: 0.9590 val Loss: 0.3331 Acc: 0.9281 Epoch 13/14 ---------- train Loss: 0.1449 Acc: 0.9385 val Loss: 0.3556 Acc: 0.9281 Epoch 14/14 ---------- train Loss: 0.1405 Acc: 0.9303 val Loss: 0.4227 Acc: 0.8758 Training complete in 0m 20s Best val Acc: 0.934641 与模型对比从头训练有素 只是为了好玩，让我们看看模型如何学习，如果我们不使用迁移学习。微调与特征提取的性能很大程度上取决于数据集，但一般都转移学习方法产生的训练时间和整体精度与从头开始训练的模型方面是有利的结果。 # Initialize the non-pretrained version of the model used for this run scratch_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False) scratch_model = scratch_model.to(device) scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9) scratch_criterion = nn.CrossEntropyLoss() _,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\")) # Plot the training curves of validation accuracy vs. number # of training epochs for the transfer learning method and # the model trained from scratch ohist = [] shist = [] ohist = [h.cpu().numpy() for h in hist] shist = [h.cpu().numpy() for h in scratch_hist] plt.title(\"Validation Accuracy vs. Number of Training Epochs\") plt.xlabel(\"Training Epochs\") plt.ylabel(\"Validation Accuracy\") plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\") plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\") plt.ylim((0,1.)) plt.xticks(np.arange(1, num_epochs+1, 1.0)) plt.legend() plt.show() Out: Epoch 0/14 ---------- train Loss: 0.7032 Acc: 0.5205 val Loss: 0.6931 Acc: 0.4641 Epoch 1/14 ---------- train Loss: 0.6931 Acc: 0.5000 val Loss: 0.6931 Acc: 0.4641 Epoch 2/14 ---------- train Loss: 0.6931 Acc: 0.4549 val Loss: 0.6931 Acc: 0.4641 Epoch 3/14 ---------- train Loss: 0.6931 Acc: 0.5041 val Loss: 0.6931 Acc: 0.4641 Epoch 4/14 ---------- train Loss: 0.6931 Acc: 0.5041 val Loss: 0.6931 Acc: 0.4641 Epoch 5/14 ---------- train Loss: 0.6931 Acc: 0.5656 val Loss: 0.6931 Acc: 0.4641 Epoch 6/14 ---------- train Loss: 0.6931 Acc: 0.4467 val Loss: 0.6931 Acc: 0.4641 Epoch 7/14 ---------- train Loss: 0.6932 Acc: 0.5123 val Loss: 0.6931 Acc: 0.4641 Epoch 8/14 ---------- train Loss: 0.6931 Acc: 0.4918 val Loss: 0.6931 Acc: 0.4641 Epoch 9/14 ---------- train Loss: 0.6931 Acc: 0.4754 val Loss: 0.6931 Acc: 0.4641 Epoch 10/14 ---------- train Loss: 0.6931 Acc: 0.4795 val Loss: 0.6931 Acc: 0.4641 Epoch 11/14 ---------- train Loss: 0.6931 Acc: 0.5205 val Loss: 0.6931 Acc: 0.4641 Epoch 12/14 ---------- train Loss: 0.6931 Acc: 0.4754 val Loss: 0.6931 Acc: 0.4641 Epoch 13/14 ---------- train Loss: 0.6932 Acc: 0.4590 val Loss: 0.6931 Acc: 0.4641 Epoch 14/14 ---------- train Loss: 0.6932 Acc: 0.5082 val Loss: 0.6931 Acc: 0.4641 Training complete in 0m 29s Best val Acc: 0.464052 最后的思考和下一步是什么 尝试运行一些其他的车型，看看准确度有多好得。此外，请注意特征提取花费较少的时间，因为在落后的过程中，我们没有计算大部分的梯度。有很多地方从这里走。你可以： 运行该代码与较硬的数据集，看迁移学习一些更多的好处 使用这里描述的方法，使用传输学习来更新不同的模式，也许在一个新的领域（即NLP，音频等） 一旦你满意的模型，您可以将其导出为ONNX模型或使用混合前端更快的速度和优化的机会进行跟踪。 脚本的总运行时间： （0分钟56.849秒） Download Python source code: finetuning_torchvision_models_tutorial.py Download Jupyter notebook: finetuning_torchvision_models_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 微调Torchvision模型 输入 辅助函数 型号培训和验证码 设置模型参数.requires_grad属性 初始化和重塑网络 RESNET Alexnet VGG Squeezenet Densenet 启V3 负载数据 创建优化 运行训练和验证步骤 与从头经过培训的模型对比 最后的思考和下一步是什么 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"intermediate/spatial_transformer_tutorial.html":{"url":"intermediate/spatial_transformer_tutorial.html","title":"空间变压器网络教程","keywords":"","body":"空间变压器网络教程 作者 ： Ghassen HAMROUNI 在本教程中，您将学习如何使用称为空间变压器网络视觉注意机制来增强你的网络。你可以阅读更多有关在 DeepMind纸空间变压器网 空间变压器网络是微注意泛化到任何空间变换。空间变换器网络（STN的简称）允许一个神经网络学习如何以提高模型的几何不变性的输入图像上执行空间变换。例如，它可以裁剪的兴趣，规模区域和纠正图像的方向。它可以是一个有用的机制，因为细胞神经网络的不不变的旋转和缩放，更全面的仿射变换。 其中一件关于STN的最好的事情就是简单地把它用很少的修改插入到任何现有CNN的能力。 # License: BSD # Author: Ghassen Hamrouni from __future__ import print_function import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim import torchvision from torchvision import datasets, transforms import matplotlib.pyplot as plt import numpy as np plt.ion() # interactive mode 加载数据 在这篇文章中，我们尝试用经典MNIST数据集。使用具有空间变换网络增加一个标准的卷积网络。 device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Training dataset train_loader = torch.utils.data.DataLoader( datasets.MNIST(root='.', train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=64, shuffle=True, num_workers=4) # Test dataset test_loader = torch.utils.data.DataLoader( datasets.MNIST(root='.', train=False, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=64, shuffle=True, num_workers=4) 日期： Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw Processing... Done! 描绘空间变换器网络 空间变压器网络可以归结为三个主要组成部分： 本地化网络是一个普通的CNN其倒退的转换参数。转型是永远不会从这个数据集显式地了解到，而非网络自动学习的空间变换，增强全球精度。 网格生成器生成对应于来自所述输出图像的每个像素在输入图像中的坐标的网格。 采样器，使用变换的参数，并将其应用于输入图像。 Note 我们需要最新版本PyTorch的包含affine_grid和grid_sample模块。 class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 10, kernel_size=5) self.conv2 = nn.Conv2d(10, 20, kernel_size=5) self.conv2_drop = nn.Dropout2d() self.fc1 = nn.Linear(320, 50) self.fc2 = nn.Linear(50, 10) # Spatial transformer localization-network self.localization = nn.Sequential( nn.Conv2d(1, 8, kernel_size=7), nn.MaxPool2d(2, stride=2), nn.ReLU(True), nn.Conv2d(8, 10, kernel_size=5), nn.MaxPool2d(2, stride=2), nn.ReLU(True) ) # Regressor for the 3 * 2 affine matrix self.fc_loc = nn.Sequential( nn.Linear(10 * 3 * 3, 32), nn.ReLU(True), nn.Linear(32, 3 * 2) ) # Initialize the weights/bias with identity transformation self.fc_loc[2].weight.data.zero_() self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float)) # Spatial transformer network forward function def stn(self, x): xs = self.localization(x) xs = xs.view(-1, 10 * 3 * 3) theta = self.fc_loc(xs) theta = theta.view(-1, 2, 3) grid = F.affine_grid(theta, x.size()) x = F.grid_sample(x, grid) return x def forward(self, x): # transform the input x = self.stn(x) # Perform the usual forward pass x = F.relu(F.max_pool2d(self.conv1(x), 2)) x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) x = x.view(-1, 320) x = F.relu(self.fc1(x)) x = F.dropout(x, training=self.training) x = self.fc2(x) return F.log_softmax(x, dim=1) model = Net().to(device) 培养模式 现在，让我们使用SGD算法训练模型。该网络学习在监督方式的分类任务。在同一时间模型在一个终端到高端时尚自动学习STN。 optimizer = optim.SGD(model.parameters(), lr=0.01) def train(epoch): model.train() for batch_idx, (data, target) in enumerate(train_loader): data, target = data.to(device), target.to(device) optimizer.zero_grad() output = model(data) loss = F.nll_loss(output, target) loss.backward() optimizer.step() if batch_idx % 500 == 0: print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item())) # # A simple test procedure to measure STN the performances on MNIST. # def test(): with torch.no_grad(): model.eval() test_loss = 0 correct = 0 for data, target in test_loader: data, target = data.to(device), target.to(device) output = model(data) # sum up batch loss test_loss += F.nll_loss(output, target, size_average=False).item() # get the index of the max log-probability pred = output.max(1, keepdim=True)[1] correct += pred.eq(target.view_as(pred)).sum().item() test_loss /= len(test_loader.dataset) print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n' .format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset))) 可视化STN结果 现在，我们要来视察我们了解到视觉注意机制的结果。 我们以可视化，同时训练转变定义一个小助手功能。 def convert_image_np(inp): \"\"\"Convert a Tensor to numpy image.\"\"\" inp = inp.numpy().transpose((1, 2, 0)) mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) inp = std * inp + mean inp = np.clip(inp, 0, 1) return inp # We want to visualize the output of the spatial transformers layer # after the training, we visualize a batch of input images and # the corresponding transformed batch using STN. def visualize_stn(): with torch.no_grad(): # Get a batch of training data data = next(iter(test_loader))[0].to(device) input_tensor = data.cpu() transformed_input_tensor = model.stn(data).cpu() in_grid = convert_image_np( torchvision.utils.make_grid(input_tensor)) out_grid = convert_image_np( torchvision.utils.make_grid(transformed_input_tensor)) # Plot the results side-by-side f, axarr = plt.subplots(1, 2) axarr[0].imshow(in_grid) axarr[0].set_title('Dataset Images') axarr[1].imshow(out_grid) axarr[1].set_title('Transformed Images') for epoch in range(1, 20 + 1): train(epoch) test() # Visualize the STN transformation on some input batch visualize_stn() plt.ioff() plt.show() Out: Train Epoch: 1 [0/60000 (0%)] Loss: 2.290877 Train Epoch: 1 [32000/60000 (53%)] Loss: 0.910913 Test set: Average loss: 0.2449, Accuracy: 9312/10000 (93%) Train Epoch: 2 [0/60000 (0%)] Loss: 0.489534 Train Epoch: 2 [32000/60000 (53%)] Loss: 0.296471 Test set: Average loss: 0.1443, Accuracy: 9563/10000 (96%) Train Epoch: 3 [0/60000 (0%)] Loss: 0.410248 Train Epoch: 3 [32000/60000 (53%)] Loss: 0.355454 Test set: Average loss: 0.1019, Accuracy: 9687/10000 (97%) Train Epoch: 4 [0/60000 (0%)] Loss: 0.217658 Train Epoch: 4 [32000/60000 (53%)] Loss: 0.185522 Test set: Average loss: 0.0818, Accuracy: 9751/10000 (98%) Train Epoch: 5 [0/60000 (0%)] Loss: 0.471464 Train Epoch: 5 [32000/60000 (53%)] Loss: 0.591574 Test set: Average loss: 0.0770, Accuracy: 9760/10000 (98%) Train Epoch: 6 [0/60000 (0%)] Loss: 0.119462 Train Epoch: 6 [32000/60000 (53%)] Loss: 0.093015 Test set: Average loss: 0.0817, Accuracy: 9744/10000 (97%) Train Epoch: 7 [0/60000 (0%)] Loss: 0.074523 Train Epoch: 7 [32000/60000 (53%)] Loss: 0.414406 Test set: Average loss: 0.0944, Accuracy: 9714/10000 (97%) Train Epoch: 8 [0/60000 (0%)] Loss: 0.100317 Train Epoch: 8 [32000/60000 (53%)] Loss: 0.114539 Test set: Average loss: 0.1519, Accuracy: 9510/10000 (95%) Train Epoch: 9 [0/60000 (0%)] Loss: 0.205053 Train Epoch: 9 [32000/60000 (53%)] Loss: 0.135724 Test set: Average loss: 0.0892, Accuracy: 9749/10000 (97%) Train Epoch: 10 [0/60000 (0%)] Loss: 0.213368 Train Epoch: 10 [32000/60000 (53%)] Loss: 0.208627 Test set: Average loss: 0.0634, Accuracy: 9813/10000 (98%) Train Epoch: 11 [0/60000 (0%)] Loss: 0.078725 Train Epoch: 11 [32000/60000 (53%)] Loss: 0.099131 Test set: Average loss: 0.0580, Accuracy: 9834/10000 (98%) Train Epoch: 12 [0/60000 (0%)] Loss: 0.133572 Train Epoch: 12 [32000/60000 (53%)] Loss: 0.213358 Test set: Average loss: 0.0506, Accuracy: 9854/10000 (99%) Train Epoch: 13 [0/60000 (0%)] Loss: 0.289802 Train Epoch: 13 [32000/60000 (53%)] Loss: 0.165571 Test set: Average loss: 0.0542, Accuracy: 9842/10000 (98%) Train Epoch: 14 [0/60000 (0%)] Loss: 0.219281 Train Epoch: 14 [32000/60000 (53%)] Loss: 0.284233 Test set: Average loss: 0.0505, Accuracy: 9856/10000 (99%) Train Epoch: 15 [0/60000 (0%)] Loss: 0.218599 Train Epoch: 15 [32000/60000 (53%)] Loss: 0.055698 Test set: Average loss: 0.0507, Accuracy: 9848/10000 (98%) Train Epoch: 16 [0/60000 (0%)] Loss: 0.048718 Train Epoch: 16 [32000/60000 (53%)] Loss: 0.093410 Test set: Average loss: 0.0502, Accuracy: 9855/10000 (99%) Train Epoch: 17 [0/60000 (0%)] Loss: 0.071185 Train Epoch: 17 [32000/60000 (53%)] Loss: 0.053381 Test set: Average loss: 0.0587, Accuracy: 9829/10000 (98%) Train Epoch: 18 [0/60000 (0%)] Loss: 0.127790 Train Epoch: 18 [32000/60000 (53%)] Loss: 0.169319 Test set: Average loss: 0.0484, Accuracy: 9863/10000 (99%) Train Epoch: 19 [0/60000 (0%)] Loss: 0.224094 Train Epoch: 19 [32000/60000 (53%)] Loss: 0.175750 Test set: Average loss: 0.0628, Accuracy: 9817/10000 (98%) Train Epoch: 20 [0/60000 (0%)] Loss: 0.251131 Train Epoch: 20 [32000/60000 (53%)] Loss: 0.024119 Test set: Average loss: 0.0445, Accuracy: 9869/10000 (99%) 脚本的总运行时间： （1分钟44.448秒） Download Python source code: spatial_transformer_tutorial.py Download Jupyter notebook: spatial_transformer_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 空间变压器网络教程 加载数据 各取空间变换器网络 训练模型 形象化STN结果 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"advanced/neural_style_tutorial.html":{"url":"advanced/neural_style_tutorial.html","title":"使用PyTorch进行神经网络传递","keywords":"","body":"神经网络传输使用PyTorch 作者 ：亚历克西黄灯笼 由 编辑：温斯顿鲱鱼 简介 本教程介绍了如何实现神经类型算法开发由Leon A. Gatys，亚历山大S.埃克和Matthias贝特格。神经风格，或神经传输，让您拍摄图像，并用新的艺术风格重现。该算法需要三个图像，输入图像，内容的图像，和一个样式图象，并且改变输入到类似于内容的图像的内容和样式图像的艺术风格。 基本原理 原理很简单：我们定义两个距离，一个是内容（ \\（D_C \\）HTG1]），一个用于样式（ \\（D_S \\）HTG3]）。 \\（D_C \\）的含量如何不同是两个图像之间的措施而 \\（D_S \\）措施的样式如何不同是两个图像之间。然后，我们把第三图像，输入，并将其转换以最大限度地减小其内容的距离与内容的图像，并与风格像它的风格距离。现在，我们可以导入必要的软件包，并开始神经传递。 导入包和选择设备 下面是实现神经传送所需的包的列表。 torch，torch.nn，numpy的（包赛前必读用于与神经网络PyTorch） torch.optim（有效梯度下坡） PIL，PIL.Image，matplotlib.pyplot（负载和显示图像） torchvision.transforms（变换PIL图像转换成张量） torchvision.models（火车或载预训练的模型） 复制（深拷贝的模型;系统封装） from __future__ import print_function import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim from PIL import Image import matplotlib.pyplot as plt import torchvision.transforms as transforms import torchvision.models as models import copy 接下来，我们需要选择在运行网络，设备和导入的内容和风格的图像。大图像运行的神经传递算法需要更长的时间，并在GPU上运行时，会快很多。我们可以使用torch.cuda.is_available（），以检测是否有可用的GPU。接下来，我们设置了torch.device在整个教程中使用。另外，。要（装置）方法用于张量或模块移动到期望的设备。 device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") 加载图像 现在，我们将导入的风格和内容的图像。原始PIL图像具有值0和255之间，但是，当转化入Torch 张量，它们的值被转换为0和1之间的图像也需要被调整到具有相同的尺寸。要注意的重要细节是，从Torch 库神经网络与张量值范围从0到1的培训。如果你尝试用0到255张图像喂网络，然后激活功能的地图将无法意义上的预期内容和风格。但是，从来自Caffe库预训练的网络被训练，用0至255张量的图像。 Note 通过以下链接下载到运行教程所需的图像： picasso.jpg 和[ dancing.jpg HTG3。下载这两个图像，并将它们与名称图像在当前工作目录添加到目录中。 # desired size of the output image imsize = 512 if torch.cuda.is_available() else 128 # use small size if no gpu loader = transforms.Compose([ transforms.Resize(imsize), # scale imported image transforms.ToTensor()]) # transform it into a torch tensor def image_loader(image_name): image = Image.open(image_name) # fake batch dimension required to fit network's input dimensions image = loader(image).unsqueeze(0) return image.to(device, torch.float) style_img = image_loader(\"./data/images/neural-style/picasso.jpg\") content_img = image_loader(\"./data/images/neural-style/dancing.jpg\") assert style_img.size() == content_img.size(), \\ \"we need to import style and content images of the same size\" 现在，让我们创建一个由再转它的一个副本，以PIL格式，并使用plt.imshow显示复制显示图像的功能。我们会尽量显示内容和风格的图像，以确保他们正确导入。 unloader = transforms.ToPILImage() # reconvert into PIL image plt.ion() def imshow(tensor, title=None): image = tensor.cpu().clone() # we clone the tensor to not do changes on it image = image.squeeze(0) # remove the fake batch dimension image = unloader(image) plt.imshow(image) if title is not None: plt.title(title) plt.pause(0.001) # pause a bit so that plots are updated plt.figure() imshow(style_img, title='Style Image') plt.figure() imshow(content_img, title='Content Image') 损失函数 丢失内容 内容损失是代表内容的距离为一个单独层的加权的版本的功能。该函数采用特征地图 \\（F {XL} \\）的层 \\（L \\）在一个网络处理输入 \\（X \\）并返回该内容加权距离 \\（W {CL} .DC ^ L（X，C）\\）的图像之间 \\（X \\）和内容图像 \\（C \\）。所述内容图像的特征映射（ \\（F {CL} \\））必须由功能，以计算其含量距离是已知的。我们用一个构造函数 \\（F {CL} \\）作为输入实现该功能作为torch模块。的距离 \\（\\ | F {XL} - F_ {CL} \\ | ^ 2 \\）是两组特征地图之间的均方误差，并且可以使用[计算HTG19 ] nn.MSELoss。 我们将直接正在用于计算内容距离的卷积层（一个或多个）之后添加该内容损耗模块。此每个网络被供给的输入图像内容的损失将在所希望的层被计算并因为汽车研究所的，所有的梯度将被计算时间的方法。现在，为了使内容损耗层透明我们必须定义计算含量损失，然后返回层的输入向前方法。所计算的损失被保存为模块的参数。 class ContentLoss(nn.Module): def __init__(self, target,): super(ContentLoss, self).__init__() # we 'detach' the target content from the tree used # to dynamically compute the gradient: this is a stated value, # not a variable. Otherwise the forward method of the criterion # will throw an error. self.target = target.detach() def forward(self, input): self.loss = F.mse_loss(input, self.target) return input Note 重要细节 ：虽然这个模块被命名为ContentLoss，它是不是一个真正的PyTorch损失函数。如果你要定义你的内容的损失为PyTorch损失函数，你必须创建一个PyTorch autograd功能重新计算/在后退方法手动实现梯度。 风格损失 风格损失模块类似地实现对内容的损失模块。它将作为其计算该层的风格损失的网络中的透明层。为了计算的样式的损失，我们需要计算克矩阵 \\（G {XL} \\）。甲克矩阵是通过它的转置矩阵的给定矩阵相乘的结果。在本申请中给出的矩阵是特征的重整的版本映射 \\（F {XL} \\）层 \\（L \\） 。 \\（F {XL} \\）被整形以形成 \\（\\帽子{F} {XL} \\），A \\（K \\） X \\（N \\）矩阵，其中 \\（K \\）是特征图中的层 \\（L \\）和数\\ （N \\）是任何量化特征地图 \\（F {XL} ^ķ\\）的长度。例如，的第一行\\（\\帽子{F} {XL} \\）对应于第一量化特征地图 \\（F_ {XL} ^ 1 \\）。 最后，克矩阵必须由在矩阵元素的总数量除以每个元素进行归一化。这种归一化是为了抵消这一事实 \\（\\帽子{F} _ {XL} \\）具有大 \\（N \\）维产量较大的革兰氏矩阵值的矩阵。这些较大的值将导致第一层（池层之前），以具有梯度下降期间产生更大的影响。风格特征往往是在网络的更深层所以这归一化步骤是至关重​​要的。 def gram_matrix(input): a, b, c, d = input.size() # a=batch size(=1) # b=number of feature maps # (c,d)=dimensions of a f. map (N=c*d) features = input.view(a * b, c * d) # resise F_XL into \\hat F_XL G = torch.mm(features, features.t()) # compute the gram product # we 'normalize' the values of the gram matrix # by dividing by the number of element in each feature maps. return G.div(a * b * c * d) 现在的风格损耗模块看起来几乎完全一样的内容损失模块。样式距离使用之间的均方误差还计算\\（G {XL} \\）和 \\（G {SL} \\）。 class StyleLoss(nn.Module): def __init__(self, target_feature): super(StyleLoss, self).__init__() self.target = gram_matrix(target_feature).detach() def forward(self, input): G = gram_matrix(input) self.loss = F.mse_loss(G, self.target) return input 导入模型 现在，我们需要进口预训练的神经网络。我们将使用19层VGG网络就像在纸中使用的一个。 PyTorch的实现VGG的是分成两个子序贯模块的模块：特征（含有卷积和集中层），和分类（含有完全连接层）。我们将使用功能模块，因为我们需要的个体卷积层的输出来衡量内容和风格的损失。一些层具有比训练评估过程中不同的行为，所以我们必须用.eval（）设置网络为评估模式。 cnn = models.vgg19(pretrained=True).features.to(device).eval() 此外，VGG网络上的图像训练与由平均归一化每个信道= [0.485，0.456，0.406]和std = [0.229，0.224，0.225]。我们将使用它们发送到其网络之前正常化的形象。 cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device) cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device) # create a module to normalize input image so we can easily put it in a # nn.Sequential class Normalization(nn.Module): def __init__(self, mean, std): super(Normalization, self).__init__() # .view the mean and std to make them [C x 1 x 1] so that they can # directly work with image Tensor of shape [B x C x H x W]. # B is batch size. C is number of channels. H is height and W is width. self.mean = torch.tensor(mean).view(-1, 1, 1) self.std = torch.tensor(std).view(-1, 1, 1) def forward(self, img): # normalize img return (img - self.mean) / self.std A 顺序模块包含的子模块的有序列表。例如，vgg19.features包含在深度的正确的顺序排列的序列（Conv2d，RELU，MaxPool2d，Conv2d，RELU ...）。我们需要他们检测的卷积层后立即加入我们的内容损失和风格损失层。要做到这一点，我们必须创建一个具有内容损失和风格损失模块正确地插入一个新的顺序模块。 # desired depth layers to compute style/content losses : content_layers_default = ['conv_4'] style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5'] def get_style_model_and_losses(cnn, normalization_mean, normalization_std, style_img, content_img, content_layers=content_layers_default, style_layers=style_layers_default): cnn = copy.deepcopy(cnn) # normalization module normalization = Normalization(normalization_mean, normalization_std).to(device) # just in order to have an iterable access to or list of content/syle # losses content_losses = [] style_losses = [] # assuming that cnn is a nn.Sequential, so we make a new nn.Sequential # to put in modules that are supposed to be activated sequentially model = nn.Sequential(normalization) i = 0 # increment every time we see a conv for layer in cnn.children(): if isinstance(layer, nn.Conv2d): i += 1 name = 'conv_{}'.format(i) elif isinstance(layer, nn.ReLU): name = 'relu_{}'.format(i) # The in-place version doesn't play very nicely with the ContentLoss # and StyleLoss we insert below. So we replace with out-of-place # ones here. layer = nn.ReLU(inplace=False) elif isinstance(layer, nn.MaxPool2d): name = 'pool_{}'.format(i) elif isinstance(layer, nn.BatchNorm2d): name = 'bn_{}'.format(i) else: raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__)) model.add_module(name, layer) if name in content_layers: # add content loss: target = model(content_img).detach() content_loss = ContentLoss(target) model.add_module(\"content_loss_{}\".format(i), content_loss) content_losses.append(content_loss) if name in style_layers: # add style loss: target_feature = model(style_img).detach() style_loss = StyleLoss(target_feature) model.add_module(\"style_loss_{}\".format(i), style_loss) style_losses.append(style_loss) # now we trim off the layers after the last content and style losses for i in range(len(model) - 1, -1, -1): if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss): break model = model[:(i + 1)] return model, style_losses, content_losses 接下来，我们选择输入图像。您可以使用内容的图像或白噪声的副本。 input_img = content_img.clone() # if you want to use white noise instead uncomment the below line: # input_img = torch.randn(content_img.data.size(), device=device) # add the original input image to the figure: plt.figure() imshow(input_img, title='Input Image') 梯度下降 正如莱昂Gatys，算法的作者，建议此处，我们将使用L- BFGS算法来运行我们的梯度下降。训练不同的网络，我们希望培养的输入图像，以尽量减少对内容/格式的损失。我们将创建一个PyTorch L-BFGS优化optim.LBFGS和我们的形象传递给它的张量来优化。 def get_input_optimizer(input_img): # this line to show that input is a parameter that requires a gradient optimizer = optim.LBFGS([input_img.requires_grad_()]) return optimizer 最后，我们必须定义执行的神经传递的功能。对于网络中的每个迭代中，它被馈送的更新的输入，并计算新的损失。我们将运行后退每个损耗模块的方法来dynamicaly计算其梯度。优化需要一个“关闭”功能，重新评估的模件，并返回损失。 我们还有最后一个约束来解决。该网络可以尝试与超过该图像的0到1张量范围内的值，以优化的输入。我们可以通过校正所述输入值是网络运行每次之间0至1解决这个问题。 def run_style_transfer(cnn, normalization_mean, normalization_std, content_img, style_img, input_img, num_steps=300, style_weight=1000000, content_weight=1): \"\"\"Run the style transfer.\"\"\" print('Building the style transfer model..') model, style_losses, content_losses = get_style_model_and_losses(cnn, normalization_mean, normalization_std, style_img, content_img) optimizer = get_input_optimizer(input_img) print('Optimizing..') run = [0] while run[0] 最后，我们可以运行的算法。 output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std, content_img, style_img, input_img) plt.figure() imshow(output, title='Output Image') # sphinx_gallery_thumbnail_number = 4 plt.ioff() plt.show() 日期： Building the style transfer model.. Optimizing.. run [50]: Style Loss : 4.169304 Content Loss: 4.235329 run [100]: Style Loss : 1.145476 Content Loss: 3.039176 run [150]: Style Loss : 0.716769 Content Loss: 2.663749 run [200]: Style Loss : 0.476047 Content Loss: 2.500893 run [250]: Style Loss : 0.347092 Content Loss: 2.410895 run [300]: Style Loss : 0.263698 Content Loss: 2.358449 脚本的总运行时间： （1分钟9.573秒） Download Python source code: neural_style_tutorial.py Download Jupyter notebook: neural_style_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 神经网络传输使用PyTorch 介绍 基本原理 导入包和选择设备 加载图像 损失函数 内容丢失 风格损失 导入模型 梯度下降 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/fgsm_tutorial.html":{"url":"beginner/fgsm_tutorial.html","title":"对抗性示例生成","keywords":"","body":"对抗性实施例代 作者： 弥敦道Inkawhich 如果你正在读这篇文章，希望你能明白一些机器学习模型的有效性如何。研究正不断ML车型更快，更准确，更高效。然而，设计和培训模式的一个经常被忽视的方面是安全性和稳健性，尤其是在谁愿意来愚弄模型对手的脸。 本教程将提高你的意识，以ML车型的安全漏洞，并会深入了解对抗机器学习的热门话题。你可能会惊讶地发现，加入不易察觉的扰动到图像 可以 导致截然不同的模型性能。考虑到这是一个教程中，我们将探讨在图像分类通过例子的话题。具体来说，我们将使用的第一个也是最流行的攻击方式之一，快速倾斜的符号攻击（FGSM），愚弄的MNIST分类。 威胁模型 对于背景下，有许多种类的敌对攻击，每一个不同的目标和攻击者的知识假设。然而，一般的总体目标是扰动的至少量添加到所述输入数据，以使所期望的错误分类。有几种类型的攻击者的知识的假设，其中两个是： 白盒 和 黑盒[HTG3。 A 白盒 攻击假定攻击者具有充分的知识，并获得了模型，包括体系结构，输入，输出，和权重。 A 黑箱 攻击假定攻击者只能访问输入和模型的输出，并且一无所知底层架构或权重。也有几种类型的目标，包括 误分类 和 源/目标误分类 。的 误判 一个目标是指对手只希望输出的分类是错误的，但并不关心新的分类是什么。 A 源/目标误分类 表示对手想要改变图像是特定源类的最初使得其被归类为特定的目标类。 在这种情况下，FGSM攻击是一种 白盒 攻击与 误判 的目标。在这样的背景信息，现在我们可以详细讨论了攻击。 快速倾斜的符号攻击 之一的第一和最流行的对抗攻击日期被称为 快速梯度注册攻击（FGSM） 并且由Goodfellow等说明。人。在解释和治理对抗性实施例。这种攻击是非常强大的，可是直觉。它的目的是通过充分利用他们学习的方式来攻击神经网络， 梯度[HTG5。这个想法是简单的，而不是工作，通过调整基于所述backpropagated梯度的权重，以尽量减少损失，攻击 调整输入数据以最大化基于相同backpropagated梯度的丧失 。换句话说，该攻击使用的损失w.r.t输入数据的梯度，然后调整输入数据以最大化损失。 在我们跳进代码，让我们来看看著名的 FGSM 熊猫例子，提取一些符号。 从该图中， \\（\\ mathbf {X} \\）是正确归类为“熊猫”， \\（Y \\）原始输入图像是用于地面实况标签 \\（\\ mathbf {X} \\）， \\（\\ mathbf {\\ THETA} \\）表示的模型参数，并 \\（j（\\ mathbf {\\ THETA} ，\\ mathbf {X}，y）的\\）是用于训练网络的损失。攻击backpropagates梯度回输入的数据来计算 \\（\\ nabla {X}Ĵ（\\ mathbf {\\ THETA}，\\ mathbf {X}，y）的\\）。然后，它调整由小步骤中的输入数据（ \\（\\小量\\）或 \\（0.007 \\）在画面）的方向（即， \\（符号（\\ nabla {X}Ĵ（\\ mathbf {\\ THETA}，\\ mathbf {X}，y）的）\\）），其将最大限度地损失。将得到的扰动图像， \\（X'\\），然后错误分类由目标网络为‘长臂猿’时，它仍然是明确了‘熊猫’ 。 现在希望本教程的动机很明显，所以让我们跳进实施。 from __future__ import print_function import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim from torchvision import datasets, transforms import numpy as np import matplotlib.pyplot as plt 实现 在本节中，我们将讨论的输入参数的教程，确定受到攻击的模型，然后编码攻击和运行一些测试。 输入 只有三个输入本教程，并定义如下： epsilons - 小量值的列表以用于运行。它保持0在列表中，因为它代表了原始的测试集模型的性能是非常重要的。此外，直观我们希望越大ε，更明显的扰动，但是在分解模型精度方面更有效的攻击。由于数据范围这里是 \\（[0,1] \\），没有小量值不应超过1。 pretrained_model - 路径，将其用训练预训练的模型MNIST pytorch /示例/ MNIST 。为简单起见，下载预训练的模型[此处HTG5。 use_cuda - 布尔标志到如果需要和可用使用CUDA。请注意，本教程为CPU不会花费太多的时间与CUDA GPU的并不重要。 epsilons = [0, .05, .1, .15, .2, .25, .3] pretrained_model = \"data/lenet_mnist_model.pth\" use_cuda=True 模式下的攻击 如所提到的，在攻击该模型是从 pytorch /示例/ MNIST 相同MNIST模型。你可以训练并保存自己的MNIST模型，或者你可以下载和使用所提供的模型。的 净 定义和测试的DataLoader这里已经从MNIST示例复制。本部分的目的是定义模型和的DataLoader，然后初始化模型并加载预训练的权重。 # LeNet Model definition class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 10, kernel_size=5) self.conv2 = nn.Conv2d(10, 20, kernel_size=5) self.conv2_drop = nn.Dropout2d() self.fc1 = nn.Linear(320, 50) self.fc2 = nn.Linear(50, 10) def forward(self, x): x = F.relu(F.max_pool2d(self.conv1(x), 2)) x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) x = x.view(-1, 320) x = F.relu(self.fc1(x)) x = F.dropout(x, training=self.training) x = self.fc2(x) return F.log_softmax(x, dim=1) # MNIST Test dataset and dataloader declaration test_loader = torch.utils.data.DataLoader( datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([ transforms.ToTensor(), ])), batch_size=1, shuffle=True) # Define what device we are using print(\"CUDA Available: \",torch.cuda.is_available()) device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\") # Initialize the network model = Net().to(device) # Load the pretrained model model.load_state_dict(torch.load(pretrained_model, map_location='cpu')) # Set the model in evaluation mode. In this case this is for the Dropout layers model.eval() 日期： Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw Processing... Done! CUDA Available: True FGSM攻击 现在，我们可以定义通过扰乱原来的输入产生对抗的例子功能。的fgsm_attack函数有三个输入， 图像 是原始干净图像（ \\（X \\））， 的ε- 为逐像素扰动量（ \\（\\小量\\））和 data_grad 是损失WRT的梯度来确定输入图像（ \\（\\ nabla_ { X}Ĵ（\\ mathbf {\\ THETA}，\\ mathbf {X}，y）的\\））。然后，该函数产生扰动的图像作为 \\[perturbed\\image = image + epsilonsign(data\\_grad) = x + \\epsilon sign(\\nabla{x} J(\\mathbf{\\theta}, \\mathbf{x}, y))\\] 最后，为了保持数据的原始范围，对于扰动的图像被夹到范围 \\（[0,1] \\）。 # FGSM attack code def fgsm_attack(image, epsilon, data_grad): # Collect the element-wise sign of the data gradient sign_data_grad = data_grad.sign() # Create the perturbed image by adjusting each pixel of the input image perturbed_image = image + epsilon*sign_data_grad # Adding clipping to maintain [0,1] range perturbed_image = torch.clamp(perturbed_image, 0, 1) # Return the perturbed image return perturbed_image 测试功能 最后，本教程的中央结果来源于测试功能。该测试功能每次调用执行对MNIST测试集一个完整的测试步骤，并报告最终精度。然而，请注意，这个功能也需要一个 的ε- 输入。这是因为测试函数将报告一个模型，它是受到攻击从对手与强度 \\（\\小量\\）的准确性。更具体地，在测试组中的每个样本，所述函数计算所述损失WRT输入数据（ \\（数据\\ _grad \\））的梯度，产生具有扰动的图像 fgsm_attack（ \\（扰动\\ _data \\）），然后检查是否被扰动的例子是对抗性。除了测试模型的准确性，功能也节省并返回稍后显现一些成功的例子对抗性。 def test( model, device, test_loader, epsilon ): # Accuracy counter correct = 0 adv_examples = [] # Loop over all examples in test set for data, target in test_loader: # Send the data and label to the device data, target = data.to(device), target.to(device) # Set requires_grad attribute of tensor. Important for Attack data.requires_grad = True # Forward pass the data through the model output = model(data) init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability # If the initial prediction is wrong, dont bother attacking, just move on if init_pred.item() != target.item(): continue # Calculate the loss loss = F.nll_loss(output, target) # Zero all existing gradients model.zero_grad() # Calculate gradients of model in backward pass loss.backward() # Collect datagrad data_grad = data.grad.data # Call FGSM Attack perturbed_data = fgsm_attack(data, epsilon, data_grad) # Re-classify the perturbed image output = model(perturbed_data) # Check for success final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability if final_pred.item() == target.item(): correct += 1 # Special case for saving 0 epsilon examples if (epsilon == 0) and (len(adv_examples) 运行攻击 实施的最后一部分是实际运行攻击。在这里，我们运行在 epsilons 输入的每个的ε- 值全测试步骤。对于每一个小量，我们也节省了最终的准确度和未来的部分要绘制一些成功的例子对抗性。注意印刷精度如何降低作为的ε值增加。另外，请注意 \\（\\小量= 0 \\）的情况下表示原始测试精度，没有攻击。 accuracies = [] examples = [] # Run test for each epsilon for eps in epsilons: acc, ex = test(model, device, test_loader, eps) accuracies.append(acc) examples.append(ex) Out: Epsilon: 0 Test Accuracy = 9810 / 10000 = 0.981 Epsilon: 0.05 Test Accuracy = 9426 / 10000 = 0.9426 Epsilon: 0.1 Test Accuracy = 8510 / 10000 = 0.851 Epsilon: 0.15 Test Accuracy = 6826 / 10000 = 0.6826 Epsilon: 0.2 Test Accuracy = 4301 / 10000 = 0.4301 Epsilon: 0.25 Test Accuracy = 2082 / 10000 = 0.2082 Epsilon: 0.3 Test Accuracy = 869 / 10000 = 0.0869 结果 精确度和小量 第一个结果是精度与小量的情节。正如先前提到的，因为小量增加，我们预计测试精度降低。这是因为更大的epsilons意味着我们采取的是将最大限度地损失方向以更大的一步。注意在曲线的趋势，即使的ε值线性间隔不是线性的。例如，在 \\（\\小量= 0.05 \\）的精度比下仅约4％\\（\\小量= 0 \\），但精度在 \\ （\\小量= 0.2 \\）大于低25％\\（\\小量= 0.15 \\）。另外，请注意该模型的准确度命中随机精度\\之间 10级分类器（\\小量= 0.25 \\）和 \\（\\小量= 0.3 \\）。 plt.figure(figsize=(5,5)) plt.plot(epsilons, accuracies, \"*-\") plt.yticks(np.arange(0, 1.1, step=0.1)) plt.xticks(np.arange(0, .35, step=0.05)) plt.title(\"Accuracy vs Epsilon\") plt.xlabel(\"Epsilon\") plt.ylabel(\"Accuracy\") plt.show() 样品对抗性实施例 记住没有免费的午餐的想法？在这种情况下，作为小量增加了测试精度降低 BUT 扰动变得更容易察觉。在现实中，有精度降解和攻击者必须考虑感之间的权衡。在这里，我们显示出对每一个小量值成功对抗的例子一些例子。情节的每行显示一个不同的小量值。第一行是 \\（\\小量= 0 \\），其表示不具有扰动原来的“干净”的图像实例。各图像的标题显示了“原始分类 - & GT ;对抗性分类。”通知，扰动开始成为在 \\（\\小量= 0.15 \\）明显，是相当明显在 \\（\\小量= 0.3 \\）。然而，在所有的情况下，人类仍然能够识别正确的类，尽管添加了噪音的。 # Plot several examples of adversarial samples at each epsilon cnt = 0 plt.figure(figsize=(8,10)) for i in range(len(epsilons)): for j in range(len(examples[i])): cnt += 1 plt.subplot(len(epsilons),len(examples[0]),cnt) plt.xticks([], []) plt.yticks([], []) if j == 0: plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14) orig,adv,ex = examples[i][j] plt.title(\"{} -> {}\".format(orig, adv)) plt.imshow(ex, cmap=\"gray\") plt.tight_layout() plt.show() 下一步去哪里？ 希望这个教程提供一些见解对立的机器学习的话题。有许多潜在的方向从这里走。这次攻击是对抗攻击的研究一开始就和因为有一直为如何攻击和对手防守ML车型很多后续的想法。事实上，在2017年NIPS有一个对抗性的攻防竞争和许多在比赛中使用的方法在本文中描述：[对抗性攻击和防御比赛HTG1。在防守上的工作还通向使机器学习模型的想法更多 健壮 在一般情况下，双方自然扰动和adversarially制作的投入。 去另一个方向是在不同的领域对抗攻击和防御。对抗性的研究不限于图像域，检查出上的语音至文本模式这个攻击。但也许更多地了解对抗机器学习的最佳方式是让你的手脏。尝试实施从2017年NIPS竞争不同的攻击，看看它与FGSM的不同之处。然后，尝试从自己的攻击防御模型。 脚本的总运行时间： （2分钟57.229秒） Download Python source code: fgsm_tutorial.py Download Jupyter notebook: fgsm_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 对抗性实施例代 威胁模型 快速倾斜的符号攻击 实现 输入 型号受到攻击 FGSM攻击 测试函数 运行攻击 结果 精度VS的Epsilon [HTG0样品对抗性实施例 下一步去哪里？ ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/dcgan_faces_tutorial.html":{"url":"beginner/dcgan_faces_tutorial.html","title":"DCGAN教程","keywords":"","body":"DCGAN教程 作者 ：弥敦道Inkawhich 简介 本教程将为通过一个例子介绍了DCGANs。我们将培养出生成对抗网络（GAN）显示它真正的许多名人照片后产生新的名人。这里的大多数代码是从 pytorch的dcgan执行/例子，而这个文件将给出实施的全面解释，并在此模型如何以及为什么工作的线索。不过不用担心，没有事先甘斯的知识是必需的，但它可能需要第一个定时器花费大约什么是引擎盖下实际发生的一段时间推理。此外，对于时间的缘故，将有助于有一个GPU，或两个。让我们从头开始。 生成对抗性网络 什么是GAN？ 甘斯是教DL模型捕捉训练数据的分布，所以我们可以产生来自同一分布的新数据的框架。甘斯分别由Ian古德费洛在2014年发明并在纸剖成对抗性篮网首先描述。它们是由两种不同的型号， 发生器 和 鉴别[HTG5。发电机的工作是产卵，看起来像训练图像“假”的图像。鉴别的工作是看图像和输出是否是真正的训练图像或从发电机假像。在培训过程中，发电机不断尝试通过生成好假货智取鉴别，而鉴别正在努力成为一个更好的侦探和准确区分真假的图像。这个游戏的平衡是当发电机发电，看起来好像他们直接从训练数据来完善假货，并鉴别留给始终在50％的置信猜测，发电机的输出是真实的还是假的。 现在，让我们开始定义与鉴别某些符号在整个教程中使用。让 \\（X \\）是表示图像的数据。 \\（d（x）的\\）是鉴别器的网络，其输出的（标量）概率 \\（X \\）来自训练数据，而不是发电机。这里，由于我们在输入处理图像，以 \\（d（x）的\\）是CHW大小3x64x64的图像。直观地说， \\（d（x）的\\）应该是HIGH时 \\（X \\）来自训练数据和LOW时 \\（X \\）附带从发电机。 \\（d（x）的\\）也可以被认为是作为一个传统的二元分类器。 用于发电机的符号，让 \\（Z \\）是从标准正态分布取样的潜在空间矢量。 \\（G（z）的\\）表示潜矢量 \\（Z \\）映射到数据空间中的发电机的功能。的目标\\（G \\）是估计训练数据来自于分布（ \\（P_ {数据} \\）），所以它可以产生从该估计的假样本分布（ \\（P_G \\））。 因此， \\（d（G（Z））\\）的概率是（标量），该发电机 \\（G \\）的输出是一个真实图像。如古德费洛的论文中描述的， \\（d \\）和 \\（G \\）发挥极大极小的游戏中， \\（d \\）尝试最大化其正确分类的实数和赝品（ \\（的logD（X）\\））和 \\（G \\）尝试的概率最小化[HTG16概率] \\（d \\）将预测其输出是假（ \\（日志（1-d（G（X）））\\））。从本文中，甘损失函数是 \\[\\underset{G}{\\text{min}} \\underset{D}{\\text{max}}V(D,G) = \\mathbb{E}{x\\sim p{data}(x)}\\big[logD(x)\\big] + \\mathbb{E}{z\\sim p{z}(z)}\\big[log(1-D(G(z)))\\big]\\] 从理论上讲，解决这一极小极大游戏是其中 \\（PG = P {数据} \\），和鉴别器猜测随机如果输入是真实的还是假。然而，甘斯的收敛理论仍在积极研究和现实中的模型并不总是训练到这一点。 什么是DCGAN？ 甲DCGAN是上述GAN的直接延伸，除了它明确使用卷积和在鉴别器和发电机分别卷积转置层。它首先被拉德福德等说明。人。在文献[无监督表示学习凭借深厚的卷积剖成对抗性网络HTG1。鉴别器由跨距卷积的层，批次规范层，和 LeakyReLU 激活。输入是3x64x64输入图像和输出是一个标量概率输入是来自真正的数据分布。发电机是由卷积转置层，批量规范层，和 RELU 激活。输入是潜向量， \\（Z \\），即从一个标准正态分布绘制和输出是3x64x64 RGB图像。的跨距CONV转置层允许潜矢量被变换成具有相同形状作为图像的体积。在论文中，作者还提供了有关如何设置优化，如何计算损失函数，以及如何初始化模型权重，所有这些都将在未来的章节来说明一些技巧。 from __future__ import print_function #%matplotlib inline import argparse import os import random import torch import torch.nn as nn import torch.nn.parallel import torch.backends.cudnn as cudnn import torch.optim as optim import torch.utils.data import torchvision.datasets as dset import torchvision.transforms as transforms import torchvision.utils as vutils import numpy as np import matplotlib.pyplot as plt import matplotlib.animation as animation from IPython.display import HTML # Set random seed for reproducibility manualSeed = 999 #manualSeed = random.randint(1, 10000) # use if you want new results print(\"Random Seed: \", manualSeed) random.seed(manualSeed) torch.manual_seed(manualSeed) 日期： Random Seed: 999 输入 让我们来定义运行一些投入： dataroot - 路径到数据集的文件夹的根目录。我们将讨论更多有关数据集在下一节 工人 - 工作线程用于与的DataLoader加载数据的数 BATCH_SIZE - 在训练中使用的批量大小。所述DCGAN本文采用的128批量大小 IMAGE_SIZE - 用于训练的图像的空间大小。此实现默认为64×64。如果另一个尺寸是期望的，d和G的结构必须改变。参见此处更多细节 NC - 在输入图像中的颜色通道的数量。对于彩色图像，这是3 新西兰 - 长度潜矢量的 NGF - 涉及特征映射的通过发电机进行的深度 NDF - 设置特征映射的通过鉴别器传播的深度 num_epochs - 训练历元的数目来运行。更长的训练可能会带来更好的结果，但也将需要更长的时间 LR - 学习培训率。正如DCGAN论文中描述，此数应为0.0002 β1的 - β1超参数为亚当优化。如在本文所描述的，这个数量应为0.5 ngpu - 可用的GPU的数目。如果是0，代码将在CPU模式下运行。如果这个数字大于0，将在这一数字的GPU运行 # Root directory for dataset dataroot = \"data/celeba\" # Number of workers for dataloader workers = 2 # Batch size during training batch_size = 128 # Spatial size of training images. All images will be resized to this # size using a transformer. image_size = 64 # Number of channels in the training images. For color images this is 3 nc = 3 # Size of z latent vector (i.e. size of generator input) nz = 100 # Size of feature maps in generator ngf = 64 # Size of feature maps in discriminator ndf = 64 # Number of training epochs num_epochs = 5 # Learning rate for optimizers lr = 0.0002 # Beta1 hyperparam for Adam optimizers beta1 = 0.5 # Number of GPUs available. Use 0 for CPU mode. ngpu = 1 数据 在本教程中，我们将使用名人- A面向数据集可在所链接的网站上下载，或者在[谷歌驱动器HTG3。该数据集将作为下载名为 img_align_celeba.zip 文件。下载完成后，创建一个名为 celeba 目录和zip文件解压到该目录中。那么，这款笔记本的 celeba刚刚创建 目录设置 dataroot 输入。生成的目录结构应该是： /path/to/celeba -> img_align_celeba -> 188242.jpg -> 173822.jpg -> 284702.jpg -> 537394.jpg ... 这是因为我们将要使用的ImageFolder DataSet类，这需要有是在数据集的根文件夹中的子目录中的重要一步。现在，我们可以创建数据集，创建的DataLoader，设置设备上运行，并最终显现的一些训练数据。 # We can use an image folder dataset the way we have it setup. # Create the dataset dataset = dset.ImageFolder(root=dataroot, transform=transforms.Compose([ transforms.Resize(image_size), transforms.CenterCrop(image_size), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ])) # Create the dataloader dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers) # Decide which device we want to run on device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\") # Plot some training images real_batch = next(iter(dataloader)) plt.figure(figsize=(8,8)) plt.axis(\"off\") plt.title(\"Training Images\") plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0))) 实现 随着我们的输入参数设置和数据集的准备，我们现在可以进入实施。我们将与weigth初始化策略开始，再谈谈发电机，鉴别，丧失功能，并且训练循环的细节。 重量初始化 从DCGAN论文中，作者指定所有模型权重应从均值= 0，标准偏差= 0.02的正态分布随机初始化。的weights_init函数接受一个初始化模型作为输入，并重新初始化所有卷积，卷积转置，并且批标准化层以满足这个标准。这个函数初始化后立即应用于模型。 # custom weights initialization called on netG and netD def weights_init(m): classname = m.__class__.__name__ if classname.find('Conv') != -1: nn.init.normal_(m.weight.data, 0.0, 0.02) elif classname.find('BatchNorm') != -1: nn.init.normal_(m.weight.data, 1.0, 0.02) nn.init.constant_(m.bias.data, 0) 发电机 的发电机， \\（G \\），被设计来映射潜在空间向量（ \\（Z \\））至数据空间。由于我们的数据是图像，转换 \\（Z \\）到数据空间装置最终与相同大小的训练图像创建RGB图像（即3x64x64）。在实践中，这是通过一系列跨距二维卷积转置层，每个具有二维批次模层和RELU激活配对的实现。发电机的输出通过双曲正切函数馈送给它返回到 \\输入数据范围（[ - 1,1] \\）。值得一卷积转置层之后注意到的批次范数函数的存在，因为这是DCGAN纸的重要贡献。这些层帮助梯度的培训过程中的流动。从DCGAN纸发电机的图像被如下所示。 通知，我们如何在输入部分设置的输入（ 新西兰 ， NGF 和 NC ）在代码影响发生器体系结构。 新西兰 是z输入矢量的长度， NGF 涉及通过发生器传播的特征地图的大小，和 NC 是多少在输出图像中的通道（设置为3为RGB图像）。下面是发电机的代码。 # Generator Code class Generator(nn.Module): def __init__(self, ngpu): super(Generator, self).__init__() self.ngpu = ngpu self.main = nn.Sequential( # input is Z, going into a convolution nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False), nn.BatchNorm2d(ngf * 8), nn.ReLU(True), # state size. (ngf*8) x 4 x 4 nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf * 4), nn.ReLU(True), # state size. (ngf*4) x 8 x 8 nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf * 2), nn.ReLU(True), # state size. (ngf*2) x 16 x 16 nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False), nn.BatchNorm2d(ngf), nn.ReLU(True), # state size. (ngf) x 32 x 32 nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False), nn.Tanh() # state size. (nc) x 64 x 64 ) def forward(self, input): return self.main(input) 现在，我们可以实例发电机和应用weights_init功能。退房的打印模型来查看生成的对象是如何构成的。 # Create the generator netG = Generator(ngpu).to(device) # Handle multi-gpu if desired if (device.type == 'cuda') and (ngpu > 1): netG = nn.DataParallel(netG, list(range(ngpu))) # Apply the weights_init function to randomly initialize all weights # to mean=0, stdev=0.2. netG.apply(weights_init) # Print the model print(netG) Out: Generator( (main): Sequential( (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (5): ReLU(inplace=True) (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (8): ReLU(inplace=True) (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (11): ReLU(inplace=True) (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (13): Tanh() ) ) 鉴别器 如所提到的，鉴别器， \\（d \\），是二元分类网络拍摄图像作为输入，并输出一个标量概率输入图像是真实的（而不是伪造的）。在此， \\（d \\）取3x64x64输入图像，通过一系列Conv2d，BatchNorm2d，和LeakyReLU层进行处理，并通过乙状结肠激活函数输出最终概率。这种架构可以用更多层，如果必要对这个问题进行扩展，但意义利用跨入卷积，BatchNorm和LeakyReLUs的。该DCGAN本文提到它是用跨入卷积，而不是集中到下采样，因为它可以让网络了解自己的池功能一个很好的做法。还批次规范和漏泄RELU功能促进健康的梯度流是用于学习过程临界既 \\（G \\）和 \\（d \\）。 鉴别码 class Discriminator(nn.Module): def __init__(self, ngpu): super(Discriminator, self).__init__() self.ngpu = ngpu self.main = nn.Sequential( # input is (nc) x 64 x 64 nn.Conv2d(nc, ndf, 4, 2, 1, bias=False), nn.LeakyReLU(0.2, inplace=True), # state size. (ndf) x 32 x 32 nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf * 2), nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*2) x 16 x 16 nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf * 4), nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*4) x 8 x 8 nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf * 8), nn.LeakyReLU(0.2, inplace=True), # state size. (ndf*8) x 4 x 4 nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False), nn.Sigmoid() ) def forward(self, input): return self.main(input) 现在，与发电机，我们可以创建鉴别，应用weights_init功能，打印模型的结构。 # Create the Discriminator netD = Discriminator(ngpu).to(device) # Handle multi-gpu if desired if (device.type == 'cuda') and (ngpu > 1): netD = nn.DataParallel(netD, list(range(ngpu))) # Apply the weights_init function to randomly initialize all weights # to mean=0, stdev=0.2. netD.apply(weights_init) # Print the model print(netD) Out: Discriminator( (main): Sequential( (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (1): LeakyReLU(negative_slope=0.2, inplace=True) (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (4): LeakyReLU(negative_slope=0.2, inplace=True) (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (7): LeakyReLU(negative_slope=0.2, inplace=True) (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False) (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (10): LeakyReLU(negative_slope=0.2, inplace=True) (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False) (12): Sigmoid() ) ) 损失函数和优化器 随着 \\（d \\）HTG1]和 \\（G \\）HTG3]设置中，我们可以指定他们通过丧失功能和优化的学习方式。我们将使用二进制交叉熵损失，在PyTorch定义为（ BCELoss ）功能： \\[\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = - \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right]\\] 注意这个功能如何提供在目标函数中两个日志组件的计算（即， \\（日志（d（X））\\）和 \\（日志（1-d（G（z）的））\\））。我们可以指定与 \\（Y \\）HTG5]输入要使用什么公元前方程式的一部分。这是在训练环路即将来临完成，而是要了解我们如何可以选择我们希望仅通过改变 \\（Y \\）[HTG7（即GT标签）来计算，其成分是很重要的。 接下来，我们定义真实标签为1和计算的的损失时，假标签为0，这些标签将被用来\\（d \\）和 \\（G \\）这也是在原来的GAN纸使用的惯例。最后，我们建立了两个分离的优化器，一个用于 \\（d \\），一个用于 \\（G \\）。正如DCGAN纸指定，都是亚当优化与学习率0.0002和Beta1的= 0.5。用于跟踪发生器的学习进展的，我们将产生潜在向量的固定批次被从高斯分布中抽取（即fixed_noise）。在训练循环中，我们将周期性地输入此fixed_noise到 \\（G \\），并且在迭代，我们将看到的图像形成了噪音。 # Initialize BCELoss function criterion = nn.BCELoss() # Create batch of latent vectors that we will use to visualize # the progression of the generator fixed_noise = torch.randn(64, nz, 1, 1, device=device) # Establish convention for real and fake labels during training real_label = 1 fake_label = 0 # Setup Adam optimizers for both G and D optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999)) optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999)) 培训 最后，现在我们都定义的GAN框架的部分，我们可以训练它。要留意的是训练甘斯是有点一种艺术形式，是不正确的超参数设置，导致用了什么差错一点解释模式的崩溃。在这里，我们将密切从古德费洛的纸遵循算法1中，同时通过一些在 ganhacks 所示的最佳实践守法。即，我们将“构建体不同的小批次真假”的图像，并且还调整G公司的目标函数最大化 \\（的logD（G（Z））\\）。培训分成两个主要部分。第1部分更新鉴别和第2部分更新生成。 第1部分 - 培养的鉴别 回想一下，训练鉴别的目标是最大化的正确分类给定的输入为实或伪造的可能性。在古德费洛方面，我们希望“通过提升其随机梯度更新鉴别”。实际上，我们希望最大化 \\（日志（d（X））+日志（1-d（G（Z）））\\）。由于从ganhacks单独的小批量的建议，我们将分两步计算此。首先，我们将构造一个批次实际样品的从训练集，向前穿过 \\（d \\），计算出损耗（ \\（日志（d（X））\\）），然后计算在后向通的梯度。其次，我们将构造一个批次与电流发生器假样本，直传这批通过 \\（d \\），计算出损耗（ \\（日志（1-d（G（Z ）））\\））和 积累 与向后通的梯度。现在，无论从所有实时和全假批次积累的梯度，我们称之为鉴别的优化的步骤。 第2部分 - 培养发电机 正如原文件中指出，我们希望通过最小化 \\训练发生器（日志（1-d（G（Z）））\\）在努力产生更好假货。如所提到的，这是通过古德费洛显示出不能提供足够的梯度，在学习过程中尤其是早期。作为一个解决方法，我们会想最大限度 \\（日志（d（G（Z）））\\）。在代码中我们通过实现此目的：从第1部分输出的发生器，提供鉴别分类，计算使用真实的标签为G的损失 GT ，计算G公司的梯度在向后通，最后用优化器更新G公司的参数步。这似乎是违反直觉的使用真正的标签为GT标签的损失函数，但这允许我们使用 \\（日志（X）\\）HTG7]的BCELoss（而非[HTG8的一部分] \\（日志（1-X）\\）HTG9]部分），这正是我们想要的东西。 最后，我们会做一些统计报告，并在每一个时代的结束，我们将通过发电机把我们fixed_noise一批视觉跟踪的G公司的培训进度。报告的训练统计数据： Loss_D - 鉴别器损失计算为对于所有实数和所有假批次损失（总和 \\（日志（d（X））+日志（d（G（Z）））\\） ）。 Loss_G - 发电机损失计算为 \\（日志（d（G（Z）））\\） 鉴别器用于所有实际批次的平均输出（跨批） - d（x）的 。这应该开始接近1，则理论上收敛到0.5当G变得更好。想想这是为什么。 d（G（Z）） - 平均鉴别器输出的所有假批次。第一个数字是d被更新之前，第二个数字是d被更新之后。这些数字应该开始接近0和收敛到0.5为G变得更好。想想这是为什么。 注： 此步骤可能需要一段时间，这取决于你运行了多少时代，如果你删除从数据集的一些数据。 # Training Loop # Lists to keep track of progress img_list = [] G_losses = [] D_losses = [] iters = 0 print(\"Starting Training Loop...\") # For each epoch for epoch in range(num_epochs): # For each batch in the dataloader for i, data in enumerate(dataloader, 0): ############################ # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z))) ########################### ## Train with all-real batch netD.zero_grad() # Format batch real_cpu = data[0].to(device) b_size = real_cpu.size(0) label = torch.full((b_size,), real_label, device=device) # Forward pass real batch through D output = netD(real_cpu).view(-1) # Calculate loss on all-real batch errD_real = criterion(output, label) # Calculate gradients for D in backward pass errD_real.backward() D_x = output.mean().item() ## Train with all-fake batch # Generate batch of latent vectors noise = torch.randn(b_size, nz, 1, 1, device=device) # Generate fake image batch with G fake = netG(noise) label.fill_(fake_label) # Classify all fake batch with D output = netD(fake.detach()).view(-1) # Calculate D's loss on the all-fake batch errD_fake = criterion(output, label) # Calculate the gradients for this batch errD_fake.backward() D_G_z1 = output.mean().item() # Add the gradients from the all-real and all-fake batches errD = errD_real + errD_fake # Update D optimizerD.step() ############################ # (2) Update G network: maximize log(D(G(z))) ########################### netG.zero_grad() label.fill_(real_label) # fake labels are real for generator cost # Since we just updated D, perform another forward pass of all-fake batch through D output = netD(fake).view(-1) # Calculate G's loss based on this output errG = criterion(output, label) # Calculate gradients for G errG.backward() D_G_z2 = output.mean().item() # Update G optimizerG.step() # Output training stats if i % 50 == 0: print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f' % (epoch, num_epochs, i, len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2)) # Save Losses for plotting later G_losses.append(errG.item()) D_losses.append(errD.item()) # Check how the generator is doing by saving G's output on fixed_noise if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)): with torch.no_grad(): fake = netG(fixed_noise).detach().cpu() img_list.append(vutils.make_grid(fake, padding=2, normalize=True)) iters += 1 Out: Starting Training Loop... [0/5][0/1583] Loss_D: 2.0937 Loss_G: 5.2059 D(x): 0.5704 D(G(z)): 0.6680 / 0.0090 [0/5][50/1583] Loss_D: 0.3774 Loss_G: 13.1007 D(x): 0.9287 D(G(z)): 0.1399 / 0.0000 [0/5][100/1583] Loss_D: 0.3890 Loss_G: 7.3600 D(x): 0.9515 D(G(z)): 0.2013 / 0.0016 [0/5][150/1583] Loss_D: 0.8623 Loss_G: 4.8858 D(x): 0.6280 D(G(z)): 0.0546 / 0.0120 [0/5][200/1583] Loss_D: 0.2328 Loss_G: 4.0880 D(x): 0.8727 D(G(z)): 0.0468 / 0.0342 [0/5][250/1583] Loss_D: 0.5606 Loss_G: 6.3940 D(x): 0.8928 D(G(z)): 0.2846 / 0.0033 [0/5][300/1583] Loss_D: 0.9473 Loss_G: 2.2100 D(x): 0.5401 D(G(z)): 0.0405 / 0.2226 [0/5][350/1583] Loss_D: 0.5938 Loss_G: 2.3492 D(x): 0.6671 D(G(z)): 0.0787 / 0.1434 [0/5][400/1583] Loss_D: 0.6209 Loss_G: 4.6997 D(x): 0.6428 D(G(z)): 0.0168 / 0.0245 [0/5][450/1583] Loss_D: 0.2974 Loss_G: 4.0321 D(x): 0.8766 D(G(z)): 0.1159 / 0.0362 [0/5][500/1583] Loss_D: 0.6701 Loss_G: 4.4486 D(x): 0.6652 D(G(z)): 0.0455 / 0.0287 [0/5][550/1583] Loss_D: 0.4637 Loss_G: 5.2266 D(x): 0.8923 D(G(z)): 0.2620 / 0.0092 [0/5][600/1583] Loss_D: 0.5639 Loss_G: 4.7983 D(x): 0.9016 D(G(z)): 0.3207 / 0.0173 [0/5][650/1583] Loss_D: 0.7982 Loss_G: 5.0614 D(x): 0.5701 D(G(z)): 0.0204 / 0.0218 [0/5][700/1583] Loss_D: 0.4445 Loss_G: 4.9462 D(x): 0.7558 D(G(z)): 0.0659 / 0.0158 [0/5][750/1583] Loss_D: 0.5148 Loss_G: 3.5789 D(x): 0.7042 D(G(z)): 0.0432 / 0.0453 [0/5][800/1583] Loss_D: 0.4863 Loss_G: 4.6765 D(x): 0.7542 D(G(z)): 0.0759 / 0.0231 [0/5][850/1583] Loss_D: 0.3902 Loss_G: 5.8273 D(x): 0.9055 D(G(z)): 0.2264 / 0.0054 [0/5][900/1583] Loss_D: 0.2873 Loss_G: 4.9891 D(x): 0.9196 D(G(z)): 0.1646 / 0.0127 [0/5][950/1583] Loss_D: 0.3514 Loss_G: 5.7773 D(x): 0.8035 D(G(z)): 0.0290 / 0.0187 [0/5][1000/1583] Loss_D: 0.2073 Loss_G: 4.6480 D(x): 0.8781 D(G(z)): 0.0526 / 0.0179 [0/5][1050/1583] Loss_D: 0.3943 Loss_G: 3.9658 D(x): 0.8101 D(G(z)): 0.1151 / 0.0375 [0/5][1100/1583] Loss_D: 0.4837 Loss_G: 7.8827 D(x): 0.9326 D(G(z)): 0.2947 / 0.0007 [0/5][1150/1583] Loss_D: 0.8206 Loss_G: 5.7468 D(x): 0.7890 D(G(z)): 0.3709 / 0.0070 [0/5][1200/1583] Loss_D: 0.3523 Loss_G: 5.2779 D(x): 0.9274 D(G(z)): 0.1794 / 0.0170 [0/5][1250/1583] Loss_D: 0.4778 Loss_G: 3.7886 D(x): 0.8180 D(G(z)): 0.1853 / 0.0392 [0/5][1300/1583] Loss_D: 0.6191 Loss_G: 4.5570 D(x): 0.6579 D(G(z)): 0.0228 / 0.0329 [0/5][1350/1583] Loss_D: 0.9187 Loss_G: 2.3565 D(x): 0.5046 D(G(z)): 0.0160 / 0.1633 [0/5][1400/1583] Loss_D: 1.3850 Loss_G: 1.4330 D(x): 0.3892 D(G(z)): 0.0022 / 0.3387 [0/5][1450/1583] Loss_D: 1.1444 Loss_G: 1.4010 D(x): 0.4826 D(G(z)): 0.0790 / 0.3273 [0/5][1500/1583] Loss_D: 0.6209 Loss_G: 2.3856 D(x): 0.6477 D(G(z)): 0.0598 / 0.1366 [0/5][1550/1583] Loss_D: 0.3691 Loss_G: 4.1789 D(x): 0.8185 D(G(z)): 0.1073 / 0.0289 [1/5][0/1583] Loss_D: 1.0041 Loss_G: 6.3416 D(x): 0.9488 D(G(z)): 0.5145 / 0.0038 [1/5][50/1583] Loss_D: 0.3362 Loss_G: 5.1711 D(x): 0.9164 D(G(z)): 0.1905 / 0.0098 [1/5][100/1583] Loss_D: 0.4752 Loss_G: 4.7347 D(x): 0.9064 D(G(z)): 0.2696 / 0.0158 [1/5][150/1583] Loss_D: 0.3594 Loss_G: 4.2543 D(x): 0.8233 D(G(z)): 0.0889 / 0.0261 [1/5][200/1583] Loss_D: 0.3224 Loss_G: 4.1060 D(x): 0.9342 D(G(z)): 0.1887 / 0.0328 [1/5][250/1583] Loss_D: 0.3484 Loss_G: 4.1485 D(x): 0.9282 D(G(z)): 0.2083 / 0.0263 [1/5][300/1583] Loss_D: 0.6082 Loss_G: 4.0181 D(x): 0.8497 D(G(z)): 0.3036 / 0.0301 [1/5][350/1583] Loss_D: 0.3780 Loss_G: 3.8947 D(x): 0.8648 D(G(z)): 0.1663 / 0.0354 [1/5][400/1583] Loss_D: 0.5670 Loss_G: 4.1670 D(x): 0.8218 D(G(z)): 0.2409 / 0.0301 [1/5][450/1583] Loss_D: 0.5585 Loss_G: 3.1787 D(x): 0.7655 D(G(z)): 0.2057 / 0.0637 [1/5][500/1583] Loss_D: 0.7137 Loss_G: 4.9132 D(x): 0.8824 D(G(z)): 0.3703 / 0.0148 [1/5][550/1583] Loss_D: 0.4914 Loss_G: 5.2257 D(x): 0.9024 D(G(z)): 0.2840 / 0.0093 [1/5][600/1583] Loss_D: 0.5191 Loss_G: 4.3694 D(x): 0.8699 D(G(z)): 0.2514 / 0.0219 [1/5][650/1583] Loss_D: 0.5218 Loss_G: 3.0204 D(x): 0.8033 D(G(z)): 0.2015 / 0.0813 [1/5][700/1583] Loss_D: 0.4707 Loss_G: 3.7884 D(x): 0.7416 D(G(z)): 0.0953 / 0.0498 [1/5][750/1583] Loss_D: 0.4335 Loss_G: 3.2868 D(x): 0.7429 D(G(z)): 0.0884 / 0.0579 [1/5][800/1583] Loss_D: 0.3846 Loss_G: 4.6926 D(x): 0.9407 D(G(z)): 0.2499 / 0.0160 [1/5][850/1583] Loss_D: 0.5482 Loss_G: 3.6550 D(x): 0.7687 D(G(z)): 0.1835 / 0.0465 [1/5][900/1583] Loss_D: 0.3070 Loss_G: 3.3886 D(x): 0.8349 D(G(z)): 0.0808 / 0.0542 [1/5][950/1583] Loss_D: 0.5366 Loss_G: 4.5934 D(x): 0.9043 D(G(z)): 0.3098 / 0.0156 [1/5][1000/1583] Loss_D: 0.7676 Loss_G: 6.3473 D(x): 0.9307 D(G(z)): 0.4354 / 0.0033 [1/5][1050/1583] Loss_D: 0.2988 Loss_G: 2.8881 D(x): 0.8340 D(G(z)): 0.0837 / 0.0806 [1/5][1100/1583] Loss_D: 0.2307 Loss_G: 4.0665 D(x): 0.8507 D(G(z)): 0.0497 / 0.0297 [1/5][1150/1583] Loss_D: 0.4752 Loss_G: 3.3592 D(x): 0.7987 D(G(z)): 0.1827 / 0.0527 [1/5][1200/1583] Loss_D: 0.4123 Loss_G: 2.8147 D(x): 0.8577 D(G(z)): 0.1978 / 0.0855 [1/5][1250/1583] Loss_D: 0.6260 Loss_G: 4.0730 D(x): 0.8506 D(G(z)): 0.3111 / 0.0348 [1/5][1300/1583] Loss_D: 1.1704 Loss_G: 0.9039 D(x): 0.3939 D(G(z)): 0.0124 / 0.4852 [1/5][1350/1583] Loss_D: 0.7011 Loss_G: 2.8476 D(x): 0.5769 D(G(z)): 0.0256 / 0.1121 [1/5][1400/1583] Loss_D: 0.4104 Loss_G: 3.1058 D(x): 0.8774 D(G(z)): 0.2140 / 0.0639 [1/5][1450/1583] Loss_D: 0.6811 Loss_G: 4.2002 D(x): 0.8413 D(G(z)): 0.3494 / 0.0231 [1/5][1500/1583] Loss_D: 1.1317 Loss_G: 4.9345 D(x): 0.9371 D(G(z)): 0.5929 / 0.0142 [1/5][1550/1583] Loss_D: 0.4742 Loss_G: 3.6869 D(x): 0.8981 D(G(z)): 0.2814 / 0.0334 [2/5][0/1583] Loss_D: 0.7098 Loss_G: 2.2753 D(x): 0.7126 D(G(z)): 0.2353 / 0.1409 [2/5][50/1583] Loss_D: 0.8551 Loss_G: 4.0366 D(x): 0.9233 D(G(z)): 0.4786 / 0.0293 [2/5][100/1583] Loss_D: 1.3078 Loss_G: 5.5286 D(x): 0.9644 D(G(z)): 0.6616 / 0.0087 [2/5][150/1583] Loss_D: 0.5860 Loss_G: 3.0621 D(x): 0.8354 D(G(z)): 0.2879 / 0.0660 [2/5][200/1583] Loss_D: 0.7063 Loss_G: 4.4227 D(x): 0.9211 D(G(z)): 0.4102 / 0.0214 [2/5][250/1583] Loss_D: 0.7483 Loss_G: 4.3158 D(x): 0.9114 D(G(z)): 0.4218 / 0.0235 [2/5][300/1583] Loss_D: 0.3818 Loss_G: 2.6245 D(x): 0.8214 D(G(z)): 0.1382 / 0.0954 [2/5][350/1583] Loss_D: 1.0843 Loss_G: 5.0712 D(x): 0.9312 D(G(z)): 0.5778 / 0.0114 [2/5][400/1583] Loss_D: 0.4509 Loss_G: 2.8962 D(x): 0.8141 D(G(z)): 0.1853 / 0.0809 [2/5][450/1583] Loss_D: 1.6330 Loss_G: 0.9981 D(x): 0.2956 D(G(z)): 0.0459 / 0.4390 [2/5][500/1583] Loss_D: 0.6487 Loss_G: 2.1938 D(x): 0.7994 D(G(z)): 0.3067 / 0.1466 [2/5][550/1583] Loss_D: 0.9323 Loss_G: 0.9386 D(x): 0.5224 D(G(z)): 0.1030 / 0.4615 [2/5][600/1583] Loss_D: 0.5440 Loss_G: 2.1702 D(x): 0.7386 D(G(z)): 0.1785 / 0.1451 [2/5][650/1583] Loss_D: 1.0955 Loss_G: 4.1925 D(x): 0.8748 D(G(z)): 0.5495 / 0.0243 [2/5][700/1583] Loss_D: 0.9323 Loss_G: 1.9101 D(x): 0.5384 D(G(z)): 0.1423 / 0.2040 [2/5][750/1583] Loss_D: 0.5053 Loss_G: 3.0426 D(x): 0.8162 D(G(z)): 0.2322 / 0.0672 [2/5][800/1583] Loss_D: 0.6751 Loss_G: 3.3158 D(x): 0.9154 D(G(z)): 0.3967 / 0.0506 [2/5][850/1583] Loss_D: 0.6562 Loss_G: 3.2938 D(x): 0.8295 D(G(z)): 0.3324 / 0.0515 [2/5][900/1583] Loss_D: 0.7118 Loss_G: 1.2240 D(x): 0.6193 D(G(z)): 0.1380 / 0.3455 [2/5][950/1583] Loss_D: 0.8978 Loss_G: 1.6854 D(x): 0.5290 D(G(z)): 0.1213 / 0.2381 [2/5][1000/1583] Loss_D: 1.7309 Loss_G: 0.4199 D(x): 0.2345 D(G(z)): 0.0295 / 0.6955 [2/5][1050/1583] Loss_D: 1.0172 Loss_G: 2.5191 D(x): 0.7005 D(G(z)): 0.4067 / 0.1074 [2/5][1100/1583] Loss_D: 0.7516 Loss_G: 4.3600 D(x): 0.9211 D(G(z)): 0.4427 / 0.0188 [2/5][1150/1583] Loss_D: 1.1362 Loss_G: 4.1261 D(x): 0.9477 D(G(z)): 0.5982 / 0.0235 [2/5][1200/1583] Loss_D: 0.4525 Loss_G: 2.9000 D(x): 0.7585 D(G(z)): 0.1208 / 0.0792 [2/5][1250/1583] Loss_D: 0.6209 Loss_G: 2.6601 D(x): 0.6727 D(G(z)): 0.1333 / 0.0993 [2/5][1300/1583] Loss_D: 0.6188 Loss_G: 1.8989 D(x): 0.6197 D(G(z)): 0.0591 / 0.1911 [2/5][1350/1583] Loss_D: 0.5986 Loss_G: 2.2171 D(x): 0.7147 D(G(z)): 0.1789 / 0.1359 [2/5][1400/1583] Loss_D: 0.6236 Loss_G: 1.5753 D(x): 0.6225 D(G(z)): 0.0892 / 0.2549 [2/5][1450/1583] Loss_D: 1.4575 Loss_G: 4.5445 D(x): 0.9019 D(G(z)): 0.6660 / 0.0170 [2/5][1500/1583] Loss_D: 0.4806 Loss_G: 2.0873 D(x): 0.7311 D(G(z)): 0.1014 / 0.1669 [2/5][1550/1583] Loss_D: 0.6069 Loss_G: 2.4878 D(x): 0.7693 D(G(z)): 0.2556 / 0.1059 [3/5][0/1583] Loss_D: 0.6953 Loss_G: 1.5334 D(x): 0.5927 D(G(z)): 0.0873 / 0.2576 [3/5][50/1583] Loss_D: 0.5561 Loss_G: 1.6132 D(x): 0.7008 D(G(z)): 0.1354 / 0.2534 [3/5][100/1583] Loss_D: 0.4794 Loss_G: 2.3090 D(x): 0.7693 D(G(z)): 0.1588 / 0.1250 [3/5][150/1583] Loss_D: 1.4472 Loss_G: 4.4442 D(x): 0.9591 D(G(z)): 0.6936 / 0.0197 [3/5][200/1583] Loss_D: 0.8359 Loss_G: 3.2797 D(x): 0.8965 D(G(z)): 0.4565 / 0.0537 [3/5][250/1583] Loss_D: 2.0792 Loss_G: 4.2226 D(x): 0.9092 D(G(z)): 0.7681 / 0.0260 [3/5][300/1583] Loss_D: 0.6438 Loss_G: 3.1580 D(x): 0.9164 D(G(z)): 0.3874 / 0.0598 [3/5][350/1583] Loss_D: 1.7056 Loss_G: 0.8386 D(x): 0.2668 D(G(z)): 0.0734 / 0.5220 [3/5][400/1583] Loss_D: 0.6288 Loss_G: 2.1909 D(x): 0.7401 D(G(z)): 0.2322 / 0.1413 [3/5][450/1583] Loss_D: 0.5742 Loss_G: 1.9729 D(x): 0.7162 D(G(z)): 0.1722 / 0.1700 [3/5][500/1583] Loss_D: 0.6798 Loss_G: 3.1593 D(x): 0.8591 D(G(z)): 0.3698 / 0.0543 [3/5][550/1583] Loss_D: 0.7612 Loss_G: 1.2536 D(x): 0.5592 D(G(z)): 0.0940 / 0.3256 [3/5][600/1583] Loss_D: 1.0874 Loss_G: 0.9601 D(x): 0.4155 D(G(z)): 0.0562 / 0.4391 [3/5][650/1583] Loss_D: 0.7018 Loss_G: 2.5142 D(x): 0.8042 D(G(z)): 0.3334 / 0.1051 [3/5][700/1583] Loss_D: 0.5612 Loss_G: 2.1963 D(x): 0.7554 D(G(z)): 0.2125 / 0.1376 [3/5][750/1583] Loss_D: 0.7318 Loss_G: 1.6377 D(x): 0.6495 D(G(z)): 0.1979 / 0.2296 [3/5][800/1583] Loss_D: 0.5621 Loss_G: 1.8894 D(x): 0.6796 D(G(z)): 0.1187 / 0.1907 [3/5][850/1583] Loss_D: 0.6477 Loss_G: 2.5308 D(x): 0.7984 D(G(z)): 0.2913 / 0.1005 [3/5][900/1583] Loss_D: 0.7904 Loss_G: 1.6153 D(x): 0.5864 D(G(z)): 0.1544 / 0.2314 [3/5][950/1583] Loss_D: 0.5315 Loss_G: 2.1866 D(x): 0.7990 D(G(z)): 0.2288 / 0.1405 [3/5][1000/1583] Loss_D: 0.8392 Loss_G: 3.7965 D(x): 0.8504 D(G(z)): 0.4431 / 0.0332 [3/5][1050/1583] Loss_D: 0.8082 Loss_G: 3.7510 D(x): 0.8679 D(G(z)): 0.4384 / 0.0341 [3/5][1100/1583] Loss_D: 0.5648 Loss_G: 1.9762 D(x): 0.7244 D(G(z)): 0.1718 / 0.1608 [3/5][1150/1583] Loss_D: 0.6545 Loss_G: 3.1910 D(x): 0.8204 D(G(z)): 0.3298 / 0.0534 [3/5][1200/1583] Loss_D: 0.6370 Loss_G: 2.0567 D(x): 0.7406 D(G(z)): 0.2551 / 0.1560 [3/5][1250/1583] Loss_D: 0.6561 Loss_G: 1.8144 D(x): 0.6885 D(G(z)): 0.2035 / 0.1921 [3/5][1300/1583] Loss_D: 0.6860 Loss_G: 1.8726 D(x): 0.5865 D(G(z)): 0.0620 / 0.1953 [3/5][1350/1583] Loss_D: 0.5618 Loss_G: 1.8079 D(x): 0.7159 D(G(z)): 0.1685 / 0.1976 [3/5][1400/1583] Loss_D: 0.6877 Loss_G: 2.5243 D(x): 0.7913 D(G(z)): 0.3214 / 0.1004 [3/5][1450/1583] Loss_D: 0.6534 Loss_G: 2.6937 D(x): 0.7997 D(G(z)): 0.3071 / 0.0848 [3/5][1500/1583] Loss_D: 0.5443 Loss_G: 2.1160 D(x): 0.7078 D(G(z)): 0.1242 / 0.1515 [3/5][1550/1583] Loss_D: 1.5968 Loss_G: 4.8972 D(x): 0.9627 D(G(z)): 0.7338 / 0.0110 [4/5][0/1583] Loss_D: 0.7820 Loss_G: 1.8219 D(x): 0.5272 D(G(z)): 0.0467 / 0.2010 [4/5][50/1583] Loss_D: 0.6637 Loss_G: 1.9136 D(x): 0.6712 D(G(z)): 0.1865 / 0.1876 [4/5][100/1583] Loss_D: 1.0259 Loss_G: 1.2513 D(x): 0.4374 D(G(z)): 0.0684 / 0.3257 [4/5][150/1583] Loss_D: 0.5099 Loss_G: 2.4926 D(x): 0.7915 D(G(z)): 0.2024 / 0.1111 [4/5][200/1583] Loss_D: 0.7905 Loss_G: 3.8833 D(x): 0.9060 D(G(z)): 0.4502 / 0.0309 [4/5][250/1583] Loss_D: 0.8218 Loss_G: 1.3731 D(x): 0.5398 D(G(z)): 0.0961 / 0.3197 [4/5][300/1583] Loss_D: 0.7159 Loss_G: 2.9385 D(x): 0.7769 D(G(z)): 0.3270 / 0.0678 [4/5][350/1583] Loss_D: 0.5711 Loss_G: 3.2981 D(x): 0.8730 D(G(z)): 0.3232 / 0.0506 [4/5][400/1583] Loss_D: 0.9274 Loss_G: 1.3243 D(x): 0.4666 D(G(z)): 0.0547 / 0.3089 [4/5][450/1583] Loss_D: 1.9290 Loss_G: 5.5781 D(x): 0.9685 D(G(z)): 0.8031 / 0.0063 [4/5][500/1583] Loss_D: 0.7317 Loss_G: 2.9507 D(x): 0.7779 D(G(z)): 0.3349 / 0.0688 [4/5][550/1583] Loss_D: 0.3878 Loss_G: 3.0483 D(x): 0.8716 D(G(z)): 0.2052 / 0.0606 [4/5][600/1583] Loss_D: 0.5016 Loss_G: 2.1415 D(x): 0.7794 D(G(z)): 0.1992 / 0.1496 [4/5][650/1583] Loss_D: 0.8692 Loss_G: 4.0726 D(x): 0.9369 D(G(z)): 0.5011 / 0.0239 [4/5][700/1583] Loss_D: 1.0189 Loss_G: 0.5405 D(x): 0.4590 D(G(z)): 0.0792 / 0.6298 [4/5][750/1583] Loss_D: 0.6823 Loss_G: 1.8271 D(x): 0.5918 D(G(z)): 0.0876 / 0.2046 [4/5][800/1583] Loss_D: 0.8343 Loss_G: 3.9417 D(x): 0.8795 D(G(z)): 0.4572 / 0.0283 [4/5][850/1583] Loss_D: 0.5352 Loss_G: 2.8730 D(x): 0.8354 D(G(z)): 0.2612 / 0.0770 [4/5][900/1583] Loss_D: 0.5948 Loss_G: 1.9490 D(x): 0.6961 D(G(z)): 0.1582 / 0.1789 [4/5][950/1583] Loss_D: 0.6370 Loss_G: 3.2704 D(x): 0.8925 D(G(z)): 0.3600 / 0.0523 [4/5][1000/1583] Loss_D: 0.7010 Loss_G: 1.9136 D(x): 0.6741 D(G(z)): 0.2126 / 0.1832 [4/5][1050/1583] Loss_D: 0.7043 Loss_G: 1.5664 D(x): 0.6225 D(G(z)): 0.1439 / 0.2530 [4/5][1100/1583] Loss_D: 0.4952 Loss_G: 2.1362 D(x): 0.7396 D(G(z)): 0.1442 / 0.1535 [4/5][1150/1583] Loss_D: 1.1702 Loss_G: 0.9483 D(x): 0.3849 D(G(z)): 0.0445 / 0.4278 [4/5][1200/1583] Loss_D: 0.6114 Loss_G: 1.6389 D(x): 0.6706 D(G(z)): 0.1427 / 0.2354 [4/5][1250/1583] Loss_D: 0.6020 Loss_G: 1.9253 D(x): 0.7218 D(G(z)): 0.1923 / 0.1769 [4/5][1300/1583] Loss_D: 0.6117 Loss_G: 3.6101 D(x): 0.8724 D(G(z)): 0.3392 / 0.0371 [4/5][1350/1583] Loss_D: 0.8552 Loss_G: 4.2809 D(x): 0.9218 D(G(z)): 0.4932 / 0.0205 [4/5][1400/1583] Loss_D: 0.6170 Loss_G: 4.0999 D(x): 0.9353 D(G(z)): 0.3772 / 0.0246 [4/5][1450/1583] Loss_D: 0.5660 Loss_G: 2.2870 D(x): 0.6739 D(G(z)): 0.1064 / 0.1389 [4/5][1500/1583] Loss_D: 0.7235 Loss_G: 3.5680 D(x): 0.8678 D(G(z)): 0.3896 / 0.0403 [4/5][1550/1583] Loss_D: 0.8062 Loss_G: 3.8185 D(x): 0.9046 D(G(z)): 0.4511 / 0.0305 结果 最后，让我们看看我们是怎么做。在这里，我们将着眼于三个不同的结果。首先，我们将看到G公司的损失在训练中如何d和改变。其次，我们将可视化的fixed_noise批次每一个时代G公司的产量。第三，我们将着眼于一批真实数据的批量从G.假数据的旁边 损耗与训练迭代 下面是d &安培的曲线图; G公司的损失与训练迭代。 plt.figure(figsize=(10,5)) plt.title(\"Generator and Discriminator Loss During Training\") plt.plot(G_losses,label=\"G\") plt.plot(D_losses,label=\"D\") plt.xlabel(\"iterations\") plt.ylabel(\"Loss\") plt.legend() plt.show() G公司的进展的可视化 还记得我们的训练每一个时代后保存在发电机上fixed_noise批量输出。现在，我们可以想像G的训练进展与动画。按PLAY键开始播放动画。 #%%capture fig = plt.figure(figsize=(8,8)) plt.axis(\"off\") ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list] ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True) HTML(ani.to_jshtml()) 真实全景与假图片 最后，让我们来看看一些真实的图像和假图像并排。 # Grab a batch of real images from the dataloader real_batch = next(iter(dataloader)) # Plot the real images plt.figure(figsize=(15,15)) plt.subplot(1,2,1) plt.axis(\"off\") plt.title(\"Real Images\") plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0))) # Plot the fake images from the last epoch plt.subplot(1,2,2) plt.axis(\"off\") plt.title(\"Fake Images\") plt.imshow(np.transpose(img_list[-1],(1,2,0))) plt.show() 下一步是什么 我们已经达到了我们的旅程结束，但有几个地方，你可以从这里走。你可以： 火车较长时间才能看到效果有多好得 修改这个模型来采取不同的数据集，并有可能改变图像的大小和模型架构 看看其他一些很酷的GAN项目此处 创建生成音乐甘斯 脚本的总运行时间： （28分钟13.763秒） Download Python source code: dcgan_faces_tutorial.py Download Jupyter notebook: dcgan_faces_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 DCGAN教程 介绍 剖成对抗性网络 什么是甘？ 什么是DCGAN？ 输入 数据 实现 重量初始化 发生器 鉴别 损失函数和优化器 培训 结果 下一步是什么 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/audio_preprocessing_tutorial.html":{"url":"beginner/audio_preprocessing_tutorial.html","title":"torchaudio教程","keywords":"","body":"torchaudio教程 PyTorch是一个开源的深度学习平台，提供给生产部署从研究原型的无缝路径与GPU的支持。 在解决机器学习问题显著的努力进入数据准备。 torchaudio利用PyTorch的GPU支持，并提供了许多工具，使数据加载容易，更具可读性。在本教程中，我们将看到如何从一个简单的数据集加载和数据预处理。 在本教程中，请确保matplotlib安装包，方便的可视化。 import torch import torchaudio import matplotlib.pyplot as plt 打开一个数据集 torchaudio支持加载在WAV和MP3格式的声音文件。我们称波形的最终原始音频信号。 filename = \"../_static/img/steam-train-whistle-daniel_simon-converted-from-mp3.wav\" waveform, sample_rate = torchaudio.load(filename) print(\"Shape of waveform: {}\".format(waveform.size())) print(\"Sample rate of waveform: {}\".format(sample_rate)) plt.figure() plt.plot(waveform.t().numpy()) 日期： Shape of waveform: torch.Size([2, 276858]) Sample rate of waveform: 44100 变换 torchaudio支持变换越来越多了。 重新取样 ：重新取样波形到不同的采样率。 谱图 ：建立从波形的频谱。 MelScale ：这接通正常STFT成梅尔频率STFT，使用转换矩阵。 AmplitudeToDB ：可打开的频谱从功率/幅度刻度分贝标度。 MFCC ：创建从波形的梅尔频率倒谱系数。 MelSpectrogram ：从使用PyTorch的STFT函数的波形创建MEL频谱图。 MuLawEncoding ：基于μ律压扩编码波形。 MuLawDecoding ：解码μ律编码波形。 由于所有的变换是nn.Modules或jit.ScriptModules，它们可以用作在任意点的神经网络的一部分。 首先，我们可以看看日志对数标度频谱图。 specgram = torchaudio.transforms.Spectrogram()(waveform) print(\"Shape of spectrogram: {}\".format(specgram.size())) plt.figure() plt.imshow(specgram.log2()[0,:,:].numpy(), cmap='gray') Out: Shape of spectrogram: torch.Size([2, 201, 1385]) 或者，我们可以看看梅尔谱图对数尺度。 specgram = torchaudio.transforms.MelSpectrogram()(waveform) print(\"Shape of spectrogram: {}\".format(specgram.size())) plt.figure() p = plt.imshow(specgram.log2()[0,:,:].detach().numpy(), cmap='gray') Out: Shape of spectrogram: torch.Size([2, 128, 1385]) 我们可以重新取样的波形，一次一个通道。 new_sample_rate = sample_rate/10 # Since Resample applies to a single channel, we resample first channel here channel = 0 transformed = torchaudio.transforms.Resample(sample_rate, new_sample_rate)(waveform[channel,:].view(1,-1)) print(\"Shape of transformed waveform: {}\".format(transformed.size())) plt.figure() plt.plot(transformed[0,:].numpy()) Out: Shape of transformed waveform: torch.Size([1, 27686]) 作为变革的另一个例子，我们可以编码基于Mu律enconding信号。但要做到这一点，我们需要的信号为-1到1之间。由于张量仅仅是一个普通PyTorch张量，我们可以把它应用标准的运营商。 # Let's check if the tensor is in the interval [-1,1] print(\"Min of waveform: {}\\nMax of waveform: {}\\nMean of waveform: {}\".format(waveform.min(), waveform.max(), waveform.mean())) Out: Min of waveform: -0.572845458984375 Max of waveform: 0.575958251953125 Mean of waveform: 9.293758921558037e-05 由于波形已经是-1到1之间，我们不需要正常化它。 def normalize(tensor): # Subtract the mean, and scale to the interval [-1,1] tensor_minusmean = tensor - tensor.mean() return tensor_minusmean/tensor_minusmean.abs().max() # Let's normalize to the full interval [-1,1] # waveform = normalize(waveform) 让我们看看用编码波形。 transformed = torchaudio.transforms.MuLawEncoding()(waveform) print(\"Shape of transformed waveform: {}\".format(transformed.size())) plt.figure() plt.plot(transformed[0,:].numpy()) Out: Shape of transformed waveform: torch.Size([2, 276858]) 而现在进行解码。 reconstructed = torchaudio.transforms.MuLawDecoding()(transformed) print(\"Shape of recovered waveform: {}\".format(reconstructed.size())) plt.figure() plt.plot(reconstructed[0,:].numpy()) Out: Shape of recovered waveform: torch.Size([2, 276858]) 我们终于可以比较其重建版本的原始波形。 # Compute median relative difference err = ((waveform-reconstructed).abs() / waveform.abs()).median() print(\"Median relative difference between original and MuLaw reconstucted signals: {:.2%}\".format(err)) Out: Median relative difference between original and MuLaw reconstucted signals: 1.28% 从移植到Kaldi torchaudio 用户可能熟悉 Kaldi ，用于语音识别的工具包。 torchaudio提供兼容性与它在torchaudio.kaldi_io。它可以从kaldi SCP，或方舟文件确实读取或流： read_vec_int_ark read_vec_flt_scp read_vec_flt_arkfile /流 read_mat_scp read_mat_ark torchaudio提供Kaldi兼容变换为谱图和fbank与GPU支持的益处，参见[这里HTG9用于更多信息。 n_fft = 400.0 frame_length = n_fft / sample_rate * 1000.0 frame_shift = frame_length / 2.0 params = { \"channel\": 0, \"dither\": 0.0, \"window_type\": \"hanning\", \"frame_length\": frame_length, \"frame_shift\": frame_shift, \"remove_dc_offset\": False, \"round_to_power_of_two\": False, \"sample_frequency\": sample_rate, } specgram = torchaudio.compliance.kaldi.spectrogram(waveform, **params) print(\"Shape of spectrogram: {}\".format(specgram.size())) plt.figure() plt.imshow(specgram.t().numpy(), cmap='gray') Out: Shape of spectrogram: torch.Size([1383, 201]) 我们也支持从波形计算滤波器功能，匹配Kaldi的实现。 fbank = torchaudio.compliance.kaldi.fbank(waveform, **params) print(\"Shape of fbank: {}\".format(fbank.size())) plt.figure() plt.imshow(fbank.t().numpy(), cmap='gray') Out: Shape of fbank: torch.Size([1383, 23]) 结论 我们使用的示例原始音频信号，或波形，以说明如何使用torchaudio打开音频文件，以及如何进行预处理和变换这样的波形。鉴于torchaudio是建立在PyTorch，这些技术可以被用来作为更先进的音频应用，如语音识别积木，同时充分利用GPU的。 脚本的总运行时间： （0分钟2.343秒） Download Python source code: audio_preprocessing_tutorial.py Download Jupyter notebook: audio_preprocessing_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 torchaudio教程 打开数据集 变换 迁移从Kaldi到torchaudio 结论 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"intermediate/char_rnn_classification_tutorial.html":{"url":"intermediate/char_rnn_classification_tutorial.html","title":"NLP从头：判断名称与字符级RNN","keywords":"","body":"NLP From Scratch：版本分类名称以字符级RNN 作者 ：肖恩·罗伯逊 我们将建设和培训基本字符级RNN分类的话。本教程，伴随着以下两个，说明如何做“从零开始” NLP建模数据预处理，特别是不使用许多的的便利功能torchtext ，所以你可以看到NLP造型如何预处理在较低水平的作品。 甲字符级RNN读取字作为一系列字符 - 在每个步骤输出预测和“隐藏状态”，喂食其先前的状态隐藏到每个下一步骤。我们采取最终预测是输出，即字属于哪个类。 具体来说，我们从18种语言起源的几千个姓氏训练，并预测该语言的名称是基于拼写： $ python predict.py Hinton (-0.47) Scottish (-1.52) English (-3.57) Irish $ python predict.py Schmidhuber (-0.19) German (-2.48) Czech (-2.68) Dutch 建议读： 我假设你已经至少安装PyTorch，知道Python和理解张量： [ https://pytorch.org/ HTG1对于安装说明 深，PyTorch学习：60分钟的闪电战 得到普遍开始PyTorch 与实施例 对于宽和深概述 学习PyTorch PyTorch为前Torch 用户 如果你是前者的LuaTorch 用户 这也将是有益的了解RNNs以及它们如何工作： 回归神经网络不合理有效性示出了一堆真实例子 理解LSTM网络为约LSTMs具体地说而且翔实约RNNs一般 准备数据 Note 从此处下载数据，并将其解压到当前目录。 包括在数据/名称目录被命名为“[语言] .TXT” 18个的文本文件。每个文件都包含了一堆名字，每行一个名字，大多罗马化（但我们仍然需要转换从Unicode到ASCII）。 我们将结束与每种语言的名称列表的字典，{语言： [名称 ...]} [HTG7。通用变量“类别”和“行”（在我们的例子中的语言和名称），用于以后的可扩展性。 from __future__ import unicode_literals, print_function, division from io import open import glob import os def findFiles(path): return glob.glob(path) print(findFiles('data/names/*.txt')) import unicodedata import string all_letters = string.ascii_letters + \" .,;'\" n_letters = len(all_letters) # Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427 def unicodeToAscii(s): return ''.join( c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn' and c in all_letters ) print(unicodeToAscii('Ślusàrski')) # Build the category_lines dictionary, a list of names per language category_lines = {} all_categories = [] # Read a file and split into lines def readLines(filename): lines = open(filename, encoding='utf-8').read().strip().split('\\n') return [unicodeToAscii(line) for line in lines] for filename in findFiles('data/names/*.txt'): category = os.path.splitext(os.path.basename(filename))[0] all_categories.append(category) lines = readLines(filename) category_lines[category] = lines n_categories = len(all_categories) 日期： ['data/names/French.txt', 'data/names/Czech.txt', 'data/names/Dutch.txt', 'data/names/Polish.txt', 'data/names/Scottish.txt', 'data/names/Chinese.txt', 'data/names/English.txt', 'data/names/Italian.txt', 'data/names/Portuguese.txt', 'data/names/Japanese.txt', 'data/names/German.txt', 'data/names/Russian.txt', 'data/names/Korean.txt', 'data/names/Arabic.txt', 'data/names/Greek.txt', 'data/names/Vietnamese.txt', 'data/names/Spanish.txt', 'data/names/Irish.txt'] Slusarski 现在我们有category_lines，一个字典映射每个类别（语言）到线（地名）的列表。我们还不断跟踪的all_categories n_categories 以供日后参考（只是一个语言列表）和[HTG9。 print(category_lines['Italian'][:5]) Out: ['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni'] 至于名称为张量 现在，我们有所有的名字组织的，我们需要把它们变成张量做任何使用它们。 来表示单个字母，我们使用尺寸&℃的“一热载体” ; 1 × n_letters [ - - ] GT ;。一个一热载体被填充有0以外的一个1在当前字母的索引，例如“B” = & LT ; 0 1 0 0 0 ... & GT ;。 为了使字我们加入了一堆那些成2D矩阵& LT ; line_length × 1 X n_letters & GT ;。 这额外的一个维是因为PyTorch假设一切都在批 - 我们只是使用1批量大小在这里。 import torch # Find letter index from all_letters, e.g. \"a\" = 0 def letterToIndex(letter): return all_letters.find(letter) # Just for demonstration, turn a letter into a Tensor def letterToTensor(letter): tensor = torch.zeros(1, n_letters) tensor[0][letterToIndex(letter)] = 1 return tensor # Turn a line into a , # or an array of one-hot letter vectors def lineToTensor(line): tensor = torch.zeros(len(line), 1, n_letters) for li, letter in enumerate(line): tensor[li][0][letterToIndex(letter)] = 1 return tensor print(letterToTensor('J')) print(lineToTensor('Jones').size()) Out: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) torch.Size([5, 1, 57]) 创建网络 autograd之前，创造了一个Torch 回归神经网络参与在几个时间步克隆层的参数。所述层保持隐藏状态和梯度其现在完全由图本身处理。这意味着你可以在一个非常“纯粹”的方式实现RNN，作为常规的前馈层。 此RNN模块（主要来自的PyTorchTorch 用户个别复制）是对输入和隐藏状态下操作，与输出后一个LogSoftmax层仅有2线性层。 import torch.nn as nn class RNN(nn.Module): def __init__(self, input_size, hidden_size, output_size): super(RNN, self).__init__() self.hidden_size = hidden_size self.i2h = nn.Linear(input_size + hidden_size, hidden_size) self.i2o = nn.Linear(input_size + hidden_size, output_size) self.softmax = nn.LogSoftmax(dim=1) def forward(self, input, hidden): combined = torch.cat((input, hidden), 1) hidden = self.i2h(combined) output = self.i2o(combined) output = self.softmax(output) return output, hidden def initHidden(self): return torch.zeros(1, self.hidden_size) n_hidden = 128 rnn = RNN(n_letters, n_hidden, n_categories) 要运行这个网络，我们需要传递一个输入的步骤（在我们的情况下，张量对于当前字母）和先前隐藏状态（这是我们在第一次初始化为零）。我们会回来的输出（每种语言的概率）和下一个隐藏的状态（这是我们保持对下一步）。 input = letterToTensor('A') hidden =torch.zeros(1, n_hidden) output, next_hidden = rnn(input, hidden) 为了提高效率起见，我们不希望成为创造每一步新的张量，因此我们将使用lineToTensor而不是letterToTensor并使用切片。这可以通过张量的预先计算的批次被进一步优化。 input = lineToTensor('Albert') hidden = torch.zeros(1, n_hidden) output, next_hidden = rnn(input[0], hidden) print(output) Out: tensor([[-2.8636, -2.8199, -2.8899, -2.9073, -2.9117, -2.8644, -2.9027, -2.9334, -2.8705, -2.8383, -2.8892, -2.9161, -2.8215, -2.9996, -2.9423, -2.9116, -2.8750, -2.8862]], grad_fn=) 正如可以看到的输出为& LT ; 1 × n_categories & GT ;张量，其中，每一个项目是该类别的可能性（较高可能性更大）。 培训 准备训练 之前进入训练中，我们应该做一些辅助功能。首先是要理解网络的输出，这是我们知道的是每个类别的可能性。我们可以使用Tensor.topk来获得最大价值的指标： def categoryFromOutput(output): top_n, top_i = output.topk(1) category_i = top_i[0].item() return all_categories[category_i], category_i print(categoryFromOutput(output)) Out: ('Czech', 1) 我们也将需要一个快速的方法来获得一个训练例子（名称和其语言）： import random def randomChoice(l): return l[random.randint(0, len(l) - 1)] def randomTrainingExample(): category = randomChoice(all_categories) line = randomChoice(category_lines[category]) category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long) line_tensor = lineToTensor(line) return category, line, category_tensor, line_tensor for i in range(10): category, line, category_tensor, line_tensor = randomTrainingExample() print('category =', category, '/ line =', line) Out: category = Dutch / line = Sanna category = Irish / line = O'Hara category = Portuguese / line = Barros category = Arabic / line = Mifsud category = Polish / line = Wojewodka category = Irish / line = O'Kelly category = Korean / line = Noh category = Korean / line = Byon category = Korean / line = Rhee category = German / line = Best 网络训练 现在，一切都需要训练这个网络是表现出来了一堆例子，有它做出猜测，并告诉它，如果它是错的。 的损失函数nn.NLLLoss是合适的，因为RNN的最后一层是nn.LogSoftmax。 criterion = nn.NLLLoss() 培训每个循环将： 创建输入和目标张量 创建一个零初始隐藏状态 阅读每个字母和 保持隐藏状态下一封信 比较最后输出到目标 背传播 返回输出和损失 learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn def train(category_tensor, line_tensor): hidden = rnn.initHidden() rnn.zero_grad() for i in range(line_tensor.size()[0]): output, hidden = rnn(line_tensor[i], hidden) loss = criterion(output, category_tensor) loss.backward() # Add parameters' gradients to their values, multiplied by learning rate for p in rnn.parameters(): p.data.add_(-learning_rate, p.grad.data) return output, loss.item() 现在，我们只需要运行与一堆例子。由于火车函数返回无论是产量和损失，我们可以打印其猜测，并跟踪丢失的密谋。既然有例子，我们1000只打印每print_every实例，并采取损失的平均值。 import time import math n_iters = 100000 print_every = 5000 plot_every = 1000 # Keep track of losses for plotting current_loss = 0 all_losses = [] def timeSince(since): now = time.time() s = now - since m = math.floor(s / 60) s -= m * 60 return '%dm %ds' % (m, s) start = time.time() for iter in range(1, n_iters + 1): category, line, category_tensor, line_tensor = randomTrainingExample() output, loss = train(category_tensor, line_tensor) current_loss += loss # Print iter number, loss, name and guess if iter % print_every == 0: guess, guess_i = categoryFromOutput(output) correct = '✓' if guess == category else '✗ (%s)' % category print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct)) # Add current loss avg to list of losses if iter % plot_every == 0: all_losses.append(current_loss / plot_every) current_loss = 0 Out: 5000 5% (0m 7s) 2.7482 Silje / French ✗ (Dutch) 10000 10% (0m 15s) 1.5569 Lillis / Greek ✓ 15000 15% (0m 22s) 2.7729 Burt / Korean ✗ (English) 20000 20% (0m 30s) 1.1036 Zhong / Chinese ✓ 25000 25% (0m 38s) 1.7088 Sarraf / Portuguese ✗ (Arabic) 30000 30% (0m 45s) 0.7595 Benivieni / Italian ✓ 35000 35% (0m 53s) 1.2900 Arreola / Italian ✗ (Spanish) 40000 40% (1m 0s) 2.3171 Gass / Arabic ✗ (German) 45000 45% (1m 8s) 3.1630 Stoppelbein / Dutch ✗ (German) 50000 50% (1m 15s) 1.7478 Berger / German ✗ (French) 55000 55% (1m 23s) 1.3516 Almeida / Spanish ✗ (Portuguese) 60000 60% (1m 31s) 1.8843 Hellewege / Dutch ✗ (German) 65000 65% (1m 38s) 1.7374 Moreau / French ✓ 70000 70% (1m 46s) 0.5718 Naifeh / Arabic ✓ 75000 75% (1m 53s) 0.6268 Zhui / Chinese ✓ 80000 80% (2m 1s) 2.2226 Dasios / Portuguese ✗ (Greek) 85000 85% (2m 9s) 1.3690 Walter / Scottish ✗ (German) 90000 90% (2m 16s) 0.5329 Zhang / Chinese ✓ 95000 95% (2m 24s) 3.4474 Skala / Czech ✗ (Polish) 100000 100% (2m 31s) 1.4720 Chi / Korean ✗ (Chinese) 绘制结果 绘制从all_losses历史损失示出了网络的学习： import matplotlib.pyplot as plt import matplotlib.ticker as ticker plt.figure() plt.plot(all_losses) 评价结果 要看到网络表现如何对不同的类别，我们将创建一个混淆矩阵，表示每一个实际的语言（行）的语言，网络的猜测（列）。为了计算混淆矩阵一堆样品的通过网络与评价（运行），它是相同的列车（）减去backprop。 # Keep track of correct guesses in a confusion matrix confusion = torch.zeros(n_categories, n_categories) n_confusion = 10000 # Just return an output given a line def evaluate(line_tensor): hidden = rnn.initHidden() for i in range(line_tensor.size()[0]): output, hidden = rnn(line_tensor[i], hidden) return output # Go through a bunch of examples and record which are correctly guessed for i in range(n_confusion): category, line, category_tensor, line_tensor = randomTrainingExample() output = evaluate(line_tensor) guess, guess_i = categoryFromOutput(output) category_i = all_categories.index(category) confusion[category_i][guess_i] += 1 # Normalize by dividing every row by its sum for i in range(n_categories): confusion[i] = confusion[i] / confusion[i].sum() # Set up plot fig = plt.figure() ax = fig.add_subplot(111) cax = ax.matshow(confusion.numpy()) fig.colorbar(cax) # Set up axes ax.set_xticklabels([''] + all_categories, rotation=90) ax.set_yticklabels([''] + all_categories) # Force label at every tick ax.xaxis.set_major_locator(ticker.MultipleLocator(1)) ax.yaxis.set_major_locator(ticker.MultipleLocator(1)) # sphinx_gallery_thumbnail_number = 2 plt.show() 你可以挑选出亮点关闭，显示它猜测的语言错误的主轴，例如中国对韩国，西班牙和意大利。这似乎与希腊做的非常好，也很不好英语（也许是因为与其他语言的重叠）。 运行在用户输入 def predict(input_line, n_predictions=3): print('\\n> %s' % input_line) with torch.no_grad(): output = evaluate(lineToTensor(input_line)) # Get top N categories topv, topi = output.topk(n_predictions, 1, True) predictions = [] for i in range(n_predictions): value = topv[0][i].item() category_index = topi[0][i].item() print('(%.2f) %s' % (value, all_categories[category_index])) predictions.append([value, all_categories[category_index]]) predict('Dovesky') predict('Jackson') predict('Satoshi') Out: > Dovesky (-0.47) Russian (-1.30) Czech (-2.90) Polish > Jackson (-1.04) Scottish (-1.72) English (-1.74) Russian > Satoshi (-0.32) Japanese (-2.63) Polish (-2.71) Italian 在实际PyTorch回购脚本的最终版本分裂上面的代码到几个文件： data.py（加载文件） model.py（定义RNN） train.py（试验训练） predict.py（运行预测（）命令行参数） server.py（服务预测为具有一个bottle.py JSON API） 运行train.py培养和保存网络。 运行predict.py使用一个名称，以查看预测： $ python predict.py Hazaki (-0.42) Japanese (-1.39) Polish (-3.51) Czech 运行server.py，参观 HTTP：//本地主机：5533 / YOURNAME 获得预测的JSON输出。 练习 用不同的数据集线的尝试 - & GT ;类别，例如： 任何字 - & GT ;语言 第一名字 - & GT ;性别 字符的名称 - & GT ;作家 页标题 - & GT ;博客或版（Subreddit） 取得更好的成绩有更大的和/或更好的网络状 添加更多线性层 尝试nn.LSTM和nn.GRU层 结合这些RNNs的多为高层网络 脚本的总运行时间： （2分钟42.458秒） Download Python source code: char_rnn_classification_tutorial.py Download Jupyter notebook: char_rnn_classification_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 NLP从头：判断名称与字符级RNN 准备数据 [HTG0转到名称成张量 创建网络 培训 准备训练 训练网络 绘制的结果 评估结果 运行于用户输入 练习 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"intermediate/char_rnn_generation_tutorial.html":{"url":"intermediate/char_rnn_generation_tutorial.html","title":"NLP从头：生成名称与字符级RNN","keywords":"","body":"NLP From Scratch：版本生成的名称用字符级RNN 作者 ：肖恩·罗伯逊 这是我们的“NLP的划痕”的三个教程第二。在第一教程& LT ; /中间/ char_rnn_classification_tutorial & GT ; 我们使用了RNN到名称分类到其原籍语言。这一次，我们将回过头来生成语言的名称。 > python sample.py Russian RUS Rovakov Uantov Shavakov > python sample.py German GER Gerren Ereng Rosher > python sample.py Spanish SPA Salla Parer Allan > python sample.py Chinese CHI Chan Hang Iun 我们还在手工编写一个小RNN与几个线性层。最大的区别是一个名称的所有字母看完之后，而不是预测的一个类别，我们输入一次一个类别，并输出一个字母。反复预测字符，以形成语言（这也可以与词语或其它高阶构建完成的）通常被称为“语言模型”。 建议读： 我假设你已经至少安装PyTorch，知道Python和理解张量： [ https://pytorch.org/ HTG1对于安装说明 深，PyTorch学习：60分钟的闪电战 得到普遍开始PyTorch 与实施例 对于宽和深概述 学习PyTorch PyTorch为前Torch 用户 如果你是前者的LuaTorch 用户 这也将是有益的了解RNNs以及它们如何工作： 回归神经网络不合理有效性示出了一堆真实例子 理解LSTM网络为约LSTMs具体地说而且翔实约RNNs一般 我也建议前面的教程， NLP From Scratch：版本分类名称以字符级RNN 准备数据 Note 从此处下载数据，并将其解压到当前目录。 看到最后教程，这个过程的更多细节。总之，存在与每一行的名称一堆纯文本文件数据/名称/ [语言]的.txt。我们分割线成一个数组，Unicode转换为ASCII码，并用字典结束{语言： [名称 ...]} [ HTG11。 from __future__ import unicode_literals, print_function, division from io import open import glob import os import unicodedata import string all_letters = string.ascii_letters + \" .,;'-\" n_letters = len(all_letters) + 1 # Plus EOS marker def findFiles(path): return glob.glob(path) # Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427 def unicodeToAscii(s): return ''.join( c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn' and c in all_letters ) # Read a file and split into lines def readLines(filename): lines = open(filename, encoding='utf-8').read().strip().split('\\n') return [unicodeToAscii(line) for line in lines] # Build the category_lines dictionary, a list of lines per category category_lines = {} all_categories = [] for filename in findFiles('data/names/*.txt'): category = os.path.splitext(os.path.basename(filename))[0] all_categories.append(category) lines = readLines(filename) category_lines[category] = lines n_categories = len(all_categories) if n_categories == 0: raise RuntimeError('Data not found. Make sure that you downloaded data ' 'from https://download.pytorch.org/tutorial/data.zip and extract it to ' 'the current directory.') print('# categories:', n_categories, all_categories) print(unicodeToAscii(\"O'Néàl\")) 日期： # categories: 18 ['French', 'Czech', 'Dutch', 'Polish', 'Scottish', 'Chinese', 'English', 'Italian', 'Portuguese', 'Japanese', 'German', 'Russian', 'Korean', 'Arabic', 'Greek', 'Vietnamese', 'Spanish', 'Irish'] O'Neal 创建网络 该网络已经延伸最后一个教程的RNN 与类别张量，这是与其他人一起串接一个额外的参数。类别张量是一热载体，就像字母输入。 我们将解释输出作为下一个字母的概率。抽样时，最有可能的输出信作为下一个输入字母。 我添加了一个第二线性层O2O（合成后隐藏和输出）给它更多的肌肉一起工作。还有一个漏失层，其随机归零其输入的部分具有给定的概率（这里0.1）和通常用于模糊输入，以防止过度拟合。这里，我们使用它向网络末端故意添加一些混乱，并增加抽样品种。 import torch import torch.nn as nn class RNN(nn.Module): def __init__(self, input_size, hidden_size, output_size): super(RNN, self).__init__() self.hidden_size = hidden_size self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size) self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size) self.o2o = nn.Linear(hidden_size + output_size, output_size) self.dropout = nn.Dropout(0.1) self.softmax = nn.LogSoftmax(dim=1) def forward(self, category, input, hidden): input_combined = torch.cat((category, input, hidden), 1) hidden = self.i2h(input_combined) output = self.i2o(input_combined) output_combined = torch.cat((hidden, output), 1) output = self.o2o(output_combined) output = self.dropout(output) output = self.softmax(output) return output, hidden def initHidden(self): return torch.zeros(1, self.hidden_size) 培训 准备训练 首先，辅助函数来获得随机对（类别，行）： import random # Random item from a list def randomChoice(l): return l[random.randint(0, len(l) - 1)] # Get a random category and random line from that category def randomTrainingPair(): category = randomChoice(all_categories) line = randomChoice(category_lines[category]) return category, line 对于每个时间步长（即，用于在训练单词的每个字母）的网络的输入将是（类别， 电流 信函 隐藏 的状态），输出将是（下一个 信函 下一个 隐藏 的状态）。因此，对于每一个训练集，我们需要的类别，一组输入字母，和一组输出/目标字母。 由于我们预测从当前字母的下一个字母每个时间步长，信对是从线连续字母组 - 例如为“ABCD & LT ; EOS & GT ;”我们将创建（“A”，“B”），（“ B”，‘C’），（‘C’，‘d’），（‘d’，‘EOS’）。 类别张量是独热张量大小的& LT ; 1 × n_categories [ - - ] GT ;。当我们训练它在每一个时间步喂到网络 - 这是一个设计选择，它可能已被列入作为初始隐藏状态的部分或其他一些策略。 # One-hot vector for category def categoryTensor(category): li = all_categories.index(category) tensor = torch.zeros(1, n_categories) tensor[0][li] = 1 return tensor # One-hot matrix of first to last letters (not including EOS) for input def inputTensor(line): tensor = torch.zeros(len(line), 1, n_letters) for li in range(len(line)): letter = line[li] tensor[li][0][all_letters.find(letter)] = 1 return tensor # LongTensor of second letter to end (EOS) for target def targetTensor(line): letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))] letter_indexes.append(n_letters - 1) # EOS return torch.LongTensor(letter_indexes) 为了在训练期间的方便，我们会成为一个randomTrainingExample功能，其获取的随机（类别，线）对并将其转换为所需的（类别，输入，目标）张量。 # Make category, input, and target tensors from a random category, line pair def randomTrainingExample(): category, line = randomTrainingPair() category_tensor = categoryTensor(category) input_line_tensor = inputTensor(line) target_line_tensor = targetTensor(line) return category_tensor, input_line_tensor, target_line_tensor 网络训练 与此相反，以分类，其中仅使用最后的输出中，我们在每个步骤进行预测，所以我们在每一步计算损失。 autograd的魔力让您只需在每一步总结这些损失，并在年底回呼。 criterion = nn.NLLLoss() learning_rate = 0.0005 def train(category_tensor, input_line_tensor, target_line_tensor): target_line_tensor.unsqueeze_(-1) hidden = rnn.initHidden() rnn.zero_grad() loss = 0 for i in range(input_line_tensor.size(0)): output, hidden = rnn(category_tensor, input_line_tensor[i], hidden) l = criterion(output, target_line_tensor[i]) loss += l loss.backward() for p in rnn.parameters(): p.data.add_(-learning_rate, p.grad.data) return output, loss.item() / input_line_tensor.size(0) 为了使培训需要多长时间我增加了timeSince（时间戳）HTG2]函数返回一个人类可读的字符串轨迹： import time import math def timeSince(since): now = time.time() s = now - since m = math.floor(s / 60) s -= m * 60 return '%dm %ds' % (m, s) 训练照常营业 - 称火车一堆时间和等待几分钟，打印出当前时间和损耗每print_every实例，并保持每一个平均损失[店面HTG4 ] plot_every 在实例all_losses供以后绘制。 rnn = RNN(n_letters, 128, n_letters) n_iters = 100000 print_every = 5000 plot_every = 500 all_losses = [] total_loss = 0 # Reset every plot_every iters start = time.time() for iter in range(1, n_iters + 1): output, loss = train(*randomTrainingExample()) total_loss += loss if iter % print_every == 0: print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss)) if iter % plot_every == 0: all_losses.append(total_loss / plot_every) total_loss = 0 Out: 0m 17s (5000 5%) 3.5187 0m 35s (10000 10%) 2.5492 0m 53s (15000 15%) 2.2320 1m 11s (20000 20%) 3.2664 1m 29s (25000 25%) 2.2973 1m 47s (30000 30%) 1.1620 2m 5s (35000 35%) 2.8624 2m 23s (40000 40%) 1.8314 2m 41s (45000 45%) 2.3952 2m 58s (50000 50%) 2.7142 3m 16s (55000 55%) 2.4662 3m 34s (60000 60%) 2.9410 3m 53s (65000 65%) 2.5558 4m 11s (70000 70%) 2.2629 4m 29s (75000 75%) 2.3106 4m 47s (80000 80%) 2.2239 5m 5s (85000 85%) 1.4803 5m 23s (90000 90%) 2.9525 5m 42s (95000 95%) 1.9797 6m 0s (100000 100%) 2.3567 绘制损失 绘制从all_losses的历史损失显示网络学习： import matplotlib.pyplot as plt import matplotlib.ticker as ticker plt.figure() plt.plot(all_losses) 采样网络 为了品尝我们给网络中的信，问下一个是什么，喂，在为下一个字母，并重复直到EOS令牌。 创建输入类别，首个字母，而空隐藏状态的张量 创建一个字符串output_name中与首字母 最多输出长度， 饲料当前信网络 获得从最高输出下一个字母，下一个隐藏的状态 如果这封信是EOS，到此为止 如果一个普通的信，添加到output_name中并继续 返回的最终名称 Note 而不是给它的首个字母，另一种策略会一直到包括“字符串的开始”令牌培训，并有网络选择自己的首个字母。 max_length = 20 # Sample from a category and starting letter def sample(category, start_letter='A'): with torch.no_grad(): # no need to track history in sampling category_tensor = categoryTensor(category) input = inputTensor(start_letter) hidden = rnn.initHidden() output_name = start_letter for i in range(max_length): output, hidden = rnn(category_tensor, input[0], hidden) topv, topi = output.topk(1) topi = topi[0][0] if topi == n_letters - 1: break else: letter = all_letters[topi] output_name += letter input = inputTensor(letter) return output_name # Get multiple samples from one category and multiple starting letters def samples(category, start_letters='ABC'): for start_letter in start_letters: print(sample(category, start_letter)) samples('Russian', 'RUS') samples('German', 'GER') samples('Spanish', 'SPA') samples('Chinese', 'CHI') Out: Rovallov Uanovakov Sanovakov Geller Eringer Raman Salos Para Allan Chan Hang Iun 练习 尝试使用不同的数据集的类 - & GT ;线，例如： 虚构系列 - & GT ;字符名称 语音的部分 - & GT ;字 国家 - [ - ] GT ;市 使用“句子的开始”标记，这样抽样可以在没有选择的开始字母来完成 取得更好的成绩有更大的和/或更好的网络状 尝试nn.LSTM和nn.GRU层 结合这些RNNs的多为高层网络 脚本的总运行时间： （6分钟0.536秒） Download Python source code: char_rnn_generation_tutorial.py Download Jupyter notebook: char_rnn_generation_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 NLP从头：生成名称与字符级RNN 准备数据 创建网络 培训 准备训练 训练网络 绘制的损失 采样网络 练习 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"intermediate/seq2seq_translation_tutorial.html":{"url":"intermediate/seq2seq_translation_tutorial.html","title":"NLP从无到有：用序列到序列网络和翻译注意","keywords":"","body":"NLP从头：用序列到序列网络和翻译注意 作者 ：肖恩·罗伯逊 这是在做“NLP的划痕”，在这里我们写我们自己的类和函数对数据进行预处理，以尽我们的NLP建模任务的第三次也是最后的教程。我们希望你完成本教程，你会继续学习如何 torchtext 可以处理很多这样的预处理为你的三个教程立即这个下面了。 在这个项目中，我们将教神经网络翻译从法语译成英语。 [KEY: > input, = target, il est en train de peindre un tableau . = he is painting a picture . pourquoi ne pas essayer ce vin delicieux ? = why not try that delicious wine ? elle n est pas poete mais romanciere . = she is not a poet but a novelist . vous etes trop maigre . = you re too skinny . ......以不同程度的成功。 这是由序列序网的简单而有力的想法，其中两个递归神经网络共同努力，一个序列变换到另一个成为可能。编码器网络冷凝的输入序列到载体中，和一个解码器网络展开该载体导入一个新的序列。 为了改善已在此模型中，我们将使用一个注意机制，它可以让解码器学会关注在输入序列的特定范围。 建议读： 我假设你已经至少安装PyTorch，知道Python和理解张量： [ https://pytorch.org/ HTG1对于安装说明 深，PyTorch学习：60分钟的闪电战 得到普遍开始PyTorch 与实施例 对于宽和深概述 学习PyTorch PyTorch为前Torch 用户 如果你是前者的LuaTorch 用户 这也将是有益的了解序列具有Sequence网络以及它们是如何工作： 学习使用RNN编码器 - 解码器对统计机器翻译短语表征 顺序以序列与神经网络的学习 通过共同学习来调整和翻译神经机器翻译 一种神经会话模型 用字符级RNN 和 NLP From Scratch的分类名称：生成的名称用字级，你还可以找到 NLP前面的教程从零开始RNN 有益，因为这些概念是非常类似于编码器和解码器模型，分别。 而对于更多的，阅读介绍这些主题的论文： 学习使用RNN编码器 - 解码器对统计机器翻译短语表征 顺序以序列与神经网络的学习 通过共同学习来调整和翻译神经机器翻译 一种神经会话模型 需求 from __future__ import unicode_literals, print_function, division from io import open import unicodedata import string import re import random import torch import torch.nn as nn from torch import optim import torch.nn.functional as F device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") 加载数据文件 该项目的数据是一组成千上万的英语法语翻译对。 开放式数据堆栈交换这个问题向我指出开放翻译网站 https://tatoeba.org/ 具有可在 https://tatoeba.org/下载英/下载 - 更好的是，有人却分裂的语言对成单个文本的额外的工作文件的位置： https://www.manythings.org/anki/ 英国法国对由于过大的回购协议包括，因此在继续之前下载到数据/ CHI-fra.txt [HTG3。该文件是翻译对制表符分隔列表： I am cold. J'ai froid. Note 从此处下载数据，并将其解压到当前目录。 类似于在字符级RNN教程使用的字符编码，我们将表示一种语言作为一热载体，或除了单一一个（这个词的索引处）的零向量巨每个单词。相比几十个可能在语言中存在的人物，有很多很多的话，那么编码向量大得多。不过，我们会欺骗了一下，修剪数据，每种语言只用几千字。 我们需要一个唯一索引每字为以后网络的投入和目标使用。要跟踪的这一切，我们将使用名为郎一个辅助类，其中有字→性指数（HTG4] word2index ）和索引→分词（index2word）词典，以及每个字的计数word2count使用稍后取代罕见词语。 SOS_token = 0 EOS_token = 1 class Lang: def __init__(self, name): self.name = name self.word2index = {} self.word2count = {} self.index2word = {0: \"SOS\", 1: \"EOS\"} self.n_words = 2 # Count SOS and EOS def addSentence(self, sentence): for word in sentence.split(' '): self.addWord(word) def addWord(self, word): if word not in self.word2index: self.word2index[word] = self.n_words self.word2count[word] = 1 self.index2word[self.n_words] = word self.n_words += 1 else: self.word2count[word] += 1 这些文件都在Unicode中，为了简化，我们将转向Unicode字符以ASCII，使一切小写和修剪大部分标点符号。 # Turn a Unicode string to plain ASCII, thanks to # https://stackoverflow.com/a/518232/2809427 def unicodeToAscii(s): return ''.join( c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn' ) # Lowercase, trim, and remove non-letter characters def normalizeString(s): s = unicodeToAscii(s.lower().strip()) s = re.sub(r\"([.!?])\", r\" \\1\", s) s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s) return s 为了读取数据文件，我们将文件分割成线，然后分割线分成两人一组。这些文件都是英语→其他语言，所以如果我们想从其他语言→英语翻译我加入了反向标志，以扭转对。 def readLangs(lang1, lang2, reverse=False): print(\"Reading lines...\") # Read the file and split into lines lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\ read().strip().split('\\n') # Split every line into pairs and normalize pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines] # Reverse pairs, make Lang instances if reverse: pairs = [list(reversed(p)) for p in pairs] input_lang = Lang(lang2) output_lang = Lang(lang1) else: input_lang = Lang(lang1) output_lang = Lang(lang2) return input_lang, output_lang, pairs 由于有 很多 举例句，我们希望快速培训的东西，我们会修剪数据设置为仅相对较短和简单的句子。在这里，最大长度为10个字（包括标点符号结束），我们正在筛选到转化为形式的句子“我”或“他”等（占更早替换撇号）。 MAX_LENGTH = 10 eng_prefixes = ( \"i am \", \"i m \", \"he is\", \"he s \", \"she is\", \"she s \", \"you are\", \"you re \", \"we are\", \"we re \", \"they are\", \"they re \" ) def filterPair(p): return len(p[0].split(' ')) 准备好数据的全过程： 阅读文本文件，并分割成线，分割线分成两人一组 由长度和内容正常化文本，过滤器 使Word列出了从成对的句子 def prepareData(lang1, lang2, reverse=False): input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse) print(\"Read %s sentence pairs\" % len(pairs)) pairs = filterPairs(pairs) print(\"Trimmed to %s sentence pairs\" % len(pairs)) print(\"Counting words...\") for pair in pairs: input_lang.addSentence(pair[0]) output_lang.addSentence(pair[1]) print(\"Counted words:\") print(input_lang.name, input_lang.n_words) print(output_lang.name, output_lang.n_words) return input_lang, output_lang, pairs input_lang, output_lang, pairs = prepareData('eng', 'fra', True) print(random.choice(pairs)) 日期： Reading lines... Read 135842 sentence pairs Trimmed to 10599 sentence pairs Counting words... Counted words: fra 4345 eng 2803 ['je ne suis pas embarrassee .', 'i m not embarrassed .'] 所述Seq2Seq模型 甲回归神经网络，或RNN，是操作上的序列，并且使用其自己的输出作为后续步骤输入的网络。 A 序列到序列网络，或seq2seq网络，或编码器解码器网络，是由两个RNNs的模型称为编码器和解码器。编码器读取的输入序列和输出的单个载体，和解码器读取矢量以产生一个输出序列。 不同于序列预测与单个RNN，其中每个输入对应于输出时，seq2seq模型可以让我们从序列长度和顺序，这使得它非常适合在两种语言之间的翻译。 考虑句子“JE NE PAS猪Le Chat Noir酒店”→“我不是黑猫”。大部分的输入句子的单词在输出句子的直接翻译，但在稍微不同的顺序，例如“聊天比诺”和“黑猫”。因为“NE / PAS”建设也有在输入句子多了一个字。这将是很难直接从输入字的顺序产生正确的翻译。 用seq2seq模型的编码器创建的单个载体，其在理想情况下，编码的输入序列的“意义”成单个载体 - 在句子在某些N维空间中的单个点。 编码器 一个seq2seq网络的编码器是RNN输出用于从所述输入语句的每一个字的一些值。对于每个输入字在编码器输出向量和一个隐藏的状态，并且使用隐藏状态用于下一个输入字。 class EncoderRNN(nn.Module): def __init__(self, input_size, hidden_size): super(EncoderRNN, self).__init__() self.hidden_size = hidden_size self.embedding = nn.Embedding(input_size, hidden_size) self.gru = nn.GRU(hidden_size, hidden_size) def forward(self, input, hidden): embedded = self.embedding(input).view(1, 1, -1) output = embedded output, hidden = self.gru(output, hidden) return output, hidden def initHidden(self): return torch.zeros(1, 1, self.hidden_size, device=device) 解码器 解码器是另一RNN，是以编码器输出向量（一个或多个），并输出单词序列来创建翻译。 简单解码器 在最简单的seq2seq解码器，我们只使用了编码器的最后一个输出。有时这最后的输出被称为 上下文向量，因为它编码从整个序列上下文 。这个上下文矢量用作解码器的初始隐蔽状态。 在解码的每一个步骤，所述解码器被给定的输入令牌和隐藏状态。初始输入令牌是启动的字符串& LT ; SOS & GT ;标记，并且所述第一隐藏状态是上下文向量（编码器的最后一个隐藏的状态）。 class DecoderRNN(nn.Module): def __init__(self, hidden_size, output_size): super(DecoderRNN, self).__init__() self.hidden_size = hidden_size self.embedding = nn.Embedding(output_size, hidden_size) self.gru = nn.GRU(hidden_size, hidden_size) self.out = nn.Linear(hidden_size, output_size) self.softmax = nn.LogSoftmax(dim=1) def forward(self, input, hidden): output = self.embedding(input).view(1, 1, -1) output = F.relu(output) output, hidden = self.gru(output, hidden) output = self.softmax(self.out(output[0])) return output, hidden def initHidden(self): return torch.zeros(1, 1, self.hidden_size, device=device) 我鼓励你培养和观察这种模式的结果，但为了节省空间，我们将直行的黄金和引入注意机制。 注意解码器 如果只有上下文矢量在编码器和解码器之间传递，即单个载体携带编码整个句子的负担。 注意允许解码器网络以“专注”在编码器的输出的用于解码器自身的输出中的每一个步骤的不同部分。首先，我们计算一组 关注权重 的。这些将由编码器输出矢量相乘以产生一个加权组合。的结果（称为在代码attn_applied）应当包含关于输入序列中的特定部分的信息，从而有助于解码器选择合适的输出字。 计算所述关注的权重与另一种前馈层经办人完成后，使用该解码器的输入和隐藏状态作为输入。因为在训练数据各种规模的句子，实际创建和培养这一层，我们必须选择一个最高刑期的长度（输入长度​​，编码器输出），它可以应用到。最大长度的句子将用全部的注意力权重，而较短的句子只会使用前几个。 class AttnDecoderRNN(nn.Module): def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH): super(AttnDecoderRNN, self).__init__() self.hidden_size = hidden_size self.output_size = output_size self.dropout_p = dropout_p self.max_length = max_length self.embedding = nn.Embedding(self.output_size, self.hidden_size) self.attn = nn.Linear(self.hidden_size * 2, self.max_length) self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size) self.dropout = nn.Dropout(self.dropout_p) self.gru = nn.GRU(self.hidden_size, self.hidden_size) self.out = nn.Linear(self.hidden_size, self.output_size) def forward(self, input, hidden, encoder_outputs): embedded = self.embedding(input).view(1, 1, -1) embedded = self.dropout(embedded) attn_weights = F.softmax( self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1) attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0)) output = torch.cat((embedded[0], attn_applied[0]), 1) output = self.attn_combine(output).unsqueeze(0) output = F.relu(output) output, hidden = self.gru(output, hidden) output = F.log_softmax(self.out(output[0]), dim=1) return output, hidden, attn_weights def initHidden(self): return torch.zeros(1, 1, self.hidden_size, device=device) Note 还有其他的，通过使用相对位置的方法解决长度不限形式的关注。阅读关于在的有效途径，以诚为本注意神经机器翻译“当地关注”。 培训 准备训练数据 为了训练，为每一对，我们需要输入张量（在输入句子中的词索引）和目标张量（在目标句中的指标）。在创建这些载体，我们将追加EOS令牌两个序列。 def indexesFromSentence(lang, sentence): return [lang.word2index[word] for word in sentence.split(' ')] def tensorFromSentence(lang, sentence): indexes = indexesFromSentence(lang, sentence) indexes.append(EOS_token) return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1) def tensorsFromPair(pair): input_tensor = tensorFromSentence(input_lang, pair[0]) target_tensor = tensorFromSentence(output_lang, pair[1]) return (input_tensor, target_tensor) 培养模式 为了训练我们通过编码器运行输入句子，并跟踪每一个输出的和最新的隐藏状态。然后，解码器被给出的& LT ; SOS & GT ;令牌作为其第一输入端，和的最后一个隐藏状态编码器作为其第一个隐藏的状态。 “教师迫使”是使用真正的目标输出作为每一个输入，而不是使用该解码器的猜测作为下一个输入的概念。用老师强迫使其收敛快，但[HTG0当训练的网络被利用，则可能出现不稳定[HTG1。 你可以观察到，与相干语法阅读而是从正确的翻译徘徊远老师强制网络输出 - 直觉告诉我已经学会代表输出语法，可以“拿起”的意思，一旦老师告诉它的前几话，但它已经无法正常学习了如何从摆在首位翻译创建了一句。 因为自由的PyTorch的autograd给我们，我们可以随意选用教师强制或不与简单的if语句。转动teacher_forcing_ratio为使用更多。 teacher_forcing_ratio = 0.5 def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH): encoder_hidden = encoder.initHidden() encoder_optimizer.zero_grad() decoder_optimizer.zero_grad() input_length = input_tensor.size(0) target_length = target_tensor.size(0) encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device) loss = 0 for ei in range(input_length): encoder_output, encoder_hidden = encoder( input_tensor[ei], encoder_hidden) encoder_outputs[ei] = encoder_output[0, 0] decoder_input = torch.tensor([[SOS_token]], device=device) decoder_hidden = encoder_hidden use_teacher_forcing = True if random.random() 这是一个辅助功能打印时间已过，估计剩余时间给出的当前时间和进度％。 import time import math def asMinutes(s): m = math.floor(s / 60) s -= m * 60 return '%dm %ds' % (m, s) def timeSince(since, percent): now = time.time() s = now - since es = s / (percent) rs = es - s return '%s (- %s)' % (asMinutes(s), asMinutes(rs)) 整个训练过程是这样的： 启动计时器 初始化优化和规范 创建集训练对 启动空损失阵列密谋 然后，我们调用训练很多时候，偶尔打印进度（实例％，时间为止，估计时间）和平均损失。 def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01): start = time.time() plot_losses = [] print_loss_total = 0 # Reset every print_every plot_loss_total = 0 # Reset every plot_every encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate) decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate) training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)] criterion = nn.NLLLoss() for iter in range(1, n_iters + 1): training_pair = training_pairs[iter - 1] input_tensor = training_pair[0] target_tensor = training_pair[1] loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion) print_loss_total += loss plot_loss_total += loss if iter % print_every == 0: print_loss_avg = print_loss_total / print_every print_loss_total = 0 print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters), iter, iter / n_iters * 100, print_loss_avg)) if iter % plot_every == 0: plot_loss_avg = plot_loss_total / plot_every plot_losses.append(plot_loss_avg) plot_loss_total = 0 showPlot(plot_losses) 绘制结果 绘图与matplotlib完成，使用损失值的阵列``保存在训练plot_losses 。 import matplotlib.pyplot as plt plt.switch_backend('agg') import matplotlib.ticker as ticker import numpy as np def showPlot(points): plt.figure() fig, ax = plt.subplots() # this locator puts ticks at regular intervals loc = ticker.MultipleLocator(base=0.2) ax.yaxis.set_major_locator(loc) plt.plot(points) 评价 评估主要是一样的训练，但没有目标，所以我们干脆喂解码器的预测回自己的每一步。每次它预测我们将它添加到输出串词，如果预测EOS原因，我们停在那里。我们还存放了解码器的注意输出，用于显示更高版本。 def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH): with torch.no_grad(): input_tensor = tensorFromSentence(input_lang, sentence) input_length = input_tensor.size()[0] encoder_hidden = encoder.initHidden() encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device) for ei in range(input_length): encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden) encoder_outputs[ei] += encoder_output[0, 0] decoder_input = torch.tensor([[SOS_token]], device=device) # SOS decoder_hidden = encoder_hidden decoded_words = [] decoder_attentions = torch.zeros(max_length, max_length) for di in range(max_length): decoder_output, decoder_hidden, decoder_attention = decoder( decoder_input, decoder_hidden, encoder_outputs) decoder_attentions[di] = decoder_attention.data topv, topi = decoder_output.data.topk(1) if topi.item() == EOS_token: decoded_words.append('') break else: decoded_words.append(output_lang.index2word[topi.item()]) decoder_input = topi.squeeze().detach() return decoded_words, decoder_attentions[:di + 1] 我们可以从训练集评估随机的句子，并打印出输入，目标和输出做出一些主观质量的判断： def evaluateRandomly(encoder, decoder, n=10): for i in range(n): pair = random.choice(pairs) print('>', pair[0]) print('=', pair[1]) output_words, attentions = evaluate(encoder, decoder, pair[0]) output_sentence = ' '.join(output_words) print('培训和评估 有了这些辅助功能（它看起来像额外的工作，但它可以更容易地运行多个实验），我们实际上可以初始化网络，并开始训练。 请记住，输入句子被大量过滤。对于这个小数据集，我们可以使用256个隐藏节点和一个GRU层相对较小的网络。在MacBook CPU上约40分钟后，我们会得到一些合理的结果。 Note 如果你运行这个笔记本，你可以训练，中断内核，评估和后继续训练。注释，其中编码器和解码器被初始化线并再次运行trainIters。 hidden_size = 256 encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device) attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device) trainIters(encoder1, attn_decoder1, 75000, print_every=5000) Out: 1m 44s (- 24m 25s) (5000 6%) 2.8246 3m 25s (- 22m 14s) (10000 13%) 2.2712 5m 6s (- 20m 26s) (15000 20%) 1.9838 6m 45s (- 18m 34s) (20000 26%) 1.6913 8m 24s (- 16m 48s) (25000 33%) 1.5066 10m 4s (- 15m 7s) (30000 40%) 1.3337 11m 45s (- 13m 26s) (35000 46%) 1.1914 13m 26s (- 11m 45s) (40000 53%) 1.0690 15m 7s (- 10m 4s) (45000 60%) 0.9474 16m 49s (- 8m 24s) (50000 66%) 0.8926 18m 31s (- 6m 44s) (55000 73%) 0.7832 20m 15s (- 5m 3s) (60000 80%) 0.7254 21m 58s (- 3m 22s) (65000 86%) 0.6642 23m 39s (- 1m 41s) (70000 93%) 0.5810 25m 20s (- 0m 0s) (75000 100%) 0.5430 evaluateRandomly(encoder1, attn_decoder1) Out: > je n ai pas peur du tout . = i m not at all afraid . > je suis ici . = i am here . > il est ici pour moi . = he s here for me . > il est respecte par tout le monde . = he is respected by everyone . > j en ai fini . = i m done with it . > je ne suis pas l entraineur . = i m not the coach . > je suis bon . = i am good . > je pars . = i m going . > j ai la baraka . = i m very fortunate . > tu en fais partie . = you re part of this . 注意可视化 注意机制的一个有用特性是它高度可解释的输出。因为它是用于加权输入序列的特定编码器输出，可想而知寻找其中，所述网络被聚焦在每个时间步长最多。 你可以简单地运行plt.matshow（关注）HTG2]看到显示的注意输出作为基质，与列在输入步骤和行是输出的步骤： output_words, attentions = evaluate( encoder1, attn_decoder1, \"je suis trop froid .\") plt.matshow(attentions.numpy()) 为了更好的观看体验，我们会做的加入轴线和标签的额外工作： def showAttention(input_sentence, output_words, attentions): # Set up figure with colorbar fig = plt.figure() ax = fig.add_subplot(111) cax = ax.matshow(attentions.numpy(), cmap='bone') fig.colorbar(cax) # Set up axes ax.set_xticklabels([''] + input_sentence.split(' ') + [''], rotation=90) ax.set_yticklabels([''] + output_words) # Show label at every tick ax.xaxis.set_major_locator(ticker.MultipleLocator(1)) ax.yaxis.set_major_locator(ticker.MultipleLocator(1)) plt.show() def evaluateAndShowAttention(input_sentence): output_words, attentions = evaluate( encoder1, attn_decoder1, input_sentence) print('input =', input_sentence) print('output =', ' '.join(output_words)) showAttention(input_sentence, output_words, attentions) evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\") evaluateAndShowAttention(\"elle est trop petit .\") evaluateAndShowAttention(\"je ne crains pas de mourir .\") evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\") Out: input = elle a cinq ans de moins que moi . output = she s five years younger than me . input = elle est trop petit . output = she is too short . input = je ne crains pas de mourir . output = i m not scared to die . input = c est un jeune directeur plein de talent . output = he s a talented young director . 练习 用不同的数据集的尝试 另一种语言对 人类→机（例如IOT命令） 聊天→响应 问→答 与预训练字的嵌入，如word2vec或手套更换的嵌入 尝试用更多的层，更隐蔽单位和更多的句子。比较了训练时间和结果。 如果您使用的翻译文件，其中对有两个相同的短语（我 是 测试 \\ T 我 是 测试），你可以用这个作为自动编码。尝试这个： 列车为自动编码器 仅保存了网络编码器 从那里培训新的解码器进行翻译 脚本的总运行时间： （25分钟27.786秒） Download Python source code: seq2seq_translation_tutorial.py Download Jupyter notebook: seq2seq_translation_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 NLP从无到有：用序列到序列网络和翻译注意 加载数据文件 [HTG0所述Seq2Seq模型 编码器 解码器 简单解码器 [HTG0注意力解码器 培训 准备的训练数据 训练模型 绘图结果 评价 训练和评价 可视注意 练习 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/text_sentiment_ngrams_tutorial.html":{"url":"beginner/text_sentiment_ngrams_tutorial.html","title":"文本分类与TorchText ","keywords":"","body":"文本分类与TorchText 本教程介绍了如何使用文本分类数据集在torchtext，其中包括 - AG_NEWS, - SogouNews, - DBpedia, - YelpReviewPolarity, - YelpReviewFull, - YahooAnswers, - AmazonReviewPolarity, - AmazonReviewFull 这个例子展示了如何训练监督学习算法使用这些TextClassification数据集中的一个的分类。 与n元语法负载数据 n元语法特征的包被应用到捕获有关地方词序一些部分信息。在实践中，双克或三克被施加比只有一个字，以提供更多的益处为字组。一个例子： \"load data with ngrams\" Bi-grams results: \"load data\", \"data with\", \"with ngrams\" Tri-grams results: \"load data with\", \"data with ngrams\" TextClassification数据集支持n元语法方法。通过n元语法设置为2，数据集中的示例文本将是单个单词加上双克字符串列表。 import torch import torchtext from torchtext.datasets import text_classification NGRAMS = 2 import os if not os.path.isdir('./.data'): os.mkdir('./.data') train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS']( root='./.data', ngrams=NGRAMS, vocab=None) BATCH_SIZE = 16 device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") 定义模型 该模型是由 EmbeddingBag 层和线性层（参见下图）的。 nn.EmbeddingBag计算出的嵌入的“袋”的平均值。这里的文本输入有不同的长度。 nn.EmbeddingBag这里不需要填充因为文本长度被保存在偏移。 另外，由于nn.EmbeddingBag积聚在飞跨嵌入物的平均值，nn.EmbeddingBag可以增强的性能和存储器效率处理张量的序列。 import torch.nn as nn import torch.nn.functional as F class TextSentiment(nn.Module): def __init__(self, vocab_size, embed_dim, num_class): super().__init__() self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True) self.fc = nn.Linear(embed_dim, num_class) self.init_weights() def init_weights(self): initrange = 0.5 self.embedding.weight.data.uniform_(-initrange, initrange) self.fc.weight.data.uniform_(-initrange, initrange) self.fc.bias.data.zero_() def forward(self, text, offsets): embedded = self.embedding(text, offsets) return self.fc(embedded) 发起一个实例 该AG_NEWS数据集有四个标签，因此类的数量是四个。 1 : World 2 : Sports 3 : Business 4 : Sci/Tec 的翻译大小等于词汇的长度（包括单词和n元语法）。类的数目等于标签的数量，这是四个AG_NEWS情况。 VOCAB_SIZE = len(train_dataset.get_vocab()) EMBED_DIM = 32 NUN_CLASS = len(train_dataset.get_labels()) model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device) 功能用于生成批量 由于文本条目具有不同的长度，自定义函数generate_batch（）被用于生成数据的批次和偏移。的函数传递到collat​​e_fn在torch.utils.data.DataLoader。输入至collat​​e_fn是具有的batch_size的大小张量的列表，并且collat​​e_fn功能它们打包成一个小批量。这里要注意，确保collat​​e_fn被声明为顶级画质。这确保了功能在每个工人可用。 在原始数据批输入的文本项被打包成一个列表，然后连接起来作为一个单一的张量作为nn.EmbeddingBag输入。偏移量是分隔符来表示文字张个人序列的开始索引的张量。标签是一个张保存单个文本输入的标签。 def generate_batch(batch): label = torch.tensor([entry[0] for entry in batch]) text = [entry[1] for entry in batch] offsets = [0] + [len(entry) for entry in text] # torch.Tensor.cumsum returns the cumulative sum # of elements in the dimension dim. # torch.Tensor([1.0, 2.0, 3.0]).cumsum(dim=0) offsets = torch.tensor(offsets[:-1]).cumsum(dim=0) text = torch.cat(text) return text, offsets, label 定义功能训练模型和评估结果。 [ torch.utils.data.DataLoader建议HTG1用于PyTorch用户，它使数据加载并行容易（一教程这里）。我们使用的DataLoader这里载入AG_NEWS数据集，并将其发送到模型的训练/验证。 from torch.utils.data import DataLoader def train_func(sub_train_): # Train the model train_loss = 0 train_acc = 0 data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch) for i, (text, offsets, cls) in enumerate(data): optimizer.zero_grad() text, offsets, cls = text.to(device), offsets.to(device), cls.to(device) output = model(text, offsets) loss = criterion(output, cls) train_loss += loss.item() loss.backward() optimizer.step() train_acc += (output.argmax(1) == cls).sum().item() # Adjust the learning rate scheduler.step() return train_loss / len(sub_train_), train_acc / len(sub_train_) def test(data_): loss = 0 acc = 0 data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch) for text, offsets, cls in data: text, offsets, cls = text.to(device), offsets.to(device), cls.to(device) with torch.no_grad(): output = model(text, offsets) loss = criterion(output, cls) loss += loss.item() acc += (output.argmax(1) == cls).sum().item() return loss / len(data_), acc / len(data_) 拆分数据集和运行模型 由于原始AG_NEWS没有有效的数据集，我们用的0.95（火车）和0.05（有效）的分流比分割训练数据集到火车/有效集。在这里，我们使用PyTorch核心库 torch.utils.data.dataset.random_split 功能。 CrossEntropyLoss 标准在单个类结合nn.LogSoftmax（）和nn.NLLLoss（）。以C类培养了分类问题时是非常有用的。 SGD 实现随机梯度下降法作为优化器。初始学习速率设置为4.0。 StepLR 在此用于调节通过历元的学习速率。 import time from torch.utils.data.dataset import random_split N_EPOCHS = 5 min_valid_loss = float('inf') criterion = torch.nn.CrossEntropyLoss().to(device) optimizer = torch.optim.SGD(model.parameters(), lr=4.0) scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9) train_len = int(len(train_dataset) * 0.95) sub_train_, sub_valid_ = \\ random_split(train_dataset, [train_len, len(train_dataset) - train_len]) for epoch in range(N_EPOCHS): start_time = time.time() train_loss, train_acc = train_func(sub_train_) valid_loss, valid_acc = test(sub_valid_) secs = int(time.time() - start_time) mins = secs / 60 secs = secs % 60 print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs)) print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)') print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)') 日期： Epoch: 1 | time in 0 minutes, 8 seconds Loss: 0.0261(train) | Acc: 84.8%(train) Loss: 0.0000(valid) | Acc: 90.4%(valid) Epoch: 2 | time in 0 minutes, 8 seconds Loss: 0.0120(train) | Acc: 93.5%(train) Loss: 0.0000(valid) | Acc: 91.2%(valid) Epoch: 3 | time in 0 minutes, 8 seconds Loss: 0.0070(train) | Acc: 96.4%(train) Loss: 0.0000(valid) | Acc: 90.8%(valid) Epoch: 4 | time in 0 minutes, 8 seconds Loss: 0.0039(train) | Acc: 98.1%(train) Loss: 0.0001(valid) | Acc: 91.0%(valid) Epoch: 5 | time in 0 minutes, 8 seconds Loss: 0.0023(train) | Acc: 99.0%(train) Loss: 0.0001(valid) | Acc: 90.9%(valid) 运行在GPU以下信息模型： 大纪元：1 |时间为0分钟，11秒 Loss: 0.0263(train) | Acc: 84.5%(train) Loss: 0.0001(valid) | Acc: 89.0%(valid) 大纪元：2 |时间0分钟，10秒 Loss: 0.0119(train) | Acc: 93.6%(train) Loss: 0.0000(valid) | Acc: 89.6%(valid) 大纪元：3 |时间0分钟，9秒 Loss: 0.0069(train) | Acc: 96.4%(train) Loss: 0.0000(valid) | Acc: 90.5%(valid) 大纪元：4 |时间为0分钟，11秒 Loss: 0.0038(train) | Acc: 98.2%(train) Loss: 0.0000(valid) | Acc: 90.4%(valid) 大纪元：5 |时间为0分钟，11秒 Loss: 0.0022(train) | Acc: 99.0%(train) Loss: 0.0000(valid) | Acc: 91.0%(valid) 评估与测试数据集的模型 print('Checking the results of test dataset...') test_loss, test_acc = test(test_dataset) print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)') Out: Checking the results of test dataset... Loss: 0.0002(test) | Acc: 89.3%(test) 检查测试数据集的结果... Loss: 0.0237(test) | Acc: 90.5%(test) 在随机新闻测试 用最好的模式，到目前为止并测试一个高尔夫新闻。标签信息可[此处HTG1。 import re from torchtext.data.utils import ngrams_iterator from torchtext.data.utils import get_tokenizer ag_news_label = {1 : \"World\", 2 : \"Sports\", 3 : \"Business\", 4 : \"Sci/Tec\"} def predict(text, model, vocab, ngrams): tokenizer = get_tokenizer(\"basic_english\") with torch.no_grad(): text = torch.tensor([vocab[token] for token in ngrams_iterator(tokenizer(text), ngrams)]) output = model(text, torch.tensor([0])) return output.argmax(1).item() + 1 ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\ enduring the season’s worst weather conditions on Sunday at The \\ Open on his way to a closing 75 at Royal Portrush, which \\ considering the wind and the rain was a respectable showing. \\ Thursday’s first round at the WGC-FedEx St. Jude Invitational \\ was another story. With temperatures in the mid-80s and hardly any \\ wind, the Spaniard was 13 strokes better in a flawless round. \\ Thanks to his best putting performance on the PGA Tour, Rahm \\ finished with an 8-under 62 for a three-stroke lead, which \\ was even more impressive considering he’d never played the \\ front nine at TPC Southwind.\" vocab = train_dataset.get_vocab() model = model.to(\"cpu\") print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, model, vocab, 2)]) Out: This is a Sports news 这是一个体育新闻 你可以找到本笔记此处中显示的代码示例。 脚本的总运行时间： （1分钟26.424秒） Download Python source code: text_sentiment_ngrams_tutorial.py Download Jupyter notebook: text_sentiment_ngrams_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 文本分类与TorchText 与n元语法负载数据 定义模型 启动一个实例 时使用的函数，以产生批次 定义函数来训练模型和评估结果。 分割数据集和运行模型 评估与测试数据集的模型 上随机新闻测试 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/torchtext_translation_tutorial.html":{"url":"beginner/torchtext_translation_tutorial.html","title":"语言翻译与TorchText ","keywords":"","body":"语言翻译与TorchText 本教程介绍了如何使用torchtext到数据预处理的几种便利类含有英语和德语句子著名的数据集，并用它来训练序列对序列模型的注意，可德国句子翻译成英文。 它是基于关闭的本教程从PyTorch社区成员本Trevett ，被赛斯魏德曼和Ben的许可创建。 在本教程的最后，你将能够： 预处理句子成用于NLP建模通常使用的格式使用以下torchtext便利类： TranslationDataset 领域HTG1] BucketIterator 领域HTG1]和 TranslationDataset torchtext具有创建数据集，可以轻松迭代完成创建语言翻译模型的目的工具。一个键类是领域HTG5]，指定每个句子应该进行预处理的方法，另一种是在 TranslationDataset ; torchtext有几个这样的数据集;在本教程中，我们将使用 Multi30k数据集，其中包含约30000句子（平均长度约13个字），英语和德语。 注：本教程中的标记化要求 Spacy 我们使用Spacy，因为它提供了英语以外的语言为符号化的大力支持。 torchtext提供basic_english标记生成器，并支持其他断词的英语（如摩西），但语言翻译 需要多个语言 - Spacy是你最好的选择。 为了运行该教程，第一安装spacy使用点子或康达。接下来，下载的英语和德语Spacy断词的原始数据： python -m spacy download en python -m spacy download de 与Spacy安装，下面的代码将标记化每个句子中基于TranslationDataset上在领域HTG6]中定义的标记生成器 from torchtext.datasets import Multi30k from torchtext.data import Field, BucketIterator SRC = Field(tokenize = \"spacy\", tokenizer_language=\"de\", init_token = '', eos_token = '', lower = True) TRG = Field(tokenize = \"spacy\", tokenizer_language=\"en\", init_token = '', eos_token = '', lower = True) train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), fields = (SRC, TRG)) 日期： downloading training.tar.gz downloading validation.tar.gz downloading mmt_task1_test2016.tar.gz 现在，我们已经定义train_data，我们可以看到的torchtext的字段一个非常有用的功能：将build_vocab方法现在允许我们创建与每个语言相关联的词汇 SRC.build_vocab(train_data, min_freq = 2) TRG.build_vocab(train_data, min_freq = 2) 一旦这些代码行已经在运行，SRC.vocab.stoi将与词汇表中的作为键的标记和它们相应的索引作为字典的值; SRC.vocab.itos将是相同的字典，交换了键和值。我们不会广泛使用这一事实在本教程中，但是这可能会在你遇到其他NLP任务有用。 BucketIterator 我们将使用最后一个torchtext具体特征是BucketIterator，这是很容易使用，因为它需要一个TranslationDataset作为它的第一个参数。具体而言，作为文档说：定义批处理类似长度的实例一起的迭代器。最小化，同时产生新鲜混洗批次为每个新历元所需要的填充量。参见所用桶装程序池。 import torch device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') BATCH_SIZE = 128 train_iterator, valid_iterator, test_iterator = BucketIterator.splits( (train_data, valid_data, test_data), batch_size = BATCH_SIZE, device = device) 这些迭代可以被称为就像DataLoader``s ; 下面， 在 中的 ``培养和评价的功能，它们被简单地称为带： for i, batch in enumerate(iterator): 每个批次于是具有SRC和TRG属性： src = batch.src trg = batch.trg 定义我们的nn.Module和优化 这主要是从一个torchtextperspecive：内置的数据集和定义的迭代器，本教程的其余部分只是我们的模型定义为nn.Module，与沿优化，然后训练它。 我们的模型而言，如下描述HTG0]此处[HTG1（你可以找到一个显著更多评论版此处）的架构。 注意：这种模式仅仅是可用于语言翻译的示例模型;我们选择它，因为它是该任务的标准模型，而不是因为它是推荐的机型使用进行翻译。正如你可能知道，国家的最先进的机型，目前基于变形金刚;你可以看到PyTorch的能力，实现变压器层此处 ;，特别的“关注”在下面的模型中使用的是多头存在于变压器模型自注意不同。 import random from typing import Tuple import torch.nn as nn import torch.optim as optim import torch.nn.functional as F from torch import Tensor class Encoder(nn.Module): def __init__(self, input_dim: int, emb_dim: int, enc_hid_dim: int, dec_hid_dim: int, dropout: float): super().__init__() self.input_dim = input_dim self.emb_dim = emb_dim self.enc_hid_dim = enc_hid_dim self.dec_hid_dim = dec_hid_dim self.dropout = dropout self.embedding = nn.Embedding(input_dim, emb_dim) self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True) self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim) self.dropout = nn.Dropout(dropout) def forward(self, src: Tensor) -> Tuple[Tensor]: embedded = self.dropout(self.embedding(src)) outputs, hidden = self.rnn(embedded) hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))) return outputs, hidden class Attention(nn.Module): def __init__(self, enc_hid_dim: int, dec_hid_dim: int, attn_dim: int): super().__init__() self.enc_hid_dim = enc_hid_dim self.dec_hid_dim = dec_hid_dim self.attn_in = (enc_hid_dim * 2) + dec_hid_dim self.attn = nn.Linear(self.attn_in, attn_dim) def forward(self, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tensor: src_len = encoder_outputs.shape[0] repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1) encoder_outputs = encoder_outputs.permute(1, 0, 2) energy = torch.tanh(self.attn(torch.cat(( repeated_decoder_hidden, encoder_outputs), dim = 2))) attention = torch.sum(energy, dim=2) return F.softmax(attention, dim=1) class Decoder(nn.Module): def __init__(self, output_dim: int, emb_dim: int, enc_hid_dim: int, dec_hid_dim: int, dropout: int, attention: nn.Module): super().__init__() self.emb_dim = emb_dim self.enc_hid_dim = enc_hid_dim self.dec_hid_dim = dec_hid_dim self.output_dim = output_dim self.dropout = dropout self.attention = attention self.embedding = nn.Embedding(output_dim, emb_dim) self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim) self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim) self.dropout = nn.Dropout(dropout) def _weighted_encoder_rep(self, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tensor: a = self.attention(decoder_hidden, encoder_outputs) a = a.unsqueeze(1) encoder_outputs = encoder_outputs.permute(1, 0, 2) weighted_encoder_rep = torch.bmm(a, encoder_outputs) weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2) return weighted_encoder_rep def forward(self, input: Tensor, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tuple[Tensor]: input = input.unsqueeze(0) embedded = self.dropout(self.embedding(input)) weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden, encoder_outputs) rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2) output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0)) embedded = embedded.squeeze(0) output = output.squeeze(0) weighted_encoder_rep = weighted_encoder_rep.squeeze(0) output = self.out(torch.cat((output, weighted_encoder_rep, embedded), dim = 1)) return output, decoder_hidden.squeeze(0) class Seq2Seq(nn.Module): def __init__(self, encoder: nn.Module, decoder: nn.Module, device: torch.device): super().__init__() self.encoder = encoder self.decoder = decoder self.device = device def forward(self, src: Tensor, trg: Tensor, teacher_forcing_ratio: float = 0.5) -> Tensor: batch_size = src.shape[1] max_len = trg.shape[0] trg_vocab_size = self.decoder.output_dim outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device) encoder_outputs, hidden = self.encoder(src) # first input to the decoder is the token output = trg[0,:] for t in range(1, max_len): output, hidden = self.decoder(output, hidden, encoder_outputs) outputs[t] = output teacher_force = random.random() Out: The model has 1,856,685 trainable parameters 注：得分尤其是语言翻译模型的性能时，我们必须告诉nn.CrossEntropyLoss函数忽略其中目标是简单地填充索引。 PAD_IDX = TRG.vocab.stoi[''] criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX) 最后，我们可以训练和评价这一模式： import math import time def train(model: nn.Module, iterator: BucketIterator, optimizer: optim.Optimizer, criterion: nn.Module, clip: float): model.train() epoch_loss = 0 for _, batch in enumerate(iterator): src = batch.src trg = batch.trg optimizer.zero_grad() output = model(src, trg) output = output[1:].view(-1, output.shape[-1]) trg = trg[1:].view(-1) loss = criterion(output, trg) loss.backward() torch.nn.utils.clip_grad_norm_(model.parameters(), clip) optimizer.step() epoch_loss += loss.item() return epoch_loss / len(iterator) def evaluate(model: nn.Module, iterator: BucketIterator, criterion: nn.Module): model.eval() epoch_loss = 0 with torch.no_grad(): for _, batch in enumerate(iterator): src = batch.src trg = batch.trg output = model(src, trg, 0) #turn off teacher forcing output = output[1:].view(-1, output.shape[-1]) trg = trg[1:].view(-1) loss = criterion(output, trg) epoch_loss += loss.item() return epoch_loss / len(iterator) def epoch_time(start_time: int, end_time: int): elapsed_time = end_time - start_time elapsed_mins = int(elapsed_time / 60) elapsed_secs = int(elapsed_time - (elapsed_mins * 60)) return elapsed_mins, elapsed_secs N_EPOCHS = 10 CLIP = 1 best_valid_loss = float('inf') for epoch in range(N_EPOCHS): start_time = time.time() train_loss = train(model, train_iterator, optimizer, criterion, CLIP) valid_loss = evaluate(model, valid_iterator, criterion) end_time = time.time() epoch_mins, epoch_secs = epoch_time(start_time, end_time) print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s') print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}') print(f'\\t Val. Loss: {valid_loss:.3f} | Val. PPL: {math.exp(valid_loss):7.3f}') test_loss = evaluate(model, test_iterator, criterion) print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |') Out: Epoch: 01 | Time: 0m 36s Train Loss: 5.686 | Train PPL: 294.579 Val. Loss: 5.250 | Val. PPL: 190.638 Epoch: 02 | Time: 0m 37s Train Loss: 5.019 | Train PPL: 151.260 Val. Loss: 5.155 | Val. PPL: 173.274 Epoch: 03 | Time: 0m 37s Train Loss: 4.757 | Train PPL: 116.453 Val. Loss: 4.976 | Val. PPL: 144.824 Epoch: 04 | Time: 0m 35s Train Loss: 4.574 | Train PPL: 96.914 Val. Loss: 4.835 | Val. PPL: 125.834 Epoch: 05 | Time: 0m 35s Train Loss: 4.421 | Train PPL: 83.185 Val. Loss: 4.783 | Val. PPL: 119.414 Epoch: 06 | Time: 0m 38s Train Loss: 4.321 | Train PPL: 75.233 Val. Loss: 4.802 | Val. PPL: 121.734 Epoch: 07 | Time: 0m 38s Train Loss: 4.233 | Train PPL: 68.957 Val. Loss: 4.675 | Val. PPL: 107.180 Epoch: 08 | Time: 0m 35s Train Loss: 4.108 | Train PPL: 60.838 Val. Loss: 4.622 | Val. PPL: 101.693 Epoch: 09 | Time: 0m 34s Train Loss: 4.020 | Train PPL: 55.680 Val. Loss: 4.530 | Val. PPL: 92.785 Epoch: 10 | Time: 0m 34s Train Loss: 3.919 | Train PPL: 50.367 Val. Loss: 4.448 | Val. PPL: 85.441 | Test Loss: 4.464 | Test PPL: 86.801 | 接下来的步骤 看看本Trevett的教程的其余部分使用torchtext这里 请继续使用其他torchtext功能与一起调整为教程nn.Transformer通过下一个单词预测语言建模！ 脚本的总运行时间： （6分钟27.732秒） Download Python source code: torchtext_translation_tutorial.py Download Jupyter notebook: torchtext_translation_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 语言翻译与TorchText 领域HTG2]和 TranslationDataset BucketIterator 定义我们的nn.Module和优化 [HTG0接下来的步骤 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/transformer_tutorial.html":{"url":"beginner/transformer_tutorial.html","title":"序列到序列与nn.Transformer和TorchText建模","keywords":"","body":"序列对序列建模nn.Transformer和TorchText 这是关于如何训练一个使用 nn.Transformer 模块的序列到序列模型的教程。 PyTorch 1.2版本包括基于纸张标准变压器模块[注意是所有你需要HTG1。变压器模型已经证明，同时更可并行是在质量为众多序列到序列问题优越。的nn.Transformer模块完全依赖于注意机制（如最近 nn.MultiheadAttention 实现的另一模块）来绘制的输入和输出之间的全局相关性。的nn.Transformer模块现在高度模块化使得单个组分（如 nn.TransformerEncoder 在本教程）可以容易地适应/组成。 定义模型 在本教程中，我们训练nn.TransformerEncoder在语言建模任务模式。语言建模任务是分配的概率为给定字（或词的序列）的可能性遵循的字序列。标记序列被传递到埋层第一，接着是位置编码层以考虑字的次序（详见下段）。的nn.TransformerEncoder由 nn.TransformerEncoderLayer 多层。随着输入序列，需要多注意口罩，因为自注意力层nn.TransformerEncoder只允许参加序列中的较早位置。对于语言建模任务，对未来位置的任何标记应该屏蔽。有实际的话，的输出nn.TransformerEncoder模型被发送到最终直线层，之后是对数使用SoftMax功能。 import math import torch import torch.nn as nn import torch.nn.functional as F class TransformerModel(nn.Module): def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5): super(TransformerModel, self).__init__() from torch.nn import TransformerEncoder, TransformerEncoderLayer self.model_type = 'Transformer' self.src_mask = None self.pos_encoder = PositionalEncoding(ninp, dropout) encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout) self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers) self.encoder = nn.Embedding(ntoken, ninp) self.ninp = ninp self.decoder = nn.Linear(ninp, ntoken) self.init_weights() def _generate_square_subsequent_mask(self, sz): mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1) mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0)) return mask def init_weights(self): initrange = 0.1 self.encoder.weight.data.uniform_(-initrange, initrange) self.decoder.bias.data.zero_() self.decoder.weight.data.uniform_(-initrange, initrange) def forward(self, src): if self.src_mask is None or self.src_mask.size(0) != len(src): device = src.device mask = self._generate_square_subsequent_mask(len(src)).to(device) self.src_mask = mask src = self.encoder(src) * math.sqrt(self.ninp) src = self.pos_encoder(src) output = self.transformer_encoder(src, self.src_mask) output = self.decoder(output) return F.log_softmax(output, dim=-1) PositionalEncoding模块注入大约序列中的令牌的相对或绝对位置的一些信息。的位置编码具有相同的尺寸，使得两个可以概括的嵌入物。在这里，我们使用不同的频率的正弦和余弦功能。 class PositionalEncoding(nn.Module): def __init__(self, d_model, dropout=0.1, max_len=5000): super(PositionalEncoding, self).__init__() self.dropout = nn.Dropout(p=dropout) pe = torch.zeros(max_len, d_model) position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1) div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) pe[:, 0::2] = torch.sin(position * div_term) pe[:, 1::2] = torch.cos(position * div_term) pe = pe.unsqueeze(0).transpose(0, 1) self.register_buffer('pe', pe) def forward(self, x): x = x + self.pe[:x.size(0), :] return self.dropout(x) 负载和批数据 训练过程中使用wikitext的-2数据集从torchtext。的翻译对象基于列车数据集构建并用于令牌numericalize成张量。从序列数据开始，batchify（）函数排列数据集到列中，修剪掉剩余的任何令牌中的数据已经被划分成大小为的batch_size的批次后。例如，具有字母的序列（26总长度）和4:1的批量大小，我们将划分成字母长度为6的4个序列： \\[\\begin{split}\\begin{bmatrix} \\text{A} & \\text{B} & \\text{C} & \\ldots & \\text{X} & \\text{Y} & \\text{Z} \\end{bmatrix} \\Rightarrow \\begin{bmatrix} \\begin{bmatrix}\\text{A} \\\\ \\text{B} \\\\ \\text{C} \\\\ \\text{D} \\\\ \\text{E} \\\\ \\text{F}\\end{bmatrix} & \\begin{bmatrix}\\text{G} \\\\ \\text{H} \\\\ \\text{I} \\\\ \\text{J} \\\\ \\text{K} \\\\ \\text{L}\\end{bmatrix} & \\begin{bmatrix}\\text{M} \\\\ \\text{N} \\\\ \\text{O} \\\\ \\text{P} \\\\ \\text{Q} \\\\ \\text{R}\\end{bmatrix} & \\begin{bmatrix}\\text{S} \\\\ \\text{T} \\\\ \\text{U} \\\\ \\text{V} \\\\ \\text{W} \\\\ \\text{X}\\end{bmatrix} \\end{bmatrix}\\end{split}\\] 这些列由模型，这意味着G和F不能被学习，依赖性但允许视为独立更有效的批处理。 import torchtext from torchtext.data.utils import get_tokenizer TEXT = torchtext.data.Field(tokenize=get_tokenizer(\"basic_english\"), init_token='', eos_token='', lower=True) train_txt, val_txt, test_txt = torchtext.datasets.WikiText2.splits(TEXT) TEXT.build_vocab(train_txt) device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") def batchify(data, bsz): data = TEXT.numericalize([data.examples[0].text]) # Divide the dataset into bsz parts. nbatch = data.size(0) // bsz # Trim off any extra elements that wouldn't cleanly fit (remainders). data = data.narrow(0, 0, nbatch * bsz) # Evenly divide the data across the bsz batches. data = data.view(bsz, -1).t().contiguous() return data.to(device) batch_size = 20 eval_batch_size = 10 train_data = batchify(train_txt, batch_size) val_data = batchify(val_txt, eval_batch_size) test_data = batchify(test_txt, eval_batch_size) 日期： downloading wikitext-2-v1.zip extracting 函数来产生输入和目标序列 get_batch（）函数生成用于变压器模型的输入和靶序列。它的源数据细分为长度BPTT的块。对于语言建模任务，该模型需要以下单词作为目标 [HTG11。例如，用BPTT的2值，我们会得到以下两个变量为i的 = 0： 应当注意的是，块是沿着维度0与S在变压器模型尺寸相一致。将批料尺寸N是沿着维度1。 bptt = 35 def get_batch(source, i): seq_len = min(bptt, len(source) - 1 - i) data = source[i:i+seq_len] target = source[i+1:i+1+seq_len].view(-1) return data, target 发起一个实例 该模型建立与下面的超参数。的词汇尺寸等于词汇对象的长度。 ntokens = len(TEXT.vocab.stoi) # the size of vocabulary emsize = 200 # embedding dimension nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder nhead = 2 # the number of heads in the multiheadattention models dropout = 0.2 # the dropout value model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device) 运行模型 CrossEntropyLoss 被施加到跟踪损耗和 SGD 实现随机梯度下降法作为优化器。初始学习速率设置为5.0。 StepLR 被施加到调节通过历元学习速率。在培训过程中，我们使用 nn.utils.clipgrad_norm 功能扩展所有梯度在一起，以防止爆炸。 criterion = nn.CrossEntropyLoss() lr = 5.0 # learning rate optimizer = torch.optim.SGD(model.parameters(), lr=lr) scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95) import time def train(): model.train() # Turn on the train mode total_loss = 0. start_time = time.time() ntokens = len(TEXT.vocab.stoi) for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)): data, targets = get_batch(train_data, i) optimizer.zero_grad() output = model(data) loss = criterion(output.view(-1, ntokens), targets) loss.backward() torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) optimizer.step() total_loss += loss.item() log_interval = 200 if batch % log_interval == 0 and batch > 0: cur_loss = total_loss / log_interval elapsed = time.time() - start_time print('| epoch {:3d} | {:5d}/{:5d} batches | ' 'lr {:02.2f} | ms/batch {:5.2f} | ' 'loss {:5.2f} | ppl {:8.2f}'.format( epoch, batch, len(train_data) // bptt, scheduler.get_lr()[0], elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss))) total_loss = 0 start_time = time.time() def evaluate(eval_model, data_source): eval_model.eval() # Turn on the evaluation mode total_loss = 0. ntokens = len(TEXT.vocab.stoi) with torch.no_grad(): for i in range(0, data_source.size(0) - 1, bptt): data, targets = get_batch(data_source, i) output = eval_model(data) output_flat = output.view(-1, ntokens) total_loss += len(data) * criterion(output_flat, targets).item() return total_loss / (len(data_source) - 1) 遍历时期。保存模型如果验证损失是到目前为止我们见过的最好的。每次调整后时代的学习率。 best_val_loss = float(\"inf\") epochs = 3 # The number of epochs best_model = None for epoch in range(1, epochs + 1): epoch_start_time = time.time() train() val_loss = evaluate(model, val_data) print('-' * 89) print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | ' 'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time), val_loss, math.exp(val_loss))) print('-' * 89) if val_loss Out: | epoch 1 | 200/ 2981 batches | lr 5.00 | ms/batch 35.59 | loss 8.12 | ppl 3348.51 | epoch 1 | 400/ 2981 batches | lr 5.00 | ms/batch 34.57 | loss 6.82 | ppl 912.80 | epoch 1 | 600/ 2981 batches | lr 5.00 | ms/batch 34.55 | loss 6.39 | ppl 597.41 | epoch 1 | 800/ 2981 batches | lr 5.00 | ms/batch 34.59 | loss 6.25 | ppl 517.17 | epoch 1 | 1000/ 2981 batches | lr 5.00 | ms/batch 34.58 | loss 6.12 | ppl 455.67 | epoch 1 | 1200/ 2981 batches | lr 5.00 | ms/batch 34.59 | loss 6.09 | ppl 442.33 | epoch 1 | 1400/ 2981 batches | lr 5.00 | ms/batch 34.60 | loss 6.04 | ppl 421.27 | epoch 1 | 1600/ 2981 batches | lr 5.00 | ms/batch 34.59 | loss 6.05 | ppl 423.61 | epoch 1 | 1800/ 2981 batches | lr 5.00 | ms/batch 34.60 | loss 5.96 | ppl 386.26 | epoch 1 | 2000/ 2981 batches | lr 5.00 | ms/batch 34.60 | loss 5.96 | ppl 387.13 | epoch 1 | 2200/ 2981 batches | lr 5.00 | ms/batch 34.60 | loss 5.85 | ppl 347.56 | epoch 1 | 2400/ 2981 batches | lr 5.00 | ms/batch 34.60 | loss 5.89 | ppl 362.72 | epoch 1 | 2600/ 2981 batches | lr 5.00 | ms/batch 34.60 | loss 5.90 | ppl 363.70 | epoch 1 | 2800/ 2981 batches | lr 5.00 | ms/batch 34.61 | loss 5.80 | ppl 330.43 ----------------------------------------------------------------------------------------- | end of epoch 1 | time: 107.65s | valid loss 5.77 | valid ppl 321.01 ----------------------------------------------------------------------------------------- | epoch 2 | 200/ 2981 batches | lr 4.75 | ms/batch 34.78 | loss 5.81 | ppl 333.28 | epoch 2 | 400/ 2981 batches | lr 4.75 | ms/batch 34.63 | loss 5.78 | ppl 324.24 | epoch 2 | 600/ 2981 batches | lr 4.75 | ms/batch 34.62 | loss 5.61 | ppl 272.10 | epoch 2 | 800/ 2981 batches | lr 4.75 | ms/batch 34.62 | loss 5.65 | ppl 283.77 | epoch 2 | 1000/ 2981 batches | lr 4.75 | ms/batch 34.61 | loss 5.60 | ppl 269.12 | epoch 2 | 1200/ 2981 batches | lr 4.75 | ms/batch 34.63 | loss 5.62 | ppl 275.40 | epoch 2 | 1400/ 2981 batches | lr 4.75 | ms/batch 34.62 | loss 5.62 | ppl 276.93 | epoch 2 | 1600/ 2981 batches | lr 4.75 | ms/batch 34.62 | loss 5.66 | ppl 287.64 | epoch 2 | 1800/ 2981 batches | lr 4.75 | ms/batch 34.63 | loss 5.59 | ppl 268.86 | epoch 2 | 2000/ 2981 batches | lr 4.75 | ms/batch 34.62 | loss 5.63 | ppl 277.73 | epoch 2 | 2200/ 2981 batches | lr 4.75 | ms/batch 34.63 | loss 5.52 | ppl 249.01 | epoch 2 | 2400/ 2981 batches | lr 4.75 | ms/batch 34.61 | loss 5.58 | ppl 265.86 | epoch 2 | 2600/ 2981 batches | lr 4.75 | ms/batch 34.62 | loss 5.60 | ppl 269.12 | epoch 2 | 2800/ 2981 batches | lr 4.75 | ms/batch 34.63 | loss 5.51 | ppl 248.37 ----------------------------------------------------------------------------------------- | end of epoch 2 | time: 107.58s | valid loss 5.60 | valid ppl 270.75 ----------------------------------------------------------------------------------------- | epoch 3 | 200/ 2981 batches | lr 4.51 | ms/batch 34.80 | loss 5.55 | ppl 257.31 | epoch 3 | 400/ 2981 batches | lr 4.51 | ms/batch 34.63 | loss 5.56 | ppl 259.12 | epoch 3 | 600/ 2981 batches | lr 4.51 | ms/batch 34.62 | loss 5.36 | ppl 213.08 | epoch 3 | 800/ 2981 batches | lr 4.51 | ms/batch 34.63 | loss 5.44 | ppl 229.59 | epoch 3 | 1000/ 2981 batches | lr 4.51 | ms/batch 34.63 | loss 5.37 | ppl 215.90 | epoch 3 | 1200/ 2981 batches | lr 4.51 | ms/batch 34.64 | loss 5.41 | ppl 223.49 | epoch 3 | 1400/ 2981 batches | lr 4.51 | ms/batch 34.63 | loss 5.43 | ppl 228.08 | epoch 3 | 1600/ 2981 batches | lr 4.51 | ms/batch 34.62 | loss 5.47 | ppl 238.36 | epoch 3 | 1800/ 2981 batches | lr 4.51 | ms/batch 34.58 | loss 5.40 | ppl 222.43 | epoch 3 | 2000/ 2981 batches | lr 4.51 | ms/batch 34.56 | loss 5.44 | ppl 229.30 | epoch 3 | 2200/ 2981 batches | lr 4.51 | ms/batch 34.55 | loss 5.32 | ppl 204.63 | epoch 3 | 2400/ 2981 batches | lr 4.51 | ms/batch 34.54 | loss 5.39 | ppl 220.17 | epoch 3 | 2600/ 2981 batches | lr 4.51 | ms/batch 34.55 | loss 5.41 | ppl 223.92 | epoch 3 | 2800/ 2981 batches | lr 4.51 | ms/batch 34.55 | loss 5.34 | ppl 209.22 ----------------------------------------------------------------------------------------- | end of epoch 3 | time: 107.47s | valid loss 5.54 | valid ppl 253.71 ----------------------------------------------------------------------------------------- 评估与所述测试数据集的模型 应用的最佳模式，以检查与测试数据集的结果。 test_loss = evaluate(best_model, test_data) print('=' * 89) print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format( test_loss, math.exp(test_loss))) print('=' * 89) Out: ========================================================================================= | End of training | test loss 5.43 | test ppl 229.27 ========================================================================================= 脚本的总运行时间： （5分钟38.763秒） Download Python source code: transformer_tutorial.py Download Jupyter notebook: transformer_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 序列到序列与nn.Transformer和TorchText建模 定义模型 负载和批数据 函数来生成输入和目标序列 启动一个实例 运行模型 评估与所述测试数据集的模型 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"intermediate/flask_rest_api_tutorial.html":{"url":"intermediate/flask_rest_api_tutorial.html","title":"1.部署PyTorch在Python经由REST API从Flask","keywords":"","body":"1.通过REST API与部署PyTorch在Python烧瓶 作者 ：阿维纳什Sajjanshetty 在本教程中，我们将使用瓶部署PyTorch模型和暴露的模型推断一个REST API。特别是，我们将部署一个预训练DenseNet 121模型检测的图像。 小费 这里使用的所有的代码是在MIT许可下发布，并可在[ Github上HTG1。 这代表了一个教程系列的第一个在生产中部署PyTorch车型。以这种方式使用瓶是目前为止最简单的方法来启动服务您PyTorch车型，但它不是一个用例性能要求较高的工作。为了那个原因： [HTG2如果你已经很熟悉TorchScript，您可以直接跳到我们的加载++ 一个TorchScript模型用C教程。 如果你首先需要在TorchScript复习，看看我们的【HTG0]介绍一个TorchScript 教程。 > API定义 首先，我们将定义我们的API端点，请求和响应类型。我们的API端点将位于/预测这需要HTTP POST请求与包含该图像的文件参数。该响应将是包含预测JSON响应的： {\"class_id\": \"n02124075\", \"class_name\": \"Egyptian_cat\"} 依赖性 安装运行下面的命令所需的依赖关系： $ pip install Flask==1.0.3 torchvision-0.3.0 简单的Web服务器 下面是一个简单的Web服务器，从瓶资料为准 from flask import Flask app = Flask(__name__) @app.route('/') def hello(): return 'Hello World!' 保存上面的代码在一个名为app.py您现在可以通过键入运行瓶开发服务器文件： $ FLASK_ENV=development FLASK_APP=app.py flask run 当您访问HTTP：//本地主机：5000 /在你的网页浏览器，你将与你好 世界打招呼！文本 我们将上述片断的轻微变化，所以它适合我们的API定义。首先，我们将重命名为预测的方法。我们将更新端点路径/预测 [HTG7。由于图像文件将通过HTTP POST请求被发送，我们会随时更新，以便它也只接受POST请求： @app.route('/predict', methods=['POST']) def predict(): return 'Hello World!' 我们也将改变响应类型，因此它返回一个包含ImageNet类ID和名称的JSON响应。更新app.py文件将是现在： from flask import Flask, jsonify app = Flask(__name__) @app.route('/predict', methods=['POST']) def predict(): return jsonify({'class_id': 'IMAGE_NET_XXX', 'class_name': 'Cat'}) 推理 在接下来的章节中，我们将集中精力编写推理代码。这将涉及到两个部分，一是我们准备的图像，以便它可以被输送到DenseNet和明年，我们将编写代码即可获得从模型的实际预测。 准备图像 DenseNet模型需要图像是尺寸224 X 224的3通道RGB图像的我们也将正常化与所需的平均和标准偏差值的图像张量。你可以阅读更多关于它的[此处HTG1。 我们将使用变换从torchvision库，并建立一个管道改造的要求，它改变我们的图像。你可以阅读更多关于变换[此处HTG9。 import io import torchvision.transforms as transforms from PIL import Image def transform_image(image_bytes): my_transforms = transforms.Compose([transforms.Resize(255), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]) image = Image.open(io.BytesIO(image_bytes)) return my_transforms(image).unsqueeze(0) 上述方法需要图像数据以字节为单位，应用一系列的变换，并返回一个张量。为了检验上述方法，读取字节模式下的图像文件（第一替换 ../_static/img/sample_file.jpeg 的实际路径到计算机上的文件），看看如果你得到一个张量背部： with open(\"../_static/img/sample_file.jpeg\", 'rb') as f: image_bytes = f.read() tensor = transform_image(image_bytes=image_bytes) print(tensor) 日期： tensor([[[[ 0.4508, 0.4166, 0.3994, ..., -1.3473, -1.3302, -1.3473], [ 0.5364, 0.4851, 0.4508, ..., -1.2959, -1.3130, -1.3302], [ 0.7077, 0.6392, 0.6049, ..., -1.2959, -1.3302, -1.3644], ..., [ 1.3755, 1.3927, 1.4098, ..., 1.1700, 1.3584, 1.6667], [ 1.8893, 1.7694, 1.4440, ..., 1.2899, 1.4783, 1.5468], [ 1.6324, 1.8379, 1.8379, ..., 1.4783, 1.7352, 1.4612]], [[ 0.5728, 0.5378, 0.5203, ..., -1.3704, -1.3529, -1.3529], [ 0.6604, 0.6078, 0.5728, ..., -1.3004, -1.3179, -1.3354], [ 0.8529, 0.7654, 0.7304, ..., -1.3004, -1.3354, -1.3704], ..., [ 1.4657, 1.4657, 1.4832, ..., 1.3256, 1.5357, 1.8508], [ 2.0084, 1.8683, 1.5182, ..., 1.4657, 1.6583, 1.7283], [ 1.7458, 1.9384, 1.9209, ..., 1.6583, 1.9209, 1.6408]], [[ 0.7228, 0.6879, 0.6531, ..., -1.6476, -1.6302, -1.6476], [ 0.8099, 0.7576, 0.7228, ..., -1.6476, -1.6476, -1.6650], [ 1.0017, 0.9145, 0.8797, ..., -1.6476, -1.6650, -1.6999], ..., [ 1.6291, 1.6291, 1.6465, ..., 1.6291, 1.8208, 2.1346], [ 2.1868, 2.0300, 1.6814, ..., 1.7685, 1.9428, 2.0125], [ 1.9254, 2.0997, 2.0823, ..., 1.9428, 2.2043, 1.9080]]]]) 预测 现在将使用预训练DenseNet 121模型预测图像类。我们将使用一个从torchvision库，加载模型，并得到一个推论。虽然我们将在这个例子中使用预训练的模型，你可以使用自己的模型同样的方法。查看更多有关此 教程 加载你的模型。 from torchvision import models # Make sure to pass `pretrained`as `True`to use the pretrained weights: model = models.densenet121(pretrained=True) # Since we are using our model only for inference, switch to `eval`mode: model.eval() def get_prediction(image_bytes): tensor = transform_image(image_bytes=image_bytes) outputs = model.forward(tensor) _, y_hat = outputs.max(1) return y_hat 预测的类ID的张量y_hat将包含索引。然而，我们需要人类可读的类名。为此，我们需要一个等级ID名称映射。下载这个文件为imagenet_class_index.json，并记住您保存它（或者，如果你是以下在本教程中的具体步骤，它保存在教程/ _static ）。此文件包含ImageNet类ID来ImageNet类名的映射。我们将加载这个JSON文件，并得到预测指数的类名。 import json imagenet_class_index = json.load(open('../_static/imagenet_class_index.json')) def get_prediction(image_bytes): tensor = transform_image(image_bytes=image_bytes) outputs = model.forward(tensor) _, y_hat = outputs.max(1) predicted_idx = str(y_hat.item()) return imagenet_class_index[predicted_idx] 使用imagenet_class_index词典之前，我们首先将张量的值转换为字符串值，因为在imagenet_class_index字典中的键是字符串。我们将测试我们上面的方法： with open(\"../_static/img/sample_file.jpeg\", 'rb') as f: image_bytes = f.read() print(get_prediction(image_bytes=image_bytes)) Out: ['n02124075', 'Egyptian_cat'] 你应该得到这样的回应： ['n02124075', 'Egyptian_cat'] 在阵列中的第一项是ImageNet类ID和第二项是人类可读的名称。 Note 你有没有注意到模型变量不是get_prediction方法的一部分？为什么是模型中的全局变量？加载模型可以是在存储器和计算方面是昂贵的操作。如果我们在get_prediction方法加载模型，那么它会得到不必要加载的每一个方法被调用的时间。因为，我们正在建立一个Web服务器，有可能是每秒数千次的请求，我们不应该浪费时间冗余负载对每个推理模型。所以，我们一直在内存中加载只有一次的模型。在生产系统中，有必要提高效率你计算的使用能够在大规模服务请求，所以你一般应为请求提供服务之前加载模型。 在我们的API服务器集成模型 在这最后一部分，我们将我们的模型添加到我们的瓶API服务器。由于我们的API服务器应该采取一个图像文件，我们会随时更新我们的预测方法来读取请求的文件： from flask import request @app.route('/predict', methods=['POST']) def predict(): if request.method == 'POST': # we will get the file from the request file = request.files['file'] # convert that to bytes img_bytes = file.read() class_id, class_name = get_prediction(image_bytes=img_bytes) return jsonify({'class_id': class_id, 'class_name': class_name}) 在app.py文件现已完成。以下是完整版;与你保存的文件，它应该运行的路径替换路径： import io import json from torchvision import models import torchvision.transforms as transforms from PIL import Image from flask import Flask, jsonify, request app = Flask(__name__) imagenet_class_index = json.load(open('/imagenet_class_index.json')) model = models.densenet121(pretrained=True) model.eval() def transform_image(image_bytes): my_transforms = transforms.Compose([transforms.Resize(255), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]) image = Image.open(io.BytesIO(image_bytes)) return my_transforms(image).unsqueeze(0) def get_prediction(image_bytes): tensor = transform_image(image_bytes=image_bytes) outputs = model.forward(tensor) _, y_hat = outputs.max(1) predicted_idx = str(y_hat.item()) return imagenet_class_index[predicted_idx] @app.route('/predict', methods=['POST']) def predict(): if request.method == 'POST': file = request.files['file'] img_bytes = file.read() class_id, class_name = get_prediction(image_bytes=img_bytes) return jsonify({'class_id': class_id, 'class_name': class_name}) if __name__ == '__main__': app.run() 让我们来测试我们的网络服务器！跑： $ FLASK_ENV=development FLASK_APP=app.py flask run 我们可以使用请求库发送POST请求到我们的应用程序： import requests resp = requests.post(\"http://localhost:5000/predict\", files={\"file\": open('/cat.jpg','rb')}) 印刷 resp.json（）现在会显示以下内容： {\"class_id\": \"n02124075\", \"class_name\": \"Egyptian_cat\"} 接下来的步骤 我们写的服务器是很琐碎，可能不是你所需要的生产应用程序的一切。所以，这里有一些事情可以做，以更好地使其： 端点/预测假定总是会有在该请求的图像文件。这可能不是适用于所有要求如此。我们的用户可以发送图像具有不同的参数或者根本不发送图像。 用户可以发送过多非图像类型的文件。由于我们没有处理错误，这将打破我们的服务器。并称将抛出一个异常明确的处理错误的道路，使我们能够更好地处理无效输入 尽管该模型可识别大量的图像类，也未必能够识别的所有图像。加强对办案时模型无法识别图像中的任何实施。 我们运行的发展模式，这是不适合在生产部署瓶服务器。您可以检查出本教程在生产部署瓶服务器。 您也可以通过创建与需要的图像，并显示预测的形式添加页面的UI。检查出一个类似的项目和它的源代码的[演示HTG1。 在本教程中，我们只展示了如何构建，可以在同一时间返回预测单个图像服务。我们可以修改我们的服务能马上回家多个图像的预测。此外，服务流光库自动排队请求您的服务和样品它们变成可被送入模型迷你批次。您可以检查出[本教程HTG3。 最后，我们建议您检查出部署PyTorch模型链接到页面的顶部我们的其他教程。 脚本的总运行时间： （0分钟0.925秒） Download Python source code: flask_rest_api_tutorial.py Download Jupyter notebook: flask_rest_api_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 [HTG0 1.部署PyTorch在Python经由REST API从Flask API定义 依赖性 简单的Web服务器 推理 准备图像 预测 在我们的API服务器整合模型 [HTG0接下来的步骤 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/Intro_to_TorchScript_tutorial.html":{"url":"beginner/Intro_to_TorchScript_tutorial.html","title":"2.介绍TorchScript","keywords":"","body":"2.介绍TorchScript 詹姆斯里德（jamesreed@fb.com），迈克尔琐（suo@fb.com） ，REV2 本教程是介绍TorchScript，一个PyTorch模型的中间表示（的nn.Module亚类），然后可以在一个高性能的环境，如C ++中运行。 在本教程中，我们将介绍： 在PyTorch，包括模型制作的基础知识： 模块 定义向前功能 构成模块到模块中的层次结构 转换PyTorch模块TorchScript具体的方法，我们的高性能运行时部署 跟踪现有模块 使用脚本来直接编译的模块 如何撰写这两种方法 保存和加载TorchScript模块 我们希望你完成本教程后，你继续去通过在后续教程这将引导您的实际调用从C TorchScript模型++的例子。 import torch # This is all you need to use both PyTorch and TorchScript! print(torch.__version__) 日期： 1.2.0 PyTorch模型制作的基础 让我们先来定义一个简单的模块 [HTG3。 A模块 是在PyTorch组合物中的基本单元。它包含： 构造函数，它准备模块，用于调用 一组参数的`和半模块 `。这些由构造初始化并且可以由模块调用期间被使用。 A 向前功能。这是被调用的模块时运行的代码。 让我们来看看一个小例子： class MyCell(torch.nn.Module): def __init__(self): super(MyCell, self).__init__() def forward(self, x, h): new_h = torch.tanh(x + h) return new_h, new_h my_cell = MyCell() x = torch.rand(3, 4) h = torch.rand(3, 4) print(my_cell(x, h)) Out: (tensor([[0.7853, 0.8882, 0.7137, 0.3746], [0.5265, 0.8508, 0.1487, 0.9144], [0.7057, 0.8217, 0.9575, 0.6132]]), tensor([[0.7853, 0.8882, 0.7137, 0.3746], [0.5265, 0.8508, 0.1487, 0.9144], [0.7057, 0.8217, 0.9575, 0.6132]])) 所以我们： 创建子类torch.nn.Module的类。 定义构造函数。构造函数没有做太多，只是要求超构造。 限定的向前函数，它有两个输入端和返回两个输出。的实际内容转发功能不是很重要，但是这有点假的 RNN细胞 - 即的IS-它是在应用功能环。 我们实例化的模块，和由×和Y，它是随机值只是3x4的矩阵。然后，我们来调用my_cell（X， h）上的细胞。这反过来又要求我们的转发功能。 让我们多一点有趣的做一些事情： class MyCell(torch.nn.Module): def __init__(self): super(MyCell, self).__init__() self.linear = torch.nn.Linear(4, 4) def forward(self, x, h): new_h = torch.tanh(self.linear(x) + h) return new_h, new_h my_cell = MyCell() print(my_cell) print(my_cell(x, h)) Out: MyCell( (linear): Linear(in_features=4, out_features=4, bias=True) ) (tensor([[0.7619, 0.7761, 0.7476, 0.0897], [0.6886, 0.4990, 0.4495, 0.2021], [0.5849, 0.5874, 0.9256, 0.0460]], grad_fn=), tensor([[0.7619, 0.7761, 0.7476, 0.0897], [0.6886, 0.4990, 0.4495, 0.2021], [0.5849, 0.5874, 0.9256, 0.0460]], grad_fn=)) 我们已经重新定义了我们的模块了myCell，但这次我们增加了self.linear属性，我们调用self.linear在向前的功能。 究竟发生在这里？ torch.nn.Linear是模块从PyTorch标准库。就像了myCell，可以使用呼叫语法调用。我们正在建设的模块个层次。 打印在模块将给出的模块的视觉表示子类层次结构。在我们的例子中，我们可以看到我们的线性子类及其参数。 通过这种方式组成模块S，我们可以succintly和可读性很强笔者型号可重用的组件。 您可能已经注意到在输出grad_fn [HTG3。这是自动分化PyTorch的方法，称为[ autograd ](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)的细节。总之，该系统使我们能够通过潜在的复杂程序计算的衍生物。该设计允许的灵活性，在模型制作的巨量。 现在，让我们来看看说的灵活性： class MyDecisionGate(torch.nn.Module): def forward(self, x): if x.sum() > 0: return x else: return -x class MyCell(torch.nn.Module): def __init__(self): super(MyCell, self).__init__() self.dg = MyDecisionGate() self.linear = torch.nn.Linear(4, 4) def forward(self, x, h): new_h = torch.tanh(self.dg(self.linear(x)) + h) return new_h, new_h my_cell = MyCell() print(my_cell) print(my_cell(x, h)) Out: MyCell( (dg): MyDecisionGate() (linear): Linear(in_features=4, out_features=4, bias=True) ) (tensor([[ 0.9077, 0.5939, 0.6809, 0.0994], [ 0.7583, 0.7180, 0.0790, 0.6733], [ 0.9102, -0.0368, 0.8246, -0.3256]], grad_fn=), tensor([[ 0.9077, 0.5939, 0.6809, 0.0994], [ 0.7583, 0.7180, 0.0790, 0.6733], [ 0.9102, -0.0368, 0.8246, -0.3256]], grad_fn=)) 我们再一次重新定义我们的了myCell类，但在这里我们定义MyDecisionGate [HTG3。这模块利用 **控制流** 。控制流由东西样环和 如果 -statements。 许多框架搭给出一个完整的程序表示计算的符号衍生品的方法。然而，在PyTorch，我们使用渐变带。因为它们发生时，我们记录的操作，并且在计算衍生向后重放。通过这种方式，框架没有明确定义的衍生物在语言的所有构造。 如何autograd作品 TorchScript的基础 现在，让我们把我们运行的例子，看看我们如何可以申请TorchScript。 总之，TorchScript提供的工具捕捉到你的模型的定义，即使在PyTorch的灵活性和动态性的光。让我们先通过检查我们称之为 追踪[HTG1。 追踪模块 class MyCell(torch.nn.Module): def __init__(self): super(MyCell, self).__init__() self.linear = torch.nn.Linear(4, 4) def forward(self, x, h): new_h = torch.tanh(self.linear(x) + h) return new_h, new_h my_cell = MyCell() x, h = torch.rand(3, 4), torch.rand(3, 4) traced_cell = torch.jit.trace(my_cell, (x, h)) print(traced_cell) traced_cell(x, h) Out: TracedModule[MyCell]( (linear): TracedModule[Linear]() ) 我们复卷一点，并采取了我们的了myCell类的第二个版本。和以前一样，我们实例化，但是，这个时候，我们称为torch.jit.trace，在模块 [HTG11通过]和in _例如输入_ 网络可能会看到通过。 正是有这个做了什么？它调用模块时，记录所发生当模块已运行的操作，和产生的[实例HTG9] torch.jit.ScriptModule（其中TracedModule是一个实例） TorchScript记录其在中间表示（或IR）的定义，通常称为深学习作为 图表 。我们可以检查与.graph属性图： print(traced_cell.graph) Out: graph(%self : ClassType, %input : Float(3, 4), %h : Float(3, 4)): %1 : ClassType = prim::GetAttr[name=\"linear\"](%self) %weight : Tensor = prim::GetAttr[name=\"weight\"](%1) %bias : Tensor = prim::GetAttr[name=\"bias\"](%1) %6 : Float(4!, 4!) = aten::t(%weight), scope: MyCell/Linear[linear] # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1369:0 %7 : int = prim::Constant[value=1](), scope: MyCell/Linear[linear] # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1369:0 %8 : int = prim::Constant[value=1](), scope: MyCell/Linear[linear] # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1369:0 %9 : Float(3, 4) = aten::addmm(%bias, %input, %6, %7, %8), scope: MyCell/Linear[linear] # /opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1369:0 %10 : int = prim::Constant[value=1](), scope: MyCell # /var/lib/jenkins/workspace/beginner_source/Intro_to_TorchScript_tutorial.py:188:0 %11 : Float(3, 4) = aten::add(%9, %h, %10), scope: MyCell # /var/lib/jenkins/workspace/beginner_source/Intro_to_TorchScript_tutorial.py:188:0 %12 : Float(3, 4) = aten::tanh(%11), scope: MyCell # /var/lib/jenkins/workspace/beginner_source/Intro_to_TorchScript_tutorial.py:188:0 %13 : (Float(3, 4), Float(3, 4)) = prim::TupleConstruct(%12, %12) return (%13) 然而，这是一个非常低的电平表示，大部分包含在图表中的信息不是为最终用户是有用的。相反，我们可以使用.CODE属性给代码的一个Python语法的解释： print(traced_cell.code) Out: def forward(self, input: Tensor, h: Tensor) -> Tuple[Tensor, Tensor]: _0 = self.linear weight = _0.weight bias = _0.bias _1 = torch.addmm(bias, input, torch.t(weight), beta=1, alpha=1) _2 = torch.tanh(torch.add(_1, h, alpha=1)) return (_2, _2) 所以 为什么 我们做了这一切？有几个原因： TorchScript代码可以在其自己的解释，这基本上是受限制的Python解释被调用。这个解释并没有获得全局解释器锁，和这么多的请求可以在同一实例同时处理。 这种格式可以让我们整个模型保存到磁盘，并将其加载到另一个环境，如写在Python以外的语言的服务器 TorchScript给了我们一个表示中，我们可以对代码做编译器优化，以提供更高效的执行 TorchScript允许我们与所需要的程序比个体经营者的更广阔的视野许多后端/设备运行时的接口。 我们可以看到，调用traced_cell产生相同的结果Python模块： print(my_cell(x, h)) print(traced_cell(x, h)) Out: (tensor([[ 0.0294, 0.2921, 0.5171, 0.2689], [ 0.5859, 0.8311, 0.2553, 0.8026], [-0.4138, 0.7641, 0.4251, 0.7217]], grad_fn=), tensor([[ 0.0294, 0.2921, 0.5171, 0.2689], [ 0.5859, 0.8311, 0.2553, 0.8026], [-0.4138, 0.7641, 0.4251, 0.7217]], grad_fn=)) (tensor([[ 0.0294, 0.2921, 0.5171, 0.2689], [ 0.5859, 0.8311, 0.2553, 0.8026], [-0.4138, 0.7641, 0.4251, 0.7217]], grad_fn=), tensor([[ 0.0294, 0.2921, 0.5171, 0.2689], [ 0.5859, 0.8311, 0.2553, 0.8026], [-0.4138, 0.7641, 0.4251, 0.7217]], grad_fn=)) 使用脚本来转换模块 还有我们用我们模块的两个版本的原因，而不是一个与控制流载货子模块。现在，让我们检查的是： class MyDecisionGate(torch.nn.Module): def forward(self, x): if x.sum() > 0: return x else: return -x class MyCell(torch.nn.Module): def __init__(self, dg): super(MyCell, self).__init__() self.dg = dg self.linear = torch.nn.Linear(4, 4) def forward(self, x, h): new_h = torch.tanh(self.dg(self.linear(x)) + h) return new_h, new_h my_cell = MyCell(MyDecisionGate()) traced_cell = torch.jit.trace(my_cell, (x, h)) print(traced_cell.code) Out: def forward(self, input: Tensor, h: Tensor) -> Tuple[Tensor, Tensor]: _0 = self.linear weight = _0.weight bias = _0.bias x = torch.addmm(bias, input, torch.t(weight), beta=1, alpha=1) _1 = torch.tanh(torch.add(torch.neg(x), h, alpha=1)) return (_1, _1) 综观.CODE输出，我们可以看到，的if-else分支无处可寻！为什么？跟踪不正是我们称将：运行代码，记录操作 这种情况发生 和构建ScriptModule这正是这么做的。不幸的是，像控制流程被删除。 我们如何能够忠实代表TorchScript这个模块？我们提供了一个 编译脚本 ，它确实你的Python源代码分析直接将其转化为TorchScript。让我们使用脚本编译器转换MyDecisionGate： scripted_gate = torch.jit.script(MyDecisionGate()) my_cell = MyCell(scripted_gate) traced_cell = torch.jit.script(my_cell) print(traced_cell.code) Out: def forward(self, x: Tensor, h: Tensor) -> Tuple[Tensor, Tensor]: _0 = self.linear _1 = _0.weight _2 = _0.bias if torch.eq(torch.dim(x), 2): _3 = torch.__isnot__(_2, None) else: _3 = False if _3: bias = ops.prim.unchecked_unwrap_optional(_2) ret = torch.addmm(bias, x, torch.t(_1), beta=1, alpha=1) else: output = torch.matmul(x, torch.t(_1)) if torch.__isnot__(_2, None): bias0 = ops.prim.unchecked_unwrap_optional(_2) output0 = torch.add_(output, bias0, alpha=1) else: output0 = output ret = output0 _4 = torch.gt(torch.sum(ret, dtype=None), 0) if bool(_4): _5 = ret else: _5 = torch.neg(ret) new_h = torch.tanh(torch.add(_5, h, alpha=1)) return (new_h, new_h) 万岁！现在，我们已经捕获忠实我们TorchScript程序的行为。现在，让我们试着运行该程序： # New inputs x, h = torch.rand(3, 4), torch.rand(3, 4) traced_cell(x, h) 混合脚本和跟踪 有些情况下需要使用跟踪，而不是脚本（例如一个模块是基于我们想不会出现在TorchScript不变的Python值做出了许多架构决策）。在这种情况下，脚本可以与由跟踪：torch.jit.script将内联一个跟踪模块的代码，和跟踪将内联代码脚本模块。 第一种情况的一个示例： class MyRNNLoop(torch.nn.Module): def __init__(self): super(MyRNNLoop, self).__init__() self.cell = torch.jit.trace(MyCell(scripted_gate), (x, h)) def forward(self, xs): h, y = torch.zeros(3, 4), torch.zeros(3, 4) for i in range(xs.size(0)): y, h = self.cell(xs[i], h) return y, h rnn_loop = torch.jit.script(MyRNNLoop()) print(rnn_loop.code) Out: def forward(self, xs: Tensor) -> Tuple[Tensor, Tensor]: h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None) y = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None) y0, h0 = y, h for i in range(torch.size(xs, 0)): _0 = self.cell _1 = torch.select(xs, 0, i) _2 = _0.linear weight = _2.weight bias = _2.bias _3 = torch.addmm(bias, _1, torch.t(weight), beta=1, alpha=1) _4 = torch.gt(torch.sum(_3, dtype=None), 0) if bool(_4): _5 = _3 else: _5 = torch.neg(_3) _6 = torch.tanh(torch.add(_5, h0, alpha=1)) y0, h0 = _6, _6 return (y0, h0) 和第二壳体的一个示例： class WrapRNN(torch.nn.Module): def __init__(self): super(WrapRNN, self).__init__() self.loop = torch.jit.script(MyRNNLoop()) def forward(self, xs): y, h = self.loop(xs) return torch.relu(y) traced = torch.jit.trace(WrapRNN(), (torch.rand(10, 3, 4))) print(traced.code) Out: def forward(self, argument_1: Tensor) -> Tensor: _0 = self.loop h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None) h0 = h for i in range(torch.size(argument_1, 0)): _1 = _0.cell _2 = torch.select(argument_1, 0, i) _3 = _1.linear weight = _3.weight bias = _3.bias _4 = torch.addmm(bias, _2, torch.t(weight), beta=1, alpha=1) _5 = torch.gt(torch.sum(_4, dtype=None), 0) if bool(_5): _6 = _4 else: _6 = torch.neg(_4) h0 = torch.tanh(torch.add(_6, h0, alpha=1)) return torch.relu(h0) 这样一来，脚本和跟踪可当形势需要每个人共同使用的使用。 保存和加载模型 我们提供的API来保存和从磁盘归档格式加载TorchScript模块/。此格式包括代码，参数，属性，和调试信息，这意味着该归档是可以在一个完全独立的过程来加载该模型的一个独立的表示。让我们保存和载入我们的包裹RNN模块： traced.save('wrapped_rnn.zip') loaded = torch.jit.load('wrapped_rnn.zip') print(loaded) print(loaded.code) Out: ScriptModule( (loop): ScriptModule( (cell): ScriptModule( (dg): ScriptModule() (linear): ScriptModule() ) ) ) def forward(self, argument_1: Tensor) -> Tensor: _0 = self.loop h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None) h0 = h for i in range(torch.size(argument_1, 0)): _1 = _0.cell _2 = torch.select(argument_1, 0, i) _3 = _1.linear weight = _3.weight bias = _3.bias _4 = torch.addmm(bias, _2, torch.t(weight), beta=1, alpha=1) _5 = torch.gt(torch.sum(_4, dtype=None), 0) if bool(_5): _6 = _4 else: _6 = torch.neg(_4) h0 = torch.tanh(torch.add(_6, h0, alpha=1)) return torch.relu(h0) 正如你所看到的，系列化保留了模块的层次结构，我们已经在整个检查代码。该模型也被加载，例如，成C ++ 免费蟒-执行。 进一步阅读 我们已经完成了教程！对于更为复杂的论证，检查出NeurIPS演示转换使用TorchScript机器翻译模型：HTG0] https://colab.research.google.com/drive/1HiICg6jRkBnr5hvK2-VnMi88Vi9pUzEJ 脚本的总运行时间： （0分钟0.252秒） Download Python source code: Intro_to_TorchScript_tutorial.py Download Jupyter notebook: Intro_to_TorchScript_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 [HTG0 2.介绍TorchScript PyTorch模型制作的基础 TorchScript的基础 跟踪模块 使用脚本来转换器模块 混合脚本和跟踪 保存和载入模型 进一步阅读 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"advanced/cpp_export.html":{"url":"advanced/cpp_export.html","title":"3.装载++一个TorchScript模型在C ","keywords":"","body":"3.装载在C TorchScript模型++ 本教程更新与PyTorch 1.2工作 正如它的名字所暗示的，以PyTorch主接口是Python编程语言。虽然Python是许多场景需要活力和易于迭代的合适的和优选的语言，有同样多的地方正是这些的Python性质是不利的情况。其中后者往往应用于一个环境中是 生产 - 低延迟和严格的部署要求的土地。对于生产情景，C ++是经常选择的语言，即使只将其绑定到像Java，生锈或转到另一种语言。以下段落将概括PyTorch提供从现有的Python模型去能够 加载 和 从C ++执行 纯粹序列化表示，与Python中没有依赖关系的路径。 第1步：转换您的PyTorch模型Torch 脚本 从Python来C ++甲PyTorch模型的旅程是由启用Torch 脚本，可被理解的，编译的和由Torch 脚本编译器序列化PyTorch模型的表示。如果你是从写在香草“渴望” API现有PyTorch模型开始了，你必须首先转换模型Torch 脚本。在最常见的情况下，下面讨论的，这个只需要很少的努力。如果你已经有了一个Torch 脚本模块，可以跳过本教程的下一节。 存在一个PyTorch模型转换为Torch 脚本的方法有两种。第一被称为 追踪 ，其中，所述模型的结构是通过评估一次使用实施例的输入，并记录这些输入通过模型的流动捕获的机制。本品适用于模型制作有限使用控制流。第二种方法是明确的注释添加到您的模型，通知Torch 脚本编译器，它可以直接解析和编译你的模型代码，受Torch 脚本语言所带来的限制。 小费 你可以找到这两种方法的完整文档，以及在其上使用，在官方Torch 脚本参考进一步的指导。 通过跟踪转换为Torch 脚本 要通过跟踪一个PyTorch模型转换为Torch 脚本，你必须用一个例子输入转达您的模型的实例到torch.jit.trace功能。这将产生一个torch.jit.ScriptModule对象与你的模型评估的嵌入模块的转发方法跟踪： import torch import torchvision # An instance of your model. model = torchvision.models.resnet18() # An example input you would normally provide to your model's forward() method. example = torch.rand(1, 3, 224, 224) # Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing. traced_script_module = torch.jit.trace(model, example) 所追踪的ScriptModule现在可以被相同地评价，以常规PyTorch模块： In[1]: output = traced_script_module(torch.ones(1, 3, 224, 224)) In[2]: output[0, :5] Out[2]: tensor([-0.2698, -0.0381, 0.4023, -0.3010, -0.0448], grad_fn=) 通过注释转换为Torch 脚本 在某些情况下，例如，如果您的模型采用控制流的特定形式，你可能想直接写脚本Torch 模型，并相应地标注模型。例如，假设您有以下香草Pytorch模型： import torch class MyModule(torch.nn.Module): def __init__(self, N, M): super(MyModule, self).__init__() self.weight = torch.nn.Parameter(torch.rand(N, M)) def forward(self, input): if input.sum() > 0: output = self.weight.mv(input) else: output = self.weight + input return output 因为这个模块的向前方法使用控制流依赖于输入，它是不适合于跟踪。相反，我们可以将其转换为ScriptModule [HTG7。为了将模块转换为 ScriptModule，需要编译torch.jit.script如下模块： class MyModule(torch.nn.Module): def __init__(self, N, M): super(MyModule, self).__init__() self.weight = torch.nn.Parameter(torch.rand(N, M)) def forward(self, input): if input.sum() > 0: output = self.weight.mv(input) else: output = self.weight + input return output my_module = MyModule(10,20) sm = torch.jit.script(my_module) 如果您需要排除一些方法你nn.Module因为他们使用Python的特点是TorchScript尚不支持，你可以注释那些@torch .jit.ignore my_module是ScriptModule的一个实例认为是准备好进行序列化。 步骤2：序列化脚本模块到一个文件 一旦你有一个ScriptModule在你的手中，无论是从跟踪或标注一个PyTorch模型，您准备将其序列化到一个文件中。后来，你就可以从该文件加载模块在C ++中，没有关于Python任何依赖性执行它。假设我们想要序列早些时候跟踪示例所示ResNet18模式。为了执行该序列，只需调用保存在模块上，并通过它一个文件名： traced_script_module.save(\"traced_resnet_model.pt\") 这将在您的工作目录中的traced_resnet_model.pt文件。如果您也想连载my_module，调用my_module.save（ “my_module_model.pt”）HTG10]我们现在已经正式离开的Python境界并准备跨越到C ++的球体。 步骤3：加载脚本模块在C ++ 要加载在C ++的序列化PyTorch模型，应用程序必须依赖于PyTorch C ++ API - 也被称为 LibTorch [HTG1。所述LibTorch分布包括共享库，头文件和CMake的建立配置文件的集合。虽然CMake的不是取决于LibTorch的要求，这是推荐的方法，将很好地支持未来。在本教程中，我们将建立使用CMake和LibTorch简单地装载一个最小的C ++应用程序和执行序列化PyTorch模型。 最小的C ++应用 让我们先来讨论代码加载一个模块。下面将已经这样做了： #include // One-stop header. #include #include int main(int argc, const char* argv[]) { if (argc != 2) { std::cerr \\n\"; return -1; } torch::jit::script::Module module; try { // Deserialize the ScriptModule from a file using torch::jit::load(). module = torch::jit::load(argv[1]); } catch (const c10::Error& e) { std::cerr 的& LT ;torch/ script.h & GT ;报头包括从运行示例所必需的库LibTorch所有有关包括。我们的应用程序接受的文件路径的串行化PyTorch ScriptModule作为其唯一的命令行参数，然后进行使用torch:: JIT反序列化模块::负载（）函数，该函数此文件路径作为输入。作为回报，我们收到Torch :: JIT ::脚本::模块对象。我们将研究如何在某一时刻执行。 根据LibTorch和构建应用 假设我们存储在上面的代码到一个名为例如-app.cpp文件。一个最小的CMakeLists.txt构建它可能看起来简单： cmake_minimum_required(VERSION 3.0 FATAL_ERROR) project(custom_ops) find_package(Torch REQUIRED) add_executable(example-app example-app.cpp) target_link_libraries(example-app \"${TORCH_LIBRARIES}\") set_property(TARGET example-app PROPERTY CXX_STANDARD 11) 我们需要构建示例应用程序的最后一件事是LibTorch分布。您可以随时抓住从下载页面在PyTorch网站上最新的稳定版本。如果您下载并解压缩最新存档，您会收到与下面的目录结构的文件夹： libtorch/ bin/ include/ lib/ share/ 在的lib /文件夹中包含您必须对链接的共享库， 在包括/文件夹中包含头文件你的程序将需要包括， 的份额/文件夹中包含的必要CMake的配置来使简单find_package（Torch ）上述命令。 Tip 在Windows中，调试和发布版本ABI不兼容。如果您计划建立在调试模式下你的项目，请尝试LibTorch的调试版本。 最后一步是构建应用程序。对于这一点，假设我们的例子中的目录布局如下： example-app/ CMakeLists.txt example-app.cpp 现在，我们可以运行下面的命令来从示例应用内/文件夹内生成应用程序： mkdir build cd build cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch .. make 其中/路径/到/ libtorch应该是完整路径解压LibTorch分布。如果一切顺利，这将是这个样子： root@4b5a67132e81:/example-app# mkdir build root@4b5a67132e81:/example-app# cd build root@4b5a67132e81:/example-app/build# cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch .. -- The C compiler identification is GNU 5.4.0 -- The CXX compiler identification is GNU 5.4.0 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Looking for pthread.h -- Looking for pthread.h - found -- Looking for pthread_create -- Looking for pthread_create - not found -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Configuring done -- Generating done -- Build files have been written to: /example-app/build root@4b5a67132e81:/example-app/build# make Scanning dependencies of target example-app [ 50%] Building CXX object CMakeFiles/example-app.dir/example-app.cpp.o [100%] Linking CXX executable example-app [100%] Built target example-app 如果我们提供的路径，跟踪ResNet18模型traced_resnet_model.pt 我们前面向所得示例中创建-app二，我们应该有一个友好的“OK”奖励。请注意，如果尝试运行与这个例子my_module_model.pt你会得到一个错误，指出你的输入是不兼容的形状。 my_module_model.pt预计1D代替4D。 root@4b5a67132e81:/example-app/build# ./example-app /traced_resnet_model.pt ok 第4步：用C执行脚本模块++ 在成功地加载我们的连载ResNet18在C ++中，我们现在的代码只是一对夫妇线远离执行它！让我们这些行添加到我们的C ++应用程序的主（）功能： // Create a vector of inputs. std::vector inputs; inputs.push_back(torch::ones({1, 3, 224, 224})); // Execute the model and turn its output into a tensor. at::Tensor output = module.forward(inputs).toTensor(); std::cout 前两行设置输入到我们的模型。我们创造torch:: JIT :: IValue（一种类型的擦除值类型的矢量脚本::模块方法接受和返回），并添加一个输入。来创建输入张量，我们使用torch::那些（）时，等价于的C ++ API在torch.ones。然后，我们运行脚本::模块的转发的方法，通过它我们创建了输入向量。作为回报，我们得到一个新的IValue，这是我们通过调用toTensor（）转换为张量。 Tip 要了解更多关于像功能Torch ::者和一般的PyTorch C ++ API，请参阅其文档在 https://pytorch.org/cppdocs 。该PyTorch C ++ API提供附近使用Python API功能奇偶校验，让您进一步的操作和处理张量就像在Python。 在最后一行，我们打印输出的前五个条目。由于我们在Python在本教程中提供的相同输入到我们的模型前，我们应该看到理想相同的输出。让我们尝试一下通过重新编译我们的应用程序，并使用相同的序列化模式运行它： root@4b5a67132e81:/example-app/build# make Scanning dependencies of target example-app [ 50%] Building CXX object CMakeFiles/example-app.dir/example-app.cpp.o [100%] Linking CXX executable example-app [100%] Built target example-app root@4b5a67132e81:/example-app/build# ./example-app traced_resnet_model.pt -0.2698 -0.0381 0.4023 -0.3010 -0.0448 [ Variable[CPUFloatType]{1,5} ] 作为参考，在Python输出先前是： tensor([-0.2698, -0.0381, 0.4023, -0.3010, -0.0448], grad_fn=) 看起来像一个很好的比赛！ Tip 要将你的模型GPU内存，你可以写model.to（在:: kCUDA）[] [HTG3。请确保输入到模型也住在CUDA内存通过调用 tensor.to（在:: kCUDA）HTG6] ，这将返回CUDA内存一个新的张量。 第5步：获取帮助和探索API 本教程希望您配备了PyTorch模型从Python来C ++路径的一个大致的了解。在本教程中描述的概念，你应该能够从香草去，“渴望” PyTorch模型，为编译ScriptModule在Python中，磁盘上的序列化的文件和 - 关闭循环 - 一个可执行脚本::模块在C ++中。 当然，也有我们没有涵盖的许多概念。例如，你可能会发现自己想扩展您的ScriptModule用C ++实现的运营商定制++或CUDA，并执行该运营商定制您的ScriptModule内装入在纯C ++的生产环境。好消息是：这是可能的，并得到广泛支持！现在，你可以探索对于这个例子文件夹，我们会跟进的教程不久。在时间之中，下面的链接可能是一般有所帮助： Torch 脚本参考： https://pytorch.org/docs/master/jit.html 所述PyTorch C ++ API文档： https://pytorch.org/cppdocs/ 所述PyTorch Python的API文档： https://pytorch.org/docs/ 与往常一样，如果您遇到任何问题或有任何疑问，您可以使用我们的论坛或 GitHub的问题取得联系。 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 3.装载++一个TorchScript模型在C 步骤1：转换您PyTorch模型Torch 脚本 通过跟踪转换为Torch 脚本 经由注释转换为Torch 脚本 [HTG0步骤2：序列化脚本模块到一个文件 步骤3：加载脚本模块在C ++ 最小的C ++应用 根据LibTorch和构建应用 [HTG0步骤4：执行脚本模块在C ++ [HTG0步骤5：获取帮助和探索API ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"advanced/super_resolution_with_onnxruntime.html":{"url":"advanced/super_resolution_with_onnxruntime.html","title":"4.（可选）从导出到PyTorch一个ONNX模型并使用ONNX运行时运行它","keywords":"","body":"4.（可选）从导出到PyTorch一个ONNX模型并使用运行它ONNX运行时 在本教程中，我们将介绍如何在PyTorch定义的模型转换成ONNX格式，然后用ONNX运行时运行它。 ONNX运行时是ONNX模型，跨多个平台和硬件（在Windows，Linux和Mac和两个CPU和GPU）有效地推论一个注重性能的发动机。 ONNX运行时已被证明大大增加了多种型号的性能，解释此处 在本教程中，你需要安装 ONNX 和[ ONNX运行[HTG3。你可以得到的二进制建立ONNX和ONNX运行与点子 安装 onnx onnxruntime [HTG13。需要注意的是ONNX运行与Python版本3.5到3.7兼容。](https://github.com/microsoft/onnxruntime) 注：本教程需要PyTorch主分支可通过以下的说明这里被安装 # Some standard imports import io import numpy as np from torch import nn import torch.utils.model_zoo as model_zoo import torch.onnx 超分辨率越来越多的图像，视频分辨率的方式，被广泛应用于图像处理和视频编辑。在本教程中，我们将使用一个小的超分辨率模型。 首先，让我们创建一个PyTorch超分辨模型。该模型采用在中描述的“实时单幅图像和视频超分辨率采用高效的子像素卷积神经网络”的高效子像素卷积层 - 石等用于提高图像的分辨率由高档的因素。该模型预计的图像作为输入的所述YCbCr的Y成分，并且输出在超分辨率放大的Y分量。 该模型直接从PyTorch的例子来不加修改： # Super Resolution model definition in PyTorch import torch.nn as nn import torch.nn.init as init class SuperResolutionNet(nn.Module): def __init__(self, upscale_factor, inplace=False): super(SuperResolutionNet, self).__init__() self.relu = nn.ReLU(inplace=inplace) self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2)) self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1)) self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1)) self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1)) self.pixel_shuffle = nn.PixelShuffle(upscale_factor) self._initialize_weights() def forward(self, x): x = self.relu(self.conv1(x)) x = self.relu(self.conv2(x)) x = self.relu(self.conv3(x)) x = self.pixel_shuffle(self.conv4(x)) return x def _initialize_weights(self): init.orthogonal_(self.conv1.weight, init.calculate_gain('relu')) init.orthogonal_(self.conv2.weight, init.calculate_gain('relu')) init.orthogonal_(self.conv3.weight, init.calculate_gain('relu')) init.orthogonal_(self.conv4.weight) # Create the super-resolution model by using the above model definition. torch_model = SuperResolutionNet(upscale_factor=3) 通常情况下，你现在会训练这个模型;然而，在本教程中，我们反而会下载一些预训练的权重。请注意，这种模式并没有良好的精度全面培训，在这里仅用于演示目的。 它调用torch_model.eval（）或torch_model.train（假）导出模型前，把该模型是非常重要的推论模式。既然喜欢在不同的推断和训练模式辍学或batchnorm运营商的行为，这是必需的。 # Load pretrained model weights model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth' batch_size = 1 # just a random number # Initialize model with the pretrained weights map_location = lambda storage, loc: storage if torch.cuda.is_available(): map_location = None torch_model.load_state_dict(model_zoo.load_url(model_url, map_location=map_location)) # set the model to inference mode torch_model.eval() 导出在PyTorch模型通过跟踪或脚本作品。这个教程将作为一个例子使用由跟踪导出的模型。要导出模型，我们称之为torch.onnx.export（）功能。这将执行模式，记录的是什么运营商来计算输出跟踪。因为出口运行模型，我们需要提供一个输入张量× [HTG11。只要它是正确的类型和尺寸在此的值可以是随机的。注意，输入尺寸将被固定在导出ONNX图形用于将输入的所有维的，除非指定为动态轴。在这个例子中，我们用的batch_size 1的输入导出模型，但然后指定所述第一尺寸为动态在dynamic_axes参数torch.onnx.export （） 。由此导出的模型将接受尺寸的输入[batch_size时，1，224，224]，其中的batch_size可以是可变的。 要了解PyTorch的出口接口的详细信息，请查看[ torch.onnx文献HTG1。 # Input to the model x = torch.randn(batch_size, 1, 224, 224, requires_grad=True) torch_out = torch_model(x) # Export the model torch.onnx.export(torch_model, # model being run x, # model input (or a tuple for multiple inputs) \"super_resolution.onnx\", # where to save the model (can be a file or file-like object) export_params=True, # store the trained parameter weights inside the model file opset_version=10, # the ONNX version to export the model to do_constant_folding=True, # wether to execute constant folding for optimization input_names = ['input'], # the model's input names output_names = ['output'], # the model's output names dynamic_axes={'input' : {0 : 'batch_size'}, # variable lenght axes 'output' : {0 : 'batch_size'}}) 我们还计算torch_out，该模型，我们将用它来验证ONNX运行中运行时，我们出口的模型计算相同的值后输出。 但在验证模型与ONNX运行时输出之前，我们将检查与ONNX的API的ONNX模型。首先，onnx.load（“super_resolution.onnx”）将加载保存的模型和将输出一个onnx.ModelProto结构（用于捆绑一个ML一个顶层文件/容器格式模型。详细信息 onnx.proto文档）。然后，onnx.checker.check_model（onnx_model）HTG8]将验证模型的结构，并确认该模型有一个有效的模式。所述ONNX图表的有效性是通过检查模型的版本，图的结构，以及作为节点，其输入和输出验证。 import onnx onnx_model = onnx.load(\"super_resolution.onnx\") onnx.checker.check_model(onnx_model) 现在，让我们计算使用ONNX运行的Python的API的输出。这一部分通常可以在一个单独的进程或另一台机器上完成，但我们会继续以同样的过程，使我们可以验证ONNX运行和PyTorch被计算为网络相同的值。 为了运行与ONNX运行模式，我们需要与所选择的配置参数（在这里我们使用默认配置）创建模型推断会话。一旦会话创建，我们评估使用的run（）API模型。这个调用的输出是含有ONNX运行时计算出的模型的输出列表。 import onnxruntime ort_session = onnxruntime.InferenceSession(\"super_resolution.onnx\") def to_numpy(tensor): return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy() # compute ONNX Runtime output prediction ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)} ort_outs = ort_session.run(None, ort_inputs) # compare ONNX Runtime and PyTorch results np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05) print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\") 我们应该看到，PyTorch和ONNX运行时的输出数值上运行，与之相匹配的给定精度（RTOL = 1E-03和蒂= 1E-05）。作为一个侧面说明，如果他们不匹配，则有在ONNX出口的问题，请与我们联系在这种情况下。 运行使用图像上的模型ONNX运行时 到目前为止，我们已经从PyTorch导出的模型，并展示了如何加载和运行ONNX与伪张量作为输入运行它。 在本教程中，我们将使用广泛使用的一个著名的猫形象，它看起来像下面 首先，让我们使用标准的PIL Python库加载图像，预先对其进行处理。请注意，这是预处理的数据处理培训/测试神经网络的标准做法。 我们首先调整图像的大小，以适应模型的输入（224x224）的大小。然后我们图象分成了Y，Cb和Cr分量。这些组件代表灰度图像（Y）和蓝色差（Cb）和红色差（Cr）的色度分量。 Y分量是对人眼更敏感，我们感兴趣的是这部分，我们将改造。提取Y分量后，我们把它转换成这将是我们模型的输入张量。 from PIL import Image import torchvision.transforms as transforms img = Image.open(\"./_static/img/cat.jpg\") resize = transforms.Resize([224, 224]) img = resize(img) img_ycbcr = img.convert('YCbCr') img_y, img_cb, img_cr = img_ycbcr.split() to_tensor = transforms.ToTensor() img_y = to_tensor(img_y) img_y.unsqueeze_(0) 现在，作为下一步，让我们代表灰度调整猫形象的张量和运行ONNX运行超高分辨率模型如前所述。 ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)} ort_outs = ort_session.run(None, ort_inputs) img_out_y = ort_outs[0] 在这一点上，该模型的输出是一个张量。现在，我们将处理模型的输出从输出张建设回来的最终输出图像，并保存图像。后处理步骤已经从PyTorch实现超高分辨率模型此处采用。 img_out_y = Image.fromarray(np.uint8((img_out_y[0] * 255.0).clip(0, 255)[0]), mode='L') # get the output image follow post-processing step from PyTorch implementation final_img = Image.merge( \"YCbCr\", [ img_out_y, img_cb.resize(img_out_y.size, Image.BICUBIC), img_cr.resize(img_out_y.size, Image.BICUBIC), ]).convert(\"RGB\") # Save the image, we will compare this with the output image from mobile device final_img.save(\"./_static/img/cat_superres_with_ort.jpg\") ONNX运行时是一个跨平台的引擎，可以跨多个平台和两个CPU和GPU运行它。 ONNX运行时也可以部署到云中使用Azure的机器学习Services模型推理。更多信息[此处HTG1。 关于ONNX运行时的性能此处更多信息。 有关ONNX运行此处更多信息。 脚本的总运行时间： （0分钟0.000秒） Download Python source code: super_resolution_with_onnxruntime.py Download Jupyter notebook: super_resolution_with_onnxruntime.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 [HTG0 4.（可选）从导出到PyTorch一个ONNX模型并使用ONNX运行时运行它 运行使用ONNX运行时的图像上的模型 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"intermediate/model_parallel_tutorial.html":{"url":"intermediate/model_parallel_tutorial.html","title":"1.型号并行最佳实践","keywords":"","body":"1.型号并行最佳实践 作者 ：沉莉 在分布式训练技巧型号并行广泛使用。先前的文章已经解释了如何使用数据并行培养上多GPU的神经网络;此功能复制相同的模型来所有的GPU，其中每个GPU消耗输入数据的不同分区。虽然它可以显著加快培训过程中，它并不适用于一些使用情况下，该模型是太大，不适合到一个单一的GPU工作。此信息显示了如何通过使用 模型平行 ，其中，与数据并行，分割一个单一的模式上不同的GPU，而不是复制来解决这个问题每个GPU整个模型（将混凝土，说一个模型M包含10层：使用数据并行时，每个GPU将有这些层10中的一个副本，在两个GPU使用模型时平行而，每个GPU可能拥有5层）。 并行模型的高级别想法是一个模型的不同的子网络放置到不同的设备，并相应地实现了向前的方法来跨设备移动中间输出。作为模型中的一部分的任何单独的设备上操作时，一组设备可以共同用作一个更大的模型。在这篇文章中，我们不会试图构建巨大的模型，并将其挤压到GPU的数量有限。取而代之的是，这篇文章的重点是展示并行模型的想法。它是由读者的想法应用到现实世界的应用。 基本用法 让我们先从一个包含两个线性层的玩具模型。上运行两个GPU此模型中，简单地把一个不同的GPU每个线性层，并移动输入和中间输出到层设备相应地匹配。 import torch import torch.nn as nn import torch.optim as optim class ToyModel(nn.Module): def __init__(self): super(ToyModel, self).__init__() self.net1 = torch.nn.Linear(10, 10).to('cuda:0') self.relu = torch.nn.ReLU() self.net2 = torch.nn.Linear(10, 5).to('cuda:1') def forward(self, x): x = self.relu(self.net1(x.to('cuda:0'))) return self.net2(x.to('cuda:1')) 需要注意的是，关于上述ToyModel看起来非常相似，一个是如何实现它在单GPU，除了五个到（设备）HTG6]其中放置线性层和张量上适当的设备的呼叫。这是需要改变的模型的唯一地方。的向后（）和torch.optim将自动仿佛模型是一个GPU采取梯度的照顾。你只需要确保标签的生产日期相同的设备的输出上调用损失函数时。 model = ToyModel() loss_fn = nn.MSELoss() optimizer = optim.SGD(model.parameters(), lr=0.001) optimizer.zero_grad() outputs = model(torch.randn(20, 10)) labels = torch.randn(20, 5).to('cuda:1') loss_fn(outputs, labels).backward() optimizer.step() 应用模型平行于现有模块 也可以用短短几行的变化上运行多个GPU现有的单GPU模块。下面的代码说明了如何分解torchvision.models.reset50（）到两个GPU。我们的想法是从现有RESNET模块继承，和施工期间层被划分到两个GPU。然后，重写向前方法通过相应地移动所述中间输出缝合两个子网络。 from torchvision.models.resnet import ResNet, Bottleneck num_classes = 1000 class ModelParallelResNet50(ResNet): def __init__(self, *args, **kwargs): super(ModelParallelResNet50, self).__init__( Bottleneck, [3, 4, 6, 3], num_classes=num_classes, *args, **kwargs) self.seq1 = nn.Sequential( self.conv1, self.bn1, self.relu, self.maxpool, self.layer1, self.layer2 ).to('cuda:0') self.seq2 = nn.Sequential( self.layer3, self.layer4, self.avgpool, ).to('cuda:1') self.fc.to('cuda:1') def forward(self, x): x = self.seq2(self.seq1(x).to('cuda:1')) return self.fc(x.view(x.size(0), -1)) 上述实施解决了这个问题。对于其中的模型太大，适合单个GPU的情况。然而，你可能已经注意到，它会比，如果你的模型适合于单一GPU运行更慢。这是因为，在任何时间点，只有两个GPU中的一个工作，而另一种是坐在那里什么都不做。性能进一步恶化作为中间输出需要从CUDA复制：0至CUDA：1之间二层和三层。 让我们进行实验获得的执行时间更定量的观点。在这个实验中，我们培养ModelParallelResNet50和现有torchvision.models.reset50（）通过贯穿其中随机输入和标签。培训结束后，该车型将不会产生任何有用的预测，但我们可以得到的执行时间有一定的了解。 import torchvision.models as models num_batches = 3 batch_size = 120 image_w = 128 image_h = 128 def train(model): model.train(True) loss_fn = nn.MSELoss() optimizer = optim.SGD(model.parameters(), lr=0.001) one_hot_indices = torch.LongTensor(batch_size) \\ .random_(0, num_classes) \\ .view(batch_size, 1) for _ in range(num_batches): # generate random inputs and labels inputs = torch.randn(batch_size, 3, image_w, image_h) labels = torch.zeros(batch_size, num_classes) \\ .scatter_(1, one_hot_indices, 1) # run forward pass optimizer.zero_grad() outputs = model(inputs.to('cuda:0')) # run backward pass labels = labels.to(outputs.device) loss_fn(outputs, labels).backward() optimizer.step() 的列车（模型）上述方法使用nn.MSELoss作为损失函数，并optim.SGD作为优化器。它模仿在训练128 X 128，其被组织成3批，其中每个批次包含120张图像的图像。然后，我们使用timeit运行列车（模型）方法10次，并用标准偏差绘制的执行时间。 import matplotlib.pyplot as plt plt.switch_backend('Agg') import numpy as np import timeit num_repeat = 10 stmt = \"train(model)\" setup = \"model = ModelParallelResNet50()\" # globals arg is only available in Python 3. In Python 2, use the following # import __builtin__ # __builtin__.__dict__.update(locals()) mp_run_times = timeit.repeat( stmt, setup, number=1, repeat=num_repeat, globals=globals()) mp_mean, mp_std = np.mean(mp_run_times), np.std(mp_run_times) setup = \"import torchvision.models as models;\" + \\ \"model = models.resnet50(num_classes=num_classes).to('cuda:0')\" rn_run_times = timeit.repeat( stmt, setup, number=1, repeat=num_repeat, globals=globals()) rn_mean, rn_std = np.mean(rn_run_times), np.std(rn_run_times) def plot(means, stds, labels, fig_name): fig, ax = plt.subplots() ax.bar(np.arange(len(means)), means, yerr=stds, align='center', alpha=0.5, ecolor='red', capsize=10, width=0.6) ax.set_ylabel('ResNet50 Execution Time (Second)') ax.set_xticks(np.arange(len(means))) ax.set_xticklabels(labels) ax.yaxis.grid(True) plt.tight_layout() plt.savefig(fig_name) plt.close(fig) plot([mp_mean, rn_mean], [mp_std, rn_std], ['Model Parallel', 'Single GPU'], 'mp_vs_rn.png') 结果表明，模型并行实现的执行时间是4.02 / 3.75-1 = 7％比现有的单GPU实现更长。因此，我们可以得出结论存在抄袭张量来回GPU的大约7％的开销。有客房的改进，因为我们知道两个GPU之一是在整个执行闲置。一个选择是每批进一步分成分割，使得当一个分割到达第二子网络，下面的分割可被馈送到第一子网络的一个管道。通过这种方式，两个连续的裂缝可以在两个GPU并行运行。 加快以流水线方式输入 在下面的实验中，我们进一步将每个120-图像批次为20个图像分割。作为PyTorch推出CUDA运算asynchronizely，实现不需要生成多个线程来实现并发。 class PipelineParallelResNet50(ModelParallelResNet50): def __init__(self, split_size=20, *args, **kwargs): super(PipelineParallelResNet50, self).__init__(*args, **kwargs) self.split_size = split_size def forward(self, x): splits = iter(x.split(self.split_size, dim=0)) s_next = next(splits) s_prev = self.seq1(s_next).to('cuda:1') ret = [] for s_next in splits: # A. s_prev runs on cuda:1 s_prev = self.seq2(s_prev) ret.append(self.fc(s_prev.view(s_prev.size(0), -1))) # B. s_next runs on cuda:0, which can run concurrently with A s_prev = self.seq1(s_next).to('cuda:1') s_prev = self.seq2(s_prev) ret.append(self.fc(s_prev.view(s_prev.size(0), -1))) return torch.cat(ret) setup = \"model = PipelineParallelResNet50()\" pp_run_times = timeit.repeat( stmt, setup, number=1, repeat=num_repeat, globals=globals()) pp_mean, pp_std = np.mean(pp_run_times), np.std(pp_run_times) plot([mp_mean, rn_mean, pp_mean], [mp_std, rn_std, pp_std], ['Model Parallel', 'Single GPU', 'Pipelining Model Parallel'], 'mp_vs_rn_vs_pp.png') 请注意，设备到设备的张量复制操作的源和目标设备上的电流流同步。如果创建多个数据流，你必须确保复制操作正确同步。编写源张量或读/完成复制操作可能会导致不确定的行为之前以书面目的地张量。上述实现仅在两个源和目的设备使用默认流，因此，没有必要执行额外同步。 实验结果表明，流水线输入到模型平行ResNet50由大致3.75 / 2.51-1 = 49％加速训练过程。它仍然是相当远从100％理想的加速比。正如我们已经推出了新的参数split_sizes在我们的管道并行实现，目前还不清楚新的参数是如何影响整体的训练时间。直观地说，用小split_size导致许多微小的CUDA内核启动，而在使用大split_size结果相对长的空闲时间第一和最后的分裂。无论是最优的。有可能是对于该特定实验的最佳split_size配置。让我们尝试使用几种不同的split_size值运行实验来找到它。 means = [] stds = [] split_sizes = [1, 3, 5, 8, 10, 12, 20, 40, 60] for split_size in split_sizes: setup = \"model = PipelineParallelResNet50(split_size=%d)\" % split_size pp_run_times = timeit.repeat( stmt, setup, number=1, repeat=num_repeat, globals=globals()) means.append(np.mean(pp_run_times)) stds.append(np.std(pp_run_times)) fig, ax = plt.subplots() ax.plot(split_sizes, means) ax.errorbar(split_sizes, means, yerr=stds, ecolor='red', fmt='ro') ax.set_ylabel('ResNet50 Execution Time (Second)') ax.set_xlabel('Pipeline Split Size') ax.set_xticks(split_sizes) ax.yaxis.grid(True) plt.tight_layout() plt.savefig(\"split_size_tradeoff.png\") plt.close(fig) 结果表明，设置split_size至12达到最快的训练速度，这导致3.75 / 2.43-1 = 54％加速。还有机会进一步加速训练过程。例如，在所有操作CUDA：0被放置在它的默认流。这意味着，对下一个分割的计算不能与先前分裂的复制操作重叠。然而，随着上一个和下一个分裂为不同的张量，没有重叠一个人与另一个人的副本计算问题。实现需要两个GPU的使用多个数据流，以及不同的子网络结构需要不同的数据流管理策略。由于没有通用的多流解决方案适用于所有型号并联使用的情况下，我们不会在本教程中讨论它。 注： 这篇文章显示了几个性能测量。运行你自己的机器上相同的代码时，您可能会看到不同的数字，因为结果取决于底层硬件和软件上。为了让您的环境中获得最佳性能，正确的做法是先产生曲线找出最佳分割尺寸，然后使用该拆分大小的管道输入。 脚本的总运行时间： （5分钟51.519秒） Download Python source code: model_parallel_tutorial.py Download Jupyter notebook: model_parallel_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 1.型号并行最佳实践 基本用法 套用模型并行为现有模块 加快通过流水线输入 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"intermediate/ddp_tutorial.html":{"url":"intermediate/ddp_tutorial.html","title":"2.入门分布式数据并行","keywords":"","body":"2.入门与分布式数据并行 作者 ：沉莉 DistributedDataParallel （DDP）实现在模块级数据并行性。它使用通信集体在 torch.distributed 包同步梯度，参数，和缓冲剂。并行可既是一个过程内和跨流程。内的方法，DDP复制输入模块在device_ids，散射沿相应的批量尺寸的输入，并收集输出到output_device指定装置，这类似于数据并行。跨进程，DDP插入在正向通行证和在向后穿过梯度同步必要的参数同步。它是由用户来映射进程可用的资源，只要工艺不共享GPU设备。推荐的（通常是最快）的方法是创建一个进程的每一个模块的副本，即，在一个进程中没有模块复制。本教程中的代码运行的8 GPU服务器上，但它可以被容易地推广到其他的环境中。 之间数据并行和DistributedDataParallel比较 在我们深入，让我们澄清为什么尽管增加的复杂性，你会考虑使用DistributedDataParallel在数据并行： 首先，从之前教程如果你的模型是太大，无法在单GPU，您必须使用 模型召回平行 将其跨多个GPU分裂。 DistributedDataParallel与 模型作品平行 ;此时数据并行没有。 数据并行是单进程，多线程，并且只能在单个机器上，而DistributedDataParallel是多进程和作品两个单和多机训练。因此，即使是单机训练，你的 数据 是足够小，适合在一台机器上，DistributedDataParallel预计比[快HTG15]数据并行。 DistributedDataParallel也复制模型，而不是前期在每次迭代并得到全局解释器锁的方式进行。 如果这两个数据是太大，无法一体机 和 你的模型是太大，无法在单GPU，您可以用模式并行（分割跨越多GPU的单一模式）相结合 DistributedDataParallel。在该机制下，各DistributedDataParallel过程可以使用模型平行，并且所有过程统称将使用数据并行。 基本用例 要创建DDP模块，首先设置进程组正常。更多详情可与PyTorch 编写分布式应用程序被发现。 import os import tempfile import torch import torch.distributed as dist import torch.nn as nn import torch.optim as optim import torch.multiprocessing as mp from torch.nn.parallel import DistributedDataParallel as DDP def setup(rank, world_size): os.environ['MASTER_ADDR'] = 'localhost' os.environ['MASTER_PORT'] = '12355' # initialize the process group dist.init_process_group(\"gloo\", rank=rank, world_size=world_size) # Explicitly setting seed to make sure that models created in two processes # start from same random weights and biases. torch.manual_seed(42) def cleanup(): dist.destroy_process_group() 现在，让我们创建一个玩具模块，与DDP纸包起来，然后用一些虚拟的输入数据给它。请注意，如果从培训随机参数开始，您可能希望确保所有DDP进程使用相同的初始值。否则，全球同步的梯度将没有意义。 class ToyModel(nn.Module): def __init__(self): super(ToyModel, self).__init__() self.net1 = nn.Linear(10, 10) self.relu = nn.ReLU() self.net2 = nn.Linear(10, 5) def forward(self, x): return self.net2(self.relu(self.net1(x))) def demo_basic(rank, world_size): setup(rank, world_size) # setup devices for this process, rank 1 uses GPUs [0, 1, 2, 3] and # rank 2 uses GPUs [4, 5, 6, 7]. n = torch.cuda.device_count() // world_size device_ids = list(range(rank * n, (rank + 1) * n)) # create model and move it to device_ids[0] model = ToyModel().to(device_ids[0]) # output_device defaults to device_ids[0] ddp_model = DDP(model, device_ids=device_ids) loss_fn = nn.MSELoss() optimizer = optim.SGD(ddp_model.parameters(), lr=0.001) optimizer.zero_grad() outputs = ddp_model(torch.randn(20, 10)) labels = torch.randn(20, 5).to(device_ids[0]) loss_fn(outputs, labels).backward() optimizer.step() cleanup() def run_demo(demo_fn, world_size): mp.spawn(demo_fn, args=(world_size,), nprocs=world_size, join=True) 正如你所看到的，DDP包下级分布式通信的细节，并提供了一个干净的API，就好像它是一个局部模型。对于基本用例，DDP只需要几个LOCS建立进程组。当应用DDP到更高级的使用情况下，有一些注意事项需要注意事项。 歪斜的处理速度 在DDP，构造，方法前进，并输出的分化分布同步点。不同的过程，预计以相同的顺序到达同步点和在大致相同的时间输入每个同步点。否则，快速的过程可能会提前到达，超时的等待掉队。因此，用户是负责整个流程平衡工作负载分布。有时候，歪斜的处理速度是不可避免的，由于，例如，网络延迟，资源冲突，不可预测的工作负载高峰。为了避免在这些情况下超时，请确保您调用 init_process_group 当传递一个足够大的超时值。 保存和载入关卡 它通常使用torch.save和torch.load训练期间检查站模块和从检查点恢复。参见保存和载入模型了解更多详情。当使用DDP，一个优化的模型保存只有一个进程，然后将其加载到所有进程，从而减少写入开销。这是正确的，因为所有处理从相同的参数开始和梯度在向后经过同步，并因此优化应保持设定参数相同的值。如果你使用这种优化，确保减排完成之前所有的进程不会开始加载。此外，加载模块时，需要提供适当的map_location参数来防止处理踏进别人的设备。如果map_location丢失，torch.load模块将首先加载到CPU，然后复制每个参数保存它，这将使用相同的一组设备导致在同一台机器上的所有进程。 def demo_checkpoint(rank, world_size): setup(rank, world_size) # setup devices for this process, rank 1 uses GPUs [0, 1, 2, 3] and # rank 2 uses GPUs [4, 5, 6, 7]. n = torch.cuda.device_count() // world_size device_ids = list(range(rank * n, (rank + 1) * n)) model = ToyModel().to(device_ids[0]) # output_device defaults to device_ids[0] ddp_model = DDP(model, device_ids=device_ids) loss_fn = nn.MSELoss() optimizer = optim.SGD(ddp_model.parameters(), lr=0.001) CHECKPOINT_PATH = tempfile.gettempdir() + \"/model.checkpoint\" if rank == 0: # All processes should see same parameters as they all start from same # random parameters and gradients are synchronized in backward passes. # Therefore, saving it in one process is sufficient. torch.save(ddp_model.state_dict(), CHECKPOINT_PATH) # Use a barrier() to make sure that process 1 loads the model after process # 0 saves it. dist.barrier() # configure map_location properly rank0_devices = [x - rank * len(device_ids) for x in device_ids] device_pairs = zip(rank0_devices, device_ids) map_location = {'cuda:%d' % x: 'cuda:%d' % y for x, y in device_pairs} ddp_model.load_state_dict( torch.load(CHECKPOINT_PATH, map_location=map_location)) optimizer.zero_grad() outputs = ddp_model(torch.randn(20, 10)) labels = torch.randn(20, 5).to(device_ids[0]) loss_fn = nn.MSELoss() loss_fn(outputs, labels).backward() optimizer.step() # Use a barrier() to make sure that all processes have finished reading the # checkpoint dist.barrier() if rank == 0: os.remove(CHECKPOINT_PATH) cleanup() 结合DDP与型号并行 DDP还与多GPU模式，而是一个过程中的重复，不支持。您需要创建每个模块的副本，这通常会导致更好的性能相比，每个进程的多个副本一个过程。 DDP包装多GPU模式培养具有巨大的数据量较大的模型时特别有用。使用此功能时，多GPU模式需要谨慎实施，以避免硬编码的设备，因为不同型号的副本将被放置到不同的设备。 class ToyMpModel(nn.Module): def __init__(self, dev0, dev1): super(ToyMpModel, self).__init__() self.dev0 = dev0 self.dev1 = dev1 self.net1 = torch.nn.Linear(10, 10).to(dev0) self.relu = torch.nn.ReLU() self.net2 = torch.nn.Linear(10, 5).to(dev1) def forward(self, x): x = x.to(self.dev0) x = self.relu(self.net1(x)) x = x.to(self.dev1) return self.net2(x) 当通过一个多GPU模型到DDP，device_ids和output_device必须不被设置。输入和输出的数据将被应用程序或模型向前（）方法被放置在适当的设备。 def demo_model_parallel(rank, world_size): setup(rank, world_size) # setup mp_model and devices for this process dev0 = rank * 2 dev1 = rank * 2 + 1 mp_model = ToyMpModel(dev0, dev1) ddp_mp_model = DDP(mp_model) loss_fn = nn.MSELoss() optimizer = optim.SGD(ddp_mp_model.parameters(), lr=0.001) optimizer.zero_grad() # outputs will be on dev1 outputs = ddp_mp_model(torch.randn(20, 10)) labels = torch.randn(20, 5).to(dev1) loss_fn(outputs, labels).backward() optimizer.step() cleanup() if __name__ == \"__main__\": run_demo(demo_basic, 2) run_demo(demo_checkpoint, 2) if torch.cuda.device_count() >= 8: run_demo(demo_model_parallel, 4) Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 [HTG0 2.入门分布式数据并行 数据并行 和DistributedDataParallel之间比较 基本用例 歪斜的处理速度 保存和载入关卡 与模型并行联合DDP ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"intermediate/dist_tuto.html":{"url":"intermediate/dist_tuto.html","title":"3. PyTorch编写分布式应用","keywords":"","body":"3. PyTorch编写分布式应用程序 作者 ： SEB阿诺德 在这个简短的教程中，我们将要在PyTorch的分布式包。我们将看到如何建立分布式设置，使用不同的沟通策略，走在包装件的一些内部结构。 设定 包括在PyTorch分布式包（即，torch.distributed `）使研究人员和从业人员跨进程和机器的集群来容易并行化的计算。为了这样做，它利用了消息传递语义允许每个进程进行数据通信的任何其他进程的。而不是在多处理（ torch.multiprocessing`）包，过程可以使用不同的通信后端和不限于在同一台机器上被执行。 为了开始，我们需要同时运行多个流程的能力。如果你有机会到计算机集群，你应该用你的本地系统管理员检查或使用自己喜欢的协调工具。 （例如， PDSH ， clustershell 或人）对于本教程的目的，我们将使用一台机器和叉的多个进程使用以下模板。 \"\"\"run.py:\"\"\" #!/usr/bin/env python import os import torch import torch.distributed as dist from torch.multiprocessing import Process def run(rank, size): \"\"\" Distributed function to be implemented later. \"\"\" pass def init_processes(rank, size, fn, backend='tcp'): \"\"\" Initialize the distributed environment. \"\"\" os.environ['MASTER_ADDR'] = '127.0.0.1' os.environ['MASTER_PORT'] = '29500' dist.init_process_group(backend, rank=rank, world_size=size) fn(rank, size) if __name__ == \"__main__\": size = 2 processes = [] for rank in range(size): p = Process(target=init_processes, args=(rank, size, run)) p.start() processes.append(p) for p in processes: p.join() 上述脚本派生两个过程谁将每个设置的分布式环境中，初始化处理组（dist.init_process_group），最后执行运行给定的功能。 让我们来看看init_processes功能。它确保每一道工序将能够通过一个主协调，使用相同的IP地址和端口。请注意，我们使用的是TCP后端，但我们也可以使用 MPI 或 GLOO 代替。 （参见 5.1节），我们会在魔术dist.init_process_group在本教程的最后发生的事情，但它基本上可以让进程间通信其他通过分享他们的位置。 点对点通信 传送和recv 数据从一个处理A转移到另一个被称为点 - 点通信。这些通过取得的发送和的recv的功能或它们的 立即 反份，isend和irecv。 \"\"\"Blocking point-to-point communication.\"\"\" def run(rank, size): tensor = torch.zeros(1) if rank == 0: tensor += 1 # Send the tensor to process 1 dist.send(tensor=tensor, dst=1) else: # Receive tensor from process 0 dist.recv(tensor=tensor, src=0) print('Rank ', rank, ' has data ', tensor[0]) 在上面的例子，这两个过程以零开始张量，然后处理增量0张量，并将其发送到处理1，使得它们都结束了1.0。请注意，过程1只需要以存储将接收数据分配内存。 还要注意，发送/ 的recv是 阻断 ：两个过程停止，直到通信完成。在另一方面的立即被 非阻塞 ;脚本将继续其执行和方法都返回一个DistributedRequest对象后，我们可以选择等待（）。 \"\"\"Non-blocking point-to-point communication.\"\"\" def run(rank, size): tensor = torch.zeros(1) req = None if rank == 0: tensor += 1 # Send the tensor to process 1 req = dist.isend(tensor=tensor, dst=1) print('Rank 0 started sending') else: # Receive tensor from process 0 req = dist.irecv(tensor=tensor, src=0) print('Rank 1 started receiving') req.wait() print('Rank ', rank, ' has data ', tensor[0]) 当使用的立即，我们必须小心我们的发送和接收的张量的使用。因为我们不知道什么时候的数据将被传递给其它工艺做的，我们不应该修改发张量也不req.wait（）完成之前访问接收到的张量。换一种说法， 写张量 ``dist.isend后（）将导致未定义的行为。 从读取张量 ``dist.irecv后（）将导致未定义的行为。 然而，req.wait（）已被执行之后，我们保证了通信发生了，并且，存储在张量的值[0]是1.0。 点至点，当我们想在我们的流程的通信进行细粒度的控制通信是有益的。它们可以被用来实现花哨的算法，如百度的DeepSpeech 或[ Facebook的大规模实验HTG3。所使用的（c.f。第4.1节） 集体通信 散点图 | 收集 ---|--- 降低 | 全减少 广播 | 全收集 相对于点对点通信电子，集体允许对 组 中所有进程的通信模式。 A组是我们所有进程的一个子集。要创建一个组，我们可以通过职级为dist.new_group（集团）名单 [HTG5。默认情况下，集体的对所有进程执行，也被称为 **世界[HTG7。例如，为了获得在所有进程都张量的总和，我们可以使用dist.all_reduce（张量， 运算， 组） 集体。** \"\"\" All-Reduce example.\"\"\" def run(rank, size): \"\"\" Simple point-to-point communication. \"\"\" group = dist.new_group([0, 1]) tensor = torch.ones(1) dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group) print('Rank ', rank, ' has data ', tensor[0]) 既然我们要在组中的所有张量的总和，我们使用dist.reduce_op.SUM为降低运营商。一般来说，任何可交换的数学运算，可以作为运营商。外的开箱，PyTorch配备了4个这样的运营商，都在逐元素级别工作： dist.reduce_op.SUM dist.reduce_op.PRODUCT dist.reduce_op.MAX dist.reduce_op.MIN。 除了dist.all_reduce（张量， 运算， 组），有一个总的目前PyTorch实现6个集体。 dist.broadcast（张量， SRC， 组）：复制张量从SRC到所有其它过程。 dist.reduce（张量， DST， 运算， 组）：应用OP所有结果张量，并存储在DST。 dist.all_reduce（张量， 运算， 组）：同降低，但其结果被存储在所有进程。 dist.scatter（张量， SRC， scatter_list， 组）：复制 \\（ I ^ {\\文本{第}} \\）张量scatter_list [I]到 \\（I ^ {\\文本{第}} \\）过程。 dist.gather（张量， DST， gather_list， 组）：复制张量从DST所有进程。 dist.all_gather（tensor_list， 张量， 组）：复制张量从所有流程，以tensor_list上的所有进程。 dist.barrier（组）：块组的所有进程，直至每一个已经进入该功能。 分布式训练 注： 你可以在这个GitHub的库本节的示例脚本。 现在我们明白了分布式模块是如何工作的，让我们写的东西与它有用。我们的目标是复制的 DistributedDataParallel 的功能。当然，这将是一个说教的例子，在现实世界situtation你应该使用官方的，经过严格测试和精心优化的版本上面链接。 简单地说，我们要实现的随机梯度下降一个分布式的版本。我们的脚本将让所有的进程都计算在他们的批量数据的他们的模型的梯度，然后平均的梯度。为了改变进程的数目时，以确保类似的收敛结果，我们首先要分区我们的数据。 （你也可以使用 tnt.dataset.SplitDataset ，而不是片段下方。） \"\"\" Dataset partitioning helper \"\"\" class Partition(object): def __init__(self, data, index): self.data = data self.index = index def __len__(self): return len(self.index) def __getitem__(self, index): data_idx = self.index[index] return self.data[data_idx] class DataPartitioner(object): def __init__(self, data, sizes=[0.7, 0.2, 0.1], seed=1234): self.data = data self.partitions = [] rng = Random() rng.seed(seed) data_len = len(data) indexes = [x for x in range(0, data_len)] rng.shuffle(indexes) for frac in sizes: part_len = int(frac * data_len) self.partitions.append(indexes[0:part_len]) indexes = indexes[part_len:] def use(self, partition): return Partition(self.data, self.partitions[partition]) 通过上述片段中，我们现在可以简单地使用下面的几行分区中的任何数据集： \"\"\" Partitioning MNIST \"\"\" def partition_dataset(): dataset = datasets.MNIST('./data', train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])) size = dist.get_world_size() bsz = 128 / float(size) partition_sizes = [1.0 / size for _ in range(size)] partition = DataPartitioner(dataset, partition_sizes) partition = partition.use(dist.get_rank()) train_set = torch.utils.data.DataLoader(partition, batch_size=bsz, shuffle=True) return train_set, bsz 假设我们有2个副本，那么每个进程将具有train_set60000/2 = 30000个样本。我们还除以副本的数量批量大小，以保持的128 总体 批量大小。 现在，我们可以写我们通常前后，优化训练码，并添加一个函数调用来平均我们的模型的梯度。 （下面是从官方 PyTorch MNIST例如很大程度上启发。） \"\"\" Distributed Synchronous SGD Example \"\"\" def run(rank, size): torch.manual_seed(1234) train_set, bsz = partition_dataset() model = Net() optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5) num_batches = ceil(len(train_set.dataset) / float(bsz)) for epoch in range(10): epoch_loss = 0.0 for data, target in train_set: optimizer.zero_grad() output = model(data) loss = F.nll_loss(output, target) epoch_loss += loss.item() loss.backward() average_gradients(model) optimizer.step() print('Rank ', dist.get_rank(), ', epoch ', epoch, ': ', epoch_loss / num_batches) 它仍然实现average_gradients（型号）功能，它只是发生在一个模型，在整个世界平均水平的梯度。 \"\"\" Gradient averaging. \"\"\" def average_gradients(model): size = float(dist.get_world_size()) for param in model.parameters(): dist.all_reduce(param.grad.data, op=dist.reduce_op.SUM) param.grad.data /= size 的Et瞧 ！我们成功地实施分布式同步新元，并可能培养了大量的计算机集群上的任何模型。 注：[HTG1虽然最后一句是 技术上 真实的，有[很多更多的技巧HTG5】实行同步SGD的生产级的落实需要。再次，用什么[已经过测试和优化HTG7。 我们自己的戒指，Allreduce 作为一个额外的挑战，假设我们要落实DeepSpeech的高效环allreduce。这是使用点至点集体相当容易实现。 \"\"\" Implementation of a ring-reduce with addition. \"\"\" def allreduce(send, recv): rank = dist.get_rank() size = dist.get_world_size() send_buff = th.zeros(send.size()) recv_buff = th.zeros(send.size()) accum = th.zeros(send.size()) accum[:] = send[:] left = ((rank - 1) + size) % size right = (rank + 1) % size for i in range(size - 1): if i % 2 == 0: # Send send_buff send_req = dist.isend(send_buff, right) dist.recv(recv_buff, left) accum[:] += recv[:] else: # Send recv_buff send_req = dist.isend(recv_buff, right) dist.recv(send_buff, left) accum[:] += send[:] send_req.wait() recv[:] = accum[:] 另外，在上述脚本中，allreduce（发送， 的recv）函数具有比PyTorch的那些稍微不同的签名。它需要一个的recv张量，将所有发张量的总和存储在里面。作为一个练习留给读者，还有我们的版本和一个在DeepSpeech之间的一个区别：它们的实现划分梯度张成 块 ，从而以最佳方式利用通信带宽。 （提示： torch.chunk ） 高级主题 我们现在就可以发现一些torch.distributed更先进的功能性。因为有很多覆盖，本节分为两个小节： 通讯后端：我们学习如何使用MPI和GLOO的GPU-GPU通信。 初始化方法：在我们了解如何最好地设置在dist.init_process_group初始协调阶段（） [HTG3。 通信后端 其中的最优雅的方面torch.distributed是它的抽象能力和建立在不同的后端之上。正如前面提到的，有目前有三个在后端实现PyTorch：TCP，MPI和GLOO。他们每个人都有不同的规格和权衡，根据所需的用例。支持的函数的比较表可以发现这里。需要注意的是第四后端，NCCL，已自创立本教程的补充。参见本部分中的torch.distributed文档有关其使用和值的详细信息的。 TCP后端 到目前为止，我们已经取得了TCP后端的广泛使用。这是作为一个开发平台非常方便，因为它是保证在大多数计算机和操作系统上运行。它还支持所有点至点和集体功能的CPU。然而，对于GPU和它的通信程序并不作为优化的MPI一个不支持。 GLOO后端 的 GLOO后端提供了一种优化的实施 集体 通信过程，无论对CPU和GPU。它特别照在GPU的，因为它可以在不使用 GPUDirect 将数据传送到CPU的存储器进行通信。另外，也能够使用 NCCL 执行快速节点内的通信，并实现其[自己的算法HTG9用于节点间的例程。 自从0.2.0版本中，GLOO后台自动包含PyTorch的预编译的二进制文件。正如你一定会注意到，如果你把模型在GPU上我们的分布式SGD例如不工作。让我们从第一替换后端= 'GLOO' 修复在init_processes（秩， 大小， FN， 后端= 'TCP'）。在这一点上，该脚本将仍然在CPU上运行，但使用的幕后GLOO后端。为了使用多GPU，让我们也做如下修改： init_processes（秩， 大小， FN， 后端= 'TCP'）\\（\\ RIGHTARROW \\） init_processes（秩， 大小， FN， 后端= 'GLOO'） 使用装置 = torch.device（ “CUDA：{}”。格式（评级）） 模型 = 净（）\\（\\ RIGHTARROW \\） 模型 = 净（）。到（装置） 使用数据， 目标 = data.to（装置）， target.to（装置） 通过上述修改，我们的模型现在的训练在两个GPU和您可以监控他们与利用观看 NVIDIA-SMI [HTG5。 MPI后端 消息传递接口（MPI）是从高性能计算领域标准化的工具。它允许做点至点和集体沟通，是为torch.distributed该API的主要灵感。存在MPI的若干实施方式（例如，开放-MPI ， MVAPICH2 ，英特尔MPI ），每个用于不同的目的进行了优化。使用MPI后端的优势在于MPI的广泛可用性 - 和优化的高层次 - 大型计算机集群。 [HTG10一些 最近 实现也能够利用CUDA IPC和GPU直接的技术，以便通过CPU来避免存储副本。 不幸的是，PyTorch的可执行文件可以不包括MPI实现，我们必须手工重新编译。幸运的是，这个过程是相当简单的因为在编译时，PyTorch看起来 本身 一个可用的MPI实现。下面的步骤安装MPI后端，通过从源安装PyTorch 。 创建并激活您的蟒蛇环境，安装所有下面的导的先决条件，但 不是 运行巨蟒 setup.py 安装呢。 选择并安装自己喜欢的MPI实现。请注意，启用CUDA感知MPI可能需要一些额外的步骤。在我们的例子中，我们将坚持开放MPI 无 GPU的支持：畅达 安装 -c 康达锻 的openmpi 现在，去你的克隆PyTorch回购和执行巨蟒 setup.py 安装 [HTG7。 为了测试我们新安装的后端，则需要进行一些修改。 更换下含量如果 __name__ == '__main__'：与init_processes （0， 0， 运行， 后端= 'MPI'）。 运行的mpirun -N 4 蟒 myscript.py。 究其原因，这些变化是，MPI需要产卵的过程之前创建自己的环境。 MPI也将产生其自己的过程，并执行在初始化方法所述的握手，使得秩和大小的参数init_process_group多余的。这实际上是相当强大的，你可以通过额外的参数的mpirun [HTG17为了调整计算资源，为每个进程。 （比如像每个进程内核，手工分配机器特定列数和[一些更](https://www.open- mpi.org/faq/?category=running#mpirun-hostfile)）这样做，则应该得到相同的熟悉输出与其它通信后端。 初始化方法 为了完成本教程，让我们来谈谈我们称为第一个函数：dist.init_process_group（后端， init_method）HTG4] [HTG5。特别是，我们会在不同的初始化方法，这是负责每道工序之间的协调最初一步。这些方法允许你定义这种协调是如何实现的。根据您的硬件设置，这些方法之一应该是自然比其他人更适合。除了下面的部分，你也应该有一个看看[官方文档[HTG7。](https://pytorch.org/docs/stable/distributed.html#initialization) 跳水进入初始化方法之前，让我们快速浏览一下背后init_process_group从C / C ++的角度会发生什么。 首先，参数解析和验证。 后端经由name2channel.at（）功能解决。 A 频道类被返回，并且将用于进行该数据传输。 的GIL被丢弃，并THDProcessGroupInit（）被调用。此实例化信道，并增加了主节点的地址。 用列0的过程中会执行主过程，而所有其他等级将是工人。 大师 创建为所有工人插座。 所有工人等待连接。 发送他们有关的其他进程的位置信息。 每个工人 创建一个套接字的主人。 将自己的位置信息。 接收有关的其他工作人员的信息。 打开一个插座和握手与所有其他工人。 初始化完成后，每个人都被连接到每一个人。 环境变量 我们一直在使用本教程的环境变量初始化方法。通过设置所有计算机上的以下四个环境变量，所有进程将能够正确地连接到主，获取有关的其他进程的信息，并最终与他们握手。 MASTER_PORT：将与等级0宿主的过程中机器上的空闲端口。 MASTER_ADDR：将与等级0宿主的过程中机器的IP地址。 WORLD_SIZE：总数的工艺，使主知道有多少工人等待。 RANK：每个处理的等级，所以他们会知道它是否是一个工人的主人。 共享文件系统 共享文件系统需要的所有进程能够访问共享文件系统，并协调将通过共享文件。这意味着，每个进程将打开该文件，写入其信息，并等待，直到每个人都这样做了。以后有什么需要的所有信息将随时提供给所有的进程。为了避免竞态条件，则文件系统必须支持通过的fcntl 锁定。请注意，您可以手动指定行列或让流程弄清楚自己。可以定义一个独特的组名每次作业你可以使用相同的文件路径为多个作业，然后安全地避免冲突。 dist.init_process_group(init_method='file:///mnt/nfs/sharedfile', world_size=4, group_name='mygroup') TCP初始化 &安培;组播 通过TCP初始化可以用两种不同的方式来实现： 通过提供过程中的IP地址与等级0和世界大小。 通过提供 任何 有效的IP 多播地址和世界的大小。 在第一种情况下，所有工人将能够与秩0连接至该过程，并按照上面描述的过程。 dist.init_process_group(init_method='tcp://10.1.1.20:23456', rank=args.rank, world_size=4) 在第二种情况下，多播地址指定组节点谁可能潜在地是活性和协调可以通过允许每个进程遵循上面的程序之前，有一个初始握手处理的。此外TCP组播初始化还支持组名参数（与共享文件的方法），从而允许多个作业要在同一群集中调度。 dist.init_process_group(init_method='tcp://[ff15:1e18:5d4c:4cf0:d02d:b659:53ba:b0a7]:23456', world_size=4) 致谢 我想感谢PyTorch开发人员就其执行，文档和测试做这样一个好工作。当代码不清楚，我总能指望文档或测试找到答案。我特别要感谢Soumith Chintala，亚当Paszke，和Natalia Gimelshein提供有见地的意见和回答有关初稿的问题。 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 3. PyTorch编写分布式应用 安装 点对点通讯 集群通信 [HTG0分布式训练 我们自己的戒指，Allreduce 高级主题 通信后端 初始化方法 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner/aws_distributed_training_tutorial.html":{"url":"beginner/aws_distributed_training_tutorial.html","title":"4.（高级）PyTorch 1.0分布式训练与Amazon AWS","keywords":"","body":"4.（高级）PyTorch 1.0分布式训练与Amazon AWS 作者 ：弥敦道Inkawhich 由 编辑：腾力 在本教程中，我们将介绍如何设置，代码，并在两个多GPU亚马逊AWS节点运行PyTorch 1.0分布式教练。我们将与描述为分布式教练的AWS设置，那么PyTorch环境配置，最后的代码开始。希望你会发现，有您当前的训练码扩展到分布式应用程序实际上需要很少的代码变化，大部分工作是在一次环境设置。 亚马逊AWS设定 在本教程中，我们将运行在两个多GPU节点的分布式训练。在本节中，我们将首先介绍如何创建节点，那么如何设置安全组，这样的节点可以与海誓山盟沟通。 创建结点 在亚马逊AWS，有七个步骤来创建一个实例。要开始，登录并选择 启动实例[HTG1。 [HTG0步骤1：选择一个亚马逊机器映像（AMI） - 在这里，我们将选择深 学习 AMI （Ubuntu的） 版 14.0。如上所述，这种情况下附带了许多安装了最流行的深学习框架，并进行了预配置CUDA，cuDNN和NCCL。正是由于这个教程一个很好的起点。 步骤2：选择一个实例类型 - 称为现在，选择GPU计算单元p2.8xlarge。通知，每个这些实例都具有不同的成本，但这种情况下，每个节点提供了8个NVIDIA特斯拉K80 GPU和提供了用于多GPU分布式训练良好的体系结构。 步骤3：配置实例详细说明 - 改变这里的唯一设置在增加的实例的 Number来2.所有其它配置可以在默认留。 第四步：添加存储 - 请注意，默认情况下，这些节点不来了大量的存储空间（只有75 GB）。对于本教程，因为我们只使用STL-10数据集，这是充足的存储空间。但是，如果你想在一个更大的数据集，如ImageNet训练，你将不得不增加更多的存储只是为了适应数据集，并要保存任何训练的模型。 [HTG0步骤5：添加标签 - 什么可以在这里完成，只是继续前进。 [HTG0步骤6：配置安全组 - 这是在配置过程中的关键步骤。默认情况下，同一安全组中的两个节点将不能够在分布式训练环境进行通信。在这里，我们要创建一个 新 为两个节点安全组是在，但我们无法完成配置在这一步。现在，只记得你的新的安全组的名称（例如，推出的向导-12），然后转移到步骤7。 [HTG0步骤7：回顾实例启动 - 在这里，查看实例，然后启动它。默认情况下，会自动启动初始化两个实例。您可以监视从仪表板的初始化进度。 配置安全组 回想一下，我们无法创建实例时正确配置安全组。一旦你启动实例，选择 网络 &放;安全& GT ;安全组在EC2仪表板选项卡。这将显示您可以访问安全组的列表。选择在步骤6中创建的新的安全组（即启动的向导-12），这将打开的选项卡被称为 说明，入站，出站，和标签 。首先，选择 入境 选项卡和 编辑 从“源”推出的向导-12安全组中添加规则允许“所有流量”。然后选择 出境 选项卡，然后做同样的事情。现在，我们已经有效地使推出的向导-12安全组中的节点之间的所有类型的所有入站和出站流量。 必要信息 在继续之前，我们必须找到并记住两个节点的IP地址。在EC2仪表板找到你正在运行的实例。对于这两种情况下，写下 IPv4公网IP 和 私人IP地址[HTG3。对于文档的其余部分，我们将把这些作为 NODE0-publicIP ， NODE0-privateIP ， 节点1-publicIP 和 node1- privateIP 。公共IP地址是我们将使用SSH连接的地址和私有地址将被用于节点间通信。 环境设置 下一关键步骤是在每个节点的设置。不幸的是，我们不能同时设置两个节点，所以这个过程必须在每个节点上分别进行。然而，这是一个时间的设置，所以一旦你正确配置的节点，您将不必重新配置为未来分布式培训项目。 第一步骤中，一旦登录到节点，是与蟒3.6和numpy的创建一个新的康达环境。一旦创建启动环境。 $ conda create -n nightly_pt python=3.6 numpy $ source activate nightly_pt 接下来，我们将安装Cuda的9.0启用PyTorch的每晚构建与在畅达环境点子。 $ pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu90/torch_nightly.html 我们还必须安装torchvision所以我们可以使用torchvision模型和数据集。此时，由于PIP安装将在默认情况下，我们刚刚安装的每晚构建的顶部安装了旧版本PyTorch的，我们必须从源代码编译torchvision。 $ cd $ git clone https://github.com/pytorch/vision.git $ cd vision $ python setup.py install 最后， 非常重要[HTG1步骤是为NCCL插座设置网络接口的名称。这被设定为环境变量NCCL_SOCKET_IFNAME。为了得到正确的名称，该节点上运行使用ifconfig命令，查看对应的接口名称节点的 privateIP [HTG11（例如ens3）。然后设置环境变量 $ export NCCL_SOCKET_IFNAME=ens3 请记住，这样做两个节点上。您也可以考虑加入NCCLSOCKET_IFNAME设置为你的 .bashrc中[HTG1。一个重要的观察是，我们没有设置节点之间共享的文件系统。因此，每个节点必须有代码的副本和所述数据集的副本。有关设置节点之间的共享的网络文件系统的更多信息，请参见这里。_ 分布式训练码 随着运行的实例和环境设置，我们现在可以进入训练码。这里的大多数代码的已采取从 PyTorch ImageNet实施例这也支持分布式训练。此代码提供了一个自定义的教练一个很好的起点，因为它有很多的样板训练循环，确认循环和准确性跟踪功能。但是，您会注意到参数解析和其他非必要的功能已被剥离出来的简单性。 在这个例子中，我们将使用 torchvision.models.resnet18 模式，并将训练它的 torchvision.datasets.STL10 数据集。为了适应对STL-10与Resnet18维数不匹配，我们将每个图像尺寸调整到224x224通过转换。请注意，模型和数据集的选择是正交的分布式训练码，你可以使用任何你想要的数据集，模型和过程是相同的。让我们得到由第一处理进口和谈论了一些辅助功能启动。然后，我们将定义火车和测试功能，这已经在很大程度上从ImageNet实施例作出。最后，我们将构建一个处理分布式训练设置的代码的主要部分。最后，我们将讨论如何实际运行代码。 进口 最重要的分布式训练特定这里进口 torch.nn.parallel ，torch.distributed ，torch.utils.data.distributed 和Torch 。多处理。同样重要的是，设置多启动方法为 菌种 或 forkserver （仅在Python 3支持），作为默认的是 叉 这可能引起死锁时使用多个工作进行dataloading处理。 import time import sys import torch if __name__ == '__main__': torch.multiprocessing.set_start_method('spawn') import torch.nn as nn import torch.nn.parallel import torch.distributed as dist import torch.optim import torch.utils.data import torch.utils.data.distributed import torchvision.transforms as transforms import torchvision.datasets as datasets import torchvision.models as models from torch.multiprocessing import Pool, Process 辅助函数 我们还必须定义一些辅助函数和类将会使培训更容易。在AverageMeter类曲目培训统计资料，例如精度和迭代次数。在精度函数计算并返回模型的前k精度，所以我们可以跟踪学习进度。两者都提供了方便训练但是没有分配具体的培训。 class AverageMeter(object): \"\"\"Computes and stores the average and current value\"\"\" def __init__(self): self.reset() def reset(self): self.val = 0 self.avg = 0 self.sum = 0 self.count = 0 def update(self, val, n=1): self.val = val self.sum += val * n self.count += n self.avg = self.sum / self.count def accuracy(output, target, topk=(1,)): \"\"\"Computes the precision@k for the specified values of k\"\"\" with torch.no_grad(): maxk = max(topk) batch_size = target.size(0) _, pred = output.topk(maxk, 1, True, True) pred = pred.t() correct = pred.eq(target.view(1, -1).expand_as(pred)) res = [] for k in topk: correct_k = correct[:k].view(-1).float().sum(0, keepdim=True) res.append(correct_k.mul_(100.0 / batch_size)) return res 列车功能 为了简化主循环中，最好是分离出训练时期步骤到一个名为列车功能。该功能用于训练的 train_loader 一个历元输入模型。在此功能仅分布训练神器的数据和标签张量 non_blocking 属性设置为前直传真 [HTG11。这使得数据传输含义异步GPU拷贝可以与计算重叠。该功能还输出沿途培训统计，所以我们可以跟踪整个时代的进步。 其它功能在这里定义为adjust_learning_rate，其衰减在一个固定的时间表初始学习速率。这又是一个样板教练功能是训练精确的模型非常有用。 def train(train_loader, model, criterion, optimizer, epoch): batch_time = AverageMeter() data_time = AverageMeter() losses = AverageMeter() top1 = AverageMeter() top5 = AverageMeter() # switch to train mode model.train() end = time.time() for i, (input, target) in enumerate(train_loader): # measure data loading time data_time.update(time.time() - end) # Create non_blocking tensors for distributed training input = input.cuda(non_blocking=True) target = target.cuda(non_blocking=True) # compute output output = model(input) loss = criterion(output, target) # measure accuracy and record loss prec1, prec5 = accuracy(output, target, topk=(1, 5)) losses.update(loss.item(), input.size(0)) top1.update(prec1[0], input.size(0)) top5.update(prec5[0], input.size(0)) # compute gradients in a backward pass optimizer.zero_grad() loss.backward() # Call step of optimizer to update model params optimizer.step() # measure elapsed time batch_time.update(time.time() - end) end = time.time() if i % 10 == 0: print('Epoch: [{0}][{1}/{2}]\\t' 'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' 'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t' 'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' 'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t' 'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format( epoch, i, len(train_loader), batch_time=batch_time, data_time=data_time, loss=losses, top1=top1, top5=top5)) def adjust_learning_rate(initial_lr, optimizer, epoch): \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\" lr = initial_lr * (0.1 ** (epoch // 30)) for param_group in optimizer.param_groups: param_group['lr'] = lr 验证函数 为了跟踪推广性能和简化主回路还我们还可以提取所述验证步骤到一个名为函数验证。该函数运行在输入验证的DataLoader输入模型的一个完整的验证步骤，并返回所述验证集的模型的顶部-1的精度。同样，你会发现这里唯一的分布式训练功能设置non_blocking =真训练数据和标签它们传递给模型前。 def validate(val_loader, model, criterion): batch_time = AverageMeter() losses = AverageMeter() top1 = AverageMeter() top5 = AverageMeter() # switch to evaluate mode model.eval() with torch.no_grad(): end = time.time() for i, (input, target) in enumerate(val_loader): input = input.cuda(non_blocking=True) target = target.cuda(non_blocking=True) # compute output output = model(input) loss = criterion(output, target) # measure accuracy and record loss prec1, prec5 = accuracy(output, target, topk=(1, 5)) losses.update(loss.item(), input.size(0)) top1.update(prec1[0], input.size(0)) top5.update(prec5[0], input.size(0)) # measure elapsed time batch_time.update(time.time() - end) end = time.time() if i % 100 == 0: print('Test: [{0}/{1}]\\t' 'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' 'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' 'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t' 'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format( i, len(val_loader), batch_time=batch_time, loss=losses, top1=top1, top5=top5)) print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}' .format(top1=top1, top5=top5)) return top1.avg 输入 随着辅助函数的方式进行，现在我们已经到了有趣的部分。这里我们将定义运行的输入。一些输入是标准模型的培训投入，如批量大小和训练时期的数量，有些是专门针对我们的分布式训练任务。所需的输入是： 的batch_size - 批量大小为 分布式训练组中的每个 过程。在分布式模型总批量大小的batch_size是* world_size 工人 - 中的每个进程与所述dataloaders使用的工作进程数 num_epochs - 历元用于训练的总次数 starting_lr - 开始进行训练学习速率 world_size - 过程在分布式训练环境数 dist_backend - 后端用于分布式训练的通信（即NCCL，GLOO，MPI，等）。在本教程中，由于我们使用几个多GPU节点，NCCL建议。 dist_url - URL来指定处理组的初始化方法。这可以包含rank0处理的IP地址和端口或者是一个共享的文件系统上的不存在的文件。这里，因为我们没有一个共享文件系统，这将包括在NODE0使用 NODE0-privateIP 和端口。 print(\"Collect Inputs...\") # Batch Size for training and testing batch_size = 32 # Number of additional worker processes for dataloading workers = 2 # Number of epochs to train for num_epochs = 2 # Starting Learning Rate starting_lr = 0.1 # Number of distributed processes world_size = 4 # Distributed backend type dist_backend = 'nccl' # Url used to setup distributed training dist_url = \"tcp://172.31.22.234:23456\" 初始化进程组 一个在PyTorch分布式训练的最重要的部分是正确设置进程组，这是在初始化torch.distributed包 第一 步骤。要做到这一点，我们将使用torch.distributed.init_process_group功能，需要几个输入。首先， 后端 输入指定后端使用（即NCCL，GLOO，MPI，等）。一个 init_method 输入其是含有rank0机器的地址和端口或共享文件系统上的一个不存在的文件的路径的URL。注意，使用文件initmethod，所有机器必须能够访问该文件，同样的网址的方法，所有机器必须能够在网络上进行通信，从而确保配置任何防火墙和网络设置，以适应。的 _init_process_group 功能也需要 秩 和 world_size 用于指定运行时该方法的秩和的过程中集体的数量，分别参数。的 init_method 输入也可以是“ENV：//”。 MASTERADDR，MASTER_PORT：在这种情况下，rank0机器的地址和端口号会从以下两个环境变量分别读取。 RANK，WORLD_SIZE：如果 位次 和 _world_size 未在 init_process_group 功能指定的参数，它们都可以从以下两个环境变量分别也被读取。 另一个重要的步骤，特别是当每一个节点具有多个GPU是设置 local_rank 该方法的。例如，如果有两个节点，每个节点8个GPU和希望与他们的训练然后 \\（世界\\ _size = 16 \\），并且每个节点将与本地秩0-的处理7。此local_rank用于设置该装置（即要使用的GPU）的过程和随后用于创建分布式数据并行模型时设置该装置。此外，还建议使用NCCL后端在这个假设的环境NCCL是优选的多GPU节点。 print(\"Initialize Process Group...\") # Initialize Process Group # v1 - init with url dist.init_process_group(backend=dist_backend, init_method=dist_url, rank=int(sys.argv[1]), world_size=world_size) # v2 - init with file # dist.init_process_group(backend=\"nccl\", init_method=\"file:///home/ubuntu/pt-distributed-tutorial/trainfile\", rank=int(sys.argv[1]), world_size=world_size) # v3 - init with environment variables # dist.init_process_group(backend=\"nccl\", init_method=\"env://\", rank=int(sys.argv[1]), world_size=world_size) # Establish Local Rank and set device on this node local_rank = int(sys.argv[2]) dp_device_ids = [local_rank] torch.cuda.set_device(local_rank) 初始化模型 下一个主要步骤是初始化进行培训的模式。在这里，我们将使用torchvision.models一个resnet18模式，但可以使用任何模型。首先，我们初始化模式，并把它放在GPU内存。接下来，我们使模型DistributedDataParallel，其处理数据的分布和模型，是分布式训练的关键。在DistributedDataParallel模块还可以处理世界各地的梯度的平均，所以我们没有在训练步骤明确平均梯度。 要注意，这是一个阻塞功能，这意味着程序执行将在此函数等到 world_size 工艺已经加入了处理组是重要的。另外，还要注意我们传递的设备ID列表，其中包含了本地等级（即GPU），我们正在使用的参数。最后，我们确定损失的功能和优化训练与模型。 print(\"Initialize Model...\") # Construct Model model = models.resnet18(pretrained=False).cuda() # Make model DistributedDataParallel model = torch.nn.parallel.DistributedDataParallel(model, device_ids=dp_device_ids, output_device=local_rank) # define loss function (criterion) and optimizer criterion = nn.CrossEntropyLoss().cuda() optimizer = torch.optim.SGD(model.parameters(), starting_lr, momentum=0.9, weight_decay=1e-4) 初始化Dataloaders 在训练准备的最后一步是指定要使用的数据集。这里我们使用 torchvision.datasets.STL10 中的[ STL-10数据集HTG1。所述STL10数据集是96x96px彩色图像的10类数据集。对于我们的模型的使用，我们调整图像224x224px在变换。本节中的一个分布式训练特定项是使用的DistributedSampler对于训练集，其被设计为与DistributedDataParallel一起使用车型。这个对象处理跨分布式环境中，这样并非所有型号都在相同的数据集，这将是适得其反的训练数据集的划分。最后，我们创建的DataLoader的其负责馈送的数据的处理。 如果它们不存在的STL-10数据集将自动节点上下载。如果你想使用自己的数据集，你应该下载的数据，编写自己的数据集的处理程序，并在这里建立了您的数据集的DataLoader。 print(\"Initialize Dataloaders...\") # Define the transform for the data. Notice, we must resize to 224x224 with this dataset and model. transform = transforms.Compose( [transforms.Resize(224), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # Initialize Datasets. STL10 will automatically download if not present trainset = datasets.STL10(root='./data', split='train', download=True, transform=transform) valset = datasets.STL10(root='./data', split='test', download=True, transform=transform) # Create DistributedSampler to handle distributing the dataset across nodes when training # This can only be called after torch.distributed.init_process_group is called train_sampler = torch.utils.data.distributed.DistributedSampler(trainset) # Create the Dataloaders to feed data to the training and validation steps train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=(train_sampler is None), num_workers=workers, pin_memory=False, sampler=train_sampler) val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=workers, pin_memory=False) 训练循环 最后一步是界定训练循环。我们已经完成了大部分的工作，为建立分布式训练所以这不是分布式训练具体。唯一的细节是设置在DistributedSampler，作为取样洗牌的数据要每个进程确定性地基于历元的当前历元计数。更新采样后，循环运行完整的训练时期，然后运行一个完整的验证步骤打印对表现最好的模型当前模型的性能至今。对于num_epochs训练结束后，退出循环和教程结束。请注意，因为这是我们没有保存模型的工作，但不妨一跟踪性能最佳的模型，然后将其保存在训练结束（见此处）。 best_prec1 = 0 for epoch in range(num_epochs): # Set epoch count for DistributedSampler train_sampler.set_epoch(epoch) # Adjust learning rate according to schedule adjust_learning_rate(starting_lr, optimizer, epoch) # train for one epoch print(\"\\nBegin Training Epoch {}\".format(epoch+1)) train(train_loader, model, criterion, optimizer, epoch) # evaluate on validation set print(\"Begin Validation @ Epoch {}\".format(epoch+1)) prec1 = validate(val_loader, model, criterion) # remember best prec@1 and save checkpoint if desired # is_best = prec1 > best_prec1 best_prec1 = max(prec1, best_prec1) print(\"Epoch Summary: \") print(\"\\tEpoch Accuracy: {}\".format(prec1)) print(\"\\tBest Accuracy: {}\".format(best_prec1)) 运行代码 与其他大多数PyTorch教程，这些代码可能无法直接从这款笔记本的运行。要运行，下载此文件的版本的.py（或使用这个将其转换）并上传一份给两个节点。细心的读者会注意到，我们硬编码了 NODE0-privateIP 和 \\（世界\\ size = 4 \\）HTG5]，但输入 位次 和 _local_rank 输入作为ARG [1]和Arg [2]的命令行参数，分别。上传后，打开两个SSH终端到每个节点。 论NODE0第一终端，运行$ 蟒 main.py 0 0 论NODE0运行第二终端$ 蟒 main.py 1 1 对节点1的第一终端，运行$ 蟒 main.py 2 0 对节点1运行第二终端$ 蟒 main.py 3 1 该程序将启动，并打印“初始化模式......”所有四个流程加盟流程组后等待。注意不重复的第一个参数，因为这是过程的独特的全球性排名。重复第二个参数，因为这是在该节点上运行的进程的本地秩。如果你运行NVIDIA-SMI每个节点上，你会看到每个节点上的两个过程，一个是关于GPU0运行，一个在GPU1。 现在我们已经完成了分布式训练的例子！希望你可以看到你将如何使用此教程，以帮助培养你自己的数据集自己的模型，即使您不使用完全相同的分布式环境不受。如果你正在使用AWS，不要忘了，如果你不使用它们 关闭NODES 或者你可以在月底发现的令人不安的大账单。 下一步去哪里 退房启动公用踢关闭运行的不同方式 检查出的[ torch.multiprocessing.spawn实用程序HTG1用于开球多个分布式方法的另一个简单的方法。 PyTorch ImageNet实施例已将其实现，并且可以显示如何使用它。 如果可能的话，设置一个NFS所以你只需要数据集中的一个副本 脚本的总运行时间： （0分钟0.000秒） Download Python source code: aws_distributed_training_tutorial.py Download Jupyter notebook: aws_distributed_training_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 [HTG0 4.（高级）PyTorch 1.0分布式训练与Amazon AWS 亚马逊AWS设定 创建节点 配置安集团 必要的信息 环境设置 [HTG0分布式训练码 进口 辅助函数 列车功能 验证函数 输入 初始化处理组 初始化模型 初始化Dataloaders 培训环 运行代码 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"advanced/torch_script_custom_ops.html":{"url":"advanced/torch_script_custom_ops.html","title":"使用自定义 C++ 扩展算TorchScript ","keywords":"","body":"使用自定义C ++算延伸TorchScript 该PyTorch 1.0版本中引入的一种新的编程模型PyTorch称为[ TorchScript HTG1。 TorchScript是可解析的，编译和优化由TorchScript编译Python编程语言的子集。此外，编译TorchScript模型有被序列化到磁盘上的文件格式，它可以随后加载和从纯C ++（以及Python）的用于推理运行选项。 TorchScript支持由Torch 提供包操作的相当大的一部分，让你表达多种复杂模型的纯粹从PyTorch的“标准库”等一系列张量操作。不过，也有可能是时候，你需要有一个自定义的C ++或CUDA功能扩展TorchScript的发现自己。虽然我们建议您只能求助于这个选项，如果你的想法不能被表达（足够有效），作为一个简单的Python函数，我们提供了一个非常友好和简单的界面使用定义自定义C ++和CUDA内核 ATEN ，PyTorch的高性能C ++库张。一旦绑定到TorchScript，您可以嵌入这些自定义内核（或“OPS”）到您的TorchScript模型，无论是在Python和直接的序列化的形式在C ++中执行。 下面的段落给出写TorchScript定制运算来调入的OpenCV ，计算机视觉库用C ++编写的一个例子。我们将讨论如何在C ++中，张量工作，如何有效地将它们转换为第三方张量格式（在这种情况下，OpenCV的 Mats），如何注册与TorchScript运行，最后如何您的运营商编译操作和Python和C ++使用它。 实施自定义操作员在C ++ 对于本教程，我们将暴露 warpPerspective 函数，它适用于透视变换的图像，从到的OpenCV作为TorchScript自定义操作符。第一步是写我们在C ++运营商定制的实现。让我们把这个实现op.cpp，使它看起来像这样的文件： #include #include torch::Tensor warp_perspective(torch::Tensor image, torch::Tensor warp) { cv::Mat image_mat(/*rows=*/image.size(0), /*cols=*/image.size(1), /*type=*/CV_32FC1, /*data=*/image.data()); cv::Mat warp_mat(/*rows=*/warp.size(0), /*cols=*/warp.size(1), /*type=*/CV_32FC1, /*data=*/warp.data()); cv::Mat output_mat; cv::warpPerspective(image_mat, output_mat, warp_mat, /*dsize=*/{8, 8}); torch::Tensor output = torch::from_blob(output_mat.ptr(), /*sizes=*/{8, 8}); return output.clone(); } 这个操作符的代码很短。在该文件的顶部，我们包括OpenCV的头文件，opencv2 / opencv.hpp，沿着torch/ script.h头部暴露从PyTorch的C ++ API所需的所有东西，我们需要编写自定义TorchScript运营商。我们的函数warp_perspective采用两个参数：输入图像和经线变换矩阵我们希望应用到图像。的类型的这些输入是torch::张量，在C PyTorch的张量类型++（其也是基础类型在Python所有张量）。我们的返回类型warp_perspective功能也将是一个Torch ::张量 [HTG31。 小费 参见本说明约ATEN，它提供了张量类PyTorch库的更多信息。此外，本教程描述了如何分配和用C初始化新张量对象++（不需要这个操作符）。 注意 所述编译器TorchScript理解的类型的固定号码。只有这些类型可以作为参数传递给您的自定义操作。目前，这些类型是：HTG0] Torch ::张量 ，Torch ::标量，双，的int64_t和的std ::矢量这些类型的第需要注意的是 只有 双和 不是 浴液HTG30]和 只有 的int64_t和 不 其他整数类型如INT，短或长的支持。 里面我们的功能，我们需要做的第一件事就是转变我们的PyTorch张量到OpenCV的矩阵，为的OpenCV的warpPerspective预计CV ::垫对象作为输入。幸运的是，有一种方法来做到这一点 而不复制任何 数据。在第几行， cv::Mat image_mat(/*rows=*/image.size(0), /*cols=*/image.size(1), /*type=*/CV_32FC1, /*data=*/image.data()); 我们呼吁此构造 OpenCV的垫类的给我们的张量转换为垫对象。我们通过它最初的图像张量，数据类型（我们定为FLOAT32为行数和列数本实施例中），最后一个原始指针到底层数据 - A 浮动*。有什么特别之处这个构造函数垫类的是，它不会复制的输入数据。相反，它会简单地引用该内存上的垫执行的所有操作。如果在image_mat进行就地操作，这将反映原始图像张量（反之亦然在）。这使我们可以调用随后OpenCV的程序与库的本地矩阵型，即使我们实际上是存储在PyTorch张量的数据。我们重复这个过程将经 PyTorch张量转换为warp_matOpenCV的矩阵： cv::Mat warp_mat(/*rows=*/warp.size(0), /*cols=*/warp.size(1), /*type=*/CV_32FC1, /*data=*/warp.data()); 接下来，我们准备调用，我们是如此渴望在TorchScript使用OpenCV的函数：warpPerspective [HTG3。为此，我们通过OpenCV的函数中的image_mat和warp_mat矩阵，以及被称为空输出矩阵output_mat 。我们还指定大小DSIZE我们要输出矩阵（图像）是。它是硬编码为8 × 8在这个例子中： cv::Mat output_mat; cv::warpPerspective(image_mat, output_mat, warp_mat, /*dsize=*/{8, 8}); 在我们的运营商定制实现的最后一步是转换的output_mat [HTG3重新站到PyTorch张量，这样我们就可以进一步PyTorch使用它。这是惊人地相似，我们先前做在其他方向转换。在这种情况下，PyTorch提供了 torch:: fromblob`方法。在这种情况下，A 一滴_ 是指一些不透明的，平坦的内存指针，我们要解释成PyTorch张量。为Torch :: from_blob调用看起来是这样的：` torch::from_blob(output_mat.ptr(), /*sizes=*/{8, 8}) 我们使用.ptr & LT ;浮子& GT ;（）上OpenCV的垫[方法HTG6]类来获得原始指针到底层数据（就像。数据& LT ;浮子& GT ;（）为PyTorch张量更早）。我们还指定张量的输出的形状，这我们硬编码为8 × 8。的输出torch:: from_blob于是为torch::张量，指向由OpenCV的基质所拥有的存储器。 从我们的运营商实现返回，这个张量之前，我们必须调用.clone（）对张进行基础数据的内存拷贝。这样做的原因是，Torch :: from_blob返回没有自己的数据的张量。在这一点上，该数据仍然由OpenCV的矩阵拥有。然而，这OpenCV的矩阵将走出去的范围，并在函数结束时被释放。如果我们返回输出张量-是，它会指向由我们使用它的功能之外的时间无效的内存。调用.clone（）返回与新张拥有自身的原始数据的副本，新的张量。因此安全回到外面的世界。 注册运营商定制与TorchScript 现在，已经在C ++中实现我们的运营商定制，我们需要 与TorchScript运行时和编译注册 它。这将允许TorchScript编译器来解决我们在TorchScript代码运营商定制引用。注册非常简单。对于我们的情况，我们需要这样写： static auto registry = torch::RegisterOperators(\"my_ops::warp_perspective\", &warp_perspective); 在某处我们的op.cpp文件的全局范围。这将创建一个全局变量注册表，这将在其构造函数注册我们的TorchScript操作（即只出现一次，每个程序）。我们指定的经营者的名称和一个指向它的实现（我们前面写的函数）。名称由两个部分组成：一个 命名空间 （my_ops），用于我们正在注册的特定运营商和一个名称（warp_perspective）。命名空间和运营商名称是由两个冒号（::）分离。 Tip 如果你想注册多个运营商，您可以链接调用.OP（）构造函数后： static auto registry = torch::RegisterOperators(\"my_ops::warp_perspective\", &warp_perspective) .op(\"my_ops::another_op\", &another_op) .op(\"my_ops::and_another_op\", &and_another_op); 在幕后，RegisterOperators将执行一些相当复杂的C ++模板元编程魔术推断函数指针的参数和返回值类型，我们把它传递（&安培; warp_perspective）。该信息被用于形成 功能架构 为我们的运营商。函数模式是运营商的结构化表示 - 一种“签名”或“原型”的 - 使用的TorchScript编译器来验证TorchScript程序的正确性。 构建自定义操作 现在，我们已经实现了我们的运营商定制的C ++及书面登记代码，它是时间来建立操作成（共享）库，我们可以在任何的Python的研究和实验加载到Python或成C ++的推理环境。存在多种方式来打造我们的运营商，使用纯CMake的，或Python的替代品如setuptools的 [HTG3。为了简便起见，下面仅段落讨论CMake的方法。本教程的附录潜入基于Python的替代品。 与CMake的构建 为了建立我们的运营商定制到一个共享库使用 CMake的构建系统，我们需要写一个简短的的CMakeLists.txt文件，并与我们以前的[放置HTG6] op.cpp 文件。对于这一点，让我们在一个目录结构，看起来像这样一致认为： warp-perspective/ op.cpp CMakeLists.txt 此外，请一定要抓住最新版本的LibTorch分布，包PyTorch的C ++库和CMake的构建文件中，在[ pytorch.org HTG1。请将解压分布在文件系统中的某个地方访问。下面的段落将参考该位置为/路径/到/ libtorch。我们的的CMakeLists.txt文件应该然后是以下内容： cmake_minimum_required(VERSION 3.1 FATAL_ERROR) project(warp_perspective) find_package(Torch REQUIRED) find_package(OpenCV REQUIRED) # Define our library target add_library(warp_perspective SHARED op.cpp) # Enable C++11 target_compile_features(warp_perspective PRIVATE cxx_range_for) # Link against LibTorch target_link_libraries(warp_perspective \"${TORCH_LIBRARIES}\") # Link against OpenCV target_link_libraries(warp_perspective opencv_core opencv_imgproc) 警告 这种设置使一些假设关于构建环境，特别是什么属于安装的OpenCV。上述的CMakeLists.txt文件被运行Ubuntu Xenial与libopencv-dev的通过[HTG9安装一个泊坞容器内测试]易于。如果它不为你工作，你觉得卡住，请使用Dockerfile中的伴随教程库建立一个隔离的，可重复的环境在其中扮演周围从本教程中的代码。如果碰上进一步的麻烦，请在本教程的库文件中的一个问题或张贴在我们的论坛的问题。 到现在建立我们的运营商，我们可以从warp_perspective文件夹中运行以下命令： $ mkdir build $ cd build $ cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch .. -- The C compiler identification is GNU 5.4.0 -- The CXX compiler identification is GNU 5.4.0 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Looking for pthread.h -- Looking for pthread.h - found -- Looking for pthread_create -- Looking for pthread_create - not found -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Found torch: /libtorch/lib/libtorch.so -- Configuring done -- Generating done -- Build files have been written to: /warp_perspective/build $ make -j Scanning dependencies of target warp_perspective [ 50%] Building CXX object CMakeFiles/warp_perspective.dir/op.cpp.o [100%] Linking CXX shared library libwarp_perspective.so [100%] Built target warp_perspective 这将放置在构建文件夹中的libwarp_perspective.so共享库文件。在上面的cmake的命令，则应更换/路径/到/ libtorch与路径解压缩后的LibTorch分布。 我们将探讨如何使用和下面进一步呼吁我们的运营商中的细节，但要获得成功的早期感觉，我们可以尝试在Python运行下面的代码： >>> import torch >>> torch.ops.load_library(\"/path/to/libwarp_perspective.so\") >>> print(torch.ops.my_ops.warp_perspective) 在这里，/path/to/libwarp_perspective.so应到libwarp_perspective.so共享库的相对或绝对路径我们只是建成。如果一切顺利的话，这应该打印像 这是Python的功能，我们将在以后使用调用我们的自定义操作。 在Python使用TorchScript运营商定制 一旦我们的运营商定制内置共享库，我们准备在我们在Python TorchScript车型使用此运算符。有两个部分，以这样的：第一加载操作到Python和第二使用TorchScript代码操作。 你已经看到了如何导入您的运营商引入Python：torch.ops.load_library（） [HTG3。此功能将路径包含运营商定制的共享库，并将其加载到当前进程。加载共享库也将执行全局RegisterOperators 对象，就放到我们的运营商定制实现文件的构造函数。这将注册我们的运营商定制与TorchScript编译器，并允许我们使用该运营商在TorchScript代码。 你可以参考你的加载运营商为torch.ops & LT []命名空间& GT ; [ - ] LT ;。函数[ - - ] GT ;，其中& LT ;命名空间& GT ;是命名空间的一部分您的操作员姓名，以及& LT ;函数& GT ;您的操作者的功能名称。对于我们上面写的操作，命名空间为my_ops和函数名warp_perspective，这意味着我们的运营商可为torch.ops.my_ops.warp_perspective。虽然这个功能可以在脚本或跟踪TorchScript模块一起使用，我们也可以只用它在香草渴望PyTorch并将其传递规律PyTorch张量： >>> import torch >>> torch.ops.load_library(\"libwarp_perspective.so\") >>> torch.ops.my_ops.warp_perspective(torch.randn(32, 32), torch.rand(3, 3)) tensor([[0.0000, 0.3218, 0.4611, ..., 0.4636, 0.4636, 0.4636], [0.3746, 0.0978, 0.5005, ..., 0.4636, 0.4636, 0.4636], [0.3245, 0.0169, 0.0000, ..., 0.4458, 0.4458, 0.4458], ..., [0.1862, 0.1862, 0.1692, ..., 0.0000, 0.0000, 0.0000], [0.1862, 0.1862, 0.1692, ..., 0.0000, 0.0000, 0.0000], [0.1862, 0.1862, 0.1692, ..., 0.0000, 0.0000, 0.0000]]) 注意 会发生什么幕后是你第一次访问torch.ops.namespace.function在Python中，TorchScript编译器（在C ++的土地）可以看到，如果一个函数命名空间::函数已经被注册，如果是这样，则返回一个Python句柄这个功能，我们可以随后使用调入从Python中我们的C ++运算符实现。这是TorchScript运营商定制和C ++扩展之间的一个显着的差异：C ++扩展结合使用pybind11手动，而TorchScript定制OPS是在由PyTorch本身飞约束。 Pybind11为您提供了更多的灵活性，以什么样的类型和类可以绑定到Python和因此建议对纯渴望代码的问候，但它不支持TorchScript欢声笑语。 从这里开始，您可以使用脚本或代码追踪您的自定义操作，就像你从Torch 等功能包。事实上，“标准库”的功能，如torch.matmul经历大致相同的注册路径作为运营商定制，这使得运营商定制真正一流的公民，当谈到如何和在那里他们可以TorchScript使用。 使用自定义操作与跟踪 让我们在跟踪功能嵌入我们的运营商开始。回想一下，跟踪，我们先从一些香草Pytorch代码： def compute(x, y, z): return x.matmul(y) + torch.relu(z) 然后在其上调用torch.jit.trace。我们进一步通过torch.jit.trace例如一些投入，它将转发给我们的实现记录为输入流过它发生的操作顺序。这样做的结果是有效的渴望PyTorch程序，其中TorchScript编译器可以进一步分析，优化和序列化的“冻结”的版本： >>> inputs = [torch.randn(4, 8), torch.randn(8, 5), torch.randn(4, 5)] >>> trace = torch.jit.trace(compute, inputs) >>> print(trace.graph) graph(%x : Float(4, 8) %y : Float(8, 5) %z : Float(4, 5)) { %3 : Float(4, 5) = aten::matmul(%x, %y) %4 : Float(4, 5) = aten::relu(%z) %5 : int = prim::Constant[value=1]() %6 : Float(4, 5) = aten::add(%3, %4, %5) return (%6); } 现在，激动人心的启示是，我们可以简单的丢弃我们的运营商定制到我们PyTorch痕迹，好像它是torch.relu或任何其他Torch函数： torch.ops.load_library(\"libwarp_perspective.so\") def compute(x, y, z): x = torch.ops.my_ops.warp_perspective(x, torch.eye(3)) return x.matmul(y) + torch.relu(z) 然后跟踪它像以前一样： >>> inputs = [torch.randn(4, 8), torch.randn(8, 5), torch.randn(8, 5)] >>> trace = torch.jit.trace(compute, inputs) >>> print(trace.graph) graph(%x.1 : Float(4, 8) %y : Float(8, 5) %z : Float(8, 5)) { %3 : int = prim::Constant[value=3]() %4 : int = prim::Constant[value=6]() %5 : int = prim::Constant[value=0]() %6 : int[] = prim::Constant[value=[0, -1]]() %7 : Float(3, 3) = aten::eye(%3, %4, %5, %6) %x : Float(8, 8) = my_ops::warp_perspective(%x.1, %7) %11 : Float(8, 5) = aten::matmul(%x, %y) %12 : Float(8, 5) = aten::relu(%z) %13 : int = prim::Constant[value=1]() %14 : Float(8, 5) = aten::add(%11, %12, %13) return (%14); } 整合TorchScript定制OPS成追溯到PyTorch代码，因为这容易！ 使用自定义操作与脚本 除了跟踪，另一种方式在PyTorch程序的TorchScript表示到达是直接写你的 TorchScript代码[HTG0。 TorchScript主要是Python语言的一个子集，有一些限制，使得它更容易为TorchScript编译器推理程序。您可以通过使用// @标注它torch.jit.script免费功能和@ torch.jit.script_method [关闭你的常规PyTorch代码到TorchScript HTG9一种用于在类方法（其也必须从torch.jit.ScriptModule派生 ）。参见[此处](https://pytorch.org/docs/master/jit.html)关于TorchScript注释的更多细节。 而不是使用跟踪TorchScript一个特别的原因是追踪无法捕捉PyTorch代码控制流。因此，让我们考虑这个功能，不使用控制流： def compute(x, y): if bool(x[0][0] == 42): z = 5 else: z = 10 return x.matmul(y) + z 从香草PyTorch到TorchScript转换这个功能，我们用将其标注为@ torch.jit.script： @torch.jit.script def compute(x, y): if bool(x[0][0] == 42): z = 5 else: z = 10 return x.matmul(y) + z 这将刚刚在时间编译计算函数成图形表示，这是我们可以在compute.graph属性检查： >>> compute.graph graph(%x : Dynamic %y : Dynamic) { %14 : int = prim::Constant[value=1]() %2 : int = prim::Constant[value=0]() %7 : int = prim::Constant[value=42]() %z.1 : int = prim::Constant[value=5]() %z.2 : int = prim::Constant[value=10]() %4 : Dynamic = aten::select(%x, %2, %2) %6 : Dynamic = aten::select(%4, %2, %2) %8 : Dynamic = aten::eq(%6, %7) %9 : bool = prim::TensorToBool(%8) %z : int = prim::If(%9) block0() { -> (%z.1) } block1() { -> (%z.2) } %13 : Dynamic = aten::matmul(%x, %y) %15 : Dynamic = aten::add(%13, %z, %14) return (%15); } 而现在，就像之前，我们可以用我们的运营商定制等我们的脚本代码中任何其他功能： torch.ops.load_library(\"libwarp_perspective.so\") @torch.jit.script def compute(x, y): if bool(x[0] == 42): z = 5 else: z = 10 x = torch.ops.my_ops.warp_perspective(x, torch.eye(3)) return x.matmul(y) + z 当TorchScript编译器看到参考torch.ops.my_ops.warp_perspective，它会找到我们通过RegisterOperators注册的实现对象在C ++中，并将其编译成其图形表示： >>> compute.graph graph(%x.1 : Dynamic %y : Dynamic) { %20 : int = prim::Constant[value=1]() %16 : int[] = prim::Constant[value=[0, -1]]() %14 : int = prim::Constant[value=6]() %2 : int = prim::Constant[value=0]() %7 : int = prim::Constant[value=42]() %z.1 : int = prim::Constant[value=5]() %z.2 : int = prim::Constant[value=10]() %13 : int = prim::Constant[value=3]() %4 : Dynamic = aten::select(%x.1, %2, %2) %6 : Dynamic = aten::select(%4, %2, %2) %8 : Dynamic = aten::eq(%6, %7) %9 : bool = prim::TensorToBool(%8) %z : int = prim::If(%9) block0() { -> (%z.1) } block1() { -> (%z.2) } %17 : Dynamic = aten::eye(%13, %14, %2, %16) %x : Dynamic = my_ops::warp_perspective(%x.1, %17) %19 : Dynamic = aten::matmul(%x, %y) %21 : Dynamic = aten::add(%19, %z, %20) return (%21); } 特别是通知所述参照my_ops :: warp_perspective在图的结尾。 Attention 所述TorchScript图表示仍然可能发生变化。不要依赖于它看起来像这样。 这就是真正的它，当它涉及到使用Python中我们的运营商定制。总之，你导入使用torch.ops.load_library包含您的运营商（S）的图书馆，并呼吁像任何其他Torch 自定义运算从您的追溯或脚本代码TorchScript操作。 在C使用自定义TorchScript算++ TorchScript的一个有用的功能是序列化模型到磁盘上的文件的能力。该文件可以通过线路被发送，存储在文件系统，或者更重要的是，动态地解串行化和执行，而无需保留原始源代码周围。这是可能在Python，而且在C ++。对于这一点，PyTorch提供[纯C ++ API HTG1用于反串行化以及执行TorchScript模型。如果你还没有，请阅读在C对加载和运行的系列化TorchScript模型教程++ ，在其未来数段将建成。 总之，运营商定制可以像从文件反序列化，即使和用C ++运行规则torch运营商来执行。这个唯一的要求就是我们前面在我们执行模型中的C ++应用程序构建运营商定制共享库链接。在Python中，这个工作只是调用torch.ops.load_library [HTG7。在C ++中，你需要的共享库，在任何的构建系统使用的是主应用程序链接。下面的例子将展示这一点使用CMake的。 Note 从技术上讲，你还可以动态加载共享库复制到运行时你的C ++应用程序中的多，我们这样做是在Python一样。在Linux上，你可以使用dlopen 做到这一点。存在着在其他平台上的等价物。 上面链接的C ++执行教程的基础上，让我们开始用最小的C ++应用程序在一个文件中，的main.cpp从我们的运营商定制不同的文件夹，即加载并执行一个序列化TorchScript模型： #include // One-stop header. #include #include int main(int argc, const char* argv[]) { if (argc != 2) { std::cerr \\n\"; return -1; } // Deserialize the ScriptModule from a file using torch::jit::load(). std::shared_ptr module = torch::jit::load(argv[1]); std::vector inputs; inputs.push_back(torch::randn({4, 8})); inputs.push_back(torch::randn({8, 5})); torch::Tensor output = module->forward(std::move(inputs)).toTensor(); std::cout 随着小的CMakeLists.txt文件： cmake_minimum_required(VERSION 3.1 FATAL_ERROR) project(example_app) find_package(Torch REQUIRED) add_executable(example_app main.cpp) target_link_libraries(example_app \"${TORCH_LIBRARIES}\") target_compile_features(example_app PRIVATE cxx_range_for) 在这一点上，我们应该能够构建应用程序： $ mkdir build $ cd build $ cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch .. -- The C compiler identification is GNU 5.4.0 -- The CXX compiler identification is GNU 5.4.0 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Looking for pthread.h -- Looking for pthread.h - found -- Looking for pthread_create -- Looking for pthread_create - not found -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Found torch: /libtorch/lib/libtorch.so -- Configuring done -- Generating done -- Build files have been written to: /example_app/build $ make -j Scanning dependencies of target example_app [ 50%] Building CXX object CMakeFiles/example_app.dir/main.cpp.o [100%] Linking CXX executable example_app [100%] Built target example_app 而没有通过模型只是还没有运行它： $ ./example_app usage: example_app 接下来，让我们序列化，我们写的脚本函数较早使用我们的自定义操作： torch.ops.load_library(\"libwarp_perspective.so\") @torch.jit.script def compute(x, y): if bool(x[0][0] == 42): z = 5 else: z = 10 x = torch.ops.my_ops.warp_perspective(x, torch.eye(3)) return x.matmul(y) + z compute.save(\"example.pt\") 最后一行将序列化脚本函数到一个名为“example.pt”文件。如果我们再通过这个序列化的模型来我们的C ++应用程序，我们可以运行它立刻： $ ./example_app example.pt terminate called after throwing an instance of 'torch::jit::script::ErrorReport' what(): Schema not found for node. File a bug report. Node: %16 : Dynamic = my_ops::warp_perspective(%0, %19) 或者可能不是。也许不是现在。当然！我们没有链接与我们的应用运营商定制库呢。现在，让我们这样做的权利，并做正确，让我们稍微更新我们的文件组织，如下所示： example_app/ CMakeLists.txt main.cpp warp_perspective/ CMakeLists.txt op.cpp 这将允许我们添加warp_perspective库CMake的目标作为我们的应用目标的子目录。顶层的CMakeLists.txt中的example_app文件夹应该是这样的： cmake_minimum_required(VERSION 3.1 FATAL_ERROR) project(example_app) find_package(Torch REQUIRED) add_subdirectory(warp_perspective) add_executable(example_app main.cpp) target_link_libraries(example_app \"${TORCH_LIBRARIES}\") target_link_libraries(example_app -Wl,--no-as-needed warp_perspective) target_compile_features(example_app PRIVATE cxx_range_for) 这个基本的CMake的配置看起来很像之前，除了我们添加warp_perspective CMake的建设作为一个子目录。一旦它的CMake的代码运行时，我们用warp_perspective共享库链接我们的example_app应用。 Attention 有嵌入在上面的例子中一个关键的细节：-Wl， - 无按需前缀到warp_perspective链接线。这是必需的，因为我们实际上不会调用在我们的应用程序代码中的warp_perspective共享库的任何功能。我们只需要在全球RegisterOperators对象的构造函数运行。麻烦的是，这混淆了连接器，并使其认为它可以只是完全跳过链接到的库。在Linux上，`轮候册， 无按需 标记强制发生的链接（注：这个标志是具体到Linux！）。还有其他的变通办法此。最简单的就是定义 _一些函数_ 在您需要从主应用程序调用操作库。这可能是作为简单的函数作废 的init（）[]在一些头，然后将其定义为空隙声明 初始化（） { } 在操作库。调用此的init（） `在主应用程序的功能将会给连接器的印象，这是值得链接到的库。不幸的是，这是我们无法控制的，我们宁可让你知道原因和简单的解决方法为这个比交给你一些不透明宏在代码噗通。 现在，因为我们现在找到Torch包在最顶层，在的CMakeLists.txt文件中的warp_perspective子目录可以缩短一个位。它应该是这样的： find_package(OpenCV REQUIRED) add_library(warp_perspective SHARED op.cpp) target_compile_features(warp_perspective PRIVATE cxx_range_for) target_link_libraries(warp_perspective PRIVATE \"${TORCH_LIBRARIES}\") target_link_libraries(warp_perspective PRIVATE opencv_core opencv_photo) 让我们重新构建我们的示例应用程序，这也将与运营商定制库链接。在顶层example_app目录： $ mkdir build $ cd build $ cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch .. -- The C compiler identification is GNU 5.4.0 -- The CXX compiler identification is GNU 5.4.0 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Looking for pthread.h -- Looking for pthread.h - found -- Looking for pthread_create -- Looking for pthread_create - not found -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Found torch: /libtorch/lib/libtorch.so -- Configuring done -- Generating done -- Build files have been written to: /warp_perspective/example_app/build $ make -j Scanning dependencies of target warp_perspective [ 25%] Building CXX object warp_perspective/CMakeFiles/warp_perspective.dir/op.cpp.o [ 50%] Linking CXX shared library libwarp_perspective.so [ 50%] Built target warp_perspective Scanning dependencies of target example_app [ 75%] Building CXX object CMakeFiles/example_app.dir/main.cpp.o [100%] Linking CXX executable example_app [100%] Built target example_app 如果我们现在运行example_app二进制，并把它我们序列化模型，我们应该在一个快乐的结局到达： $ ./example_app example.pt 11.4125 5.8262 9.5345 8.6111 12.3997 7.4683 13.5969 9.0850 11.0698 9.4008 7.4597 15.0926 12.5727 8.9319 9.0666 9.4834 11.1747 9.0162 10.9521 8.6269 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 10.0000 [ Variable[CPUFloatType]{8,5} ] 成功！您现在可以推论了。 结论 本教程走你扔了如何实现在C ++中的自定义TorchScript运营商，如何将它建设成一个共享库，如何在Python中使用它来定义TorchScript模型，最后如何将其加载到用于推断工作量C ++应用程序。您现在可以使用C ++运算符与第三方C ++库接口扩展您的TorchScript模型，编写自定义的高性能CUDA内核，或实现需要Python，TorchScript和C ++之间的界限顺利融入任何其他使用情况。 与往常一样，如果您遇到任何问题或有任何疑问，您可以使用我们的论坛或 GitHub的问题取得联系。此外，我们的常见问题（FAQ）页可能有帮助的信息。 附录A：建筑运营商定制的更多方法 “建设运营商定制”一节中介绍如何构建一个运营商定制成使用CMake的共享库。本附录概述了编译另外两个方法。他们都使用Python作为“驾驶员”或“接口”的编译过程。此外，两个重复使用现有的基础设施 PyTorch提供 C ++扩展 ，它们是香草（渴望）PyTorch等效TorchScript运营商定制的依赖于 pybind11 为选自C的函数“明确的”结合++成Python。 第一种方法使用C ++的扩展方便刚刚在实时（JIT）编译接口编译代码在你PyTorch脚本的后台运行它的第一次。第二种方法依赖于古老setuptools的包和涉及编写单独的setup.py文件。这允许更高级的配置以及整合与其他setuptools的为基础的项目。我们将探讨在下面详细两种方法。 与JIT编译馆 由PyTorch C ++扩展工具包中提供的JIT编译特征允许嵌入自定义操作的汇编直接进入Python代码，例如在你的训练脚本的顶部。 Note “JIT编译”这里没有什么做的JIT编译发生在TorchScript编译器优化你的程序。它只是意味着你的运营商定制的C ++代码将一个文件夹在你的系统的 / tmp目录目录下的第一次导入它，就好像你自己事先编编就。 这JIT编译功能有两种形式。在第一个，你还是留着你的运营商实现在一个单独的文件（op.cpp），然后用torch.utils.cpp_extension.load（）编译你的扩展。通常情况下，这个函数将返回Python模块暴露你的C ++的扩展。然而，由于我们没有编制我们的运营商定制到自己的Python模块，我们只是编译一个普通的共享库。幸运的是，torch.utils.cpp_extension.load（）有一个参数is_python_module，我们可以设置为假表明，我们只建立一个共享库，而不是一个Python模块感兴趣。 torch.utils.cpp_extension.load（）将然后编译和共享库也加载到当前进程，就象torch.ops.load_library以前那样： import torch.utils.cpp_extension torch.utils.cpp_extension.load( name=\"warp_perspective\", sources=[\"op.cpp\"], extra_ldflags=[\"-lopencv_core\", \"-lopencv_imgproc\"], is_python_module=False, verbose=True ) print(torch.ops.my_ops.warp_perspective) 这应该大约打印： JIT编译的第二香味可以让你通过源代码为您定制TorchScript运营商作为一个字符串。对于这一点，使用torch.utils.cpp_extension.load_inline： import torch import torch.utils.cpp_extension op_source = \"\"\" #include #include torch::Tensor warp_perspective(torch::Tensor image, torch::Tensor warp) { cv::Mat image_mat(/*rows=*/image.size(0), /*cols=*/image.size(1), /*type=*/CV_32FC1, /*data=*/image.data()); cv::Mat warp_mat(/*rows=*/warp.size(0), /*cols=*/warp.size(1), /*type=*/CV_32FC1, /*data=*/warp.data()); cv::Mat output_mat; cv::warpPerspective(image_mat, output_mat, warp_mat, /*dsize=*/{64, 64}); torch::Tensor output = torch::from_blob(output_mat.ptr(), /*sizes=*/{64, 64}); return output.clone(); } static auto registry = torch::RegisterOperators(\"my_ops::warp_perspective\", &warp_perspective); \"\"\" torch.utils.cpp_extension.load_inline( name=\"warp_perspective\", cpp_sources=op_source, extra_ldflags=[\"-lopencv_core\", \"-lopencv_imgproc\"], is_python_module=False, verbose=True, ) print(torch.ops.my_ops.warp_perspective) 当然，最好的做法是只使用torch.utils.cpp_extension.load_inline如果你的源代码是相当短的。 请注意，如果你在一个Jupyter笔记本电脑用这个，你不应该因为每次执行注册一个新的图书馆，并重新注册运营商定制执行与登记多次的细胞。如果您需要重新执行它，请事先重新启动笔记本的Python的内核。 与setuptools的构建 专门从Python的建设我们的运营商定制的第二种方法是使用setuptools的 [HTG3。这具有setuptools的 具有用于建筑用C ++编写Python模块一个相当强大的和广泛的接口的优点。然而，由于setuptools的 真的打算用于建筑Python模块和非纯共享库（不具有必要的入口点Python从一个模块期望），这条路线可以稍微古怪。这就是说，你需要的是到位的，看起来像这样的 的CMakeLists.txtAsetup.py文件： from setuptools import setup from torch.utils.cpp_extension import BuildExtension, CppExtension setup( name=\"warp_perspective\", ext_modules=[ CppExtension( \"warp_perspective\", [\"example_app/warp_perspective/op.cpp\"], libraries=[\"opencv_core\", \"opencv_imgproc\"], ) ], cmdclass={\"build_ext\": BuildExtension.with_options(no_python_abi_suffix=True)}, ) 请注意，我们启用了no_python_abi_suffix中的BuildExtension在底部的选项。这指示setuptools的省略任何的Python-3特异性ABI后缀在所产生的共享库的名称。否则，关于Python 3.7例如，库可以被称为warp_perspective.cpython-37m-x86_64-linux-gnu.so其中CPython的-37M-x86_64的-linux-GNU是ABI标签，但我们真的只是希望它被称为warp_perspective.so 如果我们现在运行巨蟒 setup.py 建 从文件夹内发展在终端中setup.py坐落，我们应该看到： $ python setup.py build develop running build running build_ext building 'warp_perspective' extension creating build creating build/temp.linux-x86_64-3.7 gcc -pthread -B /root/local/miniconda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include -I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include/torch/csrc/api/include -I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include/TH -I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include/THC -I/root/local/miniconda/include/python3.7m -c op.cpp -o build/temp.linux-x86_64-3.7/op.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=warp_perspective -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11 cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++ creating build/lib.linux-x86_64-3.7 g++ -pthread -shared -B /root/local/miniconda/compiler_compat -L/root/local/miniconda/lib -Wl,-rpath=/root/local/miniconda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/op.o -lopencv_core -lopencv_imgproc -o build/lib.linux-x86_64-3.7/warp_perspective.so running develop running egg_info creating warp_perspective.egg-info writing warp_perspective.egg-info/PKG-INFO writing dependency_links to warp_perspective.egg-info/dependency_links.txt writing top-level names to warp_perspective.egg-info/top_level.txt writing manifest file 'warp_perspective.egg-info/SOURCES.txt' reading manifest file 'warp_perspective.egg-info/SOURCES.txt' writing manifest file 'warp_perspective.egg-info/SOURCES.txt' running build_ext copying build/lib.linux-x86_64-3.7/warp_perspective.so -> Creating /root/local/miniconda/lib/python3.7/site-packages/warp-perspective.egg-link (link to .) Adding warp-perspective 0.0.0 to easy-install.pth file Installed /warp_perspective Processing dependencies for warp-perspective==0.0.0 Finished processing dependencies for warp-perspective==0.0.0 这将产生所谓的共享库warp_perspective.so，其中我们可以通过torch.ops.load_library 正如我们前面所做为让我们的运营商看到TorchScript： >>> import torch >>> torch.ops.load_library(\"warp_perspective.so\") >>> print(torch.ops.custom.warp_perspective) Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 使用自定义C ++扩展算TorchScript 用C实现运营商定制++ 与TorchScript注册自定义操作 构建自定义操作 与CMake的构建 在Python使用TorchScript运营商定制 使用运营商定制与跟踪 使用运营商定制与脚本 在C使用自定义TorchScript算++ 结论 [HTG0附录A：建筑运营商定制的更多方法 与JIT编译馆 与setuptools的构建 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"advanced/numpy_extensions_tutorial.html":{"url":"advanced/numpy_extensions_tutorial.html","title":"创建扩展使用numpy的和SciPy的","keywords":"","body":"创建扩展使用numpy的和SciPy的 作者 ：亚当Paszke 由 更新：亚当Dziedzic的 在本教程中，我们将通过两个任务去： 创建不带参数的神经网络层。 * 该调用到 **numpy的的** 作为其实现的一部分 创建具有可学习的权重神经网络层 * 该调用到 **SciPy的的** 作为其实现的一部分 import torch from torch.autograd import Function 无参数的例子 这层不特别做任何有用的或数学上是正确的。 它恰当地命名为BadFFTFunction 层实现 from numpy.fft import rfft2, irfft2 class BadFFTFunction(Function): @staticmethod def forward(ctx, input): numpy_input = input.detach().numpy() result = abs(rfft2(numpy_input)) return input.new(result) @staticmethod def backward(ctx, grad_output): numpy_go = grad_output.numpy() result = irfft2(numpy_go) return grad_output.new(result) # since this layer does not have any parameters, we can # simply declare this as a function, rather than as an nn.Module class def incorrect_fft(input): return BadFFTFunction.apply(input) 所创建的层的实例： input = torch.randn(8, 8, requires_grad=True) result = incorrect_fft(input) print(result) result.backward(torch.randn(result.size())) print(input) 日期： tensor([[ 7.4515, 2.2547, 7.6126, 2.8310, 13.8079], [12.0822, 6.2765, 3.5208, 2.2051, 3.7491], [ 5.7192, 4.8086, 4.7709, 17.7730, 0.6329], [ 9.4613, 4.3585, 4.1035, 8.0416, 5.4456], [16.4615, 2.8314, 8.1768, 5.0839, 9.6213], [ 9.4613, 12.6283, 3.2765, 4.8069, 5.4456], [ 5.7192, 4.9651, 18.9993, 9.2646, 0.6329], [12.0822, 3.0731, 3.7945, 12.1748, 3.7491]], grad_fn=) tensor([[ 0.1924, 0.7354, -0.0498, -1.2294, -0.2937, -0.1854, -0.8866, -0.5025], [-0.4862, -0.2749, 0.7363, -0.3230, 0.6703, 0.2308, 0.5687, -2.1133], [ 0.0432, -0.5409, -0.7979, 1.3634, -1.1702, 0.0747, 1.5215, 0.0555], [ 1.6646, -0.2177, -0.4921, -0.7097, 0.5300, -1.3457, -1.1927, 0.3836], [-0.5561, 2.3293, 0.5014, -1.0231, 2.8309, 1.1796, 1.1218, 0.8208], [-0.3520, 0.4791, -1.3561, -2.2878, 0.6373, -0.6391, -0.0277, -0.5974], [ 0.5807, -2.2914, 0.9253, 0.8924, -0.7267, 0.5135, 0.0629, -0.9859], [-0.1888, -1.5387, -0.2399, -1.1361, 0.7858, -1.0179, -1.3784, -0.7279]], requires_grad=True) 参数化示例 在深学习文献中，这个层被混淆的被称为卷积而实际操作是互相关（唯一的区别是，过滤器被翻转为卷积，这对于互相关的情况下）。 与可学习权重，其中，互相关具有过滤器（内核）表示权重的层的实施方式。 向后过程计算的梯度WRT输入和梯度WRT过滤器。 from numpy import flip import numpy as np from scipy.signal import convolve2d, correlate2d from torch.nn.modules.module import Module from torch.nn.parameter import Parameter class ScipyConv2dFunction(Function): @staticmethod def forward(ctx, input, filter, bias): # detach so we can cast to NumPy input, filter, bias = input.detach(), filter.detach(), bias.detach() result = correlate2d(input.numpy(), filter.numpy(), mode='valid') result += bias.numpy() ctx.save_for_backward(input, filter, bias) return torch.as_tensor(result, dtype=input.dtype) @staticmethod def backward(ctx, grad_output): grad_output = grad_output.detach() input, filter, bias = ctx.saved_tensors grad_output = grad_output.numpy() grad_bias = np.sum(grad_output, keepdims=True) grad_input = convolve2d(grad_output, filter.numpy(), mode='full') # the previous line can be expressed equivalently as: # grad_input = correlate2d(grad_output, flip(flip(filter.numpy(), axis=0), axis=1), mode='full') grad_filter = correlate2d(input.numpy(), grad_output, mode='valid') return torch.from_numpy(grad_input), torch.from_numpy(grad_filter).to(torch.float), torch.from_numpy(grad_bias).to(torch.float) class ScipyConv2d(Module): def __init__(self, filter_width, filter_height): super(ScipyConv2d, self).__init__() self.filter = Parameter(torch.randn(filter_width, filter_height)) self.bias = Parameter(torch.randn(1, 1)) def forward(self, input): return ScipyConv2dFunction.apply(input, self.filter, self.bias) 实例： module = ScipyConv2d(3, 3) print(\"Filter and bias: \", list(module.parameters())) input = torch.randn(10, 10, requires_grad=True) output = module(input) print(\"Output from the convolution: \", output) output.backward(torch.randn(8, 8)) print(\"Gradient for the input map: \", input.grad) Out: Filter and bias: [Parameter containing: tensor([[ 1.7061, -0.1771, 0.6047], [-0.5862, 1.0628, -0.3486], [ 0.0778, 1.0832, -0.4671]], requires_grad=True), Parameter containing: tensor([[-0.0718]], requires_grad=True)] Output from the convolution: tensor([[ 0.2062, 1.9303, -0.7497, 0.4171, 1.5641, -5.1289, -2.3736, 3.7649], [ 2.7773, -2.5988, 2.9943, -0.3176, 0.8576, -4.0404, 3.2371, -1.6735], [ 2.7032, 2.0101, -1.6930, 5.7152, -2.3599, -1.3598, -0.9169, -0.9801], [ 2.2197, 0.6012, 1.2883, -0.9301, -1.2504, -3.7107, -3.8789, 1.2738], [-0.1329, 3.8820, -2.1698, 2.1074, 1.1566, 1.0722, -1.4080, -0.8036], [ 3.1168, 1.6253, 1.7778, 1.0007, -3.1746, -2.1811, -1.5891, -1.8327], [ 0.6647, -2.6461, 1.3050, -4.5868, 3.2904, -0.8035, -1.3580, 0.2333], [ 4.1536, 5.0878, -2.0750, 0.8895, 1.0726, -0.7173, 4.1948, -1.1099]], grad_fn=) Gradient for the input map: tensor([[-5.1065e+00, -4.0534e-01, -3.3325e+00, -1.2726e+00, 2.4771e+00, -3.2429e+00, -1.5069e+00, 1.5726e+00, -1.2231e+00, 7.7367e-01], [ 1.9218e+00, -5.0568e+00, 1.2643e-02, -2.6672e+00, 1.5748e+00, 2.0034e+00, -2.7221e+00, -2.6116e+00, 1.0872e+00, -7.6352e-01], [ 2.1668e-01, -1.8442e+00, -1.9986e+00, -2.6523e+00, -1.9327e+00, 5.6665e+00, -3.1624e+00, -2.5519e+00, 1.9742e+00, -7.9616e-01], [-9.4981e-01, 2.1246e-02, -2.6692e+00, -2.6164e+00, -1.2055e+00, 2.8694e+00, 9.6858e-01, -2.8408e+00, -1.8077e-01, 1.2826e-01], [-2.0616e+00, -1.2810e+00, 2.4630e+00, -1.6501e+00, 1.6563e+00, 2.8737e+00, 1.8403e+00, 1.4945e-01, -1.4603e+00, 6.9704e-01], [ 4.0963e+00, -3.5031e-01, -2.8858e+00, -7.2992e-01, -3.5853e+00, 7.3722e-01, -2.0150e+00, -1.2854e+00, -1.0418e+00, 1.9080e-01], [-1.1950e+00, -6.5445e-01, -1.3459e+00, -4.7732e-01, -1.3988e+00, 1.9046e+00, -8.2274e-01, 4.5361e-01, 7.6111e-01, 6.7929e-01], [ 1.6332e-01, 5.5551e+00, 2.6393e+00, -1.8013e+00, 1.0392e+00, 2.8623e+00, -1.1749e-01, -2.0843e+00, 2.6226e+00, -8.2416e-01], [-7.9535e-03, -1.0495e+00, 4.9276e-01, -6.3320e-01, -2.2379e-01, -1.2710e+00, 2.2692e+00, -5.2379e-01, 1.1417e+00, -5.0747e-01], [ 1.3845e-03, 1.6173e-01, 2.0946e+00, 8.4693e-01, -2.9453e-01, 2.0683e-01, 2.0648e+00, -7.6050e-01, -5.9649e-01, 2.1951e-01]]) 检查梯度： from torch.autograd.gradcheck import gradcheck moduleConv = ScipyConv2d(3, 3) input = [torch.randn(20, 20, dtype=torch.double, requires_grad=True)] test = gradcheck(moduleConv, input, eps=1e-6, atol=1e-4) print(\"Are the gradients correct: \", test) Out: Are the gradients correct: True 脚本的总运行时间： （0分钟3.843秒） Download Python source code: numpy_extensions_tutorial.py Download Jupyter notebook: numpy_extensions_tutorial.ipynb 通过斯芬克斯-廊产生廊 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 创建扩展使用numpy的和SciPy的 参数少示例 参数化的实例 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"advanced/cpp_extension.html":{"url":"advanced/cpp_extension.html","title":"自定义 C++ 和CUDA扩展","keywords":"","body":"定制C ++和CUDA扩展 作者 ：彼得戈尔兹伯勒 PyTorch提供相关的神经网络，任意张量代数，数据扯皮和其他用途的操作过多。但是，你还是会发现自己需要一个更个性化的操作。例如，你可能想使用你发现了一种新的激活功能纸，或者实现你开发了一个操作你的研究的一部分。 在PyTorch整合这样的自定义动作的最简单的方法是通过延长函数和模块所概述[HTG8将它写在Python ]此处[HTG9。这使您可以自动分化的全功率（备件从编写导函数）以及Python的通常的表现。然而，有时可能当你的操作是更好的用C ++实现。例如，你的代码可能需要 真的 快，因为它被称为非常频繁的模型或者甚至几个电话非常昂贵。另一个可行的原因是，它依赖于或与其它的C或C ++库交互。为了解决这样的情况下，提供PyTorch编写自定义 C ++扩展 的一个非常简单的方法。 C ++扩展是我们已经开发以允许用户（你）来创建PyTorch运营商定义的 外的源 ，即，从PyTorch后端分离的机构。这种方法 从本地PyTorch业务的实现方式不同[HTG3。 C ++扩展旨在免去你多用，同时为您提供为基于PyTorch项目具有高度的灵活性集成的操作与PyTorch的后端相关的样板。然而，一旦你已经确定你的操作为C ++的扩展，把它变成一个本地PyTorch功能主要是组织代码，你可以在事后，如果你决定上游有助于您的操作解决的问题。 动机和实施例 本说明的其余部分将通过编写和使用C ++（和CUDA）延伸的一个实际的例子行走。如果你正在追逐或有人会解雇你，如果你没有得到运到这天结束时完成，你可以跳过这一节，并直奔下一节的实施细节。 比方说，你已经来到了一个新的重复单元的，你发现有比现有技术的优异性能。此重复单元是类似于LSTM，但不同之处在于它缺乏一个 忘记门 ，并使用 指数线性单位 （ELU）作为其内部的激活功能。由于本机永远不会忘记，我们把它叫做 LLTM 或 长，长期内存 单元。 其中LLTMs香草LSTMs不同的两种方式是不够显著，我们不能配置PyTorch的LSTMCell我们的目的，所以我们必须创建一个自定义单元格。在所有情况下的第一步，并有可能 - - 这样做的第一个和最简单的方法是使用Python平原PyTorch来实现我们所期望的功能。对于这一点，我们需要继承torch.nn.Module和实施LLTM的直传。这将是这个样子： class LLTM(torch.nn.Module): def __init__(self, input_features, state_size): super(LLTM, self).__init__() self.input_features = input_features self.state_size = state_size # 3 * state_size for input gate, output gate and candidate cell gate. # input_features + state_size because we will multiply with [input, h]. self.weights = torch.nn.Parameter( torch.empty(3 * state_size, input_features + state_size)) self.bias = torch.nn.Parameter(torch.empty(3 * state_size)) self.reset_parameters() def reset_parameters(self): stdv = 1.0 / math.sqrt(self.state_size) for weight in self.parameters(): weight.data.uniform_(-stdv, +stdv) def forward(self, input, state): old_h, old_cell = state X = torch.cat([old_h, input], dim=1) # Compute the input, output and candidate cell gates with one MM. gate_weights = F.linear(X, self.weights, self.bias) # Split the combined gate weight matrix into its components. gates = gate_weights.chunk(3, dim=1) input_gate = torch.sigmoid(gates[0]) output_gate = torch.sigmoid(gates[1]) # Here we use an ELU instead of the usual tanh. candidate_cell = F.elu(gates[2]) # Compute the new cell state. new_cell = old_cell + candidate_cell * input_gate # Compute the new hidden state and output. new_h = torch.tanh(new_cell) * output_gate return new_h, new_cell 然后我们可以使用如预期： import torch X = torch.randn(batch_size, input_features) h = torch.randn(batch_size, state_size) C = torch.randn(batch_size, state_size) rnn = LLTM(input_features, state_size) new_h, new_C = rnn(X, (h, C)) 当然，如果在所有可能的和合理的，你应该用这种方式来延长PyTorch。由于PyTorch已高度优化其操作的实现的用于CPU 和 GPU，搭载库如 NVIDIA cuDNN ，英特尔MKL 或 NNPACK 像上面PyTorch代码往往是速度不够快。但是，我们也可以看到，为什么在某些情况下，有余地进一步的性能提升。最明显的原因是，PyTorch没有了 算法 你正在实施的知识。它知道只有你用它来撰写你的算法个人操作。因此，PyTorch必须单独执行你的操作，一前一后。由于一个操作的实现（或 内核 ），这可能涉及推出了CUDA核心的每一个人打电话，有一定的开销，这种开销可能会成为跨越许多函数调用显著。此外，运行我们的代码Python解释器本身可以放慢我们的节目。 因此超速东西一个明确的方法是重写份C ++（或CUDA）和 熔丝操作的 特定的基团。熔化装置的许多功能的实现合并成一个单一的功能，其利润较少的内核启动，以及我们可以用数据的全球流动的知名度提高进行其他优化。 让我们来看看如何使用C ++的扩展来实现 融合 的LLTM的版本。我们将通过在普通的C ++写它开始，使用 ATEN 库，权力多大PyTorch的后端，看看它是如何让我们很容易把我们的Python代码。随后，我们将移动模型的部分CUDA内核从大规模并行GPU的提供有利于更加快速度。 写一个C ++扩展 C ++的扩展有两种形式：他们可以“提前”与setuptools的，或“即时”通过torch.utils.cpp_extension建。负载（）。我们将与第一种方法开始，再讨论后者。 以建设setuptools的 对于“提前”的味道，我们建立我们的C ++写一个使用setuptools的编译我们的C ++代码setup.py脚本扩展。对于LLTM，它看起来像这样简单： from setuptools import setup, Extension from torch.utils import cpp_extension setup(name='lltm_cpp', ext_modules=[cpp_extension.CppExtension('lltm_cpp', ['lltm.cpp'])], cmdclass={'build_ext': cpp_extension.BuildExtension}) 在该代码中，CppExtension是一个方便的包装周围setuptools.Extension认为传递正确的包含路径，并设置扩展的语言于C ++。等效香草setuptools的代码将仅仅是： Extension( name='lltm_cpp', sources=['lltm.cpp'], include_dirs=cpp_extension.include_paths(), language='c++') BuildExtension执行许多所需的配置步骤和检查，并还管理混合汇编在混合的C ++ / CUDA扩展的情况下。而这一切，我们真正需要知道的关于建立C ++的扩展，现在！现在让我们来看看我们的C ++的扩展，它进入lltm.cpp的实施。 写入C ++作业 让我们开始实现C ++中的LLTM！我们需要为后向通行功能之一是乙状结肠的衍生物。这是一个足够小的一段代码，讨论编写C ++扩展时，提供给我们的整体环境： #include #include torch::Tensor d_sigmoid(torch::Tensor z) { auto s = torch::sigmoid(z); return (1 - s) * s; } & LT ;torch/ extension.h & GT ;是一站式头部以包括所有必要的PyTorch位写C ++的扩展。这包括： 该ATEN库，它是我们的张量计算主要的API， pybind11 ，这是我们如何创造我们的C ++代码的Python绑定， 该管理ATEN和pybind11相互作用的细节头。 d_sigmoid的执行（）示出了如何使用阿坦API。 PyTorch的张量和可变接口从ATEN库自动生成的，所以我们可以1或多或少地把我们的Python实现：1到C ++。我们对所有的计算主要数据类型将是Torch ::张量 [HTG7。它的完整的API可以检查[此处[HTG9。还要注意的是，我们可以包括& LT ;的iostream & GT ;或 _任何其他C或C ++头_ - 我们的C ++ 11的全部力量在我们的处置。](https://pytorch.org/cppdocs/api/classat_1_1_tensor.html) 直传 接下来，我们可以端口我们整个直传到C ++： #include std::vector lltm_forward( torch::Tensor input, torch::Tensor weights, torch::Tensor bias, torch::Tensor old_h, torch::Tensor old_cell) { auto X = torch::cat({old_h, input}, /*dim=*/1); auto gate_weights = torch::addmm(bias, X, weights.transpose(0, 1)); auto gates = gate_weights.chunk(3, /*dim=*/1); auto input_gate = torch::sigmoid(gates[0]); auto output_gate = torch::sigmoid(gates[1]); auto candidate_cell = torch::elu(gates[2], /*alpha=*/1.0); auto new_cell = old_cell + candidate_cell * input_gate; auto new_h = torch::tanh(new_cell) * output_gate; return {new_h, new_cell, input_gate, output_gate, candidate_cell, X, gate_weights}; } 倒推 C ++的扩展API目前不提供自动生成一个向后的功能为我们的方式。因此，我们也必须实现我们的LLTM，其计算损失的衍生物相对于直传的每个输入端的复路。最终，我们将扑通正向和反向功能为torch.autograd.Function创建一个不错的Python绑定。落后的功能是稍微有点复杂，所以我们将不会深入挖掘代码（如果你有兴趣，亚历克斯·格雷夫斯论文是这方面的更多信息，很好看的）： // tanh'(z) = 1 - tanh^2(z) torch::Tensor d_tanh(torch::Tensor z) { return 1 - z.tanh().pow(2); } // elu'(z) = relu'(z) + { alpha * exp(z) if (alpha * (exp(z) - 1)) 0).type_as(z) + mask.type_as(z) * (alpha * e); } std::vector lltm_backward( torch::Tensor grad_h, torch::Tensor grad_cell, torch::Tensor new_cell, torch::Tensor input_gate, torch::Tensor output_gate, torch::Tensor candidate_cell, torch::Tensor X, torch::Tensor gate_weights, torch::Tensor weights) { auto d_output_gate = torch::tanh(new_cell) * grad_h; auto d_tanh_new_cell = output_gate * grad_h; auto d_new_cell = d_tanh(new_cell) * d_tanh_new_cell + grad_cell; auto d_old_cell = d_new_cell; auto d_candidate_cell = input_gate * d_new_cell; auto d_input_gate = candidate_cell * d_new_cell; auto gates = gate_weights.chunk(3, /*dim=*/1); d_input_gate *= d_sigmoid(gates[0]); d_output_gate *= d_sigmoid(gates[1]); d_candidate_cell *= d_elu(gates[2]); auto d_gates = torch::cat({d_input_gate, d_output_gate, d_candidate_cell}, /*dim=*/1); auto d_weights = d_gates.t().mm(X); auto d_bias = d_gates.sum(/*dim=*/0, /*keepdim=*/true); auto d_X = d_gates.mm(weights); const auto state_size = grad_h.size(1); auto d_old_h = d_X.slice(/*dim=*/1, 0, state_size); auto d_input = d_X.slice(/*dim=*/1, state_size); return {d_old_h, d_input, d_weights, d_bias, d_old_cell}; } 结合到Python 一旦你用C语言编写你的操作++和ATEN，您可以使用pybind11绑定你的C ++函数或类成Python以非常简单的方式。您有任何关于PyTorch C ++的扩展，这部分疑问或问题将在很大程度上被 pybind11文献解决。 对于我们的扩展，必要的绑定代码仅仅跨越四行： PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) { m.def(\"forward\", &lltm_forward, \"LLTM forward\"); m.def(\"backward\", &lltm_backward, \"LLTM backward\"); } 一位这里需要注意的是宏TORCH_EXTENSION_NAME [HTG3。Torch 扩展构建将其定义为名字会在setup.py 脚本您的分机。在这种情况下，的值TORCH_EXTENSION_NAME将是“lltm”。这是为了避免必须在两个地方维护扩展（构建脚本和C ++代码）的名称，因为这两个之间的不匹配会导致讨厌的，难以跟踪的问题。 利用分机 我们现在设置为导入我们在PyTorch扩展。在这一点上，你的目录结构可能会是这个样子： pytorch/ lltm-extension/ lltm.cpp setup.py 现在，运行巨蟒 setup.py 安装构建和安装你的扩展。这应该是这个样子： running install running bdist_egg running egg_info creating lltm_cpp.egg-info writing lltm_cpp.egg-info/PKG-INFO writing dependency_links to lltm_cpp.egg-info/dependency_links.txt writing top-level names to lltm_cpp.egg-info/top_level.txt writing manifest file 'lltm_cpp.egg-info/SOURCES.txt' reading manifest file 'lltm_cpp.egg-info/SOURCES.txt' writing manifest file 'lltm_cpp.egg-info/SOURCES.txt' installing library code to build/bdist.linux-x86_64/egg running install_lib running build_ext building 'lltm_cpp' extension creating build creating build/temp.linux-x86_64-3.7 gcc -pthread -B ~/local/miniconda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I~/local/miniconda/lib/python3.7/site-packages/torch/include -I~/local/miniconda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I~/local/miniconda/lib/python3.7/site-packages/torch/include/TH -I~/local/miniconda/lib/python3.7/site-packages/torch/include/THC -I~/local/miniconda/include/python3.7m -c lltm.cpp -o build/temp.linux-x86_64-3.7/lltm.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=lltm_cpp -D_GLIBCXX_USE_CXX11_ABI=1 -std=c++11 cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++ creating build/lib.linux-x86_64-3.7 g++ -pthread -shared -B ~/local/miniconda/compiler_compat -L~/local/miniconda/lib -Wl,-rpath=~/local/miniconda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/lltm.o -o build/lib.linux-x86_64-3.7/lltm_cpp.cpython-37m-x86_64-linux-gnu.so creating build/bdist.linux-x86_64 creating build/bdist.linux-x86_64/egg copying build/lib.linux-x86_64-3.7/lltm_cpp.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg creating stub loader for lltm_cpp.cpython-37m-x86_64-linux-gnu.so byte-compiling build/bdist.linux-x86_64/egg/lltm_cpp.py to lltm_cpp.cpython-37.pyc creating build/bdist.linux-x86_64/egg/EGG-INFO copying lltm_cpp.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO copying lltm_cpp.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO copying lltm_cpp.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO copying lltm_cpp.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt zip_safe flag not set; analyzing archive contents... __pycache__.lltm_cpp.cpython-37: module references __file__ creating 'dist/lltm_cpp-0.0.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it removing 'build/bdist.linux-x86_64/egg' (and everything under it) Processing lltm_cpp-0.0.0-py3.7-linux-x86_64.egg removing '~/local/miniconda/lib/python3.7/site-packages/lltm_cpp-0.0.0-py3.7-linux-x86_64.egg' (and everything under it) creating ~/local/miniconda/lib/python3.7/site-packages/lltm_cpp-0.0.0-py3.7-linux-x86_64.egg Extracting lltm_cpp-0.0.0-py3.7-linux-x86_64.egg to ~/local/miniconda/lib/python3.7/site-packages lltm-cpp 0.0.0 is already the active version in easy-install.pth Installed ~/local/miniconda/lib/python3.7/site-packages/lltm_cpp-0.0.0-py3.7-linux-x86_64.egg Processing dependencies for lltm-cpp==0.0.0 Finished processing dependencies for lltm-cpp==0.0.0 对编译器的小记：由于ABI版本问题，编译器用于构建你的C ++扩展名必须是 ABI兼容 与编译器PyTorch与建造。在实践中，这意味着你必须使用GCC 4.9版及以上的Linux操作系统。为Ubuntu 16.04和其他更近期的Linux发行版，这应该是默认的编译器了。在MacOS上，您必须使用铛（其中没有任何ABI版本问题）。在最坏的情况下，你可以从你的编译器源代码编译PyTorch，然后建立与相同的编译器扩展。 一旦你的扩展构建，你可以简单地将其导入在Python中，使用您在setup.py脚本中指定的名称。只是一定要进口 Torch第一，因为这将解决一些符号动态链接程序必须看到： In [1]: import torch In [2]: import lltm_cpp In [3]: lltm_cpp.forward Out[3]: 如果我们调用帮助（）在功能或模块，我们可以看到，其签名符合我们的C ++代码： In[4] help(lltm_cpp.forward) forward(...) method of builtins.PyCapsule instance forward(arg0: torch::Tensor, arg1: torch::Tensor, arg2: torch::Tensor, arg3: torch::Tensor, arg4: torch::Tensor) -> List[torch::Tensor] LLTM forward 由于我们现在能够从Python中调用我们的C ++函数，我们可以用他们包裹 torch.autograd.Function和torch.nn.Module让他们PyTorch的一等公民： import math import torch # Our module! import lltm_cpp class LLTMFunction(torch.autograd.Function): @staticmethod def forward(ctx, input, weights, bias, old_h, old_cell): outputs = lltm_cpp.forward(input, weights, bias, old_h, old_cell) new_h, new_cell = outputs[:2] variables = outputs[1:] + [weights] ctx.save_for_backward(*variables) return new_h, new_cell @staticmethod def backward(ctx, grad_h, grad_cell): outputs = lltm_cpp.backward( grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_variables) d_old_h, d_input, d_weights, d_bias, d_old_cell = outputs return d_input, d_weights, d_bias, d_old_h, d_old_cell class LLTM(torch.nn.Module): def __init__(self, input_features, state_size): super(LLTM, self).__init__() self.input_features = input_features self.state_size = state_size self.weights = torch.nn.Parameter( torch.empty(3 * state_size, input_features + state_size)) self.bias = torch.nn.Parameter(torch.empty(3 * state_size)) self.reset_parameters() def reset_parameters(self): stdv = 1.0 / math.sqrt(self.state_size) for weight in self.parameters(): weight.data.uniform_(-stdv, +stdv) def forward(self, input, state): return LLTMFunction.apply(input, self.weights, self.bias, *state) 性能比较 现在我们已经能够使用和调用我们的C ++从PyTorch代码，我们可以运行一个小的基准测试，看看我们有多少的性能从此改写了我们的运算在C ++中获得的。我们将运行LLTM向前和向后几次，测量时间： import time import torch batch_size = 16 input_features = 32 state_size = 128 X = torch.randn(batch_size, input_features) h = torch.randn(batch_size, state_size) C = torch.randn(batch_size, state_size) rnn = LLTM(input_features, state_size) forward = 0 backward = 0 for _ in range(100000): start = time.time() new_h, new_C = rnn(X, (h, C)) forward += time.time() - start start = time.time() (new_h.sum() + new_C.sum()).backward() backward += time.time() - start print('Forward: {:.3f} us | Backward {:.3f} us'.format(forward * 1e6/1e5, backward * 1e6/1e5)) 如果我们运行这段代码与我们在纯Python这个帖子的开头写的最原始LLTM，我们可以得到下面的数字（我的机器上）： Forward: 506.480 us | Backward 444.694 us 并与我们的新的C ++版本： Forward: 349.335 us | Backward 443.523 us 我们已经可以看到的转发功能（30％以上），一个显著加速。对于落后的功能的加速是可见的，虽然不是主要的一个。复路我上面写的不是特别的优化，肯定可以得到改善。此外，PyTorch的自动分化引擎可以自动并行计算图形，可以使用操作更有效的流动从整体来看，在C ++中也实现的，所以它的预期要快。然而，这是一个良好的开端。 对GPU设备的性能 关于PyTorch的 ATEN 后端一个美妙的事实是，它抽象您正在运行的计算设备。这意味着可以 也 运行在GPU我们为CPU写相同的代码，并单独行动将相应地分派给GPU优化的实现。对于像矩阵乘法的某些操作（例如毫米或addmm），这是一个大的胜利。让我们来看看我们是多么的性能随CUDA张量运行我们的C ++代码获得。没有改变我们的实现是必需的，我们只需要简单地把我们的张量从Python的GPU内存，搭配要么加入设备= cuda_device参数在创建时或使用。要（cuda_device） [HTG19创建后]： import torch assert torch.cuda.is_available() cuda_device = torch.device(\"cuda\") # device object representing GPU batch_size = 16 input_features = 32 state_size = 128 # Note the device=cuda_device arguments here X = torch.randn(batch_size, input_features, device=cuda_device) h = torch.randn(batch_size, state_size, device=cuda_device) C = torch.randn(batch_size, state_size, device=cuda_device) rnn = LLTM(input_features, state_size).to(cuda_device) forward = 0 backward = 0 for _ in range(100000): start = time.time() new_h, new_C = rnn(X, (h, C)) torch.cuda.synchronize() forward += time.time() - start start = time.time() (new_h.sum() + new_C.sum()).backward() torch.cuda.synchronize() backward += time.time() - start print('Forward: {:.3f} us | Backward {:.3f} us'.format(forward * 1e6/1e5, backward * 1e6/1e5)) 一旦更多的与我们的C ++版本比较我们的平原PyTorch代码，现在无论在CUDA设备上运行，我们再次看到性能提升。对于Python / PyTorch： Forward: 187.719 us | Backward 410.815 us 和C ++ / ATEN： Forward: 149.802 us | Backward 393.458 us 这是相对于非CUDA代码有很大的整体加速。但是，我们可以通过编写自定义的CUDA内核，我们将深入很快拉更是表现出我们的C ++代码。在此之前，让我们dicuss建立你的C ++扩展的另一种方式。 JIT编译扩展 以前，我提到过有建立C ++扩展的方法有两种：使用setuptools的或只是在时间（JIT）。在覆盖了前者，让我们详细阐述了后者。在JIT编译机制提供了编译和通过调用PyTorch的API）一个简单的函数调用torch.utils.cpp_extension.load（加载在飞行您的扩展方式。对于LLTM，这看起来简单，如下： from torch.utils.cpp_extension import load lltm_cpp = load(name=\"lltm_cpp\", sources=[\"lltm.cpp\"]) 在这里，我们提供相同的信息作为setuptools的功能。在此背景下，这将做到以下几点： 创建一个临时目录/ TMP / torch_extensions / lltm 发出忍者建立文件保存到临时目录， 源文件编译成一个共享库， 导入此共享库作为一个Python模块。 事实上，如果你通过详细=真至cpp_extension.load（），您作的过程中获悉： Using /tmp/torch_extensions as PyTorch extensions root... Emitting ninja build file /tmp/torch_extensions/lltm_cpp/build.ninja... Building extension module lltm_cpp... Loading extension module lltm_cpp... 将得到的Python模块将通过setuptools的产生完全一样的，但移除具有维护一个单独的setup.py建立文件的要求。如果您的设置较为复杂，你需要的全功率的setuptools，你 可以 写自己setup.py- 但在很多情况下，这JIT技术会做得很好。您通过这条线首次运行，它需要一定的时间，为扩展在后台编译。由于我们使用的忍者建立系统建立你的源代码，重新编译的增量，从而重新加载扩展当你运行你的Python模块的第二时间快，并具有低开销，如果你没有更改扩展名的源文件。 写一个混合的C ++ / CUDA扩展 要真正把我们的实施，一个新的水平，我们可以手工编写我们前进的部件和定制CUDA内核向后传递。对于LLTM，这具有特别有效的前景，因为有大量的序列逐点操作，可所有的融合，并在单个内核的CUDA并行化。让我们来看看，我们怎么能写这样的CUDA核心。它使用PyTorch这个扩展机制整合。 用于写入CUDA扩展的一般策略是先写一个C ++文件，该文件定义了将在Python被调用的功能，并结合这些功能到Python与pybind11。此外，该文件也将 声明在CUDA（.CU）文件中定义的功能。然后，C ++函数会做一些检查，并最终推进其调用的CUDA功能。在CUDA的文件，我们写我们的实际CUDA内核。的cpp_extension包将然后采取与C ++编译器编译的C ++源的象GCC和CUDA源NVIDIA的[HTG14护理] NVCC 编译器。这确保了每个编译器负责文件的它知道最好的编译。最终，他们将被链接到这是提供给我们从Python代码一个共享库。 我们将与C ++文件，我们称之为lltm_cuda.cpp，例如开始： #include #include // CUDA forward declarations std::vector lltm_cuda_forward( torch::Tensor input, torch::Tensor weights, torch::Tensor bias, torch::Tensor old_h, torch::Tensor old_cell); std::vector lltm_cuda_backward( torch::Tensor grad_h, torch::Tensor grad_cell, torch::Tensor new_cell, torch::Tensor input_gate, torch::Tensor output_gate, torch::Tensor candidate_cell, torch::Tensor X, torch::Tensor gate_weights, torch::Tensor weights); // C++ interface #define CHECK_CUDA(x) AT_ASSERTM(x.type().is_cuda(), #x \" must be a CUDA tensor\") #define CHECK_CONTIGUOUS(x) AT_ASSERTM(x.is_contiguous(), #x \" must be contiguous\") #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x) std::vector lltm_forward( torch::Tensor input, torch::Tensor weights, torch::Tensor bias, torch::Tensor old_h, torch::Tensor old_cell) { CHECK_INPUT(input); CHECK_INPUT(weights); CHECK_INPUT(bias); CHECK_INPUT(old_h); CHECK_INPUT(old_cell); return lltm_cuda_forward(input, weights, bias, old_h, old_cell); } std::vector lltm_backward( torch::Tensor grad_h, torch::Tensor grad_cell, torch::Tensor new_cell, torch::Tensor input_gate, torch::Tensor output_gate, torch::Tensor candidate_cell, torch::Tensor X, torch::Tensor gate_weights, torch::Tensor weights) { CHECK_INPUT(grad_h); CHECK_INPUT(grad_cell); CHECK_INPUT(input_gate); CHECK_INPUT(output_gate); CHECK_INPUT(candidate_cell); CHECK_INPUT(X); CHECK_INPUT(gate_weights); CHECK_INPUT(weights); return lltm_cuda_backward( grad_h, grad_cell, new_cell, input_gate, output_gate, candidate_cell, X, gate_weights, weights); } PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) { m.def(\"forward\", &lltm_forward, \"LLTM forward (CUDA)\"); m.def(\"backward\", &lltm_backward, \"LLTM backward (CUDA)\"); } 正如你所看到的，它在很大程度上是样板，检查和转发到，我们将在CUDA文件中定义的功能。我们将其命名该文件lltm_cuda_kernel.cu（注意.CU扩展！）。 NVCC可以合理编译C ++ 11，因此，我们仍然有ATEN和C ++提供给我们的标准库（但不是torch.h）。需要注意的是setuptools的不能处理具有相同名称但不同的扩展名的文件，因此，如果您使用setup.py方法而不是JIT方法，你必须给你的CUDA的文件不同的名称比你的C ++文件（JIT的方法，lltm.cpp和lltm.cu将正常工作）。让我们来看看这是什么文件将看起来像一个小偷看： #include #include #include #include template __device__ __forceinline__ scalar_t sigmoid(scalar_t z) { return 1.0 / (1.0 + exp(-z)); } 在这里，我们看到我刚才所描述的报头，以及我们使用特定CUDA申述状__device__和事实__forceinline__和类似的功能EXP。让我们继续，我们将需要几个辅助函数： template __device__ __forceinline__ scalar_t d_sigmoid(scalar_t z) { const auto s = sigmoid(z); return (1.0 - s) * s; } template __device__ __forceinline__ scalar_t d_tanh(scalar_t z) { const auto t = tanh(z); return 1 - (t * t); } template __device__ __forceinline__ scalar_t elu(scalar_t z, scalar_t alpha = 1.0) { return fmax(0.0, z) + fmin(0.0, alpha * (exp(z) - 1.0)); } template __device__ __forceinline__ scalar_t d_elu(scalar_t z, scalar_t alpha = 1.0) { const auto e = exp(z); const auto d_relu = z 到现在实际上实现一个功能，我们将再次需要两样东西：执行我们不希望明确手工写操作并调用CUDA内核一个功能，并为部分则实际CUDA内核，我们要加快。对于直传，第一个函数应该是这样的： std::vector lltm_cuda_forward( torch::Tensor input, torch::Tensor weights, torch::Tensor bias, torch::Tensor old_h, torch::Tensor old_cell) { auto X = torch::cat({old_h, input}, /*dim=*/1); auto gates = torch::addmm(bias, X, weights.transpose(0, 1)); const auto batch_size = old_cell.size(0); const auto state_size = old_cell.size(1); auto new_h = torch::zeros_like(old_cell); auto new_cell = torch::zeros_like(old_cell); auto input_gate = torch::zeros_like(old_cell); auto output_gate = torch::zeros_like(old_cell); auto candidate_cell = torch::zeros_like(old_cell); const int threads = 1024; const dim3 blocks((state_size + threads - 1) / threads, batch_size); AT_DISPATCH_FLOATING_TYPES(gates.type(), \"lltm_forward_cuda\", ([&] { lltm_cuda_forward_kernel>>( gates.data(), old_cell.data(), new_h.data(), new_cell.data(), input_gate.data(), output_gate.data(), candidate_cell.data(), state_size); })); return {new_h, new_cell, input_gate, output_gate, candidate_cell, X, gates}; } 这里关注的主要点是AT_DISPATCH_FLOATING_TYPES宏和内核启动（由表示的& LT ; & LT ; & LT ; ... & GT ; & GT ; & GT ;） 。虽然ATEN抽象了我们处理张量的设备和数据类型，张量会在运行时，仍然可以通过一个具体类型的存储器的具体设备上的支持。因此，我们需要在运行什么类型的一个张量，然后有选择地调用与相应的正确的类型签名功能确定的一种方式。手工完成，这将（概念）是这个样子： switch (tensor.type().scalarType()) { case torch::ScalarType::Double: return function(tensor.data()); case torch::ScalarType::Float: return function(tensor.data()); ... } AT_DISPATCH_FLOATING_TYPES的目的是为了照顾记者发稿我们。它需要一个类型（gates.type（）在我们的例子），一个名称（错误消息）和lambda函数。这里面lambda函数，所述类型别名scalar_t可用，并且被定义为张量实际上是在这方面的运行时的类型。因此，如果我们有一个模板函数（我们的CUDA内核会），我们可以用这个scalar_t别名实例化，并正确的函数将被调用。在这种情况下，我们也想取回张量的数据指针为scalar_t类型的指针。如果你想派遣了所有类型的并不仅仅是浮点类型（浴液HTG22]和双），你可以使用AT_DISPATCH_ALL_TYPES。 请注意，我们执行某些操作与普通ATEN。这些操作仍然会在GPU上运行，但使用ATEN的默认实现。这是有意义的，因为宏正将使用高度优化的例程，用于像矩阵乘法的东西（例如，addmm）或回旋这将是更难实施，提高自己。 作为内核启动本身，我们在这里指定每个CUDA块将具有1024个线程，并且整个GPU网格被分成1 ×的许多块 1024线程如需要填写我们的矩阵，每个部件的一个线程。例如，如果我们的状态大小是2048和我们的批量大小4，我们就启动一个总的4 × 2 = 8块与每个1024个螺纹。如果你从来没有听说过CUDA“块”或“网格”之前已经，一个入门了解CUDA 可能解决问题。 实际的CUDA内核是相当简单的（如果你以往的GPU编程）： template __global__ void lltm_cuda_forward_kernel( const scalar_t* __restrict__ gates, const scalar_t* __restrict__ old_cell, scalar_t* __restrict__ new_h, scalar_t* __restrict__ new_cell, scalar_t* __restrict__ input_gate, scalar_t* __restrict__ output_gate, scalar_t* __restrict__ candidate_cell, size_t state_size) { const int column = blockIdx.x * blockDim.x + threadIdx.x; const int index = blockIdx.y * state_size + column; const int gates_row = blockIdx.y * (state_size * 3); if (column 什么是有趣的，主要是在这里，我们能够计算所有这些逐点操作的完全平行于我们的大门矩阵各个组件。如果你想像一下与 循环遍历序列百万元的巨型做到这一点，你可以看到为什么会快得多。 使用访问 您可以在CUDA内核，我们直接与正确类型的指针看到工作。事实上，直接与CUDA内核内的高级别类型不可知的张量的工作效率会很低。 然而，这是以易用性和可读性的成本，尤其是对高维数据。在我们的例子中，我们知道的例子，连续门张量有3个方面： 的的batch_size批次，尺寸和步幅3 * state_size 的3行，尺寸和步幅state_size 的state_size索引，大小和1的步幅 我们怎样才能访问元素门[N] [行] [列]，然后在内核里？事实证明，你所需要的进步与一些简单的算术来访问你的元素。 gates.data()[n*3*state_size + row*state_size + column] 除了是冗长，这个表达式需要步幅被明确地已知的，因此传递给它的参数内的核函数。你可以看到，在内核函数接受多张量大小不同，你会最终有一个很长的参数列表的情况。 幸运的是，ATEN提供了与单个动态检查，一个张量的类型和尺寸的数量创建访问器。存取然后暴露的API用于有效地访问张量元素，而不必转换为单个指针： torch::Tensor foo = torch::rand({12, 12}); // assert foo is 2-dimensional and holds floats. auto foo_a = foo.accessor(); float trace = 0; for(int i = 0; i 访问对象具有一个相对高的水平界面，用.size（）和.stride（）方法和多维索引。的.accessor & LT ; & GT ;接口被设计为高效地访问CPU的张量数据。为CUDA张量相当于是packed_accessor & LT ; & GT ;，其产生的盒装访问器。 与访问者的根本区别在于它的结构内部的填充访问器拷贝规模和步幅数据，而不是指向它。它允许我们将它传递给一个CUDA内核函数，并使用它里面它的接口。 我们可以设计一个函数，盒装访问者，而不是指针。 __global__ void lltm_cuda_forward_kernel( const torch::PackedTensorAccessor gates, const torch::PackedTensorAccessor old_cell, torch::PackedTensorAccessor new_h, torch::PackedTensorAccessor new_cell, torch::PackedTensorAccessor input_gate, torch::PackedTensorAccessor output_gate, torch::PackedTensorAccessor candidate_cell) 让我们分解这里使用的模板。前两个参数scalar_t和2是相同的规则访问器。的参数torch:: RestrictPtrTraits表示__restrict__必须使用关键字。最后，参数为size_t表示的尺寸和进展必须被存储在为size_t整数。这是因为默认情况下的int64_t 使用重要，可以使内核速度较慢。 该函数声明成为 template __global__ void lltm_cuda_forward_kernel( const torch::PackedTensorAccessor gates, const torch::PackedTensorAccessor old_cell, torch::PackedTensorAccessor new_h, torch::PackedTensorAccessor new_cell, torch::PackedTensorAccessor input_gate, torch::PackedTensorAccessor output_gate, torch::PackedTensorAccessor candidate_cell) { //batch index const int n = blockIdx.y; // column index const int c = blockIdx.x * blockDim.x + threadIdx.x; if (c 实施更加可读！该函数然后通过与创建盒装访问者称为.packed_accessor & LT ; & GT ;主机功能内的方法。 std::vector lltm_cuda_forward( torch::Tensor input, torch::Tensor weights, torch::Tensor bias, torch::Tensor old_h, torch::Tensor old_cell) { auto X = torch::cat({old_h, input}, /*dim=*/1); auto gate_weights = torch::addmm(bias, X, weights.transpose(0, 1)); const auto batch_size = old_cell.size(0); const auto state_size = old_cell.size(1); auto gates = gate_weights.reshape({batch_size, 3, state_size}); auto new_h = torch::zeros_like(old_cell); auto new_cell = torch::zeros_like(old_cell); auto input_gate = torch::zeros_like(old_cell); auto output_gate = torch::zeros_like(old_cell); auto candidate_cell = torch::zeros_like(old_cell); const int threads = 1024; const dim3 blocks((state_size + threads - 1) / threads, batch_size); AT_DISPATCH_FLOATING_TYPES(gates.type(), \"lltm_forward_cuda\", ([&] { lltm_cuda_forward_kernel>>( gates.packed_accessor(), old_cell.packed_accessor(), new_h.packed_accessor(), new_cell.packed_accessor(), input_gate.packed_accessor(), output_gate.packed_accessor(), candidate_cell.packed_accessor()); })); return {new_h, new_cell, input_gate, output_gate, candidate_cell, X, gates}; } 向后传球遵循几乎相同的模式，我不就可以了进一步阐述： template __global__ void lltm_cuda_backward_kernel( torch::PackedTensorAccessor d_old_cell, torch::PackedTensorAccessor d_gates, const torch::PackedTensorAccessor grad_h, const torch::PackedTensorAccessor grad_cell, const torch::PackedTensorAccessor new_cell, const torch::PackedTensorAccessor input_gate, const torch::PackedTensorAccessor output_gate, const torch::PackedTensorAccessor candidate_cell, const torch::PackedTensorAccessor gate_weights) { //batch index const int n = blockIdx.y; // column index const int c = blockIdx.x * blockDim.x + threadIdx.x; if (c lltm_cuda_backward( torch::Tensor grad_h, torch::Tensor grad_cell, torch::Tensor new_cell, torch::Tensor input_gate, torch::Tensor output_gate, torch::Tensor candidate_cell, torch::Tensor X, torch::Tensor gates, torch::Tensor weights) { auto d_old_cell = torch::zeros_like(new_cell); auto d_gates = torch::zeros_like(gates); const auto batch_size = new_cell.size(0); const auto state_size = new_cell.size(1); const int threads = 1024; const dim3 blocks((state_size + threads - 1) / threads, batch_size); AT_DISPATCH_FLOATING_TYPES(X.type(), \"lltm_forward_cuda\", ([&] { lltm_cuda_backward_kernel>>( d_old_cell.packed_accessor(), d_gates.packed_accessor(), grad_h.packed_accessor(), grad_cell.packed_accessor(), new_cell.packed_accessor(), input_gate.packed_accessor(), output_gate.packed_accessor(), candidate_cell.packed_accessor(), gates.packed_accessor()); })); auto d_gate_weights = d_gates.reshape({batch_size, 3*state_size}); auto d_weights = d_gate_weights.t().mm(X); auto d_bias = d_gate_weights.sum(/*dim=*/0, /*keepdim=*/true); auto d_X = d_gate_weights.mm(weights); auto d_old_h = d_X.slice(/*dim=*/1, 0, state_size); auto d_input = d_X.slice(/*dim=*/1, state_size); return {d_old_h, d_input, d_weights, d_bias, d_old_cell, d_gates}; } 与PyTorch集成C ++ / CUDA操作 我们与PyTorch支持CUDA运算整合又是非常简单的。如果你想要写一个setup.py脚本，它看起来是这样的： from setuptools import setup from torch.utils.cpp_extension import BuildExtension, CUDAExtension setup( name='lltm', ext_modules=[ CUDAExtension('lltm_cuda', [ 'lltm_cuda.cpp', 'lltm_cuda_kernel.cu', ]) ], cmdclass={ 'build_ext': BuildExtension }) 相反CppExtension的（），我们现在使用的CUDAExtension（） [HTG7。我们可以只指定.CU与的.cpp 文件文件一起 - 库通吃，这需要对麻烦的护理您。 JIT的机制是更简单： from torch.utils.cpp_extension import load lltm = load(name='lltm', sources=['lltm_cuda.cpp', 'lltm_cuda_kernel.cu']) 性能比较 我们的希望是，并行化和融合的我们与CUDA代码的逐点行动将提高我们的LLTM的性能。让我们来看看是否能成立。我们可以跑我前面列出运行基准测试的代码。我们最快的早期版本是基于CUDA的C ++代码： Forward: 149.802 us | Backward 393.458 us 现在通过我们的定制内核CUDA： Forward: 129.431 us | Backward 304.641 us 更多的性能提升！ 结论 现在，您应该配备的PyTorch的C ++扩展机制很好的概述，以及使用他们的动机。你可以找到本笔记此处中显示的代码示例。如果您有任何疑问，请使用[论坛HTG3。此外，一定要检查我们的常见问题如果你遇到的任何问题。 Next Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 自定义C ++和CUDA扩展 动机与实施例 编写C ++扩展 与构建setuptools的 编写C ++作业 直传 倒推 结合到Python 利用分机 性能比较 对GPU设备的性能 JIT编译扩展 编写混合的C ++ / CUDA扩展 使用访问器 与PyTorch集成一个C ++ / CUDA操作 性能比较 结论 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"advanced/cpp_frontend.html":{"url":"advanced/cpp_frontend.html","title":"使用PyTorch C++ 前端","keywords":"","body":"使用PyTorch C ++前端 所述PyTorch C ++前端是一个纯粹的C ++接口到PyTorch机器学习框架。而到PyTorch主接口自然是Python中，这个Python的API上面坐大幅C ++代码库提供基本的数据结构和功能性，诸如张量和自动分化。 C ++的前端暴露出扩展与机器学习培训和推理所需的工具这一潜在的C ++代码库纯C ++ 11 API。这包括神经网络建模的通用组件的内置集合;一个API来扩展此集合与自定义模块;的流行优化算法如随机梯度下降这样的库;与API并行数据加载定义和数据集负载;系列化例程等等。 本教程将指导您完成训练模式与C ++前端的终端到终端的例子。具体而言，我们将训练 DCGAN - 一种生成模式 - 生成的数字MNIST图像。虽然概念上一个简单的例子，它应该足够给你PyTorch C ++前端的旋风概述和湿你的胃口训练更复杂的模型。我们将与你为什么会想使用C ++前端开始与一些激励的话开始，然后潜水直接进入定义和训练我们的模型。 小费 腕表从CppCon 2018 这个闪电谈话对C ++的前端快速（幽默）的介绍。 Tip 本说明提供C ++前端的部件和设计理念的清扫概述。 Tip 为PyTorch C ++生态系统文档可在https://pytorch.org/cppdocs。在那里，你可以找到高水平的描述以及API级文档。 动机 我们踏上我们的甘斯和MNIST数字令人兴奋的旅程之前，让我们退后一步，并讨论你为什么会想使用C ++前端，而不是Python的一个开始。我们（PyTorch队）创造了C ++前端，以使研究中的Python不能使用，或者是根本就没有为工作的工具环境。对于这样的环境的例子包括： 低延迟系统 ：您可能想要做的强化学习研究在高帧每秒和低延迟要求一个纯C ++游戏引擎。使用纯C ++库是一个更好的拟合比Python库这样的环境。蟒蛇可能不听话，因为在所有的Python解释器的缓慢的。 高多线程环境 ：由于全局解释器锁（GIL），Python不能上同时运行多个系统线程。多是一种选择，但不作为可扩展的，具有显著的缺点。 C ++有没有这样的约束和线程易于使用和创造。需要重并行化，像那些在使用的模型深Neuroevolution ，可以受益于这种。 现有的C ++代码库 ：您可以是现有的C ++应用程序在后端服务器网页服务中的照片编辑软件渲染3D图形做任何事情的所有者，并希望机器学习方法集成到系统中。 C ++的前端可以让你留在C ++和饶了自己的结合来回Python和C ++之间的麻烦，同时保留大部分的传统PyTorch（Python）的经验，灵活性和直观性。 C ++的前端不打算使用Python前端竞争。它的目的是补充。我们知道，研究人员和工程师都喜欢PyTorch它的简单性，灵活性和直观的API。我们的目标是确保你能在每一个可能的环境中充分利用这些核心设计原理的优势，包括上述的那些。如果这些情况之一描述你的使用情况很好，或者如果你对此有兴趣或好奇，就像我们在下面的段落中探索C ++详细前端跟随一起。 Tip C ++的前端试图提供尽可能接近到了Python前端的API。如果您正在使用Python的前端有经验和不断问自己“我怎么做X与C ++前端？”，写你的代码在Python会的方式，往往不是同一个函数和方法将在C ++中如在Python（只记得，以取代双冒号点）。 编写基本应用 首先，让我们写一个最小的C ++应用程序来验证我们对我们的设置在同一页上，并建立环境。首先，你需要抢 LibTorch 分布的副本 - 我们是包中的所有相关标题，库和CMake的构建使用C ++前端所需的文件准备建造的zip压缩包。该LibTorch分布可供下载 PyTorch网站适用于Linux，MacOS和窗户上。本教程将承担基本的Ubuntu Linux操作系统环境的其余部分，但是你可以自由沿在Mac OS或Windows跟随了。 Tip 上安装PyTorch的C ++分布的说明更详细地描述的以下步骤。 Tip 在Windows中，调试和发布版本ABI不兼容。如果您计划建立在调试模式下你的项目，请尝试LibTorch的调试版本。 第一步是在本地下载LibTorch分布，通过从PyTorch网站检索到的链接。对于香草Ubuntu Linux操作系统的环境中，这意味着运行： # If you need e.g. CUDA 9.0 support, please replace \"cpu\" with \"cu90\" in the URL below. wget https://download.pytorch.org/libtorch/nightly/cpu/libtorch-shared-with-deps-latest.zip unzip libtorch-shared-with-deps-latest.zip 接下来，让我们写所谓的dcgan.cpp一个微小的C ++文件，其中包括Torch / torch.h现在来看只是打印出来三乘三个矩阵： #include #include int main() { torch::Tensor tensor = torch::eye(3); std::cout 要构建这个小应用程序，以及我们全面的培训脚本，稍后我们将使用这个的CMakeLists.txt文件： cmake_minimum_required(VERSION 3.0 FATAL_ERROR) project(dcgan) find_package(Torch REQUIRED) add_executable(dcgan dcgan.cpp) target_link_libraries(dcgan \"${TORCH_LIBRARIES}\") set_property(TARGET dcgan PROPERTY CXX_STANDARD 11) 注意 虽然CMake的是LibTorch推荐的构建系统，它不是一个硬性要求。您还可以使用Visual Studio项目文件，QMAKE，普通的Makefile或者你觉得舒服的任何其他构建环境。但是，我们不提供这个外的现成支持。 记在上述文件的CMake线4：find_package（Torch REQUIRED）。这CMake的指示找到了LibTorch库的构建配置。为了让CMake的了解 ，其中 找到这些文件，必须设定CMAKE_PREFIX_PATH当调用cmake的。我们这样做之前，让我们对我们的dcgan应用下面的目录结构达成一致意见： dcgan/ CMakeLists.txt dcgan.cpp 此外，我将提到的路径，解压缩后的LibTorch分发/路径/到/ libtorch。请注意，这 必须是绝对路径[HTG5。特别是，设置CMAKE_PREFIX_PATH喜欢的东西../../libtorch会以意想不到的方式打破。相反，写$ PWD /../../ libtorch来获得相应的绝对路径。现在，我们准备建立我们的应用程序： root@fa350df05ecf:/home# mkdir build root@fa350df05ecf:/home# cd build root@fa350df05ecf:/home/build# cmake -DCMAKE_PREFIX_PATH=/path/to/libtorch .. -- The C compiler identification is GNU 5.4.0 -- The CXX compiler identification is GNU 5.4.0 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Looking for pthread.h -- Looking for pthread.h - found -- Looking for pthread_create -- Looking for pthread_create - not found -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- Found torch: /path/to/libtorch/lib/libtorch.so -- Configuring done -- Generating done -- Build files have been written to: /home/build root@fa350df05ecf:/home/build# make -j Scanning dependencies of target dcgan [ 50%] Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o [100%] Linking CXX executable dcgan [100%] Built target dcgan 以上，我们首先创建了dcgan目录内建文件夹，进入该文件夹，跑cmake的命令产生必要的建立（MAKE）文件，并最终通过运行让 -j编制的项目成功。我们目前都在集中执行我们最小的二进制和完成基本的项目配置本节： root@fa350df05ecf:/home/build# ./dcgan 1 0 0 0 1 0 0 0 1 [ Variable[CPUFloatType]{3,3} ] 看起来像一个单位矩阵给我！ 定义神经网络模型 现在，我们已经配置了基本的环境中，我们可以潜入本教程的更有趣的部分。首先，我们将讨论如何定义，并与在C ++前端模块交互。我们将使用由C ++前端提供内置模块的扩展库基本的，小规模的例子模块开始，然后实现一个完整的甘。 模块API基础 与Python接口线的基础上，C ++前端神经网络是由所谓的 模块 可重复使用的构建块。存在来自所有其他模块来源的基本模块类。在Python，这个类是torch.nn.Module和在C ++中它是torch::ン::模块。除了一个向前（）实施模块封装，模块通常包含任何三种子对象的算法方法：参数，缓冲剂和子模块。 参数和缓冲区存储在张量的形式状态。参数的记录梯度，而缓冲器不会。参数通常是你的神经网络训练的权重。缓冲剂的实例包括装置和用于批标准化变化。为了重复使用逻辑和状态的特定块时，PyTorch API允许模块被嵌套。嵌套模块被称为 子模块 。 参数，缓冲区和模块必须明确登记。一旦注册，如参数）的方法（或缓冲剂（）可用于检索所有参数的容器，在整个（嵌套的）模块的层次结构。类似地，如方法（......），其中例如至（torch:: kCUDA）移动的所有参数和缓冲器从CPU到CUDA存储器，工作对整个模块的层次结构。 定义模块和注册参数 为了把这些话转换成代码，让我们考虑用Python接口这个简单的模块： import torch class Net(torch.nn.Module): def __init__(self, N, M): super(Net, self).__init__() self.W = torch.nn.Parameter(torch.randn(N, M)) self.b = torch.nn.Parameter(torch.randn(M)) def forward(self, input): return torch.addmm(self.b, input, self.W) 在C ++中，它应该是这样的： #include struct Net : torch::nn::Module { Net(int64_t N, int64_t M) { W = register_parameter(\"W\", torch::randn({N, M})); b = register_parameter(\"b\", torch::randn(M)); } torch::Tensor forward(torch::Tensor input) { return torch::addmm(b, input, W); } torch::Tensor W, b; }; 就像在Python中，我们定义了一个名为网（为简单起见这里类，而不是A结构 类），并从模块基类派生它。构造函数中，我们创建一个使用Torch 张量:: randn就像我们使用torch.randn在Python。一个有趣的差异是我们如何注册的参数。在Python，我们包裹张量与torch.nn.Parameter类，而在C ++我们通过传递张量的register_parameter方法来代替。这样做的原因是，Python API中可以检测到一个属性是类型torch.nn.Parameter的和自动注册这样张量。在C ++中，反射是非常有限的，因此提供了一种更传统的（和更小神奇）的方法。 注册子模和遍历模块层次结构 以同样的方式，我们可以注册参数，我们还可以注册子模块。在Python，子模块被自动检测和注册时它们被分配作为一个模块的属性： class Net(torch.nn.Module): def __init__(self, N, M): super(Net, self).__init__() # Registered as a submodule behind the scenes self.linear = torch.nn.Linear(N, M) self.another_bias = torch.nn.Parameter(torch.rand(M)) def forward(self, input): return self.linear(input) + self.another_bias 这允许，例如，使用参数（）方法递归地访问在我们的模块层次中的所有参数： >>> net = Net(4, 5) >>> print(list(net.parameters())) [Parameter containing: tensor([0.0808, 0.8613, 0.2017, 0.5206, 0.5353], requires_grad=True), Parameter containing: tensor([[-0.3740, -0.0976, -0.4786, -0.4928], [-0.1434, 0.4713, 0.1735, -0.3293], [-0.3467, -0.3858, 0.1980, 0.1986], [-0.1975, 0.4278, -0.1831, -0.2709], [ 0.3730, 0.4307, 0.3236, -0.0629]], requires_grad=True), Parameter containing: tensor([ 0.2038, 0.4638, -0.2023, 0.1230, -0.0516], requires_grad=True)] 在C ++寄存器子模块，使用恰当地命名为register_module（）方法注册等torch的模块::ン::线性： struct Net : torch::nn::Module { Net(int64_t N, int64_t M) : linear(register_module(\"linear\", torch::nn::Linear(N, M))) { another_bias = register_parameter(\"b\", torch::randn(M)); } torch::Tensor forward(torch::Tensor input) { return linear(input) + another_bias; } torch::nn::Linear linear; torch::Tensor another_bias; }; Tip 你可以找到可用的内置模块一样的完整列表Torch :: NN ::线性，Torch :: NN ::差或Torch :: NN :: Conv2d中的Torch 的文档:: NN命名空间这里。 关于上述代码的一个微妙之处就是为什么子模块是在构造函数的初始化列表中创建的，而参数是在构造函数体内部创建的。有一个很好的理由，我们将在对C ++前端的 所有权模式 下面进一步的部分在此碰。最终的结果，但是，我们可以递归访问我们的模块树的参数，就像在Python。主叫参数（）返回的std ::矢量& LT ;torch::张量& GT ;，我们可以遍历： int main() { Net net(4, 5); for (const auto& p : net.parameters()) { std::cout 其打印： root@fa350df05ecf:/home/build# ./dcgan 0.0345 1.4456 -0.6313 -0.3585 -0.4008 [ Variable[CPUFloatType]{5} ] -0.1647 0.2891 0.0527 -0.0354 0.3084 0.2025 0.0343 0.1824 -0.4630 -0.2862 0.2500 -0.0420 0.3679 -0.1482 -0.0460 0.1967 0.2132 -0.1992 0.4257 0.0739 [ Variable[CPUFloatType]{5,4} ] 0.01 * 3.6861 -10.1166 -45.0333 7.9983 -20.0705 [ Variable[CPUFloatType]{5} ] 有三个参数，就像在Python。还看到这些参数的名称，在C ++ API提供了named_pa​​rameters（）方法，它返回一个OrderedDict就像在Python ： Net net(4, 5); for (const auto& pair : net.named_parameters()) { std::cout 我们可以再次执行看到的输出： root@fa350df05ecf:/home/build# make && ./dcgan 11:13:48 Scanning dependencies of target dcgan [ 50%] Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o [100%] Linking CXX executable dcgan [100%] Built target dcgan b: -0.1863 -0.8611 -0.1228 1.3269 0.9858 [ Variable[CPUFloatType]{5} ] linear.weight: 0.0339 0.2484 0.2035 -0.2103 -0.0715 -0.2975 -0.4350 -0.1878 -0.3616 0.1050 -0.4982 0.0335 -0.1605 0.4963 0.4099 -0.2883 0.1818 -0.3447 -0.1501 -0.0215 [ Variable[CPUFloatType]{5,4} ] linear.bias: -0.0250 0.0408 0.3756 -0.2149 -0.3636 [ Variable[CPUFloatType]{5} ] Note 的文档为torch::ン::模块包含的，关于模块的层次结构进行操作的方法的完整列表。 在正向模式下运行的网络 为了执行在C ++中的网络中，我们只需调用向前（）方法中，我们定义自己： int main() { Net net(4, 5); std::cout 它打印是这样的： root@fa350df05ecf:/home/build# ./dcgan 0.8559 1.1572 2.1069 -0.1247 0.8060 0.8559 1.1572 2.1069 -0.1247 0.8060 [ Variable[CPUFloatType]{2,5} ] 模块所有权 在这一点上，我们知道如何定义在C ++模块，注册参数，注册子模块，通过像参数）的方法（穿越模块的层次结构，并最终运行模块的向前（）方法。虽然还有更多的方法，类和主题的C ++ API中吞噬，我会向您推荐文档完整的菜单。我们也将触及一些概念，我们实现在短短一秒钟DCGAN模型和终端到终端的培训渠道。在这样做之前，让当 所有权模式 C ++的前端提供了Torch 的子类，我简要地谈谈:: NN ::模块 [HTG15。 为了便于讨论，所有权模式是指模块存储并通过周围的方式 - 它决定谁或什么 拥有 特定模块实例。在Python，对象总是动态分配（在堆上），并且具有引用语义。这是非常易于使用和易于理解。事实上，在Python中，你可以在很大程度上忘记对象居住在哪里以及如何他们得到引用，并专注于做事情。 C ++，作为一个较低级别的语言，提供了在此领域的更多选项。这增加了复杂性和严重影响了设计和C ++前端的人体工程学设计。特别地，对于在C ++前端模块，我们有使用 为 值语义 或 引用语义的选项。第一种情况是最简单的和实施例中迄今为止被证明：模块对象被分配在栈上，并传递给函数时，既可以复制，移动（与的std ::移动）或采取引用或指针： struct Net : torch::nn::Module { }; void a(Net net) { } void b(Net& net) { } void c(Net* net) { } int main() { Net net; a(net); a(std::move(net)); b(net); c(&net); } 对于第二种情况 - 参考语义 - 我们可以使用的std :: shared_ptr的。引用传递的好处是，像在Python，它减少想着模块必须如何传递给函数和参数必须如何申报的认知开销（假设你使用shared_ptr的到处）。 struct Net : torch::nn::Module {}; void a(std::shared_ptr net) { } int main() { auto net = std::make_shared(); a(net); } 在我们的经验中，研究人员从动态语言来非常喜欢引用语义过值语义，即使后者更是“原生”到C ++。同样重要的是要注意，Torch :: NN ::模块的设计，以贴近了Python API的人体工程学设计，依赖于共享所有权 [HTG3。例如，利用网 我们先前的（这里缩短）的定义： struct Net : torch::nn::Module { Net(int64_t N, int64_t M) : linear(register_module(\"linear\", torch::nn::Linear(N, M))) { } torch::nn::Linear linear; }; 为了使用线性子模块，我们希望直接存储在我们班。但是，我们也希望在模块的基类来了解并有机会获得这个子模块。为此，它必须保存到该子模块的参考。在这一点上，我们已经到达了需要共享所有权。两者torch::ン::模块类和混凝土净类需要到子模块的引用。由于这个原因，基类存储模块为的shared_ptrS，因此，混凝土类必须太。 可是等等！我没有看到的在上面的代码中的shared_ptr任何提及！这是为什么？那么，因为的std :: shared_ptr的& LT ; MyModule的& GT ;是很多类型的地狱。为了使我们的研究人员生产力，我们想出了一个精心设计的方案，以隐藏提的shared_ptr - 一个好处通常保留值语义 - 同时保持引用语义。要理解这是如何工作的，我们可以看看在Torch 的简化定义:: NN ::线性模块中的核心库（完整的定义是在这里）： struct LinearImpl : torch::nn::Module { LinearImpl(int64_t in, int64_t out); Tensor forward(const Tensor& input); Tensor weight, bias; }; TORCH_MODULE(Linear); 简而言之：将模块不叫线性，但LinearImpl。宏，TORCH_MODULE然后定义实际线性类。这个“而生成”类实际上是在一个包装一的std :: shared_ptr的& LT ; LinearImpl & GT ;。这是一个包装，而不是一个简单的typedef，这样，除其他事项外，还构造如预期，即你仍然可以写Torch :: NN ::线性（3， 4 ）而非的std :: make_shared & LT ; LinearImpl & GT ;（3， 4）。我们呼吁由宏模块 持有者 创建的类。像（共享的）指针，则使用箭头操作者访问底层对象（如模型 - & GT ;向前（......））。最终的结果是所有权模式，类似于Python的API的颇有渊源。引用语义成为默认，但没有额外的输入的std :: shared_ptr的或的std :: make_shared [HTG45。对于我们的网 ，使用模块底座API看起来是这样的： struct NetImpl : torch::nn::Module {}; TORCH_MODULE(Net); void a(Net net) { } int main() { Net net; a(net); } 有一个值得在这里提到一个微妙的问题。默认构造的std :: shared_ptr的是“空的”，即，包含一个空指针。在默认构造什么线性或网？嗯，这是一个棘手的选择。我们可以说，它应该是一个空（NULL）的std :: shared_ptr的& LT ; LinearImpl & GT ; [HTG15。然而，回想线性（3， 4） 是与的std :: make_shared & LT [; ] LinearImpl & GT ;（3， 4） 。这意味着，如果我们已经决定，线性 线性; 应该是一个空指针，则就没有办法来构造的模块不采取任何构造函数的参数，或者默认所有的人。出于这个原因，目前的API中，默认的构建模块保持器（如线性（） ）调用底层模块的默认构造（LinearImpl（） ）。如果底层模块不会有一个默认的构造函数，你得到一个编译错误。为了构建，而不是空的持有人，你可以通过nullptr到支架的构造。 在实践中，这意味着你可以使用子模块要么喜欢早些时候，当模块注册，并在 初始化列表 构造图所示： struct Net : torch::nn::Module { Net(int64_t N, int64_t M) : linear(register_module(\"linear\", torch::nn::Linear(N, M))) { } torch::nn::Linear linear; }; 或者你可以先建立持有人一个空指针，然后分配给它的构造器（用于Pythonistas比较熟悉）： struct Net : torch::nn::Module { Net(int64_t N, int64_t M) { linear = register_module(\"linear\", torch::nn::Linear(N, M)); } torch::nn::Linear linear{nullptr}; // construct an empty holder }; 结论：哪个所有制模式 - 其语义 - 你应该使用？在C ++前端的API最好的支持模块保持所提供的所有权模式。这个机制的唯一缺点是模块声明以下样板的一个额外的行。这就是说，最简单的模型是静止在介绍C ++模块中示出的值语义模型。对于小型，简单的脚本，你可以逃脱它。但你会发现早晚，由于技术原因，它并不总是支持。例如，串行化API（torch::保存和torch::负载）仅支持模块保持器（或纯shared_ptr的）。这样，模块保持器API是定义与C ++前端模块的推荐的方法，我们将在本教程此后使用该API。 限定DCGAN模块 我们现在有必要的背景介绍和定义，我们希望在这个岗位，解决了机器学习任务模块。要回顾一下：我们的任务是生成从 MNIST数据集的数字图像。我们要使用生成对抗网络（GAN）HTG3]来解决这个任务。特别是，我们将使用 DCGAN架构 - 第一，它的那种简单的，但完全足以完成这个任务之一。 Tip 您可以在此存储库在本教程提出了完整的源代码。 什么是甘阿甘？ 甲GAN包括两个不同的神经网络模型：一个 发生器 和a 鉴别 。发电机从噪声分布接收样本，且其目的是将每个噪声采样转变成类似于那些目标分布的图像 - 在我们的情况下，MNIST数据集。反过来鉴别从所述数据集MNIST接收任一 真实 的图像，或者从发电机 假 图像。它被要求发射的概率判断如何真实（越接近1）或假（越接近0）的特定图像是。从如何真正由发电机产生的图像被用来训练发生器鉴别反馈。如何很好的真实性眼睛的鉴别已经被用于优化鉴别反馈。从理论上讲，在发电机和鉴别器之间的微妙平衡使得它们在串联提高，导致发生器产生从目标分布没有区别的图像，欺骗鉴别的（通过随后）优异的眼成发光的0.5的概率两个真假图像。对我们来说，最终的结果是接收噪声作为输入并产生数字作为其输出逼真的图像的机器。 所述发生器模块 我们首先定义发生器模块，它由一系列换位2D卷积，一批归一化和激活RELU单位的。像在Python，PyTorch这里提供了一种用于模型定义两个API：功能性的，其中输入通过连续函数过去了，更之一，我们构建含有序贯模块的面向对象的整个模型的子模块。让我们来看看我们的发电机的外观与任何API，你可以自己决定你更喜欢哪一个。首先，使用序贯： using namespace torch; nn::Sequential generator( // Layer 1 nn::Conv2d(nn::Conv2dOptions(kNoiseSize, 256, 4) .with_bias(false) .transposed(true)), nn::BatchNorm(256), nn::Functional(torch::relu), // Layer 2 nn::Conv2d(nn::Conv2dOptions(256, 128, 3) .stride(2) .padding(1) .with_bias(false) .transposed(true)), nn::BatchNorm(128), nn::Functional(torch::relu), // Layer 3 nn::Conv2d(nn::Conv2dOptions(128, 64, 4) .stride(2) .padding(1) .with_bias(false) .transposed(true)), nn::BatchNorm(64), nn::Functional(torch::relu), // Layer 4 nn::Conv2d(nn::Conv2dOptions(64, 1, 4) .stride(2) .padding(1) .with_bias(false) .transposed(true)), nn::Functional(torch::tanh)); Tip A 序贯模块简单地执行功能的组合物。该第一子模块的输出变成第二输入，第三的输出变为第四等的输入。 特定模块选择，如NN :: Conv2d和NN :: BatchNorm，如下前面概括的结构。的kNoiseSize常数决定输入噪声向量的大小和设置为100。还要注意的是，我们使用Torch :: NN ::功能模块为我们的激活功能，通过它Torch :: RELU为内层和torch::的tanh作为最终活化。超参数进行，当然，通过研究生血统找到。 Note Python的前端具有用于每个激活功能一个模块，如torch.nn.ReLU或torch.nn.Tanh。在C ++中，我们不是仅提供功能模块中，向其中可以传递任何C ++函数，将内部被称为功能“S 向前（）方法。 注意 没有研究生在超参数的发现受到伤害。他们定期喂食Soylent。 对于第二种方法，我们明确地通过模块之间的输入（以功能性方式）在向前（）的模块的方法，我们定义自己： struct GeneratorImpl : nn::Module { GeneratorImpl(int kNoiseSize) : conv1(nn::Conv2dOptions(kNoiseSize, 256, 4) .with_bias(false) .transposed(true)), batch_norm1(256), conv2(nn::Conv2dOptions(256, 128, 3) .stride(2) .padding(1) .with_bias(false) .transposed(true)), batch_norm2(128), conv3(nn::Conv2dOptions(128, 64, 4) .stride(2) .padding(1) .with_bias(false) .transposed(true)), batch_norm3(64), conv4(nn::Conv2dOptions(64, 1, 4) .stride(2) .padding(1) .with_bias(false) .transposed(true)), batch_norm4(64), conv5(nn::Conv2dOptions(64, 1, 4) .stride(2) .padding(1) .with_bias(false) .transposed(true)) { // register_module() is needed if we want to use the parameters() method later on register_module(\"conv1\", conv1); register_module(\"conv2\", conv2); register_module(\"conv3\", conv3); register_module(\"conv4\", conv4); register_module(\"batch_norm1\", batch_norm1); register_module(\"batch_norm2\", batch_norm1); register_module(\"batch_norm3\", batch_norm1); } torch::Tensor forward(torch::Tensor x) { x = torch::relu(batch_norm1(conv1(x))); x = torch::relu(batch_norm2(conv2(x))); x = torch::relu(batch_norm3(conv3(x))); x = torch::tanh(conv4(x)); return x; } nn::Conv2d conv1, conv2, conv3, conv4; nn::BatchNorm batch_norm1, batch_norm2, batch_norm3; }; TORCH_MODULE(Generator); Generator generator; 我们使用哪种方法，我们现在可以调用向前（）关于发生器映射一个噪声样本的图像。 Note 在途中选项的简要字被传递给内置模块等Conv2d在C ++前端：每个模块具有一些所需的选项，如特征为[数HTG5] BatchNorm。如果你只需要配置所需选项，你可以直接将它们传递到模块的构造，如BatchNorm（128）或降（0.5）或Conv2d（8， 4， 2）（用于输入信道数，输出信道数，和内核大小）。但是，如果你需要修改的其他选项，这通常是默认，如with_bias对Conv2d，你需要构建并传递一个 项 对象。在C ++前端每个模块都有一个相关联的选项结构，称为ModuleOptions其中模块是模块的名称，如LinearOptions为线性。这就是我们的Conv2d上述模块做。 所述鉴别器模块 鉴别器是同样的卷积，批次归一和激活的序列。然而，盘旋现在一些约定俗成的，而不是换位，我们用一个漏水的RELU为0.2，而不是香草RELU的alpha值。另外，最终活化变为乙状结肠，其南瓜值成范围在0和1之间然后，我们可以解释这些压扁值作为鉴别器分配给图像是真实的概率： nn::Sequential discriminator( // Layer 1 nn::Conv2d( nn::Conv2dOptions(1, 64, 4).stride(2).padding(1).with_bias(false)), nn::Functional(torch::leaky_relu, 0.2), // Layer 2 nn::Conv2d( nn::Conv2dOptions(64, 128, 4).stride(2).padding(1).with_bias(false)), nn::BatchNorm(128), nn::Functional(torch::leaky_relu, 0.2), // Layer 3 nn::Conv2d( nn::Conv2dOptions(128, 256, 4).stride(2).padding(1).with_bias(false)), nn::BatchNorm(256), nn::Functional(torch::leaky_relu, 0.2), // Layer 4 nn::Conv2d( nn::Conv2dOptions(256, 1, 3).stride(1).padding(0).with_bias(false)), nn::Functional(torch::sigmoid)); Note 当该功能我们通过功能需要更多的参数比单个张量，我们可以将它们传递到功能构造，这将它们转发到每个函数调用。对于上面的泄漏RELU，这意味着torch:: leaky_relu（previous_output_tensor， 0.2）是调用。 载入数据 现在，我们已经定义了发电机和鉴别模型，我们需要一些数据，我们可以一起训练这些模型。 C ++的前端，诸如Python之一，带有一个强大的并行数据加载器。该数据加载器可以读取一个数据集的数据批次（你可以自己定义），并提供了许多配置旋钮。 Note 虽然Python数据加载程序使用多处理中，C ++数据加载器是真正的多线程和不启动任何新的过程。 数据加载是C ++前端的数据API，包含在torch::数据::命名空间的一部分。这个API是由几个不同的部分组成： 数据加载器类， 用于定义数据集的API， 用于限定 变换 的API，其可以被应用到数据集， 用于限定 取样 ，它产生与数据集编索引的索引的API， 现有数据集，转换器和采样库。 在本教程中，我们可以使用自带的C ++前端的MNIST数据集。让我们来实例化一个Torch ::数据::数据集:: MNIST对于这一点，并应用两个转变：一是标准化的图像，使它们在范围-1-至+1（从原始范围至[0 `HTG21] 1 ）。其次，我们应用堆栈 `整理 ，这需要一批张量，并将它们堆叠成沿着第一维度单一张量： auto dataset = torch::data::datasets::MNIST(\"./mnist\") .map(torch::data::transforms::Normalize<>(0.5, 0.5)) .map(torch::data::transforms::Stack<>()); 需要注意的是MNIST数据集应位于./mnist相对于无论你执行从训练二进制文件目录。您可以使用这个脚本下载MNIST数据集。 接下来，我们创建了一个数据加载器，并通过它这个数据集。为了使新的数据加载，我们使用Torch ::数据:: make_data_loader，它返回的一个的std ::的unique_ptr正确的类型（这取决于数据集，采样器和其他一些实施细节的类型的类型）： auto data_loader = torch::data::make_data_loader(std::move(dataset)); 数据装载的确有很多的选择。您可以检查整套此处[HTG1。例如，为了加快数据加载，我们可以增加工人的数量。默认号码是零，这意味着主线程将被使用。如果我们设置工人至2，两个线程将同时催生该负载数据。我们还应该从它的默认增加批量大小1 HTG12]的东西比较合理，喜欢64（值kBatchSize）。因此，让我们创建一个DataLoaderOptions对象，并设置相应的属性： auto data_loader = torch::data::make_data_loader( std::move(dataset), torch::data::DataLoaderOptions().batch_size(kBatchSize).workers(2)); 现在，我们可以写一个循环来加载数据，我们将只打印到控制台现在的批次： for (torch::data::Example<>& batch : *data_loader) { std::cout () 由数据装入程序在这种情况下返回的类型是torch::数据::实施例。这种类型是一个简单的结构与用于数据的数据字段和一个标签目标字段。因为我们应用了堆栈核对之前，则数据加载器仅返回一个这样的例子。如果我们没有施加核对，数据加载器将产生的std ::矢量& LT ;torch::数据::实施例& LT ; [ - - ] GT ; & GT ;代替，以在每批次例如一个元素。 如果重建并运行这段代码，你会看到这样的事情： root@fa350df05ecf:/home/build# make Scanning dependencies of target dcgan [ 50%] Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o [100%] Linking CXX executable dcgan [100%] Built target dcgan root@fa350df05ecf:/home/build# make [100%] Built target dcgan root@fa350df05ecf:/home/build# ./dcgan Batch size: 64 | Labels: 5 2 6 7 2 1 6 7 0 1 6 2 3 6 9 1 8 4 0 6 5 3 3 0 4 6 6 6 4 0 8 6 0 6 9 2 4 0 2 8 6 3 3 2 9 2 0 1 4 2 3 4 8 2 9 9 3 5 8 0 0 7 9 9 Batch size: 64 | Labels: 2 2 4 7 1 2 8 8 6 9 0 2 2 9 3 6 1 3 8 0 4 4 8 8 8 9 2 6 4 7 1 5 0 9 7 5 4 3 5 4 1 2 8 0 7 1 9 6 1 6 5 3 4 4 1 2 3 2 3 5 0 1 6 2 Batch size: 64 | Labels: 4 5 4 2 1 4 8 3 8 3 6 1 5 4 3 6 2 2 5 1 3 1 5 0 8 2 1 5 3 2 4 4 5 9 7 2 8 9 2 0 6 7 4 3 8 3 5 8 8 3 0 5 8 0 8 7 8 5 5 6 1 7 8 0 Batch size: 64 | Labels: 3 3 7 1 4 1 6 1 0 3 6 4 0 2 5 4 0 4 2 8 1 9 6 5 1 6 3 2 8 9 2 3 8 7 4 5 9 6 0 8 3 0 0 6 4 8 2 5 4 1 8 3 7 8 0 0 8 9 6 7 2 1 4 7 Batch size: 64 | Labels: 3 0 5 5 9 8 3 9 8 9 5 9 5 0 4 1 2 7 7 2 0 0 5 4 8 7 7 6 1 0 7 9 3 0 6 3 2 6 2 7 6 3 3 4 0 5 8 8 9 1 9 2 1 9 4 4 9 2 4 6 2 9 4 0 Batch size: 64 | Labels: 9 6 7 5 3 5 9 0 8 6 6 7 8 2 1 9 8 8 1 1 8 2 0 7 1 4 1 6 7 5 1 7 7 4 0 3 2 9 0 6 6 3 4 4 8 1 2 8 6 9 2 0 3 1 2 8 5 6 4 8 5 8 6 2 Batch size: 64 | Labels: 9 3 0 3 6 5 1 8 6 0 1 9 9 1 6 1 7 7 4 4 4 7 8 8 6 7 8 2 6 0 4 6 8 2 5 3 9 8 4 0 9 9 3 7 0 5 8 2 4 5 6 2 8 2 5 3 7 1 9 1 8 2 2 7 Batch size: 64 | Labels: 9 1 9 2 7 2 6 0 8 6 8 7 7 4 8 6 1 1 6 8 5 7 9 1 3 2 0 5 1 7 3 1 6 1 0 8 6 0 8 1 0 5 4 9 3 8 5 8 4 8 0 1 2 6 2 4 2 7 7 3 7 4 5 3 Batch size: 64 | Labels: 8 8 3 1 8 6 4 2 9 5 8 0 2 8 6 6 7 0 9 8 3 8 7 1 6 6 2 7 7 4 5 5 2 1 7 9 5 4 9 1 0 3 1 9 3 9 8 8 5 3 7 5 3 6 8 9 4 2 0 1 2 5 4 7 Batch size: 64 | Labels: 9 2 7 0 8 4 4 2 7 5 0 0 6 2 0 5 9 5 9 8 8 9 3 5 7 5 4 7 3 0 5 7 6 5 7 1 6 2 8 7 6 3 2 6 5 6 1 2 7 7 0 0 5 9 0 0 9 1 7 8 3 2 9 4 Batch size: 64 | Labels: 7 6 5 7 7 5 2 2 4 9 9 4 8 7 4 8 9 4 5 7 1 2 6 9 8 5 1 2 3 6 7 8 1 1 3 9 8 7 9 5 0 8 5 1 8 7 2 6 5 1 2 0 9 7 4 0 9 0 4 6 0 0 8 6 ... 这意味着我们能够成功地从MNIST数据集加载数据。 写作训练循环 现在，让我们完成我们的例子中的算法部分和实施发电机和鉴别之间微妙的舞蹈。首先，我们将创建两个优化，一个发电机和一个用于鉴别。在优化我们使用实现亚当算法： torch::optim::Adam generator_optimizer( generator->parameters(), torch::optim::AdamOptions(2e-4).beta1(0.5)); torch::optim::Adam discriminator_optimizer( discriminator->parameters(), torch::optim::AdamOptions(5e-4).beta1(0.5)); Note 在撰写本文时，C ++的前端提供了实施Adagrad，亚当，LBFGS，RMSprop和SGD优化。在文档有向上的最新名单。 接下来，我们需要更新我们的训练循环。我们将增加一个外环用尽数据加载每个时间段，然后写GAN训练码： for (int64_t epoch = 1; epoch & batch : *data_loader) { // Train discriminator with real images. discriminator->zero_grad(); torch::Tensor real_images = batch.data; torch::Tensor real_labels = torch::empty(batch.data.size(0)).uniform_(0.8, 1.0); torch::Tensor real_output = discriminator->forward(real_images); torch::Tensor d_loss_real = torch::binary_cross_entropy(real_output, real_labels); d_loss_real.backward(); // Train discriminator with fake images. torch::Tensor noise = torch::randn({batch.data.size(0), kNoiseSize, 1, 1}); torch::Tensor fake_images = generator->forward(noise); torch::Tensor fake_labels = torch::zeros(batch.data.size(0)); torch::Tensor fake_output = discriminator->forward(fake_images.detach()); torch::Tensor d_loss_fake = torch::binary_cross_entropy(fake_output, fake_labels); d_loss_fake.backward(); torch::Tensor d_loss = d_loss_real + d_loss_fake; discriminator_optimizer.step(); // Train generator. generator->zero_grad(); fake_labels.fill_(1); fake_output = discriminator->forward(fake_images); torch::Tensor g_loss = torch::binary_cross_entropy(fake_output, fake_labels); g_loss.backward(); generator_optimizer.step(); std::printf( \"\\r[%2ld/%2ld][%3ld/%3ld] D_loss: %.4f | G_loss: %.4f\", epoch, kNumberOfEpochs, ++batch_index, batches_per_epoch, d_loss.item(), g_loss.item()); } } 上面，我们首先评估真实图像，它应该指定一个高概率的鉴别。对于这一点，我们使用torch::空（batch.data.size（0））。uniform_（0.8， 1.0）作为目标概率。 Note 我们挑选到处都在为了使鉴别训练更强大的0.8和1.0，而不是1.0之间均匀分布的随机值。这一招被称为 标签平滑[HTG1。 评估鉴别之前，我们归零其参数的梯度。计算损失后，我们通过网络通过调用d_loss.backward（）来计算新的梯度回传播。我们重复这个高谈阔论的假像。而不是使用图片来自数据集的，我们让发电机通过喂养它了一批随机噪声的创建这种假像。然后，我们这些假图像转发到鉴别。这一次，我们要鉴别发出低概率，最好全部为零。一旦我们计算了两个批次的真实与虚假批图像的鉴别损失，我们可以以更新其参数一步进展鉴别的优化。 为了训练发电机，我们再次先零的梯度，然后重新评估的假图像鉴别。然而，这一次我们要鉴别分配的概率非常接近，这表明该发生器可以产生这种欺骗鉴别以为他们实际上是（从数据集）的真实图像。为此，我们填补fake_labels全部为一张量。我们终于步发电机的优化也更新其参数。 现在，我们应该准备训练CPU上我们的模型。我们没有任何代码尚未捕获状态或样品产出，但我们会在短短的时刻添加此。现在，就让我们看到，我们的模型是做 东西 - 我们将根据生成的图像这个东西是否是有意义的再验证。重新构建和运行应打印是这样的： root@3c0711f20896:/home/build# make && ./dcgan Scanning dependencies of target dcgan [ 50%] Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o [100%] Linking CXX executable dcgan [100%] Built target dcga [ 1/10][100/938] D_loss: 0.6876 | G_loss: 4.1304 [ 1/10][200/938] D_loss: 0.3776 | G_loss: 4.3101 [ 1/10][300/938] D_loss: 0.3652 | G_loss: 4.6626 [ 1/10][400/938] D_loss: 0.8057 | G_loss: 2.2795 [ 1/10][500/938] D_loss: 0.3531 | G_loss: 4.4452 [ 1/10][600/938] D_loss: 0.3501 | G_loss: 5.0811 [ 1/10][700/938] D_loss: 0.3581 | G_loss: 4.5623 [ 1/10][800/938] D_loss: 0.6423 | G_loss: 1.7385 [ 1/10][900/938] D_loss: 0.3592 | G_loss: 4.7333 [ 2/10][100/938] D_loss: 0.4660 | G_loss: 2.5242 [ 2/10][200/938] D_loss: 0.6364 | G_loss: 2.0886 [ 2/10][300/938] D_loss: 0.3717 | G_loss: 3.8103 [ 2/10][400/938] D_loss: 1.0201 | G_loss: 1.3544 [ 2/10][500/938] D_loss: 0.4522 | G_loss: 2.6545 ... 移动到GPU 虽然我们当前的脚本可以运行在CPU上就好了，大家都知道卷积都在GPU快了很多。让我们快速讨论如何我们的培训走上了GPU。我们需要为这个做两件事情：一个GPU设备规范传递给我们分配自己张量，并明确通过以（）法任何其他张量复制到所有GPU张量和模块在C ++前端有。实现这两个最简单的方法是在我们的训练脚本的顶层创建Torch ::设备的实例，然后将该设备传递给张厂的功能，如torch::零以及至（）方法。我们可以通过与CPU设备这样开始： // Place this somewhere at the top of your training script. torch::Device device(torch::kCPU); 新张量分配像 torch::Tensor fake_labels = torch::zeros(batch.data.size(0)); 应该被更新为取装置作为最后一个参数： torch::Tensor fake_labels = torch::zeros(batch.data.size(0), device); 对于张量其创建是不在我们手里，像那些从MNIST数据集的到来，我们必须插入明确的以（）通话。这意味着 torch::Tensor real_images = batch.data; 变 torch::Tensor real_images = batch.data.to(device); 而且我们的模型参数应该被移动到正确的设备： generator->to(device); discriminator->to(device); Note 如果张量已经住供应到在设备上（），该呼叫是一个空操作。无需额外的副本。 在这一点上，我们只是做我们以前的CPU-居住代码更加明确。不过，现在也很容易对设备更改为CUDA设备： torch::Device device(torch::kCUDA) 而现在所有的张量将住在GPU上，调入快速CUDA内核的所有操作，不用我们无需更改任何代码的下游。如果我们想要指定一个特定的设备索引，它可以作为第二个参数设备构造函数传递。如果我们想要不同张量住在不同设备上，我们可以（CUDA装置0和其他CUDA装置1上例如一种）通过单独的装置的实例。我们甚至可以这样做动态配置，这往往是有益的，使我们的培训脚本更便于携带： torch::Device device = torch::kCPU; if (torch::cuda::is_available()) { std::cout 甚至 torch::Device device(torch::cuda::is_available() ? torch::kCUDA : torch::kCPU); 检查点和恢复训练状况 最后的增强，我们应该对我们的训练脚本定期保存我们的模型参数，我们优化的状态，以及一些生成的图像样本的状态。如果我们的电脑是在训练过程中间崩溃，前两个将使我们能够恢复训练状态。对于长期的培训课程，这是绝对必要的。幸运的是，C ++前端提供了一个API来序列和反序列化两者模型和优化器状态，​​以及个别张量。 核心API因为这是Torch ::保存（的东西，文件名）HTG2]和Torch ::负载（的东西，文件名）HTG6]其中事情可以是torch::ン::模块亚类或类似的亚当的优化实例对象，我们在我们的培训讲稿。让我们来更新我们的训练循环检查点在一定的时间间隔模型和优化状态： if (batch_index % kCheckpointEvery == 0) { // Checkpoint the model and optimizer state. torch::save(generator, \"generator-checkpoint.pt\"); torch::save(generator_optimizer, \"generator-optimizer-checkpoint.pt\"); torch::save(discriminator, \"discriminator-checkpoint.pt\"); torch::save(discriminator_optimizer, \"discriminator-optimizer-checkpoint.pt\"); // Sample the generator and save the images. torch::Tensor samples = generator->forward(torch::randn({8, kNoiseSize, 1, 1}, device)); torch::save((samples + 1.0) / 2.0, torch::str(\"dcgan-sample-\", checkpoint_counter, \".pt\")); std::cout checkpoint \" 其中kCheckpointEvery是一个整数设置为类似100检查点每100批次和checkpoint_counter是一个反撞我们每一个检查点的时间。 要恢复训练状态，可以将所有的模型之后添加这样的诗句和优化创建，但训练循环之前： torch::optim::Adam generator_optimizer( generator->parameters(), torch::optim::AdamOptions(2e-4).beta1(0.5)); torch::optim::Adam discriminator_optimizer( discriminator->parameters(), torch::optim::AdamOptions(2e-4).beta1(0.5)); if (kRestoreFromCheckpoint) { torch::load(generator, \"generator-checkpoint.pt\"); torch::load(generator_optimizer, \"generator-optimizer-checkpoint.pt\"); torch::load(discriminator, \"discriminator-checkpoint.pt\"); torch::load( discriminator_optimizer, \"discriminator-optimizer-checkpoint.pt\"); } int64_t checkpoint_counter = 0; for (int64_t epoch = 1; epoch & batch : *data_loader) { 检查生成的图像 我们的培训剧本现已完成。我们准备训练我们的甘，无论是在CPU或GPU。要检查我们的训练过程的中介输出，为此我们添加的代码，以图像样本定期保存到“dcgan-sample-xxx.pt”文件，我们可以写一个小Python脚本加载张量，并与matplotlib显示它们： from __future__ import print_function from __future__ import unicode_literals import argparse import matplotlib.pyplot as plt import torch parser = argparse.ArgumentParser() parser.add_argument(\"-i\", \"--sample-file\", required=True) parser.add_argument(\"-o\", \"--out-file\", default=\"out.png\") parser.add_argument(\"-d\", \"--dimension\", type=int, default=3) options = parser.parse_args() module = torch.jit.load(options.sample_file) images = list(module.parameters())[0] for index in range(options.dimension * options.dimension): image = images[index].detach().cpu().reshape(28, 28).mul(255).to(torch.uint8) array = image.numpy() axis = plt.subplot(options.dimension, options.dimension, 1 + index) plt.imshow(array, cmap=\"gray\") axis.get_xaxis().set_visible(False) axis.get_yaxis().set_visible(False) plt.savefig(options.out_file) print(\"Saved \", options.out_file) 现在让我们来训练我们的模型大约30时期： root@3c0711f20896:/home/build# make && ./dcgan 10:17:57 Scanning dependencies of target dcgan [ 50%] Building CXX object CMakeFiles/dcgan.dir/dcgan.cpp.o [100%] Linking CXX executable dcgan [100%] Built target dcgan CUDA is available! Training on GPU. [ 1/30][200/938] D_loss: 0.4953 | G_loss: 4.0195 -> checkpoint 1 [ 1/30][400/938] D_loss: 0.3610 | G_loss: 4.8148 -> checkpoint 2 [ 1/30][600/938] D_loss: 0.4072 | G_loss: 4.36760 -> checkpoint 3 [ 1/30][800/938] D_loss: 0.4444 | G_loss: 4.0250 -> checkpoint 4 [ 2/30][200/938] D_loss: 0.3761 | G_loss: 3.8790 -> checkpoint 5 [ 2/30][400/938] D_loss: 0.3977 | G_loss: 3.3315 ... -> checkpoint 120 [30/30][938/938] D_loss: 0.3610 | G_loss: 3.8084 并显示出图的图像： root@3c0711f20896:/home/build# python display.py -i dcgan-sample-100.pt Saved out.png 这应该是这个样子： 数字！万岁！现在球在你的场内：您可以改进模型，使数字更好看？ 结论 本教程希望能够给您的PyTorch C ++前端的消化消化。机器学习库像PyTorch必然具有非常广阔和丰富的API。因此，有很多的概念，我们没有时间或空间在这里讨论。不过，我鼓励你尝试了API，当你遇到问题请教我们的文档，特别是库API 部分。此外，请记住，你可以期望的C ++前端遵循的设计和Python的前端的语义，只要我们能做到这一点，那么你可以利用这一点来提高你的学习速度。 Tip You can find the full source code presented in this tutorial in this repository. 与往常一样，如果您遇到任何问题或有任何疑问，您可以使用我们的论坛或 GitHub的问题取得联系。 Previous Was this helpful? Yes No Thank you ©版权所有2017年，PyTorch。 使用PyTorch C ++前端 动机 编写基本应用 定义神经网络模型 模块API基础 定义模块和注册参数 注册子模和遍历模块层次结构 在正向模式中运行的网络 模块所有权 定义DCGAN模块 什么是甘阿甘？ [HTG0所述发生器模块 [HTG0所述鉴别器模块 加载数据 写作训练循环 移动到GPU 和点校验恢复训练状况 检查生成的图像 结论 ![](https://www.facebook.com/tr?id=243028289693773&ev=PageView &noscript=1) 分析流量和优化经验，我们为这个站点的Cookie。通过点击或导航，您同意我们的cookies的使用。因为这个网站目前维护者，Facebook的Cookie政策的适用。了解更多信息，包括有关可用的控制：[饼干政策HTG1。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes/autograd.html":{"url":"notes/autograd.html","title":"自动求导机制","keywords":"","body":"Autograd力学 这说明将呈现autograd是如何工作的，并记录操作的概述。这不是绝对必要了解这一切，但我们建议熟悉它，因为它会帮助你编写更高效，更清洁的程序，可以帮助您进行调试。 从不含子图向后 每张量有一个标志：requires_grad，其允许从梯度计算子图的细粒排斥和可以提高工作效率。 requires_grad 如果有一个单一的输入操作，需要梯度，它的输出也需要梯度。相反，只有当所有的输入不需要梯度，输出也不会需要它。向后计算是从来没有在子图，所有的张量并不需要梯度进行。 >>> x = torch.randn(5, 5) # requires_grad=False by default >>> y = torch.randn(5, 5) # requires_grad=False by default >>> z = torch.randn((5, 5), requires_grad=True) >>> a = x + y >>> a.requires_grad False >>> b = a + z >>> b.requires_grad True 当你想冻结模型的一部分，这是非常有用的，或者你事先知道你不打算使用渐变w.r.t.一些参数。例如，如果你想微调预训练CNN，这足以切换requires_grad标志的冷冻基地，没有中间缓冲区将被保存，直到计算得到最后一个层，其中，所述仿射变换将使用需要梯度权重，并且所述网络的输出也将需要它们。 model = torchvision.models.resnet18(pretrained=True) for param in model.parameters(): param.requires_grad = False # Replace the last fully-connected layer # Parameters of newly constructed modules have requires_grad=True by default model.fc = nn.Linear(512, 100) # Optimize only the classifier optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9) autograd如何编码的历史 Autograd是反向自动分化系统。从概念上讲，autograd记录的图形记录所有创建该数据的操作为您执行操作，给你一个向无环图，叶子是输入张量和根输出张量。通过跟踪从根此图的叶子，可以自动计算使用链式法则的梯度。 在内部，autograd表示该图表为函数对象（真表达式）的曲线图，其可以是申请（） ED来计算评价的曲线图的结果。当计算向前传，同时autograd执行所请求的计算和积聚的曲线图表示计算梯度（的.grad_fn属性函数中的每个 torch.Tensor是一个入口点到该图）。当向前传球完成后，我们评估该图在向后传递给计算梯度。 要注意的重要一点是，图形是从头开始，在每次迭代重建，而这正是允许使用任意Python控制流语句，可以在每次迭代改变图形的整体形状和大小。你不必编码所有可能的路径在启动之前的训练 你运行的是你区分什么。 就地与autograd操作 在autograd支持就地操作是很难的事，我们不鼓励在大多数情况下，它们的使用。 Autograd咄咄逼人的缓冲释放和再利用使得它非常有效，也有极少数场合就地操作任何显著量实际上更低的内存使用率。除非你在重内存压力工作，你可能永远需要使用它们。 有限制就地操作的应用主要有两个原因： 就地操作可能会覆盖计算梯度所需的值。 每个就地操作实际上需要执行重写计算图。外的地方版本简单分配新对象，并保持引用旧图，而就地操作，需要更改的所有投入的创作者到功能表示此操作。这可以是棘手的，尤其是如果有引用相同的存储（例如，通过索引或调换创建）许多张量，和就地如果改性输入的存储是通过引用的函数实际上将产生一个错误的任何其他张量。 就地正确性检查 每张量保持一个版本计数器，即每递增它标志着在任何操作脏的时间。当一个函数保存任何张量为落后的，其包含的张量的一个版本计数器被保存为好。一旦你进入self.saved_tensors检查，如果它比保存的值将引发一个错误更大。这确保了如果你使用就地功能，没有看到任何错误，你可以肯定的是，计算的梯度是正确的。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes/broadcasting.html":{"url":"notes/broadcasting.html","title":"广播语义","keywords":"","body":"广播语义 许多PyTorch运营支持[ NumPy的 广播 语义 HTG9。 简言之，如果一个PyTorch操作支持广播，那么它的张量参数可以自动扩展为等于尺寸的（不使数据的副本）。 通用语义 二张量“broadcastable”如果以下规则成立： 每个张量至少有一个尺寸。 当迭代的尺寸大小，在开始尾部尺寸，该尺寸大小必须是相等的，它们中的一个是1，或它们中的一个不存在。 例如： >>> x=torch.empty(5,7,3) >>> y=torch.empty(5,7,3) # same shapes are always broadcastable (i.e. the above rules always hold) >>> x=torch.empty((0,)) >>> y=torch.empty(2,2) # x and y are not broadcastable, because x does not have at least 1 dimension # can line up trailing dimensions >>> x=torch.empty(5,3,4,1) >>> y=torch.empty( 3,1,1) # x and y are broadcastable. # 1st trailing dimension: both have size 1 # 2nd trailing dimension: y has size 1 # 3rd trailing dimension: x size == y size # 4th trailing dimension: y dimension doesn't exist # but: >>> x=torch.empty(5,2,4,1) >>> y=torch.empty( 3,1,1) # x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3 如果两个张量×，Y的“broadcastable”，所得到的张量大小的计算方法如下： 如果×和Y不等于，在前面加上1用更少的尺寸张量的尺寸，使维数它们相等的长度。 然后，对于每个维度大小，所得到的尺寸大小是×和尺寸Y沿着该维度的最大值。 For Example: # can line up trailing dimensions to make reading easier >>> x=torch.empty(5,1,4,1) >>> y=torch.empty( 3,1,1) >>> (x+y).size() torch.Size([5, 3, 4, 1]) # but not necessary: >>> x=torch.empty(1) >>> y=torch.empty(3,1,7) >>> (x+y).size() torch.Size([3, 1, 7]) >>> x=torch.empty(5,2,4,1) >>> y=torch.empty(3,1,1) >>> (x+y).size() RuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1 就地语义 一个复杂的是，就地操作不允许就地张量改变形状作为广播的结果。 For Example: >>> x=torch.empty(5,3,4,1) >>> y=torch.empty(3,1,1) >>> (x.add_(y)).size() torch.Size([5, 3, 4, 1]) # but: >>> x=torch.empty(1,3,1) >>> y=torch.empty(3,1,7) >>> (x.add_(y)).size() RuntimeError: The expanded size of the tensor (1) must match the existing size (7) at non-singleton dimension 2. 向后兼容 PyTorch的现有版本允许某些逐点函数来执行对具有不同形状的张量，只要在每个张量元素的数量是相等的。逐点操作将随后通过查看每个张量作为1维的来进行。 PyTorch现在支持广播和“一维”逐点行为被废弃了，会产生在张量不broadcastable，但有相同数量的元素的情况下，一个Python警告。 需要注意的是引入广播可能会导致以下情况：张量不具有相同的形状，向后兼容的更改，但broadcastable，并且具有相同数目的元素。例如： >>> torch.add(torch.ones(4,1), torch.randn(4)) 将先前产生具有尺寸的张量：torch.Size（[4,1]），但现在产生具有尺寸的张量：torch.Size（[4,4]）。为了帮助识别代码的情况下向后通过广播介绍不兼容性可能存在，你可以通过设置 torch.utils.backcompat.broadcast_warning.enabled 至真，这将产生一个python在这种情况下警告。 For Example: >>> torch.utils.backcompat.broadcast_warning.enabled=True >>> torch.add(torch.ones(4,1), torch.ones(4)) __main__:1: UserWarning: self and other do not have the same shape, but are broadcastable, and have the same number of elements. Changing behavior in a backwards incompatible manner to broadcasting rather than viewing as 1-dimensional. Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes/cpu_threading_torchscript_inference.html":{"url":"notes/cpu_threading_torchscript_inference.html","title":"CPU线程和TorchScript推理","keywords":"","body":"CPU线程和TorchScript推理 PyTorch允许TorchScript模型推理过程中使用多个CPU线程。下图显示了不同程度的并行人们会发现在一个典型的应用： 一个或多个线程推断在给定的输入，执行一个模型的直传。每个推理线程调用JIT解释执行模型内嵌的OPS，一个接一个。模型可以利用一个叉 TorchScript原语发起异步任务。在一次分叉几个操作导致在并行执行的任务。的叉操作者返回一个未来可用于稍后同步上，例如对象： @torch.jit.script def compute_z(x): return torch.mm(x, self.w_z) @torch.jit.script def forward(x): # launch compute_z asynchronously: fut = torch.jit._fork(compute_z, x) # execute the next operation in parallel to compute_z: y = torch.mm(x, self.w_y) # wait for the result of compute_z: z = torch.jit._wait(fut) return y + z PyTorch使用单个线程池的-OP间并行性，这个线程池是由在应用过程中的分叉的所有任务进行推演共享。 除了- OP间并行性，也PyTorch可以利用OPS（帧内运算并行）内的多个线程。这可能是在许多情况下，包括大张量等元素方面的OPS，卷积，GEMMS，嵌入查找和有用的。 构建选项 PyTorch使用内部ATEN库来实现欢声笑语。除此之外，PyTorch还可以与支持外部库，如 MKL 和 MKL-DNN ，加快对CPU计算的建造。 ATEN，MKL和MRL-DNN支持内部运算的并行和取决于以下并行库来实现它： 的OpenMP - 一个标准（和图书馆，通常有一个编译器运），广泛用于外部库; > TBB - 一个较新的并行库基于任务的并行性和并发环境优化。 > > OpenMP的历史已经使用了大量的库。它是著名的相对易用性和支持基于循环的并行性和其他原语。与此同时OpenMP是不知道与应用程序使用的其他线程库一个良好的互操作性。特别是，OpenMP的并不能保证一个每个进程内部运算的线程池会在应用程序中使用。相反，两个不同的运算线程间可能会使用内部的运算工作不同OpenMP的线程池。这可能会导致大量的应用程序所使用的线程。 TBB是用来在外部库在较小程度上，但，在同一时间，为并发环境进行了优化。 PyTorch的TBB后端保证有一个独立的，单一的，每个进程内部运算线程通过所有在运行的应用程序的OPS的使用池。 根据不同的使用情况下，可能会发现一个或另一个并行库在他们的应用程序更好的选择。 PyTorch允许在构建时用下面的生成选项使用宏正和其他库并行后端的选择： 图书馆 | 构建选项 | 值 | 笔记 ---|---|---|--- ATEN | ATEN_THREADING | OMP（默认），TBB | MKL | MKL_THREADING | （相同） | 为了使MKL使用BLAS = MKL MRL-DNN | MKLDNN_THREADING | (same) | 为了使MKL-DNN用USE_MKLDNN = 1 强烈建议不要一个构建中混合使用OpenMP和TBB。 任何TBB值的上述要求USE_TBB = 1建立设定（缺省值：OFF）。一个单独的设置USE_OPENMP = 1（默认值：ON）需要将OpenMP并行。 运行时API 下面的API是用来控制线的设置： 并行的类型 | 设置 | Notes ---|---|--- 跨运算的并行 | 在:: set_num_interop_threads，在:: get_num_interop_threads（C ++） set_num_interop_threads，get_num_interop_threads（Python中， torch 模块） | 设定*功能只能使用一次，并且只有在启动期间调用时，实际的运算符之前运行; 线程的默认编号：CPU核心数量。 内部运算的并行 | 在:: set_num_threads，在:: get_num_threads（C ++）set_num_threads`` get_num_threads（Python中， torch模块） 环境变量：OMP_NUM_THREADS和MKL_NUM_THREADS 对于内部运算的并行设置，在:: set_num_threads，torch.set_num_threads总是优先于环境变量，MKL_NUM_THREADS变量优先于OMP_NUM_THREADS。 注意 可用于调试parallel_info关于线程设置和工具打印信息。类似的输出也可以在Python与torch.__配置得到__。parallel_info（）调用。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes/cuda.html":{"url":"notes/cuda.html","title":"CUDA语义","keywords":"","body":"CUDA语义 torch.cuda用于设置和运行CUDA操作。它跟踪当前选择的GPU，而你分配所有CUDA张量将默认在该设备上创建。所选择的设备可以与 torch.cuda.device上下文管理器被改变。 然而，一旦张量分配，你可以在上面做的操作，不论所选择的设备的，其结果将始终放置在相同的装置上张。 横GPU操作默认不允许，以 copy_除外（）等方法与复制样的功能，如 至（）和 CUDA（）。除非你能对等网络存储器存取，任何企图发动对分布在不同的设备上会产生一个错误张量欢声笑语。 下面你可以找到一个小例子展示了这一点： cuda = torch.device('cuda') # Default CUDA device cuda0 = torch.device('cuda:0') cuda2 = torch.device('cuda:2') # GPU 2 (these are 0-indexed) x = torch.tensor([1., 2.], device=cuda0) # x.device is device(type='cuda', index=0) y = torch.tensor([1., 2.]).cuda() # y.device is device(type='cuda', index=0) with torch.cuda.device(1): # allocates a tensor on GPU 1 a = torch.tensor([1., 2.], device=cuda) # transfers a tensor from CPU to GPU 1 b = torch.tensor([1., 2.]).cuda() # a.device and b.device are device(type='cuda', index=1) # You can also use ``Tensor.to``to transfer a tensor: b2 = torch.tensor([1., 2.]).to(device=cuda) # b.device and b2.device are device(type='cuda', index=1) c = a + b # c.device is device(type='cuda', index=1) z = x + y # z.device is device(type='cuda', index=0) # even within a context, you can specify the device # (or give a GPU index to the .cuda call) d = torch.randn(2, device=cuda2) e = torch.randn(2).to(cuda2) f = torch.randn(2).cuda(cuda2) # d.device, e.device, and f.device are all device(type='cuda', index=2) 异步执行 默认情况下，GPU的操作都是异步的。当你调用一个使用GPU功能，操作排队的 __ 到特定的设备，但直到后来不一定执行。这使我们能够并行执行更多的计算，包括CPU或其它GPU的操作。 一般情况下，异步计算的效果是不可见的呼叫者，因为（1）的每个设备在它们被排队的顺序来执行操作，和（2）PyTorch复制CPU和GPU之间或两个GPU之间的数据时自动执行必要的同步。因此，计算将继续进行，如果每一个操作同步执行。 可以通过设置环境变量 CUDA_LAUNCH_BLOCKING强制同步计算= 1 。当在GPU上发生错误，这是很方便的。 （随着异步执行，不报告这样的错误，直到之后实际执行的操作，因此堆栈跟踪不显示它被请求）。 作为例外，有几个功能，如 至（）和 copy_（）承认显式non_blocking参数，它允许呼叫方旁路同步时，它是不必要的。另一个例外是CUDA流，解释如下。 CUDA流 A CUDA流是执行的线性序列属于特定的设备。你通常不需要明确创建一个：在默认情况下，每个设备使用自己的“默认”流。 每个流内的操作被序列在它们被创建的顺序，但来自不同流的操作可以以任何相对顺序同时执行，除非明确的同步功能（如 同步（） 或 wait_stream（））被使用。例如，下面的代码是不正确： cuda = torch.device('cuda') s = torch.cuda.Stream() # Create a new stream. A = torch.empty((100, 100), device=cuda).normal_(0.0, 1.0) with torch.cuda.stream(s): # sum() may start execution before normal_() finishes! B = torch.sum(A) 当“当前流”是默认流，PyTorch自动执行必要的同步数据时，到处移动，如上所述。然而，使用非默认流时，它是用户的责任，以确保正确的同步。 存储器管理 PyTorch使用缓存内存分配器，以加快内存分配。这允许快速内存释放不同步设备。然而，由分配器所管理的未使用的存储器仍然会显示为如果在使用NVIDIA- SMI。您可以使用 memory_allocated（） 和 max_memory_allocated（）监视内存占用的由张量，并使用 memory_cached（） 和 max_memory_cached（）监视内存缓存分配器管理。主叫 empty_cache（） 释放所有 从PyTorch未使用 高速缓存的存储器，使得那些可由其他GPU应用中。然而，由张量占用GPU内存不会被释放，因此它不能增加GPU的内存可用于PyTorch量。 CUFFT计划缓存 对于每个CUDA设备，CUFFT的LRU高速缓存预案来加快重复运行FFT方法（例如， torch.fft（） ）上的CUDA张量与相同的结构相同的几何形状。由于一些CUFFT计划可能分配GPU内存，这些缓存有一个最大容量。 您可以控制和查询与以下API当前设备的高速缓存的性能： torch.backends.cuda.cufft_plan_cache.max_size给出缓存的容量（默认为4096上CUDA 10和更新，和1023对旧CUDA版本）。设置这个值直接修改的能力。 torch.backends.cuda.cufft_plan_cache.size给出的当前驻留在缓存中的计划数。 torch.backends.cuda.cufft_plan_cache.clear（）清除缓存。 为了控制和非默认装置的查询计划的高速缓存，则可以用索引任一个torch.device的 torch.backends.cuda.cufft_plan_cache对象对象或设备索引，并获得上述的属性之一。例如，要设置高速缓冲存储器的容量为设备1，可以写torch.backends.cuda.cufft_plan_cache [1] .max_size = 10。 最佳实践 设备无关的代码 由于PyTorch的结构，则可能需要明确写入设备无关的（CPU或GPU）代码;实例，可创建新的张量作为回归神经网络的初始隐蔽状态。 第一步是确定GPU是否应使用与否。一个常见的模式是使用Python的argparse模块在用户参数读取，并且具有可被用于禁用CUDA的标志，结合 is_available（）。在下文中，args.device结果在可用于张量移动到CPU或CUDA一个torch.device对象。 import argparse import torch parser = argparse.ArgumentParser(description='PyTorch Example') parser.add_argument('--disable-cuda', action='store_true', help='Disable CUDA') args = parser.parse_args() args.device = None if not args.disable_cuda and torch.cuda.is_available(): args.device = torch.device('cuda') else: args.device = torch.device('cpu') 现在，我们有args.device，我们可以用它到所需的设备上创建一个张量。 x = torch.empty((8, 42), device=args.device) net = Network().to(device=args.device) 这可以在许多情况下，以产生设备无关代码的使用。下面是使用的DataLoader时的例子： cuda0 = torch.device('cuda:0') # CUDA GPU 0 for i, x in enumerate(train_loader): x = x.to(cuda0) 当使用多GPU的系统上工作，你可以使用CUDA_VISIBLE_DEVICES环境标志来管理其GPU的可供PyTorch。如上所述，手动控制其中GPU上创建一个张量，最好的做法是使用一个 torch.cuda.device上下文管理器。 print(\"Outside device is 0\") # On device 0 (default in most scenarios) with torch.cuda.device(1): print(\"Inside device is 1\") # On device 1 print(\"Outside device is still 0\") # On device 0 如果你有一个张量，并希望创造在同一设备上同一类型的新张，那么你可以使用torch.Tensor.new_ *方法（参见 torch.Tensor）。虽然前面提到的Torch 。*工厂函数（ 创建行动 ）取决于当前GPU上下文和你传递的属性参数torch.Tensor.new_ *方法保持装置和张量的其他属性。 这是推荐的做法，当创建模块在新的张量需要在直传过程中内部创建的。 cuda = torch.device('cuda') x_cpu = torch.empty(2) x_gpu = torch.empty(2, device=cuda) x_cpu_long = torch.empty(2, dtype=torch.int64) y_cpu = x_cpu.new_full([3, 2], fill_value=0.3) print(y_cpu) tensor([[ 0.3000, 0.3000], [ 0.3000, 0.3000], [ 0.3000, 0.3000]]) y_gpu = x_gpu.new_full([3, 2], fill_value=-5) print(y_gpu) tensor([[-5.0000, -5.0000], [-5.0000, -5.0000], [-5.0000, -5.0000]], device='cuda:0') y_cpu_long = x_cpu_long.new_tensor([[1, 2, 3]]) print(y_cpu_long) tensor([[ 1, 2, 3]]) 如果你想创建另一个张量的相同类型和大小的张量，并与任一或零填充， ones_like（） 或 zeros_like（） 被设置作为方便的辅助功能（其也保留torch.device和torch.dtype 张量的）。 x_cpu = torch.empty(2, 3) x_gpu = torch.empty(2, 3) y_cpu = torch.ones_like(x_cpu) y_gpu = torch.zeros_like(x_gpu) 使用固定的内存缓冲区 主机到GPU副本要快得多，当他们从固定（锁定页）内存起源。 CPU张量和存储器露出 pin_memory（） 的方法，即返回对象的一个​​副本，其中放入一个钉扎区域数据。 此外，一旦你钉住张量或存储，您可以使用异步GPU副本。只是通过一个额外的non_blocking =真参数向 至（） 或 CUDA（） 呼叫。这可以使用具有计算重叠的数据传输。 您可以在 的DataLoader回批通过传递pin_memory =真给它的构造放置在固定的内存。 使用nn.DataParallel而不是多处理 涉及成批输入和多个GPU大多数使用情况应默认使用 数据并行利用多于一个的GPU。即使在GIL，一个Python程序可以饱和多个GPU。 随着0.1.9版本的GPU（8个）的大量可能没有被充分利用。然而，这是一个已知的问题，目前正在积极发展。与往常一样，测试你的使用情况。 有显著的注意事项使用CUDA型号 多重处理 ;，除非小心地恰好满足数据处理的要求，很可能你的程序将有不正确的或不确定的行为。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes/extending.html":{"url":"notes/extending.html","title":"扩展PyTorch","keywords":"","body":"扩展PyTorch 在这份说明中，我们将介绍torch.nn 延长 的方式，[torch.autograd](../autograd.html#module-torch.autograd \"torch.autograd\")，并编写利用我们的C库定制的C扩展。 延伸[ torch.autograd](../autograd.html#module-torch.autograd \"torch.autograd\") 加法运算到 autograd需要实现一个新的 函数亚类为每个操作。回想一下， 功能 S是什么 autograd用途计算结果和梯度和编码操作历史。每一个新的功能需要实现2种方法： 向前（） - 执行操作的代码。只要你想，可以采取许多参数，其中一些是可选的，如果指定的默认值。各种Python对象都在这里接受。 张量参数跟踪历史（即，与requires_grad =真）将被转换为那些不前的跟踪历史打电话，和他们的使用将在图形注册。请注意，这个逻辑不会遍历列表/类型的字典/任何其他的数据结构，将只考虑张量S是直接的参数调用。可以返回一个单一张量输出，或 元组 张量的S，如果有多个输出。另外，请参考 功能的文档找到有用的方法的描述，只能从 前被调用（ ）。 向后（） - 梯度公式。这将被给定为许多张量参数作为有输出，与它们中的每代表梯度w.r.t.该输出。因为有输入则它应该返回尽可能多的张量S，与它们中的每含有梯度w.r.t.其相应的输入。如果输入不要求梯度（HTG14] needs_input_grad 是指示每个输入是否需要梯度计算布尔值的元组），或者被非张量的对象，就可以返回无 [HTG25。另外，如果您有可选参数为[向前（） ](../autograd.html#torch.autograd.Function.forward \"torch.autograd.Function.forward\")你可以返回更多的梯度比有投入，只要他们都[无 ](https://docs.python.org/3/library/constants.html#None \"\\(in Python v3.7\\)\")。 下面你可以找到的代码为线性功能从 torch.nn，以补充意见： # Inherit from Function class LinearFunction(Function): # Note that both forward and backward are @staticmethods @staticmethod # bias is an optional argument def forward(ctx, input, weight, bias=None): ctx.save_for_backward(input, weight, bias) output = input.mm(weight.t()) if bias is not None: output += bias.unsqueeze(0).expand_as(output) return output # This function has only a single output, so it gets only one gradient @staticmethod def backward(ctx, grad_output): # This is a pattern that is very convenient - at the top of backward # unpack saved_tensors and initialize all gradients w.r.t. inputs to # None. Thanks to the fact that additional trailing Nones are # ignored, the return statement is simple even when the function has # optional inputs. input, weight, bias = ctx.saved_tensors grad_input = grad_weight = grad_bias = None # These needs_input_grad checks are optional and there only to # improve efficiency. If you want to make your code simpler, you can # skip them. Returning gradients for inputs that don't require it is # not an error. if ctx.needs_input_grad[0]: grad_input = grad_output.mm(weight) if ctx.needs_input_grad[1]: grad_weight = grad_output.t().mm(input) if bias is not None and ctx.needs_input_grad[2]: grad_bias = grad_output.sum(0).squeeze(0) return grad_input, grad_weight, grad_bias 现在，为了更容易地使用这些定制的OPS，我们建议他们走样应用方法： linear = LinearFunction.apply 在这里，我们给由非张量参数的参数化功能的附加示例： class MulConstant(Function): @staticmethod def forward(ctx, tensor, constant): # ctx is a context object that can be used to stash information # for backward computation ctx.constant = constant return tensor * constant @staticmethod def backward(ctx, grad_output): # We return as many input gradients as there were arguments. # Gradients of non-Tensor arguments to forward must be None. return grad_output * ctx.constant, None 注意 输入向后，即grad_output，也可以是张量的跟踪历史。因此，如果向后与可微操作，实现（例如，另一个定制函数的调用），高阶导数将工作。 你可能想检查是否实际执行的落后方法计算你的函数的导数。它可以通过使用小的有限差与数值近似比较： from torch.autograd import gradcheck # gradcheck takes a tuple of tensors as input, check if your gradient # evaluated with these tensors are close enough to numerical # approximations and returns True if they all verify this condition. input = (torch.randn(20,20,dtype=torch.double,requires_grad=True), torch.randn(30,20,dtype=torch.double,requires_grad=True)) test = gradcheck(linear, input, eps=1e-6, atol=1e-4) print(test) 参见 数值梯度检查 用于在有限差分梯度比较的更多细节。 延伸 torch.nn NN出口两种接口 - 模块及其功能的版本。您可以以两种方式扩展它，但我们建议您使用模块的各种层，持有任何参数或缓冲区，并推荐使用函数形式参数的操作较少样激活功能，池等 添加的操作的功能版本已经完全覆盖在上面的部分。 添加 模块 由于 NN大量利用 autograd ，添加一个新的 模块 需要实现一个 函数 执行操作，并且可以计算出梯度。从现在开始，让我们假设我们要实现一个线性模块，我们必须在以上列表中实现的功能。有添加这需要非常少的代码。现在，有一些需要实现两个功能： __init__（ 可选 ） - 发生在参数如内核尺寸，特征的数字等，并初始化参数和缓冲剂。 向前（） - 实例化 函数，并使用它来执行操作。这是非常类似于上面所示的功能性包装。 这是一个线性模块如何可以实现： class Linear(nn.Module): def __init__(self, input_features, output_features, bias=True): super(Linear, self).__init__() self.input_features = input_features self.output_features = output_features # nn.Parameter is a special kind of Tensor, that will get # automatically registered as Module's parameter once it's assigned # as an attribute. Parameters and buffers need to be registered, or # they won't appear in .parameters() (doesn't apply to buffers), and # won't be converted when e.g. .cuda() is called. You can use # .register_buffer() to register buffers. # nn.Parameters require gradients by default. self.weight = nn.Parameter(torch.Tensor(output_features, input_features)) if bias: self.bias = nn.Parameter(torch.Tensor(output_features)) else: # You should always register all possible parameters, but the # optional ones can be None if you want. self.register_parameter('bias', None) # Not a very smart way to initialize weights self.weight.data.uniform_(-0.1, 0.1) if bias is not None: self.bias.data.uniform_(-0.1, 0.1) def forward(self, input): # See the autograd section for explanation of what happens here. return LinearFunction.apply(input, self.weight, self.bias) def extra_repr(self): # (Optional)Set the extra information about this module. You can test # it by printing an object of this class. return 'in_features={}, out_features={}, bias={}'.format( self.in_features, self.out_features, self.bias is not None ) 编写自定义C ++扩展 看到这个[ PyTorch教程HTG1用于详细说明和实施例。 单证可在 torch.utils.cpp_extension 。 编写自定义的C扩展 实施例可在本GitHub的库。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes/faq.html":{"url":"notes/faq.html","title":"常见问题","keywords":"","body":"常见问题 我的模型报告“CUDA运行时错误（2）：内存不足” 由于错误信息提示，您已经在GPU上运行的内存不足。因为我们经常处理大量的数据PyTorch的，小错可迅速导致你的程序使用了所有的GPU ;幸运的是，在这些情况下修复往往比较简单。这里有一些共同的东西进行检查： 不要堆积在你的训练循环的历史。 缺省情况下，涉及的变量需要梯度计算将保持历史。这意味着你应该避免在计算中，将活过你的训练循环，例如，跟踪统计信息时，使用这样的变量。相反，你应该分离变量或访问其基础数据。 有时，它可以是非明显，当微变量可能发生。考虑下面的训练循环（从源删节）： total_loss = 0 for i in range(10000): optimizer.zero_grad() output = model(input) loss = criterion(output) loss.backward() optimizer.step() total_loss += loss 在这里，total_loss是在你的训练循环积累的历史，因为损失是autograd历史上的一个微变量。可以通过编写 total_loss =浮子（损失）代替解决这个问题。 这个问题的其他情况：HTG0] 1 [HTG1。 不要守住张量和你不需要的变量。 [HTG1如果您分配一个张量或变量到本地，Python将不会解除分配，直到当地超出范围。您可以使用德尔 ×释放此引用。同样地，如果分配一个张量或变量的一个对象的成员变量，它不会解除分配，直到对象超出范围。你会得到最好的内存使用情况，如果你不抓住你不需要的临时。 当地人的范围可能比预期的大。例如： for i in range(5): intermediate = f(input[i]) result += g(intermediate) output = h(result) return output 在此，中间体遗体活甚至当H正在执行，因为它的范围挤出过去的循环的结束。较早释放它，你应该德尔 中间体当你用它做。 不要太大序列运行RNNs。 的存储器通过RNN到backpropagate，所需的量与的RNN输入的长度成线性比例;这样，就会耗尽存储器如果试图养活RNN的序列太长。 造成这一现象的技术术语为经过时间反向传播，并有大量关于如何实现截断BPTT，包括字的语言模型例如参考;截断被处理如这个论坛帖子所述的重新打包功能。 不要使用太大的线性层。 的线性层nn.Linear（M， N）使用 O （ n的 M ） O（nm）的 O （ n的 M ） 存储器：即，权重的存储器要求与特征的数量的二次方成比例。这是很容易为通过您的记忆吹这种方式（请记住，你将需要重中的至少两倍的大小，因为你还需要存储的梯度。） 我的GPU内存不释放正确 PyTorch使用缓存内存分配器，以加快内存分配。其结果是，在NVIDIA-SMI通常不反映真实的存储器使用所示的值。参见 内存管理 关于GPU内存管理的更多细节。 如果退出的Python即使您的GPU内存不释放，这很可能是一些Python子进程仍然活着。您可能会发现他们通过PS -elf | 用grep 蟒和手动杀死它们与杀 -9 [PID]。 我的数据加载工返乡相同随机数 您可能使用其他库，以生成数据集中的随机数。例如，当工人的子过程通过叉开始与NumPy的RNG被复制。参见 torch.utils.data.DataLoader的与它的worker_init_fn工人[关于如何正确设置随机种子文件HTG12 ]选项。 我经常性的网络不与数据并行工作 有在使用收拾 序列的微妙 - & GT ; 复发 网络 - & GT ; 解压 序列在 模块图案 与 数据并行 或 data_parallel（）。输入到每个向前（）每个设备上仅是整个输入的一部分。因为解包运算 torch.nn.utils.rnn.pad_packed_sequence（） 缺省仅焊盘到它看到最长输入，即，所述最长那个特定的设备，当结果被聚集在一起会发生大小不匹配。因此，可以改为取total_length的 pad_packed_sequence参数的优势（） ，以确保该向前（）调用返回相同长度的序列。例如，你可以这样写： from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence class MyModule(nn.Module): # ... __init__, other methods, etc. # padded_input is of shape [B x T x *] (batch_first mode) and contains # the sequences sorted by lengths # B is the batch size # T is max sequence length def forward(self, padded_input, input_lengths): total_length = padded_input.size(1) # get the max sequence length packed_input = pack_padded_sequence(padded_input, input_lengths, batch_first=True) packed_output, _ = self.my_lstm(packed_input) output, _ = pad_packed_sequence(packed_output, batch_first=True, total_length=total_length) return output m = MyModule().cuda() dp_m = nn.DataParallel(m) 另外，加倍小心需要采取当批量尺寸是昏暗1（即batch_first =假）与数据并行性。在这种情况下，pack_padded_sequence的第一个参数padding_input将形状的[T × B × *]和应沿着昏暗1分散，但第二个参数input_lengths将形状的[B]和应沿着昏暗0散射。将需要额外的代码来处理张量的形状。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes/large_scale_deployments.html":{"url":"notes/large_scale_deployments.html","title":"对于大规模部署的特点","keywords":"","body":"对于大规模部署的特点 舰队宽操作者剖析 API使用记录 将元数据附加到保存TorchScript模型 构建环境的考虑 普通的扩展点 本说明有关一个更大的系统内运行PyTorch或操作在一个更大的组织使用PyTorch多个系统时可能有用的几个扩展点和技巧讲座。 它不包括生产部署模型的主题。检查 torch.jit或相应的教程。 该说明假定您无论是从源组织中的建PyTorch或有静态链接用于PyTorch时加载额外的代码的能力。因此，许多钩的公开为C ++的API，可以一次在一个集中的地方来触发，例如在静态初始化代码。 舰队宽操作仿形 PyTorch自带torch.autograd.profiler能够测量按需采取个体经营者时间的。人们可以使用相同的机制做“永远在线”的三围运行PyTorch任何进程。这可能是收集有关在给定的过程或整组机器的运行PyTorch工作负荷的信息是有用的。 对于任何运营商调用回调新可以用添加Torch :: autograd ::探查:: pushCallback [HTG3。钩将与被称为Torch :: autograd ::探查:: RecordFunction结构描述调用上下文（例如，名称）。如果启用，RecordFunction ::输入（） 包含表示为torch:: IValue变体类型的函数的自变量。请注意，该输入记录是比较昂贵的，因此，必须明确启用。 调用回调增加了一些开销，所以通常它只是随机采样操作调用有用。这可以在每个回调基础上通过Torch :: autograd ::探查:: setSamplingProbability 中指定的全局采样率启用。 请注意，pushCallback和setSamplingProbability不是线程安全的，没有PyTorch操作运行，只有当可以被调用。通常情况下，这是一个好主意，在初始化时调用了它们一次。 下面是一个例子： // Called somewhere in the program beginning void init() { // Sample one in a hundred operator runs randomly torch::autograd::setSamplingProbability(0.01); pushCallback( &onFunctionEnter, &onFunctionExit, /* needs_inputs */ true, /* sampled */ true ); } void onFunctionEnter(const RecordFunction& fn) { std::cerr API使用登录 当在更广泛的生态系统中运行，例如在管理作业调度程序，但是这是要跟踪的二进制文件调用特定的API PyTorch。存在于触发一个给定的回调几个重要的API点注射简单的仪器。因为通常PyTorch是一次性的Python脚本调用，回调火灾只有一次针对每个API的规定的处理。 C10 :: SetAPIUsageHandler可用于注册API使用的仪器处理程序。传递的参数将是一个“API密钥”识别用于点，例如python.import [HTG7用于PyTorch延长进口或torch.script.compile [HTG11如果TorchScript编译被触发。`` SetAPIUsageLogger([](const std::string& event_name) { std::cerr 注意为开发新的API的触发点可以在代码被添加与C10_LOG_API_USAGE_ONCE（ “my_api”）在C ++或torch._C._log_api_usage_once（“我的。 API“）在Python。 将元数据附加到保存TorchScript模型 TorchScript模块可以保存为捆绑串行化参数和模块代码作为TorchScript存档文件（见 torch.jit.save（） ）。这是很方便的与该模型一起捆绑的其他信息，例如，模型制作者或辅助的工件的描述。 它可以通过使_extra_files参数为 torch.jit.save（）和[HTG10来实现] Torch :: JIT ::负载 存储和保存过程中检索任意的二进制块。由于TorchScript文件定期ZIP档案，额外的信息被存储作为普通的文件归档的额外/目录内。 还有一个全局钩子允许额外的文件附加到当前进程产生的任何TorchScript存档。这可能是与制片人的元数据，类似于数码相机产生的JPEG元数据标签模型有用。用法示例可能类似于： SetExportModuleExtraFilesHook([](const script::Module&) { script::ExtraFilesMap files; files[\"producer_info.json\"] = \"{\\\"user\\\": \\\"\" + getenv(\"USER\") + \"\\\"}\"; return files; }); 构建环境的考虑 TorchScript的编译需要访问原来的Python文件，因为它使用python的inspect.getsource通话。在某些生产环境，可能需要与预编译.pyc文件沿着明确部署的.py文件。 普通的扩展点 PyTorch的API通常是松散耦合的，很容易与专门的版本替换部件。常见的扩展点包括： 用C语言实现运营商定制++ - 参见了解详情教程。 自定义数据读取经常可以通过调用相应的Python库直接集成。的 现有功能torch.utils.data可以通过扩展被利用 数据集或 IterableDataset。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes/multiprocessing.html":{"url":"notes/multiprocessing.html","title":"多处理最佳实践","keywords":"","body":"多处理器的最佳做法 torch.multiprocessing是在更换液滴为Python的 多处理 模块。它支持完全相同的操作，但它延伸，以便通过 multiprocessing.Queue ，将其数据发送的所有张量移入共享存储器和将只发送一个句柄到另一个进程。 注意 当 张量被发送到另一个的过程中， 张量 数据是共享。如果 torch.Tensor.grad 不是无，它也共享。后一个 张量无 torch.Tensor.grad 字段被发送到其他过程中，它创建了一个标准过程特异性.grad 张量 未自动共享跨越所有流程，不像如何 张量的 数据已被共享。 这使得实现各种训练方法，如Hogwild，A3C，或需要异步操作的任何其他人。 CUDA在多处理 CUDA运行时不支持叉启动方法。然而， 多处理 在Python 2可使用叉仅创建子进程。所以Python 3和任一菌种或forkserver启动方法需要在子过程使用CUDA。 Note start方法则可以通过创建与multiprocessing.get_context上下文设置（...）或直接使用multiprocessing.set_start_method（...）。 不同于CPU张量，需要在发送过程中保持原有的张量，只要该接收处理保留了张量的副本。它的引擎盖下实现的，但需要用户遵循最佳实践的程序才能正常运行。例如，发送过程必须只要活着，消费过程中有对张引用，如果消费者通过处理一个致命的信号异常退出的引用计数不能救你。参见[ 本节 HTG3。 另请参见： 使用nn.DataParallel而不是多处理 最佳做法和技巧 避免和战斗死锁 有很多事情，当一个新的进程产生，死锁是后台线程的最常见的原因可能出错。如果有持有锁或导入一个模块，叉被称为，这是非常有可能的是，子进程将处于损坏状态，并会死锁或在不同的失败的任何线索方式。请注意，即使你不这样做，Python的内置在图书馆做 - 没有必要进一步看起来比[ 多重处理HTG9。 multiprocessing.Queue 实际上是一个非常复杂的类，会派生用来序列，发送和接收对象的多个线程，并且他们可以也导致上述问题。如果在这样的情况下发现自己尝试使用multiprocessing.queues.SimpleQueue，即不使用任何额外的线程。 我们正在尽我们所能，让您轻松，并确保这些死锁不会发生，但有些事情是我们无法控制的。如果您有无法应付了，而任何问题，请在论坛上伸出，我们会看到，如果它是我们能够解决的问题。 重用缓冲器通过队列传递 请记住，每次你把 张量到 multiprocessing.Queue 它必须被移动到共享存储器中。如果它已经共享的，它是一个空操作，否则会产生额外的内存拷贝，可以减慢整个过程。即使你有发送数据到单一的进程池中，使缓冲区发回 这几乎是免费的，可以让发送下一批当你避免副本。 异步多进程训练（例如Hogwild） 使用 torch.multiprocessing，所以可以以异步方式训练模式，与参数共用所有的时间，或周期性地同步。在第一种情况下，建议发送在整个模型对象，而在后者中，我们建议只发送的 state_dict（）。 我们建议您使用 multiprocessing.Queue 传递各种PyTorch对象的进程之间。有可能例如使用叉启动方法当继承张量和存储器已经在共享存储器中，但是这是非常容易产生的错误，应该小心使用，并且仅由高级用户。队列，即使他们有时不太优雅的解决方案，将正确地适用于所有情况。 警告 你应该小心为全球性陈述，未与如果 __name__ == '__main__' 把守 [ HTG9。如果超过不同的启动方法叉 时，它们将被所有子过程执行。 Hogwild 一个具体的实施Hogwild可以在实例库中找到，但展示的代码的总体结构，也有以下以及一个最小的例子： import torch.multiprocessing as mp from model import MyModel def train(model): # Construct data_loader, optimizer, etc. for data, labels in data_loader: optimizer.zero_grad() loss_fn(model(data), labels).backward() optimizer.step() # This will update the shared parameters if __name__ == '__main__': num_processes = 4 model = MyModel() # NOTE: this is required for the ``fork``method to work model.share_memory() processes = [] for rank in range(num_processes): p = mp.Process(target=train, args=(model,)) p.start() processes.append(p) for p in processes: p.join() Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes/randomness.html":{"url":"notes/randomness.html","title":"重复性","keywords":"","body":"再现性 完全可重复的结果不能跨PyTorch版本中，提交个人或不同的平台保证。此外，结果不需要是CPU和GPU执行之间可重现的，使用相同的种子时也是如此。 然而，为了使计算您在一个特定的平台和PyTorch释放特定问题的确定性，有几个要采取的步骤。 有参与PyTorch 2个伪随机数生成器，您将需要手动种子，使运行重复性。此外，你应该确保所有其他库的代码依赖和使用随机数也使用固定的种子。 PyTorch 可以使用 torch.manual_seed（）种子为所有设备（CPU和CUDA）的RNG： import torch torch.manual_seed(0) 存在使用CUDA功能，可以是非确定性的源一些PyTorch功能。一类这样的CUDA功能是原子操作，特别是atomicAdd，其中并行加法的为相同的值的顺序是不确定的，并且对于浮点变量，方差的源在结果中。 PyTorch功能，在前进用atomicAdd包括 torch.Tensor.index_add_（）， torch.Tensor.scatter_add_（） ， torch.bincount（）。 多个操作的具有向后的是使用atomicAdd，特别是 torch.nn.functional.embedding_bag（） ， torch.nn.functional.ctc_loss（） 和池，填充和采样的许多形式。当前有避免这些功能的非确定性的没有简单的方法。 CuDNN 当在CuDNN后台运行，另外两个选项必须设置： torch.backends.cudnn.deterministic = True torch.backends.cudnn.benchmark = False 警告 确定性模式可以有一个性能的影响，这取决于你的模型。这意味着，由于模型的确定性性质，处理速度（即每秒处理批次项目）可以比当模型是非确定性较低。 numpy的 如果您或任何你正在使用的库的依赖numpy的，你应该播种numpy的RNG以及。这是可以做到的： import numpy as np np.random.seed(0) Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes/serialization.html":{"url":"notes/serialization.html","title":"序列化语义","keywords":"","body":"序列化语义 最佳实践 用于保存模型的推荐方法 有序列化和恢复模型的两种主要方法。 第一个（推荐）保存并只加载模型参数： torch.save(the_model.state_dict(), PATH) 再后来： the_model = TheModelClass(*args, **kwargs) the_model.load_state_dict(torch.load(PATH)) 第二保存和加载整个模型： torch.save(the_model, PATH) Then later: the_model = torch.load(PATH) 然而，在这种情况下，序列化的数据绑定到特定的类和使用的准确的目录结构，所以在其他项目中使用时，它可以通过各种方式突破，或在一些严重的refactors。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes/windows.html":{"url":"notes/windows.html","title":"Windows 常见问题","keywords":"","body":"Windows 常见问题 从源大厦 包括任选的组分 目前的Windows PyTorch支持的两个组成部分：MKL与岩浆。这里有与他们建立的步骤。 REM Make sure you have 7z and curl installed. REM Download MKL files curl https://s3.amazonaws.com/ossci-windows/mkl_2018.2.185.7z -k -O 7z x -aoa mkl_2018.2.185.7z -omkl REM Download MAGMA files REM cuda100/cuda101 is also available for `CUDA_PREFIX`. There are also 2.4.0 binaries for cuda80/cuda92. REM The configuration could be `debug`or `release`for 2.5.0. Only `release`is available for 2.4.0. set CUDA_PREFIX=cuda90 set CONFIG=release curl -k https://s3.amazonaws.com/ossci-windows/magma_2.5.0_%CUDA_PREFIX%_%CONFIG%.7z -o magma.7z 7z x -aoa magma.7z -omagma REM Setting essential environment variables set \"CMAKE_INCLUDE_PATH=%cd%\\\\mkl\\\\include\" set \"LIB=%cd%\\\\mkl\\\\lib;%LIB%\" set \"MAGMA_HOME=%cd%\\\\magma\" CUDA加速构建于Windows Visual Studio中不支持当前并行自定义任务。作为替代方案，我们可以使用忍者并行CUDA建设任务。它可以通过输入代码只有几行使用。 REM Let's install ninja first. pip install ninja REM Set it as the cmake generator set CMAKE_GENERATOR=Ninja 一个键安装脚本 你可以看看[这套脚本HTG1。它会带路为您服务。 分机 CFFI扩展 对于CFFI扩展的支持是非常实验性的。一般是有两个步骤，使其能够在Windows下。 首先，请在分机对象的附加库，使其在Windows上构建。 ffi = create_extension( '_ext.my_lib', headers=headers, sources=sources, define_macros=defines, relative_to=__file__, with_cuda=with_cuda, extra_compile_args=[\"-std=c99\"], libraries=['ATen', '_C'] # Append cuda libaries when necessary, like cudart ) 其次，在这里是“引发的的extern THCState *状态解析外部符号状态;”用于workground 改变源代码从C到C ++。一个例子如下所列。 #include #include THCState *state = at::globalContext().thc_state; extern \"C\" int my_lib_add_forward_cuda(THCudaTensor *input1, THCudaTensor *input2, THCudaTensor *output) { if (!THCudaTensor_isSameSizeAs(state, input1, input2)) return 0; THCudaTensor_resizeAs(state, output, input1); THCudaTensor_cadd(state, output, input1, 1.0, input2); return 1; } extern \"C\" int my_lib_add_backward_cuda(THCudaTensor *grad_output, THCudaTensor *grad_input) { THCudaTensor_resizeAs(state, grad_input, grad_output); THCudaTensor_fill(state, grad_input, 1); return 1; } CPP扩展 与以往的相比这种类型的扩展有更好的支持。但是，它仍然需要一些手动配置。首先，你应该打开 x86_x64跨工具命令提示符为VS 2017年[HTG1。然后，你就可以开始你的编译过程。 安装 包装在Win-32频道未找到。 Solving environment: failed PackagesNotFoundError: The following packages are not available from current channels: - pytorch Current channels: - https://conda.anaconda.org/pytorch/win-32 - https://conda.anaconda.org/pytorch/noarch - https://repo.continuum.io/pkgs/main/win-32 - https://repo.continuum.io/pkgs/main/noarch - https://repo.continuum.io/pkgs/free/win-32 - https://repo.continuum.io/pkgs/free/noarch - https://repo.continuum.io/pkgs/r/win-32 - https://repo.continuum.io/pkgs/r/noarch - https://repo.continuum.io/pkgs/pro/win-32 - https://repo.continuum.io/pkgs/pro/noarch - https://repo.continuum.io/pkgs/msys2/win-32 - https://repo.continuum.io/pkgs/msys2/noarch PyTorch不能在32位系统中工作。请使用Windows和Python的64位版本。 为什么没有Python的2包的Windows？ 因为它不够稳定。还有一些是需要之前，我们正式发布它要解决的问题。您可以通过建立它自己。 导入错误 from torch._C import * ImportError: DLL load failed: The specified module could not be found. 该问题是由重要文件丢失引起的。其实，我们几乎都可以看到PyTorch需要为康达包装除了VC2017可再发行组件和一些MKL库的基本文件。您可以通过键入以下命令来解决此问题。 conda install -c peterjc123 vc vs2017_runtime conda install mkl_fft intel_openmp numpy mkl 至于这些轮子包，因为我们没有收拾一些libaries和VS2017再发行的文件，请确保您手动安装它们。在 VS 2017年再分发安装可以下载。而且你还要注意你的NumPy的安装。确保它使用的不是OpenBLAS MKL。您可以在下面的命令类型。 pip install numpy mkl intel-openmp mkl_fft 另一个可能的原因可能是您使用的GPU版本，而NVIDIA显卡。请与CPU更换你的GPU封装。 from torch._C import * ImportError: DLL load failed: The operating system cannot run %1. 这实际上是蟒蛇的上游问题。当你初始化畅达锻通道的环境中，这个问题将会出现。您可以通过此命令修复英特尔的OpenMP库。 conda install -c defaults intel-openmp -f 使用量（多处理） 多处理错误，而不if子句保护 RuntimeError: An attempt has been made to start a new process before the current process has finished its bootstrapping phase. This probably means that you are not using fork to start your child processes and you have forgotten to use the proper idiom in the main module: if __name__ == '__main__': freeze_support() ... The \"freeze_support()\" line can be omitted if the program is not going to be frozen to produce an executable. 多处理 的实施是不同的Windows，其使用菌种 而非叉 。因此，我们必须使用if子句来包装代码保护代码执行多次。重构代码为如下的结构。 import torch def main() for i, data in enumerate(dataloader): # do something here if __name__ == '__main__': main() 多处理错误“断管” ForkingPickler(file, protocol).dump(obj) BrokenPipeError: [Errno 32] Broken pipe 当子进程结束父进程完成发送数据之前，这个问题会发生。可能有一些错误代码。您可以通过减少num_worker为零 的DataLoader 调试代码，看看问题是否依然存在。 多处理错误“司机关闭” Couldn’t open shared file mapping: , error code: at torch\\lib\\TH\\THAllocator.c:154 [windows] driver shut down 请更新您的显卡驱动程序。如果这仍然存在，这可能是你的显卡太旧或计算是你的卡太重。请你照这个信息更新TDR设置。 CUDA IPC操作 THCudaCheck FAIL file=torch\\csrc\\generic\\StorageSharing.cpp line=252 error=63 : OS call failed or operation not supported on this OS 他们不支持Windows。喜欢的东西做的CUDA张量多能不能成功，有两个备选方案这一点。 1.不要用多重处理 [HTG3。将num_worker为零的[的DataLoader](../data.html#torch.utils.data.DataLoader \"torch.utils.data.DataLoader\")。 2.共享CPU张量来代替。请确保您的自定义数据集返回CPU张量。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"community/contribution_guide.html":{"url":"community/contribution_guide.html","title":"PyTorch贡献说明书","keywords":"","body":"PyTorch贡献指南 PyTorch是GPU加速的Python张量计算包大楼建成基于磁带的系统autograd深层神经网络。 所述PyTorch贡献过程 该PyTorch组织由[ PyTorch治理管辖HTG1。 该PyTorch开发过程中涉及的核心开发团队和社区之间公开讨论的一个健康的量。 PyTorch操作类似于GitHub上大多数开源项目。但是，如果你从来没有促成一个开源项目，下面是基本的过程。 找出你要什么去努力。 大多数的开源贡献来自让人摸不着自己的痒处。但是，如果你不知道你想要什么工作，或者只是希望获得与该项目有更多的了解，这里有一些提示，了解如何找到适当的任务： 通览问题跟踪，看看是否有您知道如何解决任何问题。由其他贡献者确认的问题往往是更好地进行调查。我们也维持其很可能是好的，为新人们，例如问题的一些标签， 集训 和 1小时 ，尽管这些标签不太良好的维护。 加入我们的时差，让我们知道你有兴趣去了解PyTorch。我们很高兴提供帮助研究人员和合作伙伴获得了代码库，以加快。 找出你的变化范围，在GitHub的问题达成了设计的意见，如果是大的。 大多数引入请求的小;在这种情况下，没有必要让我们知道你想要做什么，只是让开裂。但是，如果改变将是大的，它通常是一个好主意，先了解一下它的一些设计意见。 如果你不知道变化有多大将是，我们可以帮你看着办吧！只是张贴关于它的问题或懈怠。 一些新增功能是非常标准化的;例如，很多人添加新的运营商或优化，以PyTorch。在这些情况下设计的讨论主要是归结，“难道我们希望这个运营商/优化？”给了其效用，例如，使用在同行评审的论文，或存在其他框架的证据，使这种情况下，当有助于一点。 - 加法运算符/从最近发布的研究算法 > 一般是不会接受的，除非有大量证据表明，这个新出版的作品有突破性的成果，并最终成为该领域的标准。如果你不知道从哪里你的方法跌倒，首先实施PR之前打开的问题。 * 核心变化和refactors可以说是相当难以协调，为发展对PyTorch主步伐也相当快。当然伸手根本性或跨领域的变化;我们经常可以提供有关如何上演这样的变化成更容易审查的作品的指导。 代码吧！ 请参阅建议的技术导则技术形态与PyTorch工作。 打开拉入请求。 如果你还没有准备好拉入请求进行审查，以[WIP]标记它。当这样做评审通过，我们将忽略它。如果你是在一个复杂的变化工作，这是很好的开始做事了作为WIP，因为你将需要花时间看CI结果看，如果事情成功的与否。 找到适合您的变化适当的评审。我们有一些人谁经常通过公关排队去尝试，审查一切，但是如果你碰巧知道受你的补丁给定子系统的维护者是谁，随时直接包括他们拉入请求。您可以了解更多有关此结构在PyTorch子系统所有权。 直到它接受了拉入请求 迭代！ 我们会尽最大努力减少审核往返，只有当有重大事项块永久居民的人数。对于引入请求的最常见的问题，看看常见误区[HTG1。 一旦拉请求被接受和CI在流逝，没有什么别的你需要做的;我们将合并PR为您服务。 入门 提出新的功能 新功能的想法是对具体问题的最佳讨论。请包括你可以尽可能多的信息，相关的数据，和您的建议的解决方案。该PyTorch团队和社区经常回顾了新的问题和意见，他们认为他们可以提供帮助。如果您在您的解决方案有信心，继续前进，实现它。 报告问题 如果您已经通过在回购现有的问题中的列表中标识的问题，第一个搜索。如果你无法找到一个类似的问题，然后创建一个新的。供应尽可能多的信息，你可以重现问题的行为。此外，包括像你期望的行为的任何额外的见解。 实施特色或修复错误 如果你想解决一个具体问题，最好与你的意图个别问题发表评论。但是，我们不锁或分配，除了在我们与开发商合作过案件的问题。这是最好的搭讪上的问题，并讨论你提出的解决方案。该PyTorch团队可以提供为您节省时间的指导。 被标记的第一新问题，低或中等优先问题提供最佳的介入点是伟大的地方开始。 添加教程 教程对 pytorch.org了大量来自社区本身，我们欢迎更多的捐款。要了解更多关于如何贡献新的教程，你可以在这里了解更多：在Github上PyTorch.org教程贡献指南 提高文件&安培;教程 我们的目标是生产出高品质的文档和教程。在极少数情况下的内容包括错别字或错误。如果你发现了一些可以修复，给我们考虑拉入请求。 看看在文档部分，以了解我们的系统是如何工作的。 参与网上讨论 你可以找到积极的讨论发生在PyTorch讨论[论坛HTG1。 提交引入请求解决悬而未决的问题 您可以查看所有打开的问题此处列表。在谈到一个问题，是一个伟大的方式来获得球队的关注。从这里你可以分享你的想法和你打算如何解决这个问题。 更具挑战性的问题，该小组将提供如何最好地解决这一问题的反馈和方向。 如果你不能够解决的问题本身，评论和分享您是否可以重现该问题可以帮助球队找出问题所在有用。 回顾开放引入请求 我们感谢您的帮助审查和评论引入请求。我们的团队努力保持开放引入请求的数量在可管理的范围，我们迅速作出反应的详细信息，如果我们需要它，我们合并，我们认为是有用的永久居民。然而，由于高度的兴趣，对引入请求额外的眼睛是赞赏。 改进代码可读性 提高代码的可读性可以帮助大家。它往往是更好地提交的少数几个触摸与文件触及许多文件大拉的请求拉请求。开始在PyTorch论坛此处或与您的改进问题的讨论是开始的最好方式。 添加测试用例，使代码库更加健壮 附加的测试覆盖率理解。 促进PyTorch 你在你的项目中，研究论文，使用PyTorch的写起坐，博客或一般性讨论在互联网有助于提高意识，为PyTorch和我们成长的社区。请联络[ pytorch- marketing@fb.com HTG1对于营销支持。 检伤分类问题 如果你觉得一个问题可以从有关这一问题的特定标签或复杂的注释水平中受益，分享你的意见。如果你觉得一个问题是未分类的正确意见，并让球队知道。 关于开源开发 如果这是您第一次贡献一个开源项目，开发过程中的某些方面可能看起来不寻常的给你。 有没有办法“要求”的问题。 人们经常想“要求”时，他们决定进行这项工作，以确保当别人结束了它的工作有没有浪费工作的问题。这并没有真正的开源工作也很好，因为有人可以决定的东西的工作，并最终没有时间去做。可以随意的信息咨询的方式，但在这一天结束时，我们将采取运行的代码，并大体一致。 [HTG0存在对于被添加新功能的高杆。 [HTG1不像在企业环境中，谁写代码的人含蓄地“拥有”，并可以预计到，立即照顾它在其生命周期的开始，一次拉请求被合并成一个开源项目，它成为该项目的所有维护人员的集体责任。当我们合并代码中，我们说我们的维护人员，都能够审查的后续变化，并作出修正错误的代码。这自然导致了更高的标准贡献。 常见的错误，以避免 你添加的测试？ （或者如果改变是很难测试，你描述你如何测试你的改变？） 我们有我们为什么要求测试的几个动机： 帮助我们告诉我们，如果以后打破它 帮助我们告诉我们，如果补丁是在第一时间正确的（是的，我们没有审查，但克努特说，“当心下面的代码，因为我还没有运行它，只是证明了它正确”） 什么时候确定不添加测试？有时变化不能方便地进行测试，或者改变是如此明显正确的（且不太可能被打破），它是确定不进行测试。相反，如果一个变化很可能（或者被称为是有可能的）被意外打破，它把在制定测试策略的时间是非常重要的。 是你的PR过长？ 这是我们更容易查看和合并小的PR。回顾公关的难度与它的大小尺度非线性。 什么时候确定，提交了大量公关？它有很大帮助，如果有中的问题相应的设计讨论，与谁是要检查您的DIFF人签署。我们还可以帮助提供有关如何拆分大的变化成单独可交付的部分建议。同样，它帮助，如果还有的公关内容的完整描述：它更容易检查的代码，如果我们知道里面是什么！ 评论对微妙的东西？ [HTG1在情况下，你的代码的行为是细致入微，请包括额外的注释和文档，使我们能够更好地理解你的代码的意图。 你添加一个黑客？ 有时，一个黑客是正确的答案。但通常，我们将要讨论它。 你要摸一个非常核心的组成部分？ [HTG1为了防止大回归，拉那一抹核心组件的请求获得额外的审查。请确保你在进行重大变化之前已经讨论过的团队所做的更改。 要添加新的功能？ [HTG1如果要添加新的功能，对相关问题发表评论你的意图。我们的团队试图发表评论，并提供反馈给社会。这是更好地之前建立新的功能与团队和社会的其他开放式讨论。这有助于我们保持知道你的工作是什么对和增加了它会被合并的机会。 你触摸无关的代码的公关？ 为了在代码审查帮助，请只在您的拉请求直接相关的更改文件。 经常问的问题 如何作为一个评论家贡献？ 有很多的价值，如果小区的开发商重现问题，尝试新的功能，或以其他方式帮助我们确定或解决问题。在谈到与环境信息的任务或引入请求是有帮助和赞赏。 CI测试失败了，这是什么意思？ 也许你需要与主合并或与最新的变化变基。推你的变化应该重新触发CI测试。如果测试持续下去，你会希望通过错误信息来跟踪和解决相关问题。 什么是最高危的变化？ 凡是触摸构建配置是一个有风险的区域。请避免改变这些，除非你已经与球队讨论事前。 嘿，提交我的分支出现了，那是什么回事？ 有时其他社区成员会提供修补程序或补丁，以您的拉请求或分公司。这通常需要获得CI测试通过。 在文档 Python文档 PyTorch文档从蟒源使用斯芬克斯生成。生成的HTML被复制到文档文件夹中的 pytorch.github.io 主分支，并且经由GitHub的页供应。 网站：HTG0] http://pytorch.org/docs GitHub的： https://github.com/pytorch/pytorch/tree/master/docs 从供应： https://github.com/pytorch/pytorch.github.io/tree/master/doc C ++文档 对于C ++代码，我们使用的Doxygen生成内容的文件。 C ++的文档都建有专门的服务器上生成的文件复制到 https://github.com/pytorch/cppdocs 回购，并从GitHub页面服务。 网站：HTG0] http://pytorch.org/cppdocs GitHub的： https://github.com/pytorch/pytorch/tree/master/docs/cpp 从供应： https://github.com/pytorch/cppdocs 教程 PyTorch教程是用于帮助了解使用PyTorch完成特定任务或要了解更全面的概念文件。教程使用狮身人面像，画廊从Python可执行文件的来源，或重组文本（RST）文件建立。 网站：HTG0] http://pytorch.org/tutorials GitHub的： http://github.com/pytorch/tutorials 教程构建概述HTG0] 对于教程拉请求触发使用CircleCI测试变化的影响，重建整个网站。此版本是分片到9个工作建立和总花费约40分钟。与此同时，我们做了Netlify建立使用 让HTML的noplot ，它建立了网站，而无需渲染笔记本输出到快速审核页面。 一个PR被接受后，该网站是重建和CircleCI部署。 贡献新的教程 PyTorch.org教程贡献指南 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"community/governance.html":{"url":"community/governance.html","title":"PyTorch治理","keywords":"","body":"PyTorch治理 治理哲学指导信条 PyTorch采用的治理结构与一小维护者驾驶朝向PyTorch的设计理念有很大成见，其中设计和代码贡献的价值在整个项目的方向。除了核心的维护者，也有一个稍微更广泛的具有直接合并引入请求和核心代码库的自己各部分的功能核心开发人员。 除了维护和核心开发者，社区鼓励贡献，文件的问题，提出建议，检讨引入请求和存在于社会。鉴于捐助和投资意愿，任何人都可以提供写访问或代码库的部分所有权。 在此基础上的治理结构，该项目由作出决定和整体文化起源的以下核心工作原则： 比企业赞助和独立软件开发商 多大关系更多的代码贡献的高度重视。 项目影响 通过捐款获得了（无论是永久居民，论坛答案，代码审查或其他方式） 关键人及其功能 项目维护者 项目维护者为PyTorch项目提供领导和指导。具体包括： 阐明该项目的凝聚力长远眼光 具备PyTorch代码库的深刻理解 协商和生产方式接受有关各方解决争议问题 PyTorch维护者： 亚当Paszke（ apaszke ） Soumith Chintala（ soumith ） 杨德昌（ ezyang ） 格雷格察南（ gchanan ） 德米特罗Dzhulgakov（ dzhulgakov ） （弃用）萨姆总值（ colesbury ） 核心开发 该PyTorch项目是由一个团队的核心开发人员开发的。您可以在 PyTorch治理发现的核心开发者名单|兴趣的人。 虽然成员由在“PyTorch核心”球队存在的“PyTorch” 组织在GitHub上确定的，贡献有多种形式： 提交更改到存储库; 审查通过别人拉的请求; 在这个问题上跟踪检伤分类错误报告; 在讨论关于官方PyTorch通信信道的话题。 版主 有这样一群人，其中一些是不是核心开发人员，负责确保在正式沟通渠道讨论遵守行为守则。他们采取鉴于侵犯行动，并帮助支持一个健康的社区。你可以找到版主这里的列表。 决策 争议的变化 主要工作情况通过bug跟踪系统问题，并在GitHub上引入请求。核心开发人员应避免直接推动其更改PyTorch库，而是依靠引入请求。批准由核心开发者拉请求允许它不经进一步处理合并。核心开发人员和项目维护者最终批准了这些变化。 通报有关专家约一个bug跟踪系统问题或拉的要求是很重要的。从给定的利率方面的专家评测强烈首选，尤其是在拉动请求批准。如果不这样做可能最终改变由相关专家回复。 有争议的决策过程 在给定的感兴趣的领域实质性的改变需要一个GitHub的问题的讨论被打开。这包括： 任何语义句法或改变的框架。 向后兼容改变了Python或CPP API。 增加的核心框架，其中包括现有的库中的大量新功能。 移除核心功能 项目维护者最终批准了这些变化。 常见问题 问：我想如果自己（或部分拥有）项目的一部分，如域API（即Torch 宣）？ 这是绝对有可能的。第一步是启动有助于现有项目区域和促进其健康和成功。除此之外，你可以通过GitHub的问题，新的功能或修改，以改善项目区的建议。 问：如果我公司希望使用PyTorch内部进行开发，可我被授予或购买一个董事会席位，以推动项目的方向是？ 没有，PyTorch项目严格维护者驱动的项目理念驱动，没有一个板或车辆采取与获得对技术发展方向的影响力捐款。 问：请问PyTorch项目的支持或补助的方式支持独立开发者使用或参与该项目？ 不，不是在这一点上。然而，我们正在寻找方法，以更好地支持各地PyTorch独立开发者社区。如果您有任何建议或输入，请在PyTorch论坛伸手讨论。 问：我如何贡献代码的项目？ [HTG1如果变化相对较小，在GitHub上拉的请求可以立即进行审核打开了，并通过该项目的提交合并。对于较大的变化，请打开一个问题提出建议之前进行讨论。也请参阅[ PyTorch投稿指南HTG3对于贡献的指导方针。 问：我能成为该项目的提交者？ [HTG1不幸的是，目前提交过程PyTorch涉及与只能通过Facebook的员工被触发的Facebook基础架构的交互。然而，我们正在寻找方法，以扩大基地的提交个人的Facebook的外面，当工具的存在是为了让这将提供更新。 问：我想如果在一次会议上或以其他方式提供一个PyTorch教程？我需要成为“正式”的提交做到这一点？ 没有，我们鼓励社区成员时，他们可以向人们展示他们的作品在任何地方和。请联络[ pytorch-marketing@fb.com HTG3对于营销支持。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"community/persons_of_interest.html":{"url":"community/persons_of_interest.html","title":"PyTorch治|兴趣的人","keywords":"","body":"PyTorch治理|者的兴趣 一般维护者 亚当Paszke（ apaszke ） Soumith Chintala（ soumith ） 杨德昌（ ezyang ） 格雷格察南（ gchanan ） 德米特罗Dzhulgakov（ dzhulgakov ） （弃用）萨姆总值（ colesbury ） 模块级维护者 JIT 扎克迪维托（ zdevito ） 迈克尔琐（琐） 分布式 彼得Noordhuis（ pietern ） 沉黎（ mrshenli ） （弃用）腾力（腾丽） Autograd引擎 阿尔Desmaison（ alband ） Adam Paszke (apaszke) 多处理和DataLoaders 西蒙·王（ SsnL ） Adam Paszke (apaszke) （提出）维塔利彼得Fedyunin（ VitalyFedyunin ） CUDA Edward Yang (ezyang) 纳塔利娅Gimelshein（ ngimel ） C ++ 请问冯（ yf225 ） （弃用）彼得戈尔兹伯勒（戈尔兹伯勒） 建+ CI Will Feng (yf225) Edward Yang (ezyang) 杰西Hellemn（ pjh5 ） Soumith Chintala (soumith) （弃用）猎户Reblitz-理查德森（ orionr ） 分布&安培; RNG 弗里茨欧博迈亚（ fritzo ） Neeraj普拉丹（ neerajprad ） 爱丽丝Bozkurt（ alicanb ） Vishwak斯里尼瓦桑（ vishwakftw ） C10 塞巴斯蒂安梅斯默（ smessmer ） Edward Yang (ezyang) ONNX & LT ; - & GT ; PyTorch 路罚嗯（ houseroad ） 拉拉海德尔（拉拉-HDR ） Spandan蒂瓦里（ spandantiwari ） 鲍恩宝（ BowenBao ） torch.nn 托马斯Viehmann（叔VI ） Adam Paszke (apaszke) Greg Chanan (gchanan) Soumith Chintala (soumith) 萨姆总值（ colesbury ） CPU性能/ SIMD 基督教Puhrsch（ cpuhrsch ） Sam Gross (colesbury) 理查德邹（ zou3519 ） AMD /的ROCm / HIP 俊杰BAI（ bddppq ） 约翰M. Dieterich的（ iotamudelta ） Windows的 彼得·约翰逊（ peterjc123 ） MKLDNN 瀛海路（瀛海） XLA 张爱玲（ ailzhang ） 格雷戈里察南（ gchanan ） 的Davide Libenzi（ dlibenzi ） 亚历Suhan（ asuhan ） PPC 阿尔弗雷门多萨（ avmgithub ） Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"torch.html":{"url":"torch.html","title":"torch","keywords":"","body":"torch Torch 包中包含用于对这些多维张量和数学运算被定义的数据结构。此外，它提供了张量的高效串行化和任意类型，以及其他有用的工具的许多工具。 它具有CUDA对应，使您可以在一个NVIDIA GPU计算能力& GT运行计算张[] = 3.0。 张量 torch.``is_tensor( obj )[source] 如果 OBJ 是一个PyTorch张返回True。 Parameters OBJ （ 对象 ） - 对象测试 torch.``is_storage( obj )[source] 如果 OBJ 是一个PyTorch存储对象返回真。 Parameters obj ( Object ) – Object to test torch.``is_floating_point( input) - > (bool) 返回true如果输入的的数据类型是一个浮点数据类型，即，torch.float64 的之一，torch.float32和 torch.float16。 Parameters 输入 （ 张量 ） - 的PyTorch张量，以测试 torch.``set_default_dtype( d )[source] 设置默认浮点D型为d。这种类型的将被用作默认浮点类型为类型推断在 torch.tensor（）。 默认浮点D型细胞是最初torch.float32。 Parameters d （ torch.dtype） - 浮点D型细胞，使默认 例： >>> torch.tensor([1.2, 3]).dtype # initial default for floating point is torch.float32 torch.float32 >>> torch.set_default_dtype(torch.float64) >>> torch.tensor([1.2, 3]).dtype # a new floating point tensor torch.float64 torch.``get_default_dtype() → torch.dtype 获得当前默认的浮点[ torch.dtypeHTG5。 Example: >>> torch.get_default_dtype() # initial default for floating point is torch.float32 torch.float32 >>> torch.set_default_dtype(torch.float64) >>> torch.get_default_dtype() # default is now changed to torch.float64 torch.float64 >>> torch.set_default_tensor_type(torch.FloatTensor) # setting tensor type also affects this >>> torch.get_default_dtype() # changed to torch.float32, the dtype for torch.FloatTensor torch.float32 torch.``set_default_tensor_type( t )[source] 设置默认torch.Tensor类型到浮点型张量 T。这种类型也将被用作默认浮点类型为类型推断在 torch.tensor（） 。 默认浮点张量类型最初是torch.FloatTensor。 Parameters T （ 输入 或 串 ） - 浮点张量类型或名称 Example: >>> torch.tensor([1.2, 3]).dtype # initial default for floating point is torch.float32 torch.float32 >>> torch.set_default_tensor_type(torch.DoubleTensor) >>> torch.tensor([1.2, 3]).dtype # a new floating point tensor torch.float64 torch.``numel( input ) → int 返回元件在输入张量的总数。 Parameters 输入 （ 张量 ） - 输入张量 Example: >>> a = torch.randn(1, 2, 3, 4, 5) >>> torch.numel(a) 120 >>> a = torch.zeros(4,4) >>> torch.numel(a) 16 torch.``set_printoptions( precision=None , threshold=None , edgeitems=None , linewidth=None , profile=None , sci_mode=None )[source] 打印设置选项。项目无耻地从NumPy的拍摄 Parameters 精度 - 的用于浮点输出（缺省值= 4）的精度位数。 阈 - 其中触发总结而不是完整再版（默认= 1000）的数组元素的总数。 edgeitems - 中的每个维度（缺省= 3）的开始和结束时在摘要数组项数。 线宽 - 每行的字符用于插入换行（缺省值= 80）的目的的数量。阈值的矩阵将忽略此参数。 个人资料 - 为漂亮的印刷理智的默认值。可与上述任何选项覆盖。 （的中任一项默认，短，充满） sci_mode - 启用（True）或禁用（假）科学记数法。如果指定无（默认值），该值是由 _Formatter定义 torch.``set_flush_denormal( mode ) → bool 禁止非正规浮于CPU编号。 返回真如果你的系统支持非标准冲洗数字和它成功配置刷新非标准模式。set_flush_denormal（） 仅支持x86架构，支持SSE3。 Parameters 模式 （ 布尔 ） - 控制是否启用冲洗反规范模式或不 Example: >>> torch.set_flush_denormal(True) True >>> torch.tensor([1e-323], dtype=torch.float64) tensor([ 0.], dtype=torch.float64) >>> torch.set_flush_denormal(False) True >>> torch.tensor([1e-323], dtype=torch.float64) tensor(9.88131e-324 * [ 1.0000], dtype=torch.float64) 创建行动 注意 随机采样生成OPS被下列出随机采样 和包括： torch.rand（） ``torch.rand_like（） ``torch.randn（） ``torch.randn_like（） ``torch.randint（） ``torch。 randint_like（） `` torch.randperm（）您也可以使用 Torch 。空（）与 就地随机抽样 的方法来创建 torch.Tensor s的值从更广阔的范围内分布的采样。 torch.``tensor( data , dtype=None , device=None , requires_grad=False , pin_memory=False ) → Tensor 构造具有数据的张量。 警告 torch.tensor（）总是副本数据。如果你有一个张量数据，并希望避免拷贝，使用 torch.Tensor.requires_grad_（）或 torch.Tensor.detach（） 。如果你有一个与NumPy ndarray，并希望避免拷贝，使用 torch.as_tensor（）[HTG35。 Warning 当数据是张量×， torch.tensor（）读出从不管它是通过 '数据'，和构造叶变量。因此torch.tensor（X）等于x.clone（）。分离（）和torch.tensor（X， requires_grad =真）等于x.clone（）。分离（）。requires_grad_（真）。使用克隆（）和分离（）的当量的建议。 Parameters 数据 （ array_like ） - 为对张量初始数据。可进行列表，元组，NumPy的ndarray，标量，和其他类型。 DTYPE （ torch.dtype，可选） - 返回的张量的所希望的数据类型。默认值：如果无，从数据推断数据类型。 装置 （ torch.device，可选） - 返回的张量的所需的设备。默认值：如果无，使用当前设备的默认张量类型（见 torch.set_default_tensor_type（））。 装置将成为CPU张量类型的CPU和用于CUDA张量类型当前CUDA设备。 requires_grad （ 布尔 ， 可选 ） - 如果autograd应返回的记录张操作。默认值：假 [HTG13。 pin_memory （ 布尔 ， 可选 ） - 如果设置，返回张量将在固定的内存分配。只为CPU张量工作。默认值：假 [HTG13。 Example: >>> torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]]) tensor([[ 0.1000, 1.2000], [ 2.2000, 3.1000], [ 4.9000, 5.2000]]) >>> torch.tensor([0, 1]) # Type inference on data tensor([ 0, 1]) >>> torch.tensor([[0.11111, 0.222222, 0.3333333]], dtype=torch.float64, device=torch.device('cuda:0')) # creates a torch.cuda.DoubleTensor tensor([[ 0.1111, 0.2222, 0.3333]], dtype=torch.float64, device='cuda:0') >>> torch.tensor(3.14159) # Create a scalar (zero-dimensional tensor) tensor(3.1416) >>> torch.tensor([]) # Create an empty tensor (of size (0,)) tensor([]) torch.``sparse_coo_tensor( indices , values , size=None , dtype=None , device=None , requires_grad=False ) → Tensor 构造在COO（rdinate）格式的稀疏张量与在给定的指数与给定的值的非零元素。稀疏张量可以未聚结的，在这种情况下，有在索引重复坐标，该索引的值是所有重复值项之和： torch.sparse 。 Parameters 用于张量初始数据 - 指数 （ array_like ）。可进行列表，元组，NumPy的ndarray，标量，和其他类型。将被转换为torch.LongTensor内部。该指数是在矩阵中的非零值的坐标，且因此应是二维，其中第一维是张量的维数，第二维是非零值的数目。 用于张量的初始值 - 值 （ array_like ）。可进行列表，元组，NumPy的ndarray，标量，和其他类型。 大小 （列表，元组，或torch.Size，可选） - 稀疏张量的大小。如果没有提供规模将被推断为最小尺寸大到足以容纳所有非零元素。 DTYPE （ torch.dtype，可选） - 返回的张量的所希望的数据类型。默认值：如果无，从值推断数据类型。 装置 （ torch.device，可选） - 返回的张量的所需的设备。默认值：如果没有，则使用当前设备的默认张量类型（见 torch.set_default_tensor_type（））。 装置将成为CPU张量类型的CPU和用于CUDA张量类型当前CUDA设备。 requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> i = torch.tensor([[0, 1, 1], [2, 0, 2]]) >>> v = torch.tensor([3, 4, 5], dtype=torch.float32) >>> torch.sparse_coo_tensor(i, v, [2, 4]) tensor(indices=tensor([[0, 1, 1], [2, 0, 2]]), values=tensor([3., 4., 5.]), size=(2, 4), nnz=3, layout=torch.sparse_coo) >>> torch.sparse_coo_tensor(i, v) # Shape inference tensor(indices=tensor([[0, 1, 1], [2, 0, 2]]), values=tensor([3., 4., 5.]), size=(2, 3), nnz=3, layout=torch.sparse_coo) >>> torch.sparse_coo_tensor(i, v, [2, 4], dtype=torch.float64, device=torch.device('cuda:0')) tensor(indices=tensor([[0, 1, 1], [2, 0, 2]]), values=tensor([3., 4., 5.]), device='cuda:0', size=(2, 4), nnz=3, dtype=torch.float64, layout=torch.sparse_coo) # Create an empty sparse tensor with the following invariants: # 1. sparse_dim + dense_dim = len(SparseTensor.shape) # 2. SparseTensor._indices().shape = (sparse_dim, nnz) # 3. SparseTensor._values().shape = (nnz, SparseTensor.shape[sparse_dim:]) # # For instance, to create an empty sparse tensor with nnz = 0, dense_dim = 0 and # sparse_dim = 1 (hence indices is a 2D tensor of shape = (1, 0)) >>> S = torch.sparse_coo_tensor(torch.empty([1, 0]), [], [1]) tensor(indices=tensor([], size=(1, 0)), values=tensor([], size=(0,)), size=(1,), nnz=0, layout=torch.sparse_coo) # and to create an empty sparse tensor with nnz = 0, dense_dim = 1 and # sparse_dim = 1 >>> S = torch.sparse_coo_tensor(torch.empty([1, 0]), torch.empty([0, 2]), [1, 2]) tensor(indices=tensor([], size=(1, 0)), values=tensor([], size=(0, 2)), size=(1, 2), nnz=0, layout=torch.sparse_coo) torch.``as_tensor( data , dtype=None , device=None ) → Tensor 将数据转换成 torch.Tensor 。如果数据已经是一个张量用相同的 DTYPE 和装置，没有副本将被执行，否则一个新的张量将是与计算图形返回保留如果数据张量具有requires_grad =真。类似地，如果数据是一个ndarray的相应的 DTYPE 和装置是CPU，没有复制将被执行。 Parameters data ( array_like ) – Initial data for the tensor. Can be a list, tuple, NumPy ndarray, scalar, and other types. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, infers data type from data. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. Example: >>> a = numpy.array([1, 2, 3]) >>> t = torch.as_tensor(a) >>> t tensor([ 1, 2, 3]) >>> t[0] = -1 >>> a array([-1, 2, 3]) >>> a = numpy.array([1, 2, 3]) >>> t = torch.as_tensor(a, device=torch.device('cuda')) >>> t tensor([ 1, 2, 3]) >>> t[0] = -1 >>> a array([1, 2, 3]) torch.``as_strided( input , size , stride , storage_offset=0 ) → Tensor 与指定的大小创建现有 torch.Tensor输入 的视图，跨步和storage_offset。 Warning 创建的张量的多于一个的元件可指代单个存储器位置。其结果是，就地操作（特别是那些有量化的）可能会导致不正确的行为。如果你需要写张量，请先克隆它们。 许多PyTorch功能，它会返回一个张量的观点，在内部使用此功能来实现。这些功能，如 torch.Tensor.expand（） ，更容易阅读，因此更可取的使用。 Parameters input ( Tensor) – the input tensor 大小 （ 元组 或 整数 ） - 输出张量的形状 步幅 （ 元组 或 整数 ） - 输出张量的步幅 storage_offset （ INT ， 可选 ） - 在输出张量的底层存储的偏移 Example: >>> x = torch.randn(3, 3) >>> x tensor([[ 0.9039, 0.6291, 1.0795], [ 0.1586, 2.1939, -0.4900], [-0.1909, -0.7503, 1.9355]]) >>> t = torch.as_strided(x, (2, 2), (1, 2)) >>> t tensor([[0.9039, 1.0795], [0.6291, 0.1586]]) >>> t = torch.as_strided(x, (2, 2), (1, 2), 1) tensor([[0.6291, 0.1586], [1.0795, 2.1939]]) torch.``from_numpy( ndarray ) → Tensor 创建 张量从 numpy.ndarray 。 返回的张量和ndarray共享相同的存储器。修改对张量将反映在ndarray，反之亦然。返回的张量是不可调整大小。 它目前接受ndarray与dtypes numpy.float64，numpy.float32``numpy.float16，numpy.int64，numpy.int32，numpy.int16，numpy.int8，numpy.uint8和numpy.bool。 Example: >>> a = numpy.array([1, 2, 3]) >>> t = torch.from_numpy(a) >>> t tensor([ 1, 2, 3]) >>> t[0] = -1 >>> a array([-1, 2, 3]) torch.``zeros( *size , out=None , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 返回填充有标量值 0 的张量，由可变参数大小中定义的形状。 Parameters 大小 （ INT ... ） - 定义输出张量的形状的整数序列。可以的参数个数可变或类似的列表或元组的集合。 OUT （ 张量 ， 可选 ） - 输出张量 DTYPE （ torch.dtype，可选） - 返回的张量的所希望的数据类型。默认值：如果无，使用全局默认设置（见 torch.set_default_tensor_type（））。 布局 （ torch.layout，可选） - 返回的张量的所需布局。默认值：torch.strided ``。 device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.zeros(2, 3) tensor([[ 0., 0., 0.], [ 0., 0., 0.]]) >>> torch.zeros(5) tensor([ 0., 0., 0., 0., 0.]) torch.``zeros_like( input , dtype=None , layout=None , device=None , requires_grad=False ) → Tensor 返回填充有标量值 0 的张量，以相同的大小为输入。 torch.zeros_like（输入）等于torch.zeros（input.size（）， D型细胞= input.dtype， 布局= input.layout， 设备= input.device）。 Warning 如为0.4，该功能不支持OUT关键字。作为替代方案，旧torch.zeros_like（输入， OUT =输出）等于torch.zeros（input.size （）， OUT =输出）。 Parameters 输入 （ 张量 ） - 输入的大小将确定输出张量的大小 DTYPE （ torch.dtype，可选） - 所需的数据返回张量的类型。默认值：如果无，默认为输入的D型。 布局 （ torch.layout，可选） - 返回的张量的所需布局。默认值：如果无，默认为输入布局。 装置 （ torch.device，可选） - 返回的张量的所需的设备。默认值：如果无，默认为输入该设备。 requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> input = torch.empty(2, 3) >>> torch.zeros_like(input) tensor([[ 0., 0., 0.], [ 0., 0., 0.]]) torch.``ones( *size , out=None , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 返回填充有标量值 1 的张量，由可变参数大小中定义的形状。 Parameters size ( int... ) – a sequence of integers defining the shape of the output tensor. Can be a variable number of arguments or a collection like a list or tuple. out ( Tensor , optional ) – the output tensor dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.ones(2, 3) tensor([[ 1., 1., 1.], [ 1., 1., 1.]]) >>> torch.ones(5) tensor([ 1., 1., 1., 1., 1.]) torch.``ones_like( input , dtype=None , layout=None , device=None , requires_grad=False ) → Tensor 返回填充有标量值 1 的张量，以相同的大小为输入。 torch.ones_like（输入）等于torch.ones（input.size（）， D型细胞= input.dtype， 布局= input.layout， 设备= input.device）。 Warning 如为0.4，该功能不支持OUT关键字。作为替代方案，旧torch.ones_like（输入， OUT =输出）等于torch.ones（input.size （）， OUT =输出）。 Parameters input ( Tensor) – the size of inputwill determine size of the output tensor dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input. layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input. device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> input = torch.empty(2, 3) >>> torch.ones_like(input) tensor([[ 1., 1., 1.], [ 1., 1., 1.]]) torch.``arange( start=0 , end , step=1 , out=None , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 返回的一个1-d张量大小 ⌈ 结束 - 开始 步骤 ⌉ \\左\\ lceil \\压裂{\\文本{端} - \\文本{开始}} {\\文本{步骤}} \\右\\ rceil ⌈ 步骤 端 - 开始 ⌉ 与来自间隔值[开始， 端）与普通差分采取步骤从开始启动。 ;注意，非整数步骤针对结束比较时受到浮点舍入误差，以避免不一致，我们建议增加一个小的ε-为在这样的情况下结束。 outi+1=outi+step\\text{out}NaN = \\text{out}{i} + \\text{step} outi+1​=outi​+step Parameters 开始 （ 号码 ） - 为对设定点的初始值。默认值：0。 结束 （ 号码 ） - 为对设定点的结束值 步骤 （ 号码 ） - 每一对相邻的点之间的间隙。默认值：1。 out ( Tensor , optional ) – the output tensor DTYPE （ torch.dtype，可选） - 返回的张量的所希望的数据类型。默认值：如果无，使用全局默认设置（见 torch.set_default_tensor_type（））。如果 D型细胞没有给出，推断从其他输入参数的数据类型。如果有任何的开始，结束或停止是浮点时， DTYPE 被推断为默认D型，请参阅 get_default_dtype（）。否则， DTYPE 被推断为 torch.int64 。 layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.arange(5) tensor([ 0, 1, 2, 3, 4]) >>> torch.arange(1, 4) tensor([ 1, 2, 3]) >>> torch.arange(1, 2.5, 0.5) tensor([ 1.0000, 1.5000, 2.0000]) torch.``range( start=0 , end , step=1 , out=None , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 返回的一个1-d张量大小 ⌊ 结束 - 开始 步骤 ⌋ + 1 \\左\\ lfloor \\压裂{\\文本{端} - \\文本{开始}} {\\文本{步骤}} \\右\\ rfloor + 1 ⌊ 步骤 结束 - 开始 [HTG9 5] ⌋ + 1 从值开始至结束与步骤步骤。步骤是在张量的两个值之间的差距。 outi+1=outi+step.\\text{out}_{i+1} = \\text{out}_i + \\text{step}. outi+1​=outi​+step. Warning 此功能有利于弃用torch.arange（）。 Parameters 开始 （ 浮动 ） - 为对设定点的初始值。默认值：0。 对于该组点的结束值 - 端 （ 浮动 ） 步骤 （ 浮动 ） - 每一对相邻的点之间的间隙。默认值：1。 out ( Tensor , optional ) – the output tensor dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). If dtype is not given, infer the data type from the other input arguments. If any of start, end, or stop are floating-point, the dtype is inferred to be the default dtype, see get_default_dtype(). Otherwise, the dtype is inferred to be torch.int64. layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.range(1, 4) tensor([ 1., 2., 3., 4.]) >>> torch.range(1, 4, 0.5) tensor([ 1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000]) torch.``linspace( start , end , steps=100 , out=None , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 返回步骤一维张量之间等距点开始和结束。 输出张量是大小步骤1-d。 Parameters 对于该组点的初始值 - 开始 （ 浮动 ） end ( float) – the ending value for the set of points 步骤 （ INT ） - 点数为开始和端之间采样。默认值：100。 out ( Tensor , optional ) – the output tensor dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.linspace(3, 10, steps=5) tensor([ 3.0000, 4.7500, 6.5000, 8.2500, 10.0000]) >>> torch.linspace(-10, 10, steps=5) tensor([-10., -5., 0., 5., 10.]) >>> torch.linspace(start=-10, end=10, steps=5) tensor([-10., -5., 0., 5., 10.]) >>> torch.linspace(start=-10, end=10, steps=1) tensor([-10.]) torch.``logspace( start , end , steps=100 , base=10.0 , out=None , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 返回与碱碱对数间隔的步骤 点的一维张量之间 基 开始 {\\文本{碱}} ^ {\\文本{开始}} 基 开始 和 基 结束 {\\文本{碱}} ^ {\\文本{端}} 基 结束 。 The output tensor is 1-D of size steps. Parameters start ( float) – the starting value for the set of points end ( float) – the ending value for the set of points steps ( int) – number of points to sample between startand end. Default: 100. 基 （ 浮动 ） - 的对数函数的基础。默认值：10.0。 out ( Tensor , optional ) – the output tensor dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.logspace(start=-10, end=10, steps=5) tensor([ 1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10]) >>> torch.logspace(start=0.1, end=1.0, steps=5) tensor([ 1.2589, 2.1135, 3.5481, 5.9566, 10.0000]) >>> torch.logspace(start=0.1, end=1.0, steps=1) tensor([1.2589]) >>> torch.logspace(start=2, end=2, steps=1, base=2) tensor([4.0]) torch.``eye( n , m=None , out=None , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 返回对角线上，一和零其他地方2 d张量。 Parameters n的 （ INT ） - 的行数 M （ INT ， 可选 ） - 列的默认数目为N out ( Tensor , optional ) – the output tensor dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Returns A 2-d张量的对角和其他地方的零那些 Return type 张量 Example: >>> torch.eye(3) tensor([[ 1., 0., 0.], [ 0., 1., 0.], [ 0., 0., 1.]]) torch.``empty( *size , out=None , dtype=None , layout=torch.strided , device=None , requires_grad=False , pin_memory=False ) → Tensor 返回填充未初始化的数据的张量。张量的形状由可变参数大小中定义。 Parameters size ( int... ) – a sequence of integers defining the shape of the output tensor. Can be a variable number of arguments or a collection like a list or tuple. out ( Tensor , optional ) – the output tensor dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. pin_memory ( bool , optional ) – If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: False. Example: >>> torch.empty(2, 3) tensor(1.00000e-08 * [[ 6.3984, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000]]) torch.``empty_like( input , dtype=None , layout=None , device=None , requires_grad=False ) → Tensor 返回与相同尺寸输入一个未初始化的张量。 torch.empty_like（输入）等于torch.empty（input.size（）， D型细胞= input.dtype， 布局= input.layout， 设备= input.device）。 Parameters input ( Tensor) – the size of inputwill determine size of the output tensor dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input. layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input. device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.empty((2,3), dtype=torch.int64) tensor([[ 9.4064e+13, 2.8000e+01, 9.3493e+13], [ 7.5751e+18, 7.1428e+18, 7.5955e+18]]) torch.``empty_strided( size , stride , dtype=None , layout=None , device=None , requires_grad=False , pin_memory=False ) → Tensor 返回填充未初始化的数据的张量。的形状和张量的进展是由可变参数大小和步幅分别定义。 torch.empty_strided（大小， 步幅）等价于.as_strided torch.empty（大小）（大小， 步幅）。 Warning 所创建的张量的多于一个的元件可指代单个存储器位置。其结果是，就地操作（特别是那些有量化的）可能会导致不正确的行为。如果你需要写张量，请先克隆它们。 Parameters 大小 （ 蟒的元组：整数 ） - 输出张量的形状 步幅 （ 蟒的元组：整数 ） - 输出张量的步幅 dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. pin_memory ( bool , optional ) – If set, returned tensor would be allocated in the pinned memory. Works only for CPU tensors. Default: False. Example: >>> a = torch.empty_strided((2, 3), (1, 2)) >>> a tensor([[8.9683e-44, 4.4842e-44, 5.1239e+07], [0.0000e+00, 0.0000e+00, 3.0705e-41]]) >>> a.stride() (1, 2) >>> a.size() torch.Size([2, 3]) torch.``full( size , fill_value , out=None , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 返回充满fill_value大小大小的张量。 Parameters 大小 （ INT ... ） - 列表，元组，或torch.Size定义输出张量的形状的整数。 fill_value - 数以填充与输出张量。 out ( Tensor , optional ) – the output tensor dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.full((2, 3), 3.141592) tensor([[ 3.1416, 3.1416, 3.1416], [ 3.1416, 3.1416, 3.1416]]) torch.``full_like( input , fill_value , out=None , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 返回与输入填充有fill_value如相同尺寸的张量。 torch.full_like（输入， fill_value）等于torch.full（input.size（）， fill_value， D型细胞= input.dtype， 布局= input.layout， 设备= input.device）。 Parameters input ( Tensor) – the size of inputwill determine size of the output tensor fill_value – the number to fill the output tensor with. dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input. layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input. device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. 索引，切片，加入，变异行动 torch.``cat( tensors , dim=0 , out=None ) → Tensor 串接SEQ 在给定的尺寸张量给定的序列。所有张量必须具有相同的形状（除了在串接的尺寸）或为空。 torch.cat（）可以被看作是对 torch.split）的逆操作（和 torch.chunk（）。 torch.cat（）可以通过最好的实施例的理解。 Parameters 张量 （ 张量 的序列） - 相同类型的张量的任何蟒序列。提供必须具有相同的形状，除了在猫尺寸非空张量。 暗淡 （ INT ， 可选 ） - 在其上张量被级联的尺寸 out ( Tensor , optional ) – the output tensor Example: >>> x = torch.randn(2, 3) >>> x tensor([[ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497]]) >>> torch.cat((x, x, x), 0) tensor([[ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497], [ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497], [ 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497]]) >>> torch.cat((x, x, x), 1) tensor([[ 0.6580, -1.0969, -0.4614, 0.6580, -1.0969, -0.4614, 0.6580, -1.0969, -0.4614], [-0.1034, -0.5790, 0.1497, -0.1034, -0.5790, 0.1497, -0.1034, -0.5790, 0.1497]]) torch.``chunk( input , chunks , dim=0 ) → List of Tensors 拆分一个张成大块的具体数量。 最后一块会比较小，如果沿给定尺寸的大小张暗淡是不是块整除。 Parameters 输入 （ 张量 ） - 张量来分割 块 （ INT ） - 组块的数目返回 暗淡 （ INT ） - 维沿着分裂张量 torch.``gather( input , dim , index , out=None , sparse_grad=False ) → Tensor 集值一起由暗淡中指定的轴。 对于3-d张量由指定的输出： out[i][j][k] = input[index[i][j][k]][j][k] # if dim == 0 out[i][j][k] = input[i][index[i][j][k]][k] # if dim == 1 out[i][j][k] = input[i][j][index[i][j][k]] # if dim == 2 如果输入是具有n维张量大小 （ × 0 ， × 1 。[HTG27 。] ， × i的 - 1 ， × i的 ， × i的 + 1 ， 。 。 ， × n的 - 1 ） （X0，X_1 ...，X {I-1}，XI，X {I + 1}，... 。，X {N-1}） （ × 0 ， × 1 。 。 。 ， × i的 - 1 ， × i的 ， × i的 + 1 ​​ ， 。 。 。 ， × n的 - 1 ） 和暗淡 = i的，然后索引必须为 n的 n的 n的 维张量与尺寸 （ × [HTG37 8] 0 ， × 1 ， 。 。 。 ， × i的 - 1 ， Y ， × i的 + 1 ， 。 。 。 ， × n的 - 1 ） （X_0，X_1，...，X {I-1}，Y，X {I + 1}，...，X {N-1}） （ × 0 ， × 1 ， 。 。 。 ， × i的 - 1 ， Y ， × i的 + 1 ， 。 。 。 ， × n的 - 1 ） 其中 Y ≥ 1 Y \\ GEQ 1 Y ≥ 1 和OUT将具有相同的大小为索引 [ HTG719。 Parameters 输入 （ 张量 ） - 源张量 暗淡 （ INT ） - 的轴，沿着该索引 索引 （ LongTensor ） - 元素的索引来收集 OUT （ 张量 ， 可选 ） - 目的地张量 sparse_grad （ 布尔 ， 可选 ） - 如果真，梯度WRT 输入将是一个稀疏张量。 Example: >>> t = torch.tensor([[1,2],[3,4]]) >>> torch.gather(t, 1, torch.tensor([[0,0],[1,0]])) tensor([[ 1, 1], [ 4, 3]]) torch.``index_select( input , dim , index , out=None ) → Tensor 使用中的条目索引返回一个新的张量，其索引输入 沿着维度张量暗淡 ``其是 LongTensor 。 返回的张量具有相同的维数与原始张量（输入）的。的暗淡次尺寸有大小为的长度相同的索引;其它尺寸具有相同的大小与在原始张量。 Note 返回的张量确实 不是 使用相同的存储与原张量。如果出具有与预期不同的形状，我们默默地将其更改为正确的形状，必要时重新分配基础存储空间。 Parameters input ( Tensor) – the input tensor 暗淡 （ INT ） - 的尺寸，其中我们索引 索引 （ LongTensor ） - 包含索引到索引1-d张量 out ( Tensor , optional ) – the output tensor Example: >>> x = torch.randn(3, 4) >>> x tensor([[ 0.1427, 0.0231, -0.5414, -1.0009], [-0.4664, 0.2647, -0.1228, -1.1068], [-1.1734, -0.6571, 0.7230, -0.6004]]) >>> indices = torch.tensor([0, 2]) >>> torch.index_select(x, 0, indices) tensor([[ 0.1427, 0.0231, -0.5414, -1.0009], [-1.1734, -0.6571, 0.7230, -0.6004]]) >>> torch.index_select(x, 1, indices) tensor([[ 0.1427, -0.5414], [-0.4664, -0.1228], [-1.1734, 0.7230]]) torch.``masked_select( input , mask , out=None ) → Tensor 返回一个新的1-d张量的输入根据布尔掩模张量掩模哪些索引其是 BoolTensor [ HTG9。 在面具张量的形状和输入张量不需要匹配，但是他们必须 broadcastable 。 Note 返回的张量并 不 使用相同的存储作为原始张量 Parameters 输入 （ 张量 ） - 输入数据 掩模 （ BoolTensor ） - 包含布尔掩码索引与张力 out ( Tensor , optional ) – the output tensor Example: >>> x = torch.randn(3, 4) >>> x tensor([[ 0.3552, -2.3825, -0.8297, 0.3477], [-1.2035, 1.2252, 0.5002, 0.6248], [ 0.1307, -2.0608, 0.1244, 2.0139]]) >>> mask = x.ge(0.5) >>> mask tensor([[False, False, False, False], [False, True, True, True], [False, False, False, True]]) >>> torch.masked_select(x, mask) tensor([ 1.2252, 0.5002, 0.6248, 2.0139]) torch.``narrow( input , dim , start , length ) → Tensor 返回一个新的张量是输入张量缩小版本。尺寸暗淡是从输入开始至开始 + 长度。返回的张量和输入张量共享同一基础存储。 Parameters 输入 （ 张量 ） - 张量来缩小 暗淡 （ INT ） - 沿其尺寸缩小 开始 （ INT ） - 的起始尺寸 长度 （ INT ） - 的距离到结束尺寸 Example: >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> torch.narrow(x, 0, 0, 2) tensor([[ 1, 2, 3], [ 4, 5, 6]]) >>> torch.narrow(x, 1, 1, 2) tensor([[ 2, 3], [ 5, 6], [ 8, 9]]) torch.``nonzero( input , * , out=None , as_tuple=False ) → LongTensor or tuple of LongTensors [HTG0当 as_tuple是假或不特定： 返回包含输入的所有非零元素的索引的张量。结果中的每行包含一个非零元素的索引在输入。其结果是字典顺序排序，最后指数变化最快的（C风格）。 如果输入具有 n的的尺寸，然后将所得的指数张量OUT是大小为 （ Z × n的 ） （Z \\ n次） （ Z × n的 ） ，其中 Z Z Z 是在输入的非零元素的总数张量。 [HTG0当 as_tuple是否成立： 返回的1-d张量在输入每个维度一个元组，一个，各含有的所有非零元素的索引（该维度）输入。 如果输入具有 n的的尺寸，然后将所得的元组包含 n的大小 Z ，其中[HTG10的张量] Z 是在输入张量的非零元素的总数。 作为一种特殊的情况下，当输入具有零种尺寸和非零标量值，它被视为一个元素的一维张量。 Parameters input ( Tensor) – the input tensor OUT （ LongTensor ， 可选 ） - 包含索引的输出张量 Returns 如果as_tuple是假的，含有索引输出张量。如果as_tuple为真，一个1-d张量针对每个维度，沿包含该维度的每个非零元素的索引。 Return type LongTensor或LongTensor的元组 Example: >>> torch.nonzero(torch.tensor([1, 1, 1, 0, 1])) tensor([[ 0], [ 1], [ 2], [ 4]]) >>> torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0], [0.0, 0.4, 0.0, 0.0], [0.0, 0.0, 1.2, 0.0], [0.0, 0.0, 0.0,-0.4]])) tensor([[ 0, 0], [ 1, 1], [ 2, 2], [ 3, 3]]) >>> torch.nonzero(torch.tensor([1, 1, 1, 0, 1]), as_tuple=True) (tensor([0, 1, 2, 4]),) >>> torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0], [0.0, 0.4, 0.0, 0.0], [0.0, 0.0, 1.2, 0.0], [0.0, 0.0, 0.0,-0.4]]), as_tuple=True) (tensor([0, 1, 2, 3]), tensor([0, 1, 2, 3])) >>> torch.nonzero(torch.tensor(5), as_tuple=True) (tensor([0]),) torch.``reshape( input , shape ) → Tensor 返回与元件为输入相同的数据和数字的张量，但随着特定的形状。如果可能的话，返回的张量将是输入的图。否则，这将是一个副本。连续的投入和兼容的进步投入而不用拷贝进行塑形，但你不应该依赖于复制与收视行为。 参见 torch.Tensor.view（）上时，它可以返回的图。 单个维度可以是-1，在这种情况下，它从剩余的尺寸和元件的在输入的数量推断。 Parameters 输入 （ 张量 ） - 要重塑张量 形状 （ 蟒的元组：整数 ） - 新的形状 Example: >>> a = torch.arange(4.) >>> torch.reshape(a, (2, 2)) tensor([[ 0., 1.], [ 2., 3.]]) >>> b = torch.tensor([[0, 1], [2, 3]]) >>> torch.reshape(b, (-1,)) tensor([ 0, 1, 2, 3]) torch.``split( tensor , split_size_or_sections , dim=0 )[source] 拆分张成块。 如果split_size_or_sections是整数类型，则 张量将被分成相等大小的块（如果可能） 。最后一块会比较小，如果沿给定尺寸的大小张暗淡是不是split_size整除。 如果split_size_or_sections是一个列表，然后 张量将被分割为LEN（根据 split_size_or_sectionssplit_size_or_sections）与大小的块暗淡。 Parameters 张量 （ 张量 ） - 张量来分割。 split_size_or_sections （ INT ）或 （ 列表 （ INT ） ） - 对于每个大块单个块或列表尺寸的大小 暗淡 （ INT ） - 维沿着分裂张量。 torch.``squeeze( input , dim=None , out=None ) → Tensor 返回与除去 大小的 1输入的所有尺寸的张量。 例如，如果输入是形状的： （ A × 1 × B × C × 1 × d ） （A \\倍1 \\倍乙\\ C时代\\倍1 \\倍d） （ A × 1 × B × C × 1 × d ） ，则 OUT 张量将是形状的： （ A × B × C × d ） （A \\倍乙\\ C时代\\倍d） （ A × B × C × d ） 。 当暗淡给出，挤压操作仅在给定的尺寸完成。如果输入是形状的： （ A × 1 × B ） （A \\倍1 \\倍B） （ A × 1 × B ） ，挤压（输入， 0）离开张量不变，但是挤压（输入， 1）会挤压张量的形状 （ A × B [H TG96]） （A \\倍B） （ A × B ） 。 Note 返回的张股与输入张量的存储，所以改变一个的内容会改变其他的内容。 Parameters input ( Tensor) – the input tensor 暗淡 （ INT ， 可选 ） - 如果给定的，该输入将被只在这个尺寸挤 out ( Tensor , optional ) – the output tensor Example: >>> x = torch.zeros(2, 1, 2, 1, 2) >>> x.size() torch.Size([2, 1, 2, 1, 2]) >>> y = torch.squeeze(x) >>> y.size() torch.Size([2, 2, 2]) >>> y = torch.squeeze(x, 0) >>> y.size() torch.Size([2, 1, 2, 1, 2]) >>> y = torch.squeeze(x, 1) >>> y.size() torch.Size([2, 2, 1, 2]) torch.``stack( tensors , dim=0 , out=None ) → Tensor 串接沿着一个新的层面张量的序列。 所有的张量需要是相同大小的。 Parameters 张量 （ 张量的序列 ） - 张量的序列来连接 暗淡 （ INT ） - 要插入的尺寸。必须是0和级联张量的维数（含）之间 out ( Tensor , optional ) – the output tensor torch.``t( input ) → Tensor 预计输入为& LT ; = 2-d张量和调换尺寸0和1。 0-d和1-d张量返回，因为它是和2- d张量可以被看作是一个短手功能为转置（输入， 0， 1）。 Parameters input ( Tensor) – the input tensor Example: >>> x = torch.randn(()) >>> x tensor(0.1995) >>> torch.t(x) tensor(0.1995) >>> x = torch.randn(3) >>> x tensor([ 2.4320, -0.4608, 0.7702]) >>> torch.t(x) tensor([.2.4320,.-0.4608,..0.7702]) >>> x = torch.randn(2, 3) >>> x tensor([[ 0.4875, 0.9158, -0.5872], [ 0.3938, -0.6929, 0.6932]]) >>> torch.t(x) tensor([[ 0.4875, 0.3938], [ 0.9158, -0.6929], [-0.5872, 0.6932]]) torch.``take( input , index ) → Tensor 返回与输入 的在给定的索引的元素的新的张量。如同其被看作是一个1-d张量的输入张量得到治疗。结果取相同的形状指数。 Parameters input ( Tensor) – the input tensor 索引 （ LongTensor ） - 索引为张量 Example: >>> src = torch.tensor([[4, 3, 5], [6, 7, 8]]) >>> torch.take(src, torch.tensor([0, 2, 5])) tensor([ 4, 5, 8]) torch.``transpose( input , dim0 , dim1 ) → Tensor 返回一个张量是输入转置版本。给定尺寸的DIM0和DIM1被交换。 将得到的OUT张量股它底层存储与输入张量，所以改变一个的内容会改变其他的内容。 Parameters input ( Tensor) – the input tensor DIM0 （ INT ） - 要调换第一维 DIM1 （ INT ） - 要调换的第二维 Example: >>> x = torch.randn(2, 3) >>> x tensor([[ 1.0028, -0.9893, 0.5809], [-0.1669, 0.7299, 0.4942]]) >>> torch.transpose(x, 0, 1) tensor([[ 1.0028, -0.1669], [-0.9893, 0.7299], [ 0.5809, 0.4942]]) torch.``unbind( input , dim=0 ) → seq 删除一个张量尺寸。 返回所有切片的元组沿着一个给定的尺寸，已经离不开它。 Parameters 输入 （ 张量 ） - 张量解除绑定 暗淡 （ INT ） - 尺寸，以除去 Example: >>> torch.unbind(torch.tensor([[1, 2, 3], >>> [4, 5, 6], >>> [7, 8, 9]])) (tensor([1, 2, 3]), tensor([4, 5, 6]), tensor([7, 8, 9])) torch.``unsqueeze( input , dim , out=None ) → Tensor 返回与在指定的位置插入一个大小的尺寸新的张量。 返回的张股与此张量相同的基础数据。 1， [ - A `[-input.dim（范围） 内暗淡值HTG11] input.dim（） + 1） 可被使用。负暗淡 施加将对应于unsqueeze（）在暗淡= 暗淡 \\+ input.dim（） \\+ 1。` Parameters input ( Tensor) – the input tensor 暗淡 （ INT ） - 索引处插入单维 out ( Tensor , optional ) – the output tensor Example: >>> x = torch.tensor([1, 2, 3, 4]) >>> torch.unsqueeze(x, 0) tensor([[ 1, 2, 3, 4]]) >>> torch.unsqueeze(x, 1) tensor([[ 1], [ 2], [ 3], [ 4]]) torch.``where() torch.``where( condition , input , other ) → Tensor 返回元件的从任一输入或其他，取决于条件 [HTG11选择的张量]。 该操作被定义为： outi={inputiif conditioniotheriotherwise\\text{out}_i = \\begin{cases} \\text{input}_i & \\text{if } \\text{condition}_i \\\\ \\text{other}_i & \\text{otherwise} \\\\ \\end{cases} outi​={inputi​otheri​​if conditioni​otherwise​ Note 张量条件，输入，其他必须 broadcastable 。 Parameters 条件 （ BoolTensor ） - 当真（非零），产率的x，否则成品率Y × （ 张量 ） - 在索引选择的值，其中条件是真 Y （ 张量 ） - 在索引选择的值，其中条件是假 Returns 形状的张量等于条件所广播的形状，输入，其他 Return type Tensor Example: >>> x = torch.randn(3, 2) >>> y = torch.ones(3, 2) >>> x tensor([[-0.4620, 0.3139], [ 0.3898, -0.7197], [ 0.0478, -0.1657]]) >>> torch.where(x > 0, x, y) tensor([[ 1.0000, 0.3139], [ 0.3898, 1.0000], [ 0.0478, 1.0000]]) torch.``where( condition ) → tuple of LongTensor torch.where（条件）是相同的torch.nonzero（条件， as_tuple =真）。 Note 另请参见 torch.nonzero（）。 发电机 classtorch._C.``Generator( device='cpu' ) → Generator 创建并返回其管理产生的伪随机数的算法的状态的生成器对象。用作许多 就地随机抽样 功能的关键字参数。 Parameters 装置 （torch.device，可选） - 用于发电机所需的设备。 Returns 一个torch.Generator对象。 Return type 发生器 Example: >>> g_cpu = torch.Generator() >>> g_cuda = torch.Generator(device='cuda') device Generator.device - & GT ;装置 获取发电机的电流设备。 Example: >>> g_cpu = torch.Generator() >>> g_cpu.device device(type='cpu') get_state() → Tensor 返回发电机状态作为torch.ByteTensor。 Returns A torch.ByteTensor ，其包含所有必要的比特到发电机还原到在特定时间点。 Return type Tensor Example: >>> g_cpu = torch.Generator() >>> g_cpu.get_state() initial_seed() → int 返回用于产生随机数的初始种子。 Example: >>> g_cpu = torch.Generator() >>> g_cpu.initial_seed() 2147483647 manual_seed( seed ) → Generator 设置生成随机数种子。返回 torch.Generator 对象。它建议设置一个大的种子，即一个数字，具有0和1位的良好平衡。避免在种子具有许多0比特。 Parameters 种子 （ INT ） - 所需的种子。 Returns An torch.Generator object. Return type Generator Example: >>> g_cpu = torch.Generator() >>> g_cpu.manual_seed(2147483647) seed() → int 从获取的std :: random_device或当前时间的非确定性的随机数，并使用该种子的发电机。 Example: >>> g_cpu = torch.Generator() >>> g_cpu.seed() 1516516984916 set_state( new_state ) → void 设置发电机的状态。 Parameters NEW_STATE （ torch.ByteTensor ） - 所需的状态。 Example: >>> g_cpu = torch.Generator() >>> g_cpu_other = torch.Generator() >>> g_cpu.set_state(g_cpu_other.get_state()) 随机取样 torch.``seed()[source] 设置用于产生随机数，以非确定性的随机数种子。返回用于播种RNG一个64位的数。 torch.``manual_seed( seed )[source] 设置生成随机数种子。返回 torch.Generator 对象。 Parameters seed ( int) – The desired seed. torch.``initial_seed()[source] 返回初始种子用于产生随机数作为一个Python 长。 torch.``get_rng_state()[source] 返回随机数发生器状态作为 torch.ByteTensor 。 torch.``set_rng_state( new_state )[source] 设置随机数生成器的状态。 Parameters NEW_STATE （ torch.ByteTensor ） - 期望状态 torch.``default_generatorReturns the default CPU torch.Generator torch.``bernoulli( input , * , generator=None , out=None ) → Tensor 从伯努利分布绘制二进制随机数（0或1）。 的输入张量应该是包含概率被用于绘制二进制随机数的张量。因此，在输入的所有值必须在范围： 0 ≤ 输入 i的 ≤ 1 0 \\当量\\文本{输入} _i \\当量1 0 ≤ 输入 i的 ≤ 1 。 的 i的 T H \\文本{I} ^ {第} I T H 输出张量的元件将以此为值 1 1 1 根据 i的 T H \\文本{I} ^ {}第 i的 T H 的概率值在输入给定的。 outi∼Bernoulli(p=inputi)\\text{out}{i} \\sim \\mathrm{Bernoulli}(p = \\text{input}{i}) outi​∼Bernoulli(p=inputi​) 返回的OUT张量仅具有值0或1，是相同的形状的作为输入。 OUT可以具有积分DTYPE，但输入必须浮点DTYPE。 Parameters 输入 （ 张量 ） - 概率值的伯努利分布的输入张量 out ( Tensor , optional ) – the output tensor Example: >>> a = torch.empty(3, 3).uniform_(0, 1) # generate a uniform random matrix with range [0, 1] >>> a tensor([[ 0.1737, 0.0950, 0.3609], [ 0.7148, 0.0289, 0.2676], [ 0.9456, 0.8937, 0.7202]]) >>> torch.bernoulli(a) tensor([[ 1., 0., 0.], [ 0., 0., 0.], [ 1., 1., 1.]]) >>> a = torch.ones(3, 3) # probability of drawing \"1\" is 1 >>> torch.bernoulli(a) tensor([[ 1., 1., 1.], [ 1., 1., 1.], [ 1., 1., 1.]]) >>> a = torch.zeros(3, 3) # probability of drawing \"1\" is 0 >>> torch.bernoulli(a) tensor([[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]]) torch.``multinomial( input , num_samples , replacement=False , out=None ) → LongTensor 返回其中每行都包含张量num_samples指数从位于张量输入 的的相应行中的多项式概率分布进行采样。 Note 的行输入不需要总和为1（在这种情况下，我们使用的值作为权重），但必须是非负的，有限的，并且有一个非零和。 指数从左到右，根据当每个取样（第一样品放置在第一列）来排序。 如果输入是矢量，OUT是大小num_samples 的的载体。 如果输入是与的矩阵M 行，OUT是形状 [HTG11的矩阵] （ M × num_samples ） （M \\倍\\文本{NUM \\ _samples}） （ M × num_samples ） 。 如果替换为真，样品绘制更换。 如果不是，他们绘制无需更换，这意味着当指数样本绘制为行，不能再为该行画出。 Note 当不需更换绘制，num_samples必须大于（在输入非零元素的数目或最小数目的非下输入 如果它是一个矩阵）的每行中非零元素。 Parameters 输入 （ 张量 ） - 包含概率输入张量 num_samples （ INT ） - 样本的数目来绘制 替换 （ 布尔 ， 可选 ） - 是否与更换或不画 out ( Tensor , optional ) – the output tensor Example: >>> weights = torch.tensor([0, 10, 3, 0], dtype=torch.float) # create a tensor of weights >>> torch.multinomial(weights, 2) tensor([1, 2]) >>> torch.multinomial(weights, 4) # ERROR! RuntimeError: invalid argument 2: invalid multinomial distribution (with replacement=False, not enough non-negative category to sample) at ../aten/src/TH/generic/THTensorRandom.cpp:320 >>> torch.multinomial(weights, 4, replacement=True) tensor([ 2, 1, 1, 1]) torch.``normal() torch.``normal( mean , std , out=None ) → Tensor 返回从独立的正态分布，其平均值和标准偏差给出绘制随机数的张量。 的 意味着是与每个输出元件的正常分布的平均值的张量 的 STD是与每个输出元件的正态分布的标准偏差的张量 的形状 [平均HTG3]和 性病不需要匹配，但是在各张量元素的总数量需要是相同的。 Note 当形状不匹配，的 形状意味着被用作形状为返回的输出张量 Parameters 意味着 （ 张量 ） - 每个元素的装置的张量 STD （ 张量 ） - 每个元素的标准偏差的张量 out ( Tensor , optional ) – the output tensor Example: >>> torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1)) tensor([ 1.0425, 3.5672, 2.7969, 4.2925, 4.7229, 6.2134, 8.0505, 8.1408, 9.0563, 10.0566]) torch.``normal( mean=0.0 , std , out=None ) → Tensor 上述功能，但是类似的装置都被绘制的元素之间共享。 Parameters 意味着 （ 浮动 ， 可选 ） - 平均为所有的发行 std ( Tensor) – the tensor of per-element standard deviations out ( Tensor , optional ) – the output tensor Example: >>> torch.normal(mean=0.5, std=torch.arange(1., 6.)) tensor([-1.2793, -1.0732, -2.0687, 5.1177, -1.2303]) torch.``normal( mean , std=1.0 , out=None ) → Tensor 与上述类似的功能，但标准偏差都绘制的元素之间共享。 Parameters mean ( Tensor) – the tensor of per-element means STD （ 浮动 ， 可选 ） - 所有分布的标准偏差 out ( Tensor , optional ) – the output tensor Example: >>> torch.normal(mean=torch.arange(1., 6.)) tensor([ 1.1552, 2.6148, 2.6535, 5.8318, 4.2361]) torch.``normal( mean , std , size , * , out=None ) → Tensor 类似于上面的功能，但是平均值和标准偏差都绘制的元素之间共享。将得到的张量具有由大小给定的大小。 Parameters 意味着 （ 浮动 ） - 平均为所有的发行 STD （ 浮 ） - 标准对于所有分布偏差 大小 （ INT ... ） - 定义输出张量的形状的整数序列。 out ( Tensor , optional ) – the output tensor Example: >>> torch.normal(2, 3, size=(1, 4)) tensor([[-1.3987, -1.9544, 3.6048, 0.7909]]) torch.``rand( *size , out=None , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 返回在区间 [ 0 填充有随机数从均匀分布的张量， 1 ） [0，1） [ 0 ， 1 ） 张量的形状由可变参数大小中定义。 Parameters size ( int... ) – a sequence of integers defining the shape of the output tensor. Can be a variable number of arguments or a collection like a list or tuple. out ( Tensor , optional ) – the output tensor dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.rand(4) tensor([ 0.5204, 0.2503, 0.3525, 0.5673]) >>> torch.rand(2, 3) tensor([[ 0.8237, 0.5781, 0.6879], [ 0.3816, 0.7249, 0.0998]]) torch.``rand_like( input , dtype=None , layout=None , device=None , requires_grad=False ) → Tensor 返回具有相同尺寸的张量为输入填充有随机数从均匀分布在区间 [ 0 ， 1 ） [0，1） [ 0 ， 1 ） 。 torch.rand_like（输入）等于torch.rand（input.size（）， D型细胞= input.dtype， 布局= input.layout， 设备= input.device）。 Parameters input ( Tensor) – the size of inputwill determine size of the output tensor dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input. layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input. device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. torch.``randint( low=0 , high , size , out=None , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 返回填充有随机整数的张量产生均匀之间低（含）和高（异）。 The shape of the tensor is defined by the variable argument size. Parameters 低 （ INT ， 可选 ） - 以从分布中抽取最低整数。默认值：0。 高 （ INT ） - 一个以上的最大整数为从分布中抽取。 大小 （ 元组 ） - 元组限定所述输出张量的形状。 out ( Tensor , optional ) – the output tensor dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.randint(3, 5, (3,)) tensor([4, 3, 4]) >>> torch.randint(10, (2, 2)) tensor([[0, 2], [5, 5]]) >>> torch.randint(3, 10, (2, 2)) tensor([[4, 5], [6, 7]]) torch.``randint_like( input , low=0 , high , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 返回与相同形状的张量作为填充有随机整数张量输入产生均匀之间低（含）和高（异）。 Parameters input ( Tensor) – the size of inputwill determine size of the output tensor low ( int , optional ) – Lowest integer to be drawn from the distribution. Default: 0. high ( int) – One above the highest integer to be drawn from the distribution. dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input. layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input. device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. torch.``randn( *size , out=None , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 返回填充的随机数从正态分布与平均值的张量 0 和方差HTG2] 1 （也称为标准正态分布）。 outi∼N(0,1)\\text{out}_{i} \\sim \\mathcal{N}(0, 1) outi​∼N(0,1) The shape of the tensor is defined by the variable argument size. Parameters size ( int... ) – a sequence of integers defining the shape of the output tensor. Can be a variable number of arguments or a collection like a list or tuple. out ( Tensor , optional ) – the output tensor dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.randn(4) tensor([-2.1436, 0.9966, 2.3426, -0.6366]) >>> torch.randn(2, 3) tensor([[ 1.5954, 2.8929, -1.0923], [ 1.1719, -0.4709, -0.1996]]) torch.``randn_like( input , dtype=None , layout=None , device=None , requires_grad=False ) → Tensor 返回一个张量的大小相同输入填充有随机数从正态分布均值为0，方差为1。torch.randn_like（输入）等于torch.randn（input.size（）， D型细胞= input.dtype， 布局= input.layout， 设备= input.device）。 Parameters input ( Tensor) – the size of inputwill determine size of the output tensor dtype (torch.dtype, optional) – the desired data type of returned Tensor. Default: if None, defaults to the dtype of input. layout (torch.layout, optional) – the desired layout of returned tensor. Default: if None, defaults to the layout of input. device (torch.device, optional) – the desired device of returned tensor. Default: if None, defaults to the device of input. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. torch.``randperm( n , out=None , dtype=torch.int64 , layout=torch.strided , device=None , requires_grad=False ) → LongTensor 返回整数的随机置换从0至n的 - 1。 Parameters n的 （ INT ） - 上限（不包括） out ( Tensor , optional ) – the output tensor DTYPE （ torch.dtype，可选） - 返回的张量的所希望的数据类型。默认值：torch.int64。 layout (torch.layout, optional) – the desired layout of returned Tensor. Default: torch.strided. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> torch.randperm(4) tensor([2, 1, 0, 3]) 就地随机抽样 有关于张量的定义以及几个就地随机抽样功能。点击进入是指他们的文档： torch.Tensor.bernoulli_（） - 就地版本 torch.bernoulli的（） torch.Tensor.cauchy_（） - 从柯西分布抽取的数字 torch.Tensor.exponential_（） - 从所述指数分布抽取的数字 torch.Tensor.geometric_（） - 从所述几何分布绘制的元素 torch.Tensor.log_normal_（） - 从所述对数正态分布的样品 torch.Tensor.normal_（） - 就地版本 torch.normal的（） torch.Tensor.random_（） - 从所述离散均匀分布采样的数字 torch.Tensor.uniform_（） - 从所述连续均匀分布采样的数字 准随机采样 classtorch.quasirandom.``SobolEngine( dimension , scramble=False , seed=None )[source] 的 torch.quasirandom.SobolEngine是用于生成（加扰）的发动机Sobol序列。 Sobol序列是低差异准随机序列的一个例子。 用于Sobol序列的发动机的这种实现能够采样序列的高达1111它使用方向编号，以产生这些序列的最大尺寸，并且这些数字已经适应从这里。 参考 艺术B.欧文。扰Sobol和的Niederreiter星点。轴颈复杂性，14（4）：466-489，1998年12月。 I. M. Sobol。点的立方体的分布和积分的准确评估。深航。 Vychisl。垫。我在。物理学，7：784-802，1967。 Parameters 维 （ INT ） - 的序列的维度要绘制 加扰 （ 布尔 ， 可选 ） - 此设定为真将产生加扰Sobol序列。扰是能够产生更好Sobol序列。默认值：假 [HTG17。 种子 （ INT ， 可选 ） - 这是对加扰种子。随机数发生器的种子被设定为这一点，如果指定。默认值：无 例子： >>> soboleng = torch.quasirandom.SobolEngine(dimension=5) >>> soboleng.draw(3) tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000], [0.7500, 0.2500, 0.7500, 0.2500, 0.7500], [0.2500, 0.7500, 0.2500, 0.7500, 0.2500]]) draw( n=1 , out=None , dtype=torch.float32 )[source] 函数从Sobol序列绘制的n的点的序列。需要注意的是样品是依赖于先前的样本。结果的大小是 （ n的 ， d i的 M E n的 S i的 O n的 ） （N，尺寸） （ n的 ， d i的 M E n的 S i的 O n的 ） 。 Parameters n的 （ INT ， 可选 ） - 点的序列的长度来绘制。默认值：1 OUT （ 张量 ， 可选 ） - 输出张量 DTYPE （torch.dtype，可选） - 返回的张量的所希望的数据类型。默认值：torch.float32 fast_forward( n )[source] 通过n的步功能快进的SobolEngine的状态。这等同于在不使用样品绘图n的样品。 Parameters n的 （ INT ） - 的步数由快进。 reset()[source] 功能重置SobolEngine到基本状态。 序列 torch.``save( obj , f , pickle_module= , pickle_protocol=2 )[source] 保存对象到磁盘文件。 参见： 用于保存模型推荐的方法 Parameters OBJ - 保存对象 F - 一个类文件对象（必须实现写和flush）或包含文件名的字符串 pickle_module - 模块用于酸洗的元数据和对象 pickle_protocol - 可以指定覆盖默认协议 Warning 如果您在使用Python 2， torch.save（）不支持StringIO.StringIO作为有效的类文件对象。这是因为写方法应该返回写入的字节数; StringIO.write（）不执行此操作。 请使用类似 io.BytesIO代替。 例 >>> # Save to file >>> x = torch.tensor([0, 1, 2, 3, 4]) >>> torch.save(x, 'tensor.pt') >>> # Save to io.BytesIO buffer >>> buffer = io.BytesIO() >>> torch.save(x, buffer) torch.``load( f , map_location=None , pickle_module= , **pickle_load_args )[source] 加载一个对象保存 从文件torch.save（）。 torch.load（） 使用Python的在unpickle设施，但对待仓库，其背后张量，特别是。他们首先反序列化在CPU上，然后被转移到他们从已保存的设备。如果失败（例如，由于运行时系统不具有一定的设备），将引发一个例外。然而，存储器可以被动态地重新映射到一组替代使用map_location参数的设备。 如果map_location是一个可调用，它将被一次为每个串行化存储用两个参数称为：存储和位置。存储参数将是存储的初始反序列化，驻留在所述CPU上。每个串行化存储具有与其相关联的位置标签识别它是从保存该设备，该标签是传递给map_location第二个参数。内置的位置代码是'CPU' [HTG11用于CPU张量和'CUDA：DEVICE_ID' （例如' CUDA：2'）为CUDA张量。map_location返回值应当是无 或存储。如果map_location 返回一个存储，它将被用作最终反序列化对象，已被移动到正确的设备。否则，torch.load（） 将回落到默认的行为，仿佛 map_locationWASN” Ť规定。 如果map_location是 torch.device 对象或字符串contraining设备标记，其指示的位置所有张量应该被加载。 否则，如果map_location是一个字典，它将被用于重新映射出现的文件（密钥）的位置标记，以那些指定在哪里放置存储器（值）。 用户扩展可使用torch.serialization.register_package（）注册自己的位置的标签和标记和反串行化的方法。 Parameters F - 一个类文件对象（必须实现读（）：methreadline，：methtell，并且：methseek），或包含文件名的字符串 map_location - 的函数， torch.device，字符串或一个字典指定如何重新映射的存储位置 pickle_module - 用于取储存元数据和对象模块（具有相匹配的pickle_module用于序列化文件） pickle_load_args - 可选的关键字参数传递到pickle_module.load（）和pickle_module.Unpickler（）例如，编码= ...。 Note 当你调用 torch.load（）在包含GPU张量的文件时，这些张量将被默认加载到GPU。可以调用torch.load（..， map_location = 'CPU'）→load_state_dict（）以避免GPU RAM浪涌加载模型的检查点时。 Note 在Python 3，加载由Python 2中保存的文件时，可能会遇到的UnicodeDecodeError： 'ASCII' 编解码器 不能 解码 字节 0X ...... [HTG15。这是由你可以使用额外的编码 关键字参数来指定这些对象应该如何被加载后，在Python2和Python 3字节串处理差异造成的如编码= 'latin1的' 使用LATIN1编码对它们进行解码为字符串，并编码= '字节' 使他们作为可稍后 byte_array.decode（......） 解码字节阵列。 Example >>> torch.load('tensors.pt') # Load all tensors onto the CPU >>> torch.load('tensors.pt', map_location=torch.device('cpu')) # Load all tensors onto the CPU, using a function >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage) # Load all tensors onto GPU 1 >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage.cuda(1)) # Map tensors from GPU 1 to GPU 0 >>> torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'}) # Load tensor from io.BytesIO object >>> with open('tensor.pt', 'rb') as f: buffer = io.BytesIO(f.read()) >>> torch.load(buffer) 并行 torch.``get_num_threads() → int 返回用于CPU并行操作的线程数 torch.``set_num_threads( int ) 设置用于CPU并行操作的线程数。警告：为确保使用的线程数目正确，set_num_threads必须在运行心切，JIT或autograd代码之前调用。 torch.``get_num_interop_threads() → int 返回用于-OP间并行CPU上的线程的数目（例如，在JIT解释器） torch.``set_num_interop_threads( int ) 设置用于互操作并行（例如，在JIT解释器）上的CPU线程的数目。警告：可以在任何跨运并行工作开始（如JIT执行）之前只能被调用一次和。 本地禁用梯度计算 ，torch.set_grad_enabled的上下文管理器torch.no_grad（），torch.enable_grad（） 和（ ） 是用于局部禁用和启用梯度计算有帮助。参见[ 本地禁用梯度计算 ](autograd.html#locally-disable- grad)关于其使用的更多细节。这些情境经理线程局部的，所以如果你使用 发送工作到另一个线程，他们将无法正常工作：模块：threading模块等。 Examples: >>> x = torch.zeros(1, requires_grad=True) >>> with torch.no_grad(): ... y = x * 2 >>> y.requires_grad False >>> is_train = False >>> with torch.set_grad_enabled(is_train): ... y = x * 2 >>> y.requires_grad False >>> torch.set_grad_enabled(True) # this can also be used as a function >>> y = x * 2 >>> y.requires_grad True >>> torch.set_grad_enabled(False) >>> y = x * 2 >>> y.requires_grad False 数学运算 逐点行动 torch.``abs( input , out=None ) → Tensor 计算给定的输入张量的逐元素的绝对值。 outi=∣inputi∣\\text{out}{i} = |\\text{input}{i}| outi​=∣inputi​∣ Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> torch.abs(torch.tensor([-1, -2, 3])) tensor([ 1, 2, 3]) torch.``acos( input , out=None ) → Tensor 返回与输入的的元素的反余弦一个新的张量。 outi=cos⁡−1(inputi)\\text{out}{i} = \\cos^{-1}(\\text{input}{i}) outi​=cos−1(inputi​) Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 0.3348, -0.5889, 0.2005, -0.1584]) >>> torch.acos(a) tensor([ 1.2294, 2.2004, 1.3690, 1.7298]) torch.``add() torch.``add( input , other , out=None ) 增加了标量其他到输入输入中的每个元素，并返回一个新的由此而来张量。 out=input+other\\text{out} = \\text{input} + \\text{other} out=input+other 如果输入是类型FloatTensor或DoubleTensor的，其他必须是一个实数，否则它应该是整数。 Parameters input ( Tensor) – the input tensor 其他 （ 号码 ） - 的数量被添加到输入的各要素 Keyword Arguments out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 0.0202, 1.0985, 1.3506, -0.6056]) >>> torch.add(a, 20) tensor([ 20.0202, 21.0985, 21.3506, 19.3944]) torch.``add( input , alpha=1 , other , out=None ) 张量的每个元素其他由标量阿尔法相乘，并加入到该张量的每个元素输入。得到的张量返回。 输入的形状和其他必须 broadcastable 。 out=input+alpha×other\\text{out} = \\text{input} + \\text{alpha} \\times \\text{other} out=input+alpha×other 如果其他是类型FloatTensor或DoubleTensor的，阿尔法必须是一个实数，否则它应该是整数。 Parameters 输入 （ 张量 ） - 第一输入张量 阿尔法 （ 号码 ） - 为标量乘数其他 其他 （ 张量 ） - 第二输入张量 Keyword Arguments out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([-0.9732, -0.3497, 0.6245, 0.4022]) >>> b = torch.randn(4, 1) >>> b tensor([[ 0.3743], [-1.7724], [-0.5811], [-0.8017]]) >>> torch.add(a, 10, b) tensor([[ 2.7695, 3.3930, 4.3672, 4.1450], [-18.6971, -18.0736, -17.0994, -17.3216], [ -6.7845, -6.1610, -5.1868, -5.4090], [ -8.9902, -8.3667, -7.3925, -7.6147]]) torch.``addcdiv( input , value=1 , tensor1 , tensor2 , out=None ) → Tensor 通过执行tensor1的逐元素除法tensor2，由标量值[HTG10相乘的结果]，并将其添加到输入。 outi=inputi+value×tensor1itensor2i\\text{out}_i = \\text{input}_i + \\text{value} \\times \\frac{\\text{tensor1}_i}{\\text{tensor2}_i} outi​=inputi​+value×tensor2i​tensor1i​​ 的形状输入，tensor1和tensor2必须 broadcastable 。 对于类型的输入 FloatTensor 或 DoubleTensor ，值必须是一个实数，否则的整数。 Parameters 输入 （ 张量 ） - 要添加的张量 值 （ 号码 ， 可选 ） - 乘数 tensor1 / tensor2 \\文本{tensor1} / \\文本{tensor2} tensor1 / tensor2 tensor1 （ 张量 ） - 分子张量 tensor2 （ 张量 ） - 分母张量 out ( Tensor , optional ) – the output tensor Example: >>> t = torch.randn(1, 3) >>> t1 = torch.randn(3, 1) >>> t2 = torch.randn(1, 3) >>> torch.addcdiv(t, 0.1, t1, t2) tensor([[-0.2312, -3.6496, 0.1312], [-1.0428, 3.4292, -0.1030], [-0.5369, -0.9829, 0.0430]]) torch.``addcmul( input , value=1 , tensor1 , tensor2 , out=None ) → Tensor 执行由tensor2 tensor1的逐元素乘法，由标量值[HTG10相乘的结果]，并将其添加到输入。 outi=inputi+value×tensor1i×tensor2i\\text{out}_i = \\text{input}_i + \\text{value} \\times \\text{tensor1}_i \\times \\text{tensor2}_i outi​=inputi​+value×tensor1i​×tensor2i​ The shapes of input, tensor1, and tensor2must be broadcastable. For inputs of type FloatTensor or DoubleTensor, valuemust be a real number, otherwise an integer. Parameters input ( Tensor) – the tensor to be added 值 （ 号码 ， 可选 ） - 乘数 T E n的 S O R 1. T E n的 S O R 2 tensor1。 tensor2 T E n的 S O R 1 。 * T E n的 S O R 2 tensor1 （ 张量 ） - 要被乘的张量 tensor2 （ 张量 ） - 要被乘的张量 out ( Tensor , optional ) – the output tensor Example: >>> t = torch.randn(1, 3) >>> t1 = torch.randn(3, 1) >>> t2 = torch.randn(1, 3) >>> torch.addcmul(t, 0.1, t1, t2) tensor([[-0.8635, -0.6391, 1.6174], [-0.7617, -0.5879, 1.7388], [-0.8353, -0.6249, 1.6511]]) torch.``asin( input , out=None ) → Tensor 返回与输入的的元素的反正弦新张量。 outi=sin⁡−1(inputi)\\text{out}{i} = \\sin^{-1}(\\text{input}{i}) outi​=sin−1(inputi​) Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([-0.5962, 1.4985, -0.4396, 1.4525]) >>> torch.asin(a) tensor([-0.6387, nan, -0.4552, nan]) torch.``atan( input , out=None ) → Tensor 返回与输入的的元素的反正切一个新的张量。 outi=tan⁡−1(inputi)\\text{out}{i} = \\tan^{-1}(\\text{input}{i}) outi​=tan−1(inputi​) Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 0.2341, 0.2539, -0.6256, -0.6448]) >>> torch.atan(a) tensor([ 0.2299, 0.2487, -0.5591, -0.5727]) torch.``atan2( input , other , out=None ) → Tensor 返回与输入的和元素 ``其他的反正切一个新的张量。 The shapes of inputand othermust be broadcastable. Parameters input ( Tensor) – the first input tensor other ( Tensor) – the second input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 0.9041, 0.0196, -0.3108, -2.4423]) >>> torch.atan2(a, torch.randn(4)) tensor([ 0.9833, 0.0811, -1.9743, -1.4151]) torch.``ceil( input , out=None ) → Tensor 返回与输入的的元素的最小整数大于或等于每个元件的小区一个新的张量。 outi=⌈inputi⌉=⌊inputi⌋+1\\text{out}{i} = \\left\\lceil \\text{input}{i} \\right\\rceil = \\left\\lfloor \\text{input}_{i} \\right\\rfloor + 1 outi​=⌈inputi​⌉=⌊inputi​⌋+1 Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([-0.6341, -1.4208, -1.0900, 0.5826]) >>> torch.ceil(a) tensor([-0., -1., -1., 1.]) torch.``clamp( input , min , max , out=None ) → Tensor 夹住输入的所有元素为范围 [ 分钟HTG9]， MAX，并返回所得到的张量： yi={minif ximaxy_i = \\begin{cases} \\text{min} & \\text{if } x_i \\text{max} \\end{cases} yi​=⎩⎪⎨⎪⎧​minxi​max​if xi​max​ 如果输入是式 FloatTensor 或 DoubleTensor ，ARGS分钟HTG11]和 MAX 必须是实数，否则他们应该是整数。 Parameters input ( Tensor) – the input tensor 分钟HTG1]（ 号码 ） - 结合的较低的范围内的被夹紧到 MAX （ 号码 ） - 上限的范围内的被夹紧到 out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([-1.7120, 0.1734, -0.0478, -0.0922]) >>> torch.clamp(a, min=-0.5, max=0.5) tensor([-0.5000, 0.1734, -0.0478, -0.0922]) torch.``clamp( input , * , min , out=None ) → Tensor 夹具在输入为大于或等于 分钟HTG7]的所有元素。 如果输入是式 FloatTensor 或 DoubleTensor ，值应该是一个真正号，否则它应该是整数。 Parameters input ( Tensor) – the input tensor 值 （ 号码 ） - 在输出中的各元素的最小值 out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([-0.0299, -2.3184, 2.1593, -0.8883]) >>> torch.clamp(a, min=0.5) tensor([ 0.5000, 0.5000, 2.1593, 0.5000]) torch.``clamp( input , * , max , out=None ) → Tensor 夹具在输入的所有元素是小于或等于 MAX。 If inputis of type FloatTensor or DoubleTensor, valueshould be a real number, otherwise it should be an integer. Parameters input ( Tensor) – the input tensor 值 （ 号码 ） - 在输出中每个元素的最大值 out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 0.7753, -0.4702, -0.4599, 1.1899]) >>> torch.clamp(a, max=0.5) tensor([ 0.5000, -0.4702, -0.4599, 0.5000]) torch.``cos( input , out=None ) → Tensor 返回与输入的的元素的余弦一个新的张量。 outi=cos⁡(inputi)\\text{out}{i} = \\cos(\\text{input}{i}) outi​=cos(inputi​) Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 1.4309, 1.2706, -0.8562, 0.9796]) >>> torch.cos(a) tensor([ 0.1395, 0.2957, 0.6553, 0.5574]) torch.``cosh( input , out=None ) → Tensor 返回与输入的的元素的双曲余弦一个新的张量。 outi=cosh⁡(inputi)\\text{out}{i} = \\cosh(\\text{input}{i}) outi​=cosh(inputi​) Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 0.1632, 1.1835, -0.6979, -0.7325]) >>> torch.cosh(a) tensor([ 1.0133, 1.7860, 1.2536, 1.2805]) torch.``div() torch.``div( input , other , out=None ) → Tensor 将输入输入中的每个元素与所述标量其他并返回一个新产生的张量。 outi=inputiother\\text{out}_i = \\frac{\\text{input}_i}{\\text{other}} outi​=otherinputi​​ 如果输入是式 FloatTensor 或 DoubleTensor ，其他应该是一个真正号，否则应该是一个整数 Parameters input ( Tensor) – the input tensor 其他 （ 号码 ） - 的数量被划分为输入的各要素 out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(5) >>> a tensor([ 0.3810, 1.2774, -0.2972, -0.3719, 0.4637]) >>> torch.div(a, 0.5) tensor([ 0.7620, 2.5548, -0.5944, -0.7439, 0.9275]) torch.``div( input , other , out=None ) → Tensor 张量输入的每个元素由张量其他的各要素分割。得到的张量返回。输入的形状和其他必须 broadcastable 。 outi=inputiotheri\\text{out}_i = \\frac{\\text{input}_i}{\\text{other}_i} outi​=otheri​inputi​​ Parameters 输入 （ 张量 ） - 分子张量 其他 （ 张量 ） - 分母张量 out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4, 4) >>> a tensor([[-0.3711, -1.9353, -0.4605, -0.2917], [ 0.1815, -1.0111, 0.9805, -1.5923], [ 0.1062, 1.4581, 0.7759, -1.2344], [-0.1830, -0.0313, 1.1908, -1.4757]]) >>> b = torch.randn(4) >>> b tensor([ 0.8032, 0.2930, -0.8113, -0.2308]) >>> torch.div(a, b) tensor([[-0.4620, -6.6051, 0.5676, 1.2637], [ 0.2260, -3.4507, -1.2086, 6.8988], [ 0.1322, 4.9764, -0.9564, 5.3480], [-0.2278, -0.1068, -1.4678, 6.3936]]) torch.``digamma( input , out=None ) → Tensor 计算在输入伽马函数的对数导数。 ψ(x)=ddxln⁡(Γ(x))=Γ′(x)Γ(x)\\psi(x) = \\frac{d}{dx} \\ln\\left(\\Gamma\\left(x\\right)\\right) = \\frac{\\Gamma'(x)}{\\Gamma(x)} ψ(x)=dxd​ln(Γ(x))=Γ(x)Γ′(x)​ Parameters 输入 （ 张量 ） - 张量来计算对双伽玛函数 Example: >>> a = torch.tensor([1, 0.5]) >>> torch.digamma(a) tensor([-0.5772, -1.9635]) torch.``erf( input , out=None ) → Tensor 计算每个元件的误差函数。误差函数定义如下： erf(x)=2π∫0xe−t2dt\\mathrm{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-t^2} dt erf(x)=π​2​∫0x​e−t2dt Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> torch.erf(torch.tensor([0, -1., 10.])) tensor([ 0.0000, -0.8427, 1.0000]) torch.``erfc( input , out=None ) → Tensor 计算的输入的各元素的互补误差函数。互补误差函数定义如下： erfc(x)=1−2π∫0xe−t2dt\\mathrm{erfc}(x) = 1 - \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-t^2} dt erfc(x)=1−π​2​∫0x​e−t2dt Parameters 张量 （ 张量 ） - 输入张量 out ( Tensor , optional ) – the output tensor Example: >>> torch.erfc(torch.tensor([0, -1., 10.])) tensor([ 1.0000, 1.8427, 0.0000]) torch.``erfinv( input , out=None ) → Tensor 计算的输入的各元素的逆误差函数。 1 [HTG16 - 逆误差函数的范围在 （ 中定义]， 1 ） （-1，1） （ - 1 ， 1 ） 为： erfinv(erf(x))=x\\mathrm{erfinv}(\\mathrm{erf}(x)) = x erfinv(erf(x))=x Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> torch.erfinv(torch.tensor([0, 0.5, -1.])) tensor([ 0.0000, 0.4769, -inf]) torch.``exp( input , out=None ) → Tensor 返回与输入张量输入的元素的指数一个新的张量。 yi=exiy{i} = e^{x{i}} yi​=exi​ Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> torch.exp(torch.tensor([0, math.log(2.)])) tensor([ 1., 2.]) torch.``expm1( input , out=None ) → Tensor 返回与元件的指数减去输入1新的张量。 yi=exi−1y{i} = e^{x{i}} - 1 yi​=exi​−1 Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> torch.expm1(torch.tensor([0, math.log(2.)])) tensor([ 0., 1.]) torch.``floor( input , out=None ) → Tensor 返回与输入的的元素的最大整数是小于或等于每一个元件的底板中的新张量。 outi=⌊inputi⌋\\text{out}{i} = \\left\\lfloor \\text{input}{i} \\right\\rfloor outi​=⌊inputi​⌋ Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([-0.8166, 1.5308, -0.2530, -0.2091]) >>> torch.floor(a) tensor([-1., 1., -1., -1.]) torch.``fmod( input , other , out=None ) → Tensor 计算事业部的元素方面的剩余部分。 该被除数和除数可以同时包含了整数和浮点数。其余具有相同的符号作为被除数输入。 当其他是一个张量，输入和其他必须的形状 broadcastable 。 Parameters 输入 （ 张量 ） - 被除数 其他 （ 张量 或 浮动 ） - 除数，其可以是数字或作为被除数的相同形状的张量 out ( Tensor , optional ) – the output tensor Example: >>> torch.fmod(torch.tensor([-3., -2, -1, 1, 2, 3]), 2) tensor([-1., -0., -1., 1., 0., 1.]) >>> torch.fmod(torch.tensor([1., 2, 3, 4, 5]), 1.5) tensor([ 1.0000, 0.5000, 0.0000, 1.0000, 0.5000]) torch.``frac( input , out=None ) → Tensor 计算每个元件的在输入的小数部分。 outi=inputi−⌊∣inputi∣⌋∗sgn⁡(inputi)\\text{out}{i} = \\text{input}{i} - \\left\\lfloor |\\text{input}{i}| \\right\\rfloor * \\operatorname{sgn}(\\text{input}{i}) outi​=inputi​−⌊∣inputi​∣⌋∗sgn(inputi​) Example: >>> torch.frac(torch.tensor([1, 2.5, -3.2])) tensor([ 0.0000, 0.5000, -0.2000]) torch.``lerp( input , end , weight , out=None ) 做两张量的线性内插开始（由输入中给出）和结束 [HTG11基于标量或张量重量 ]并返回生成的OUT张量。 outi=starti+weighti×(endi−starti)\\text{out}_i = \\text{start}_i + \\text{weight}_i \\times (\\text{end}_i - \\text{start}_i) outi​=starti​+weighti​×(endi​−starti​) 的形状开始和结束必须 broadcastable 。如果重量是一个张量，则形状重量，开始和结束必须 broadcastable 。 Parameters 输入 （ 张量 ） - ，起点的张量 端 （ 张量 ） - 与该结束点的张量 重量 （ 浮动 或 张量 ） - 用于内插公式的权重 out ( Tensor , optional ) – the output tensor Example: >>> start = torch.arange(1., 5.) >>> end = torch.empty(4).fill_(10) >>> start tensor([ 1., 2., 3., 4.]) >>> end tensor([ 10., 10., 10., 10.]) >>> torch.lerp(start, end, 0.5) tensor([ 5.5000, 6.0000, 6.5000, 7.0000]) >>> torch.lerp(start, end, torch.full_like(start, 0.5)) tensor([ 5.5000, 6.0000, 6.5000, 7.0000]) torch.``log( input , out=None ) → Tensor 返回与输入的的元素的自然对数新的张量。 yi=log⁡e(xi)y{i} = \\log{e} (x_{i}) yi​=loge​(xi​) Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(5) >>> a tensor([-0.7168, -0.5471, -0.8933, -1.4428, -0.1190]) >>> torch.log(a) tensor([ nan, nan, nan, nan, nan]) torch.``log10( input , out=None ) → Tensor 返回与对数新的张量，以输入的的元素的基极10。 yi=log⁡10(xi)y{i} = \\log{10} (x_{i}) yi​=log10​(xi​) Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.rand(5) >>> a tensor([ 0.5224, 0.9354, 0.7257, 0.1301, 0.2251]) >>> torch.log10(a) tensor([-0.2820, -0.0290, -0.1392, -0.8857, -0.6476]) torch.``log1p( input , out=None ) → Tensor 返回与（1 + 输入）的自然对数新的张量。 yi=log⁡e(xi+1)yi = \\log{e} (x_i + 1) yi​=loge​(xi​+1) Note 此函数是更精确的比 torch.log（）为输入的值较小 Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(5) >>> a tensor([-1.0090, -0.9923, 1.0249, -0.5372, 0.2492]) >>> torch.log1p(a) tensor([ nan, -4.8653, 0.7055, -0.7705, 0.2225]) torch.``log2( input , out=None ) → Tensor 返回与对数新的张量，以输入的的元素的基体2。 yi=log⁡2(xi)y{i} = \\log{2} (x_{i}) yi​=log2​(xi​) Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.rand(5) >>> a tensor([ 0.8419, 0.8003, 0.9971, 0.5287, 0.0490]) >>> torch.log2(a) tensor([-0.2483, -0.3213, -0.0042, -0.9196, -4.3504]) torch.``mul() torch.``mul( input , other , out=None ) 乘以所述标量其他输入输入中的每个元素，并返回一个新产生的张量。 outi=other×inputi\\text{out}_i = \\text{other} \\times \\text{input}_i outi​=other×inputi​ If inputis of type FloatTensor or DoubleTensor, othershould be a real number, otherwise it should be an integer Parameters input ( Tensor) – the input tensor 其他 （ 号码 ） - 数相乘以输入的各要素 out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(3) >>> a tensor([ 0.2015, -0.4255, 2.6087]) >>> torch.mul(a, 100) tensor([ 20.1494, -42.5491, 260.8663]) torch.``mul( input , other , out=None ) 张量输入的每个元素是由相应的元素相乘的张量其他。得到的张量返回。 The shapes of inputand othermust be broadcastable. outi=inputi×otheri\\text{out}_i = \\text{input}_i \\times \\text{other}_i outi​=inputi​×otheri​ Parameters 输入 （ 张量 ） - 第一被乘数张量 其他 （ 张量 ） - 第二被乘数张量 out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4, 1) >>> a tensor([[ 1.1207], [-0.3137], [ 0.0700], [ 0.8378]]) >>> b = torch.randn(1, 4) >>> b tensor([[ 0.5146, 0.1216, -0.5244, 2.2382]]) >>> torch.mul(a, b) tensor([[ 0.5767, 0.1363, -0.5877, 2.5083], [-0.1614, -0.0382, 0.1645, -0.7021], [ 0.0360, 0.0085, -0.0367, 0.1567], [ 0.4312, 0.1019, -0.4394, 1.8753]]) torch.``mvlgamma( input , p ) → Tensor 与尺寸 P HTG11计算多元对数伽玛函数（[ [参考文献] ） ] p p 逐元素，给出通过 log⁡(Γp(a))=C+∑i=1plog⁡(Γ(a−i−12))\\log(\\Gamma{p}(a)) = C + \\displaystyle \\sum{i=1}^{p} \\log\\left(\\Gamma\\left(a - \\frac{i - 1}{2}\\right)\\right) log(Γp​(a))=C+i=1∑p​log(Γ(a−2i−1​)) 其中 C = 日志 ⁡ （ π ） × p （ p - 1 ） 4 C = \\日志（\\ PI） \\倍\\压裂{对 - （对1）} {4} C = LO G （ π ） × 4 P （ P - 1 ） 和 Γ （ ⋅ ） \\伽玛（\\ CDOT） Γ （ ⋅ ） 是Gamma函数。 如果任何元件都小于或等于 P - 1 2 \\压裂{对 - 1} {2} 2 p - 1 ，然后引发错误。 Parameters 输入 （ 张量 ） - 张量来计算多变量数伽玛函数 P （ INT ） - 维数 Example: >>> a = torch.empty(2, 3).uniform_(1, 2) >>> a tensor([[1.6835, 1.8474, 1.1929], [1.0475, 1.7162, 1.4180]]) >>> torch.mvlgamma(a, 2) tensor([[0.3928, 0.4007, 0.7586], [1.0311, 0.3901, 0.5049]]) torch.``neg( input , out=None ) → Tensor 返回与负输入的的元素的新的张量。 out=−1×input\\text{out} = -1 \\times \\text{input} out=−1×input Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(5) >>> a tensor([ 0.0090, -0.2262, -0.0682, -0.2866, 0.3940]) >>> torch.neg(a) tensor([-0.0090, 0.2262, 0.0682, 0.2866, -0.3940]) torch.``pow() torch.``pow( input , exponent , out=None ) → Tensor 注意到每个元件的功率在输入与指数，并返回一个张量的结果。 指数可以是一个单一的浮动号码或张量具有相同数量的元素[的HTG10 ] 输入 。 当指数是一个标量值，所施加的操作： outi=xiexponent\\text{out}_i = x_i ^ \\text{exponent} outi​=xiexponent​ 当指数是一个张量，所施加的操作： outi=xiexponenti\\text{out}_i = x_i ^ {\\text{exponent}_i} outi​=xiexponenti​​ 当指数是一个张量，输入和指数必须的形状 broadcastable 。 Parameters input ( Tensor) – the input tensor 指数 （ 浮动 或 张量 ） - 指数值 out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 0.4331, 1.2475, 0.6834, -0.2791]) >>> torch.pow(a, 2) tensor([ 0.1875, 1.5561, 0.4670, 0.0779]) >>> exp = torch.arange(1., 5.) >>> a = torch.arange(1., 5.) >>> a tensor([ 1., 2., 3., 4.]) >>> exp tensor([ 1., 2., 3., 4.]) >>> torch.pow(a, exp) tensor([ 1., 4., 27., 256.]) torch.``pow( self , exponent , out=None ) → Tensor 自是一个标量浮动值和指数是一个张量。返回的张量OUT是相同的形状的作为指数 所施加的操作是： outi=selfexponenti\\text{out}_i = \\text{self} ^ {\\text{exponent}_i} outi​=selfexponenti​ Parameters 为电源操作的标量基值 - 自 （ 浮动 ） 指数 （ 张量 ） - 指数张量 out ( Tensor , optional ) – the output tensor Example: >>> exp = torch.arange(1., 5.) >>> base = 2 >>> torch.pow(base, exp) tensor([ 2., 4., 8., 16.]) torch.``reciprocal( input , out=None ) → Tensor 返回一个新的张量输入的元素的倒数 outi=1inputi\\text{out}{i} = \\frac{1}{\\text{input}{i}} outi​=inputi​1​ Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([-0.4595, -2.1219, -1.4314, 0.7298]) >>> torch.reciprocal(a) tensor([-2.1763, -0.4713, -0.6986, 1.3702]) torch.``remainder( input , other , out=None ) → Tensor Computes the element-wise remainder of division. 该除数和被除数可以同时包含了整数和浮点数。其余有相同的符号与除数。 When otheris a tensor, the shapes of inputand othermust be broadcastable. Parameters input ( Tensor) – the dividend 其他 （ 张量 或 浮动 ） - 其可以是除数数或作为被除数的相同形状的张量 out ( Tensor , optional ) – the output tensor Example: >>> torch.remainder(torch.tensor([-3., -2, -1, 1, 2, 3]), 2) tensor([ 1., 0., 1., 1., 0., 1.]) >>> torch.remainder(torch.tensor([1., 2, 3, 4, 5]), 1.5) tensor([ 1.0000, 0.5000, 0.0000, 1.0000, 0.5000]) 也可以看看 torch.fmod（），它等效计算分割的逐元素其余部分C库函数FMOD（）。 torch.``round( input , out=None ) → Tensor 返回与每个的元素的一个新的张量舍入到最接近的整数的输入。 Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 0.9920, 0.6077, 0.9734, -1.0362]) >>> torch.round(a) tensor([ 1., 1., 1., -1.]) torch.``rsqrt( input , out=None ) → Tensor 返回与每个输入的的元素的平方根的倒数的新张量。 outi=1inputi\\text{out}{i} = \\frac{1}{\\sqrt{\\text{input}{i}}} outi​=inputi​​1​ Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([-0.0370, 0.2970, 1.5420, -0.9105]) >>> torch.rsqrt(a) tensor([ nan, 1.8351, 0.8053, nan]) torch.``sigmoid( input , out=None ) → Tensor 返回与输入的的元素的乙状结肠新张量。 outi=11+e−inputi\\text{out}{i} = \\frac{1}{1 + e^{-\\text{input}{i}}} outi​=1+e−inputi​1​ Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 0.9213, 1.0887, -0.8858, -1.7683]) >>> torch.sigmoid(a) tensor([ 0.7153, 0.7481, 0.2920, 0.1458]) torch.``sign( input , out=None ) → Tensor 返回与输入的的元素的标志新的张量。 outi=sgn⁡(inputi)\\text{out}{i} = \\operatorname{sgn}(\\text{input}{i}) outi​=sgn(inputi​) Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.tensor([0.7, -1.2, 0., 2.3]) >>> a tensor([ 0.7000, -1.2000, 0.0000, 2.3000]) >>> torch.sign(a) tensor([ 1., -1., 0., 1.]) torch.``sin( input , out=None ) → Tensor 返回与输入的的元素的正弦一个新的张量。 outi=sin⁡(inputi)\\text{out}{i} = \\sin(\\text{input}{i}) outi​=sin(inputi​) Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([-0.5461, 0.1347, -2.7266, -0.2746]) >>> torch.sin(a) tensor([-0.5194, 0.1343, -0.4032, -0.2711]) torch.``sinh( input , out=None ) → Tensor 返回与输入的的元素的双曲正弦一个新的张量。 outi=sinh⁡(inputi)\\text{out}{i} = \\sinh(\\text{input}{i}) outi​=sinh(inputi​) Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 0.5380, -0.8632, -0.1265, 0.9399]) >>> torch.sinh(a) tensor([ 0.5644, -0.9744, -0.1268, 1.0845]) torch.``sqrt( input , out=None ) → Tensor 返回与输入的的元素的平方根一个新的张量。 outi=inputi\\text{out}{i} = \\sqrt{\\text{input}{i}} outi​=inputi​​ Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([-2.0755, 1.0226, 0.0831, 0.4806]) >>> torch.sqrt(a) tensor([ nan, 1.0112, 0.2883, 0.6933]) torch.``tan( input , out=None ) → Tensor 返回与输入的的元素的切线一个新的张量。 outi=tan⁡(inputi)\\text{out}{i} = \\tan(\\text{input}{i}) outi​=tan(inputi​) Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([-1.2027, -1.7687, 0.4412, -1.3856]) >>> torch.tan(a) tensor([-2.5930, 4.9859, 0.4722, -5.3366]) torch.``tanh( input , out=None ) → Tensor 返回与输入的的元素的双曲正切一个新的张量。 outi=tanh⁡(inputi)\\text{out}{i} = \\tanh(\\text{input}{i}) outi​=tanh(inputi​) Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 0.8986, -0.7279, 1.1745, 0.2611]) >>> torch.tanh(a) tensor([ 0.7156, -0.6218, 0.8257, 0.2553]) torch.``trunc( input , out=None ) → Tensor 返回与输入的的元素的截尾整数值的新张量。 Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 3.4742, 0.5466, -0.8008, -0.9079]) >>> torch.trunc(a) tensor([ 3., 0., -0., -0.]) 还原行动 torch.``argmax() torch.``argmax( input ) → LongTensor 返回在输入张量的所有元素的最大值的索引。 这是通过 torch.max（）返回的第二值。看到它的文档，这种方法的准确语义。 Parameters input ( Tensor) – the input tensor Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 1.3398, 0.2663, -0.2686, 0.2450], [-0.7401, -0.8805, -0.3402, -1.1936], [ 0.4907, -1.3948, -1.0691, -0.3132], [-1.6092, 0.5419, -0.2993, 0.3195]]) >>> torch.argmax(a) tensor(0) torch.``argmax( input , dim , keepdim=False ) → LongTensor 返回跨尺度张量的最大值的指标。 This is the second value returned by torch.max(). See its documentation for the exact semantics of this method. Parameters input ( Tensor) – the input tensor 暗淡 （ INT ） - 的尺寸，以减少。如果无，则返回扁平输入的argmax。 keepdim （ 布尔 ） - 输出张量是否有暗淡保留或没有。如果暗淡=无忽略。 Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 1.3398, 0.2663, -0.2686, 0.2450], [-0.7401, -0.8805, -0.3402, -1.1936], [ 0.4907, -1.3948, -1.0691, -0.3132], [-1.6092, 0.5419, -0.2993, 0.3195]]) >>> torch.argmax(a, dim=1) tensor([ 0, 2, 0, 1]) torch.``argmin() torch.``argmin( input ) → LongTensor 返回在输入张量的所有元素的最小值的索引。 这是通过 torch.min返回的第二值（）。看到它的文档，这种方法的准确语义。 Parameters input ( Tensor) – the input tensor Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 0.1139, 0.2254, -0.1381, 0.3687], [ 1.0100, -1.1975, -0.0102, -0.4732], [-0.9240, 0.1207, -0.7506, -1.0213], [ 1.7809, -1.2960, 0.9384, 0.1438]]) >>> torch.argmin(a) tensor(13) torch.``argmin( input , dim , keepdim=False , out=None ) → LongTensor 返回跨尺度张量的最低值的索引。 This is the second value returned by torch.min(). See its documentation for the exact semantics of this method. Parameters input ( Tensor) – the input tensor 暗淡 （ INT ） - 的尺寸，以减少。如果无，则返回扁平输入的argmin。 keepdim ( bool) – whether the output tensors have dimretained or not. Ignored if dim=None. Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 0.1139, 0.2254, -0.1381, 0.3687], [ 1.0100, -1.1975, -0.0102, -0.4732], [-0.9240, 0.1207, -0.7506, -1.0213], [ 1.7809, -1.2960, 0.9384, 0.1438]]) >>> torch.argmin(a, dim=1) tensor([ 2, 1, 3, 1]) torch.``cumprod( input , dim , out=None , dtype=None ) → Tensor 返回输入 的元件的累积产物在尺寸暗淡 。 例如，如果输入是大小为N的向量，其结果也将大小为N的向量，包含元素。 yi=x1×x2×x3×⋯×xiy_i = x_1 \\times x_2\\times x_3\\times \\dots \\times x_i yi​=x1​×x2​×x3​×⋯×xi​ Parameters input ( Tensor) – the input tensor 暗淡 （ INT ） - 的尺寸到超过做手术 DTYPE （ torch.dtype，可选） - 返回的张量的所希望的数据类型。如果指定，输入张量浇铸到在执行操作之前D型细胞。这是为了防止数据溢出型有用。默认值：无。 out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(10) >>> a tensor([ 0.6001, 0.2069, -0.1919, 0.9792, 0.6727, 1.0062, 0.4126, -0.2129, -0.4206, 0.1968]) >>> torch.cumprod(a, dim=0) tensor([ 0.6001, 0.1241, -0.0238, -0.0233, -0.0157, -0.0158, -0.0065, 0.0014, -0.0006, -0.0001]) >>> a[5] = 0.0 >>> torch.cumprod(a, dim=0) tensor([ 0.6001, 0.1241, -0.0238, -0.0233, -0.0157, -0.0000, -0.0000, 0.0000, -0.0000, -0.0000]) torch.``cumsum( input , dim , out=None , dtype=None ) → Tensor 返回在尺寸输入 的元素的累积和暗淡 。 For example, if inputis a vector of size N, the result will also be a vector of size N, with elements. yi=x1+x2+x3+⋯+xiy_i = x_1 + x_2 + x_3 + \\dots + x_i yi​=x1​+x2​+x3​+⋯+xi​ Parameters input ( Tensor) – the input tensor dim ( int) – the dimension to do the operation over dtype (torch.dtype, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to dtypebefore the operation is performed. This is useful for preventing data type overflows. Default: None. out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(10) >>> a tensor([-0.8286, -0.4890, 0.5155, 0.8443, 0.1865, -0.1752, -2.0595, 0.1850, -1.1571, -0.4243]) >>> torch.cumsum(a, dim=0) tensor([-0.8286, -1.3175, -0.8020, 0.0423, 0.2289, 0.0537, -2.0058, -1.8209, -2.9780, -3.4022]) torch.``dist( input , other , p=2 ) → Tensor 返回的p范数（输入- 其他） The shapes of inputand othermust be broadcastable. Parameters input ( Tensor) – the input tensor 其他 （ 张量 ） - 的右手侧的输入张量 P （ 浮动 ， 可选 ） - 范数被计算 Example: >>> x = torch.randn(4) >>> x tensor([-1.5393, -0.8675, 0.5916, 1.6321]) >>> y = torch.randn(4) >>> y tensor([ 0.0967, -1.0511, 0.6295, 0.8360]) >>> torch.dist(x, y, 3.5) tensor(1.6727) >>> torch.dist(x, y, 3) tensor(1.6973) >>> torch.dist(x, y, 0) tensor(inf) >>> torch.dist(x, y, 1) tensor(2.6537) torch.``logsumexp( input , dim , keepdim=False , out=None ) 返回输入张量中的每一行的求和指数的日志中的给定维度暗淡。计算是数值上稳定。 用于求和指数 [HTG6：J [HTG9：J [HTG18：J 由暗淡和给定的其他指数 i的 i的 i的 ，其结果是 logsumexp （ × ） i的 = 日志 ⁡ Σ [HTG29：J 实验值 ⁡ （ × i的 f] ） \\文本{logsumexp}（x）的 {I} = \\ LOG \\ sum_j \\ EXP（X {IJ}） logsumexp （ × ） i的 [HTG10 0] = LO G [HTG122：J Σ EXP （ × i的 [HTG166：J ） 如果keepdim是真，输出张量是相同的大小为输入除了在尺寸（s）实施HTG12] 暗淡 其中它是尺寸1的否则，暗淡被挤出（见 torch.squeeze（）），导致具有1的输出张量（或LEN（暗））较少的维（S）。 Parameters input ( Tensor) – the input tensor 暗淡 （ INT 或 蟒的元组：整数 ） - 的尺寸或尺寸，以减少 keepdim （ 布尔 ） - 输出张量是否有暗淡保留或不 out ( Tensor , optional ) – the output tensor Example:: >>> a = torch.randn(3, 3) >>> torch.logsumexp(a, 1) tensor([ 0.8442, 1.4322, 0.8711]) torch.``mean() torch.``mean( input ) → Tensor 返回所有元素的在输入张量的平均值。 Parameters input ( Tensor) – the input tensor Example: >>> a = torch.randn(1, 3) >>> a tensor([[ 0.2294, -0.5481, 1.3288]]) >>> torch.mean(a) tensor(0.3367) torch.``mean( input , dim , keepdim=False , out=None ) → Tensor 返回在给定维度的输入张量中的每一行的平均值暗淡。如果暗淡为维度的列表，减少过度所有的人。 If keepdimis True, the output tensor is of the same size as input except in the dimension(s) dimwhere it is of size 1. Otherwise, dimis squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). Parameters input ( Tensor) – the input tensor dim ( int or tuple of python:ints ) – the dimension or dimensions to reduce keepdim ( bool) – whether the output tensor has dimretained or not OUT （ 张量 ） - 输出张量 Example: >>> a = torch.randn(4, 4) >>> a tensor([[-0.3841, 0.6320, 0.4254, -0.7384], [-0.9644, 1.0131, -0.6549, -1.4279], [-0.2951, -1.3350, -0.7694, 0.5600], [ 1.0842, -0.9580, 0.3623, 0.2343]]) >>> torch.mean(a, 1) tensor([-0.0163, -0.5085, -0.4599, 0.1807]) >>> torch.mean(a, 1, True) tensor([[-0.0163], [-0.5085], [-0.4599], [ 0.1807]]) torch.``median() torch.``median( input ) → Tensor 返回所有元素的在输入张量的中值。 Parameters input ( Tensor) – the input tensor Example: >>> a = torch.randn(1, 3) >>> a tensor([[ 1.5219, -1.5212, 0.2202]]) >>> torch.median(a) tensor(0.2202) torch.``median( input , dim=-1 , keepdim=False , values=None , indices=None) - > (Tensor, LongTensor ) 返回namedtuple （值 索引）其中值为各行的中值的输入张量在给定的尺寸暗淡。和指数是找到的每个中间值的索引位置。 默认情况下，暗淡为输入张量的最后维度。 如果keepdim是真，输出张量是相同大小的作为输入除了在尺寸暗淡其中它们是尺寸1的否则，暗淡被挤出（见 torch.squeeze（）），导致具有比1种输入更少尺寸的输出张量。 Parameters input ( Tensor) – the input tensor 暗淡 （ INT ） - 的尺寸，以减少 keepdim （ 布尔 ） - 输出张量是否有暗淡保留或不 值 （ 张量 ， 可选 ） - 输出张量 指数 （ 张量 ， 可选 ） - 输出索引张量 Example: >>> a = torch.randn(4, 5) >>> a tensor([[ 0.2505, -0.3982, -0.9948, 0.3518, -1.3131], [ 0.3180, -0.6993, 1.0436, 0.0438, 0.2270], [-0.2751, 0.7303, 0.2192, 0.3321, 0.2488], [ 1.0778, -1.9510, 0.7048, 0.4742, -0.7125]]) >>> torch.median(a, 1) torch.return_types.median(values=tensor([-0.3982, 0.2270, 0.2488, 0.4742]), indices=tensor([1, 4, 4, 3])) torch.``mode( input , dim=-1 , keepdim=False , values=None , indices=None) - > (Tensor, LongTensor ) 返回namedtuple （值 索引）其中值是每行的模式值的输入张量在给定的尺寸暗淡，即，最经常出现在该行中的值，并索引是找到的每个模式值的索引位置。 By default, dimis the last dimension of the inputtensor. 如果keepdim是真，输出张量是相同大小的作为输入除了在尺寸暗淡其中它们是尺寸1的否则，暗淡被挤出（见 torch.squeeze（）），导致具有比1种输入更少尺寸的输出张量。 Note 此功能还没有为torch.cuda.Tensor中定义爱好。 Parameters input ( Tensor) – the input tensor dim ( int) – the dimension to reduce keepdim ( bool) – whether the output tensors have dimretained or not values ( Tensor , optional ) – the output tensor indices ( Tensor , optional ) – the output index tensor Example: >>> a = torch.randint(10, (5,)) >>> a tensor([6, 5, 1, 0, 2]) >>> b = a + (torch.randn(50, 1) * 5).long() >>> torch.mode(b, 0) torch.return_types.mode(values=tensor([6, 5, 1, 0, 2]), indices=tensor([2, 2, 2, 2, 2])) torch.``norm( input , p='fro' , dim=None , keepdim=False , out=None , dtype=None )[source] 返回给定张量的矩阵范数或向量范数。 Parameters input ( Tensor) – the input tensor P （ INT ， 浮动 ， INF ， -INF ， '来回' ， 'NUC' ， 可选 ） - 规范的秩序。默认值：'来回'可以计算以下规范： ORD | 矩阵范 | 向量模 ---|---|--- 没有 | 弗洛比尼范数 | 2范 “回回” | Frobenius norm | - “国统会” | 核标准 | – 其他 | 作为VEC规范时，昏暗的是无 | 总和（ABS（X） ORD）（1./ord） 暗淡 （ INT ， 蟒的2元组：整型 ， 蟒2-列表：整数 ， 可选 ） - 如果它是一个int，矢量范数将被计算，如果是整数的2元组，矩阵范数将被计算。如果该值是无，当输入仅张量具有两个维度矩阵范数将被计算，当输入张量只有一个维度矢量范数将被计算。如果输入张量具有多于两个尺寸，矢量范数将被应用到最后尺寸。 keepdim （ 布尔 ， 可选 ） - 输出张量是否有暗淡保留或没有。忽略如果暗淡= 无和OUT= 无。默认值：假 OUT （ 张量 ， 可选 ） - 输出张量。忽略如果暗淡= 无和OUT= 无。 DTYPE （ torch.dtype，可选） - 返回的张量的所希望的数据类型。执行操作“D型”：如果指定，输入张量浇铸到：ATTR。默认值：无。 Example: >>> import torch >>> a = torch.arange(9, dtype= torch.float) - 4 >>> b = a.reshape((3, 3)) >>> torch.norm(a) tensor(7.7460) >>> torch.norm(b) tensor(7.7460) >>> torch.norm(a, float('inf')) tensor(4.) >>> torch.norm(b, float('inf')) tensor(4.) >>> c = torch.tensor([[ 1, 2, 3],[-1, 1, 4]] , dtype= torch.float) >>> torch.norm(c, dim=0) tensor([1.4142, 2.2361, 5.0000]) >>> torch.norm(c, dim=1) tensor([3.7417, 4.2426]) >>> torch.norm(c, p=1, dim=1) tensor([6., 6.]) >>> d = torch.arange(8, dtype= torch.float).reshape(2,2,2) >>> torch.norm(d, dim=(1,2)) tensor([ 3.7417, 11.2250]) >>> torch.norm(d[0, :, :]), torch.norm(d[1, :, :]) (tensor(3.7417), tensor(11.2250)) torch.``prod() torch.``prod( input , dtype=None ) → Tensor 返回在输入张量的所有元素的乘积。 Parameters input ( Tensor) – the input tensor dtype (torch.dtype, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to dtypebefore the operation is performed. This is useful for preventing data type overflows. Default: None. Example: >>> a = torch.randn(1, 3) >>> a tensor([[-0.8020, 0.5428, -1.5854]]) >>> torch.prod(a) tensor(0.6902) torch.``prod( input , dim , keepdim=False , dtype=None ) → Tensor 返回输入张量的各行的产品在给定的尺寸暗淡。 如果keepdim是真，输出张量是相同的大小为输入除了在尺寸暗淡其中它是尺寸1的否则，暗淡被挤出（见 torch.squeeze（）），导致具有比1种输入更少尺寸的输出张量。 Parameters input ( Tensor) – the input tensor dim ( int) – the dimension to reduce keepdim ( bool) – whether the output tensor has dimretained or not dtype (torch.dtype, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to dtypebefore the operation is performed. This is useful for preventing data type overflows. Default: None. Example: >>> a = torch.randn(4, 2) >>> a tensor([[ 0.5261, -0.3837], [ 1.1857, -0.2498], [-1.1646, 0.0705], [ 1.1131, -1.0629]]) >>> torch.prod(a, 1) tensor([-0.2018, -0.2962, -0.0821, -1.1831]) torch.``std() torch.``std( input , unbiased=True ) → Tensor 返回在输入张量的所有元素的标准偏差。 如果无偏是假，则标准偏差将被经由偏估计计算。否则，贝塞尔修正将被使用。 Parameters input ( Tensor) – the input tensor 无偏 （ 布尔 ） - 是否使用无偏估计或不 Example: >>> a = torch.randn(1, 3) >>> a tensor([[-0.8166, -1.3802, -0.3560]]) >>> torch.std(a) tensor(0.5130) torch.``std( input , dim , keepdim=False , unbiased=True , out=None ) → Tensor 返回维度中的输入张量的各行的标准偏差暗淡。如果暗淡为维度的列表，减少过度所有的人。 If keepdimis True, the output tensor is of the same size as input except in the dimension(s) dimwhere it is of size 1. Otherwise, dimis squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). If unbiasedis False, then the standard-deviation will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used. Parameters input ( Tensor) – the input tensor dim ( int or tuple of python:ints ) – the dimension or dimensions to reduce keepdim ( bool) – whether the output tensor has dimretained or not unbiased ( bool) – whether to use the unbiased estimation or not out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 0.2035, 1.2959, 1.8101, -0.4644], [ 1.5027, -0.3270, 0.5905, 0.6538], [-1.5745, 1.3330, -0.5596, -0.6548], [ 0.1264, -0.5080, 1.6420, 0.1992]]) >>> torch.std(a, dim=1) tensor([ 1.0311, 0.7477, 1.2204, 0.9087]) torch.``std_mean() torch.``std_mean( input , unbiased=True) - > (Tensor, Tensor ) 返回在输入张量的所有元素的标准偏差和平均值。 If unbiasedis False, then the standard-deviation will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used. Parameters input ( Tensor) – the input tensor unbiased ( bool) – whether to use the unbiased estimation or not Example: >>> a = torch.randn(1, 3) >>> a tensor([[0.3364, 0.3591, 0.9462]]) >>> torch.std_mean(a) (tensor(0.3457), tensor(0.5472)) torch.``std( input , dim , keepdim=False , unbiased=True) - > (Tensor, Tensor ) 返回维度中的输入张量的各行的标准偏差和平均值暗淡。如果暗淡为维度的列表，减少过度所有的人。 If keepdimis True, the output tensor is of the same size as input except in the dimension(s) dimwhere it is of size 1. Otherwise, dimis squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). If unbiasedis False, then the standard-deviation will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used. Parameters input ( Tensor) – the input tensor dim ( int or tuple of python:ints ) – the dimension or dimensions to reduce keepdim ( bool) – whether the output tensor has dimretained or not unbiased ( bool) – whether to use the unbiased estimation or not Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 0.5648, -0.5984, -1.2676, -1.4471], [ 0.9267, 1.0612, 1.1050, -0.6014], [ 0.0154, 1.9301, 0.0125, -1.0904], [-1.9711, -0.7748, -1.3840, 0.5067]]) >>> torch.std_mean(a, 1) (tensor([0.9110, 0.8197, 1.2552, 1.0608]), tensor([-0.6871, 0.6229, 0.2169, -0.9058])) torch.``sum() torch.``sum( input , dtype=None ) → Tensor 返回在输入张量的所有元素的总和。 Parameters input ( Tensor) – the input tensor dtype (torch.dtype, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to dtypebefore the operation is performed. This is useful for preventing data type overflows. Default: None. Example: >>> a = torch.randn(1, 3) >>> a tensor([[ 0.1133, -0.9567, 0.2958]]) >>> torch.sum(a) tensor(-0.5475) torch.``sum( input , dim , keepdim=False , dtype=None ) → Tensor 返回在给定维度的输入张量的每一行的总和暗淡。如果暗淡为维度的列表，减少过度所有的人。 If keepdimis True, the output tensor is of the same size as input except in the dimension(s) dimwhere it is of size 1. Otherwise, dimis squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). Parameters input ( Tensor) – the input tensor dim ( int or tuple of python:ints ) – the dimension or dimensions to reduce keepdim ( bool) – whether the output tensor has dimretained or not dtype (torch.dtype, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to dtypebefore the operation is performed. This is useful for preventing data type overflows. Default: None. Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 0.0569, -0.2475, 0.0737, -0.3429], [-0.2993, 0.9138, 0.9337, -1.6864], [ 0.1132, 0.7892, -0.1003, 0.5688], [ 0.3637, -0.9906, -0.4752, -1.5197]]) >>> torch.sum(a, 1) tensor([-0.4598, -0.1381, 1.3708, -2.6217]) >>> b = torch.arange(4 * 5 * 6).view(4, 5, 6) >>> torch.sum(b, (2, 1)) tensor([ 435., 1335., 2235., 3135.]) torch.``unique( input , sorted=True , return_inverse=False , return_counts=False , dim=None )[source] 返回输入张量的独特元素。 Parameters input ( Tensor) – the input tensor 排序 （ 布尔 ） - 是否返回作为输出之前按升序对独特的元素进行排序。 return_inverse （ 布尔 ） - 是否也返回如在原有的输入元素在返回的唯一列表结束了索引。 return_counts （ 布尔 ） - 是否也返回的计数为每个唯一的元件。 暗淡 （ INT ） - 维度应用是唯一的。如果无，独特的扁平输入的被返回。默认值：无 Returns 的张量或张量的含有一个元组 输出 （ 张量 ）：唯一的标量元件的输出列表。 > inverse_indices （ 张量 ）：（可选）如果return_inverse为True，将有一个附加的返回张量（相同的形状作为输入）表示用于其中在原始输入地图元素到输出索引;否则，该函数将只返回单个张量。 > 计数 （ 张量 ）：（可选）如果return_counts为True，将有一个附加的返回张量（相同的形状的输出或output.size（DIM），如果调光被指定）代表出现的每个唯一值，或张量的数目。 > > Return type （张量，张量（可选），张量（可选）） Example: >>> output = torch.unique(torch.tensor([1, 3, 2, 3], dtype=torch.long)) >>> output tensor([ 2, 3, 1]) >>> output, inverse_indices = torch.unique( torch.tensor([1, 3, 2, 3], dtype=torch.long), sorted=True, return_inverse=True) >>> output tensor([ 1, 2, 3]) >>> inverse_indices tensor([ 0, 2, 1, 2]) >>> output, inverse_indices = torch.unique( torch.tensor([[1, 3], [2, 3]], dtype=torch.long), sorted=True, return_inverse=True) >>> output tensor([ 1, 2, 3]) >>> inverse_indices tensor([[ 0, 2], [ 1, 2]]) torch.``unique_consecutive( input , return_inverse=False , return_counts=False , dim=None )[source] 消除了所有的但等效从元件的每个连续组的第一个元素。 Note 此功能是由不同torch.unique（）在这个意义上，此功能仅消除连续重复的值。这个语义类似于的std ::用C独特的 ++。 Parameters input ( Tensor) – the input tensor return_inverse ( bool) – Whether to also return the indices for where elements in the original input ended up in the returned unique list. return_counts ( bool) – Whether to also return the counts for each unique element. dim ( int) – the dimension to apply unique. If None, the unique of the flattened input is returned. default: None Returns A tensor or a tuple of tensors containing output ( Tensor ): the output list of unique scalar elements. > inverse_indices ( Tensor ): (optional) if return_inverseis True, there will be an additional returned tensor (same shape as input) representing the indices for where elements in the original input map to in the output; otherwise, this function will only return a single tensor. > counts ( Tensor ): (optional) if return_countsis True, there will be an additional returned tensor (same shape as output or output.size(dim), if dim was specified) representing the number of occurrences for each unique value or tensor. > > Return type (Tensor, Tensor (optional), Tensor (optional)) Example: >>> x = torch.tensor([1, 1, 2, 2, 3, 1, 1, 2]) >>> output = torch.unique_consecutive(x) >>> output tensor([1, 2, 3, 1, 2]) >>> output, inverse_indices = torch.unique_consecutive(x, return_inverse=True) >>> output tensor([1, 2, 3, 1, 2]) >>> inverse_indices tensor([0, 0, 1, 1, 2, 3, 3, 4]) >>> output, counts = torch.unique_consecutive(x, return_counts=True) >>> output tensor([1, 2, 3, 1, 2]) >>> counts tensor([2, 2, 1, 2, 1]) torch.``var() torch.``var( input , unbiased=True ) → Tensor 返回所有元素的在输入张量的方差。 如果无偏是假，然后方差将经由偏估计计算。否则，贝塞尔修正将被使用。 Parameters input ( Tensor) – the input tensor unbiased ( bool) – whether to use the unbiased estimation or not Example: >>> a = torch.randn(1, 3) >>> a tensor([[-0.3425, -1.2636, -0.4864]]) >>> torch.var(a) tensor(0.2455) torch.``var( input , dim , keepdim=False , unbiased=True , out=None ) → Tensor 返回输入张量中的每一行的方差在给定的尺寸暗淡。 If keepdimis True, the output tensor is of the same size as input except in the dimension(s) dimwhere it is of size 1. Otherwise, dimis squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). If unbiasedis False, then the variance will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used. Parameters input ( Tensor) – the input tensor dim ( int or tuple of python:ints ) – the dimension or dimensions to reduce keepdim ( bool) – whether the output tensor has dimretained or not unbiased ( bool) – whether to use the unbiased estimation or not out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4, 4) >>> a tensor([[-0.3567, 1.7385, -1.3042, 0.7423], [ 1.3436, -0.1015, -0.9834, -0.8438], [ 0.6056, 0.1089, -0.3112, -1.4085], [-0.7700, 0.6074, -0.1469, 0.7777]]) >>> torch.var(a, 1) tensor([ 1.7444, 1.1363, 0.7356, 0.5112]) torch.``var_mean() torch.``var_mean( input , unbiased=True) - > (Tensor, Tensor ) 返回所有元素的在输入张量的方差和平均值。 If unbiasedis False, then the variance will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used. Parameters input ( Tensor) – the input tensor unbiased ( bool) – whether to use the unbiased estimation or not Example: >>> a = torch.randn(1, 3) >>> a tensor([[0.0146, 0.4258, 0.2211]]) >>> torch.var_mean(a) (tensor(0.0423), tensor(0.2205)) torch.``var_mean( input , dim , keepdim=False , unbiased=True) - > (Tensor, Tensor ) 返回输入张量中的每一行的方差和平均值在给定的尺寸暗淡。 If keepdimis True, the output tensor is of the same size as input except in the dimension(s) dimwhere it is of size 1. Otherwise, dimis squeezed (see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s). If unbiasedis False, then the variance will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used. Parameters input ( Tensor) – the input tensor dim ( int or tuple of python:ints ) – the dimension or dimensions to reduce keepdim ( bool) – whether the output tensor has dimretained or not unbiased ( bool) – whether to use the unbiased estimation or not Example: >>> a = torch.randn(4, 4) >>> a tensor([[-1.5650, 2.0415, -0.1024, -0.5790], [ 0.2325, -2.6145, -1.6428, -0.3537], [-0.2159, -1.1069, 1.2882, -1.3265], [-0.6706, -1.5893, 0.6827, 1.6727]]) >>> torch.var_mean(a, 1) (tensor([2.3174, 1.6403, 1.4092, 2.0791]), tensor([-0.0512, -1.0946, -0.3403, 0.0239])) 比较行动 torch.``allclose( input , other , rtol=1e-05 , atol=1e-08 , equal_nan=False ) → bool 此功能检查是否所有输入和其他满足条件： ∣input−other∣≤atol+rtol×∣other∣\\lvert \\text{input} - \\text{other} \\rvert \\leq \\texttt{atol} + \\texttt{rtol} \\times \\lvert \\text{other} \\rvert ∣input−other∣≤atol+rtol×∣other∣ 的elementwise，对于 和输入的所有元素其它 。此函数的行为类似于[ numpy.allclose ](https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html) Parameters 输入 （ 张量 ） - 第一伸张器，以比较 其他 （ 张量 ） - 第二伸张器，以比较 蒂 （ 浮动 ， 可选 ） - 绝对公差。默认值：1E-08 RTOL （ 浮动 ， 可选 ） - 相对公差。默认值：1E-05 equal_nan （ 布尔 ， 可选 ） - 如果真，然后2 的NaNS将被相等比较。默认值：假 Example: >>> torch.allclose(torch.tensor([10000., 1e-07]), torch.tensor([10000.1, 1e-08])) False >>> torch.allclose(torch.tensor([10000., 1e-08]), torch.tensor([10000.1, 1e-09])) True >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')])) False >>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]), equal_nan=True) True torch.``argsort( input , dim=-1 , descending=False , out=None ) → LongTensor 返回由值升序排列沿给定尺寸的张量的指数。 这是通过 torch.sort（）返回的第二值。看到它的文档，这种方法的准确语义。 Parameters input ( Tensor) – the input tensor 暗淡 （ INT ， 可选 ） - 的尺寸进行排序沿 降序 （ 布尔 ， 可选 ） - 控制所述排序顺序（升序或降序） Example: >>> a = torch.randn(4, 4) >>> a tensor([[ 0.0785, 1.5267, -0.8521, 0.4065], [ 0.1598, 0.0788, -0.0745, -1.2700], [ 1.2208, 1.0722, -0.7064, 1.2564], [ 0.0669, -0.2318, -0.8229, -0.9280]]) >>> torch.argsort(a, dim=1) tensor([[2, 0, 3, 1], [3, 2, 1, 0], [2, 1, 0, 3], [3, 2, 1, 0]]) torch.``eq( input , other , out=None ) → Tensor 计算元素方面的平等 第二个参数可以是一个数字或一个张量，其形状为 broadcastable 的第一个参数。 Parameters 输入 （ 张量 ） - 张量来比较 其他 （ 张量 或 浮动 ） - 张量或值进行比较 OUT （ 张量 ， 可选 ） - 输出张量。必须是 BoolTensor Returns A torch.BoolTensor [HTG3含有一个True在每个位置处，其中比较结果为真 Return type Tensor Example: >>> torch.eq(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[True, False], [False, True]]) torch.``equal( input , other ) → bool 真如果两个张量具有相同的尺寸和元素，假否则。 Example: >>> torch.equal(torch.tensor([1, 2]), torch.tensor([1, 2])) True torch.``ge( input , other , out=None ) → Tensor 计算 输入 ≥ 其他 \\文本{输入} \\ GEQ \\文本{其它} 输入 ≥ 其他 逐元素。 The second argument can be a number or a tensor whose shape is broadcastable with the first argument. Parameters input ( Tensor) – the tensor to compare other ( Tensor or float) – the tensor or value to compare OUT （ 张量 ， 可选 ） - 输出张量必须是一个 BoolTensor Returns A torch.BoolTensorcontaining a True at each location where comparison is true Return type Tensor Example: >>> torch.ge(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[True, True], [False, True]]) torch.``gt( input , other , out=None ) → Tensor 计算 输入 & GT ; 其他 \\ {文本输入} & GT ; \\ {文本其他} 输入 & GT ; 其他 逐元素。 The second argument can be a number or a tensor whose shape is broadcastable with the first argument. Parameters input ( Tensor) – the tensor to compare other ( Tensor or float) – the tensor or value to compare out ( Tensor , optional ) – the output tensor that must be a BoolTensor Returns A torch.BoolTensorcontaining a True at each location where comparison is true Return type Tensor Example: >>> torch.gt(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[False, True], [False, False]]) torch.``isfinite( tensor )[source] 返回与表示如果每个元素是有限或不布尔元素的新张量。 Parameters 张量 （ 张量 ） - 甲张量，以检查 Returns A torch.Tensor 与 DTYPE torch.bool [HTG11含有一个True在每个有限元素和假的位置，否则 Return type Tensor Example: >>> torch.isfinite(torch.tensor([1, float('inf'), 2, float('-inf'), float('nan')])) tensor([True, False, True, False, False]) torch.``isinf( tensor )[source] 返回与表示如果每个元素是 +/- INF 或不布尔元素的新张量。 Parameters tensor ( Tensor) – A tensor to check Returns A torch.Tensor 与 DTYPE torch.bool [HTG11含有一个True在每个 +/- INF 元素和假的位置，否则 Return type Tensor Example: >>> torch.isinf(torch.tensor([1, float('inf'), 2, float('-inf'), float('nan')])) tensor([False, True, False, True, False]) torch.``isnan() 返回与表示如果每个元素是的NaN 或不布尔元素的新张量。 Parameters 输入 （ 张量 ） - 甲张量，以检查 Returns A torch.BoolTensor含有在真NaN的元素每个位置。 Return type Tensor Example: >>> torch.isnan(torch.tensor([1, float('nan'), 2])) tensor([False, True, False]) torch.``kthvalue( input , k , dim=None , keepdim=False , _out=None) (Tensor, _LongTensor ) 返回一个namedtuple （值 索引）其中值在K在给定的维度上的输入张量中的每一行的第最小元素暗淡。和指数是找到的每个元素的索引位置。 如果暗淡没有给出，则输入的最后尺寸被选择。 如果keepdim是真，无论是值和指数张量是相同的大小为输入，除了在尺寸暗淡其中它们的尺寸1，否则暗淡被挤出（见 torch.squeeze（）），从而导致在两个值和指数具有1名比输入张量较少维张量。 Parameters input ( Tensor) – the input tensor K （ INT ） - K为第k个最小的元素 暗淡 （ INT ， 可选 ） - 的尺寸沿着找到的第k个值 keepdim ( bool) – whether the output tensors have dimretained or not OUT （ 元组 ， 可选 ） - （张量，LongTensor）的输出元组可任选地给定的以用作输出缓冲器 Example: >>> x = torch.arange(1., 6.) >>> x tensor([ 1., 2., 3., 4., 5.]) >>> torch.kthvalue(x, 4) torch.return_types.kthvalue(values=tensor(4.), indices=tensor(3)) >>> x=torch.arange(1.,7.).resize_(2,3) >>> x tensor([[ 1., 2., 3.], [ 4., 5., 6.]]) >>> torch.kthvalue(x, 2, 0, True) torch.return_types.kthvalue(values=tensor([[4., 5., 6.]]), indices=tensor([[1, 1, 1]])) torch.``le( input , other , out=None ) → Tensor 计算 输入 ≤ 其他 \\文本{输入} \\当量\\文本{其它} 输入 ≤ 其他 逐元素。 The second argument can be a number or a tensor whose shape is broadcastable with the first argument. Parameters input ( Tensor) – the tensor to compare other ( Tensor or float) – the tensor or value to compare out ( Tensor , optional ) – the output tensor that must be a BoolTensor Returns A torch.BoolTensorcontaining a True at each location where comparison is true Return type Tensor Example: >>> torch.le(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[True, False], [True, True]]) torch.``lt( input , other , out=None ) → Tensor 计算 输入 & LT ; 其他 \\ {文本输入} & LT ; \\ {文本其他} 输入 & LT ; 其他 逐元素。 The second argument can be a number or a tensor whose shape is broadcastable with the first argument. Parameters input ( Tensor) – the tensor to compare other ( Tensor or float) – the tensor or value to compare out ( Tensor , optional ) – the output tensor that must be a BoolTensor Returns A torch.BoolTensor [HTG1含有一个True在每个位置处，其中比较结果为真 Return type Tensor Example: >>> torch.lt(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[False, False], [True, False]]) torch.``max() torch.``max( input ) → Tensor 返回所有元素的在输入张量的最大值。 Parameters input ( Tensor) – the input tensor Example: >>> a = torch.randn(1, 3) >>> a tensor([[ 0.6763, 0.7445, -2.2369]]) >>> torch.max(a) tensor(0.7445) torch.``max( input , dim , keepdim=False , out=None) - > (Tensor, LongTensor ) 返回namedtuple （值 索引）其中值是每行的最大值输入张量在给定的尺寸暗淡。和指数是找到的每个最大值的索引位置（argmax）。 如果keepdim是真，输出张量是相同大小的作为输入除了在尺寸暗淡其中它们是尺寸1的否则，暗淡被挤出（见 torch.squeeze（）），导致具有比1种输入更少尺寸的输出张量。 Parameters input ( Tensor) – the input tensor dim ( int) – the dimension to reduce keepdim （ 布尔 ， 可选 ） - 输出张量是否有暗淡保留或没有。默认值：假 [HTG17。 OUT （ 元组 ， 可选 ） - 两个输出张量的结果元组（最大，max_indices） Example: >>> a = torch.randn(4, 4) >>> a tensor([[-1.2360, -0.2942, -0.1222, 0.8475], [ 1.1949, -1.1127, -2.2379, -0.6702], [ 1.5717, -0.9207, 0.1297, -1.8768], [-0.6172, 1.0036, -0.6060, -0.2432]]) >>> torch.max(a, 1) torch.return_types.max(values=tensor([0.8475, 1.1949, 1.5717, 1.0036]), indices=tensor([3, 0, 0, 1])) torch.``max( input , other , out=None ) → Tensor 张量输入的每个元素与张力其他和逐元素最大取的对应元素进行比较。 输入和等不需要匹配，但是他们必须 broadcastable [HTG10的形状] 。 outi=max⁡(tensori,otheri)\\text{out}_i = \\max(\\text{tensor}_i, \\text{other}_i) outi​=max(tensori​,otheri​) Note 当形状不匹配，则返回的输出张量的形状遵循 广播规则 。 Parameters input ( Tensor) – the input tensor other ( Tensor) – the second input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 0.2942, -0.7416, 0.2653, -0.1584]) >>> b = torch.randn(4) >>> b tensor([ 0.8722, -1.7421, -0.4141, -0.5055]) >>> torch.max(a, b) tensor([ 0.8722, -0.7416, 0.2653, -0.1584]) torch.``min() torch.``min( input ) → Tensor 返回所有元素的在输入张量的最小值。 Parameters input ( Tensor) – the input tensor Example: >>> a = torch.randn(1, 3) >>> a tensor([[ 0.6750, 1.0857, 1.7197]]) >>> torch.min(a) tensor(0.6750) torch.``min( input , dim , keepdim=False , out=None) - > (Tensor, LongTensor ) 返回namedtuple （值 索引）其中值是每行的最小值输入张量在给定的尺寸暗淡。和指数是发现（argmin）各最小值的索引位置。 如果keepdim是真，输出张量是相同大小的作为输入除了在尺寸暗淡其中它们是尺寸1的否则，暗淡被挤出（见 torch.squeeze（）），导致具有比1种输入更少尺寸的输出张量。 Parameters input ( Tensor) – the input tensor dim ( int) – the dimension to reduce keepdim ( bool) – whether the output tensors have dimretained or not OUT （ 元组 ， 可选 ） - 两个输出张量的元组（分钟，min_indices） Example: >>> a = torch.randn(4, 4) >>> a tensor([[-0.6248, 1.1334, -1.1899, -0.2803], [-1.4644, -0.2635, -0.3651, 0.6134], [ 0.2457, 0.0384, 1.0128, 0.7015], [-0.1153, 2.9849, 2.1458, 0.5788]]) >>> torch.min(a, 1) torch.return_types.min(values=tensor([-1.1899, -1.4644, 0.0384, -0.1153]), indices=tensor([2, 0, 1, 0])) torch.``min( input , other , out=None ) → Tensor 张量输入的每个元素与张力其他和被取逐元素的最小的对应元素进行比较。得到的张量返回。 The shapes of inputand otherdon’t need to match, but they must be broadcastable. outi=min⁡(tensori,otheri)\\text{out}_i = \\min(\\text{tensor}_i, \\text{other}_i) outi​=min(tensori​,otheri​) Note When the shapes do not match, the shape of the returned output tensor follows the broadcasting rules. Parameters input ( Tensor) – the input tensor other ( Tensor) – the second input tensor out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4) >>> a tensor([ 0.8137, -1.1740, -0.6460, 0.6308]) >>> b = torch.randn(4) >>> b tensor([-0.1369, 0.1555, 0.4019, -0.1929]) >>> torch.min(a, b) tensor([-0.1369, -1.1740, -0.6460, -0.1929]) torch.``ne( input , other , out=None ) → Tensor 计算 i的 n的 P U T ≠ O T H E R 输入\\ NEQ其他 i的 n的 p U T  = O T H E R [HT G105]逐元素。 The second argument can be a number or a tensor whose shape is broadcastable with the first argument. Parameters input ( Tensor) – the tensor to compare other ( Tensor or float) – the tensor or value to compare out ( Tensor , optional ) – the output tensor that must be a BoolTensor Returns A torch.BoolTensor含有在真其中比较为真每个位置。 Return type Tensor Example: >>> torch.ne(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]])) tensor([[False, True], [True, False]]) torch.``sort( input , dim=-1 , descending=False , out=None) - > (Tensor, LongTensor ) 排序输入张量的沿给定的维度以升序通过值的元素。 If dimis not given, the last dimension of the input is chosen. 如果降序是真然后将元件在由值降序排列。 （值，索引）的namedtuple被返回，其中，所述值是排序的值和指数是在原输入张量的元素的索引。 Parameters input ( Tensor) – the input tensor dim ( int , optional ) – the dimension to sort along descending ( bool , optional ) – controls the sorting order (ascending or descending) OUT （ 元组 ， 可选 ） - 的（张量的输出元组， LongTensor ），其可任选地给定的用作输出缓冲器 Example: >>> x = torch.randn(3, 4) >>> sorted, indices = torch.sort(x) >>> sorted tensor([[-0.2162, 0.0608, 0.6719, 2.3332], [-0.5793, 0.0061, 0.6058, 0.9497], [-0.5071, 0.3343, 0.9553, 1.0960]]) >>> indices tensor([[ 1, 0, 2, 3], [ 3, 1, 0, 2], [ 0, 3, 1, 2]]) >>> sorted, indices = torch.sort(x, 0) >>> sorted tensor([[-0.5071, -0.2162, 0.6719, -0.5793], [ 0.0608, 0.0061, 0.9497, 0.3343], [ 0.6058, 0.9553, 1.0960, 2.3332]]) >>> indices tensor([[ 2, 0, 0, 1], [ 0, 1, 1, 2], [ 1, 2, 2, 0]]) torch.``topk( input , k , dim=None , largest=True , sorted=True , out=None) - > (Tensor, LongTensor ) 返回沿给定的维度上的给定的输入张量的K最大元素。 If dimis not given, the last dimension of the input is chosen. 如果大是假然后按 K 返回最小的元素。 的甲namedtuple（值，索引）被返回，其中，所述指数是在原输入张量的元素的索引。 排序的布尔选项如果真，将确保返回 K 元素本身也是分类 Parameters input ( Tensor) – the input tensor K （ INT ） - 在“前k”第k dim ( int , optional ) – the dimension to sort along 最大 （ 布尔 ， 可选 ） - 控制是否返回最大或最小的元素 排序 （ 布尔 ， 可选 ） - 控制是否返回按排序顺序中的元素 OUT （ 元组 ， 可选 ） - （张量，LongTensor）的输出元组，可以是任选给定将被用作输出缓冲器 Example: >>> x = torch.arange(1., 6.) >>> x tensor([ 1., 2., 3., 4., 5.]) >>> torch.topk(x, 3) torch.return_types.topk(values=tensor([5., 4., 3.]), indices=tensor([4, 3, 2])) 光谱行动 torch.``fft( input , signal_ndim , normalized=False ) → Tensor 复杂到复杂的离散傅立叶变换 此方法计算复杂到复杂的离散傅立叶变换。忽略批次尺寸，它计算下面的表达式： X[ω1,…,ωd]=∑n1=0N1−1⋯∑nd=0Nd−1x[n1,…,nd]e−j 2π∑i=0dωiniNi,X[\\omega1, \\dots, \\omega_d] = \\sum{n1=0}^{N_1-1} \\dots \\sum{nd=0}^{N_d-1} x[n_1, \\dots, n_d] e^{-j\\ 2 \\pi \\sum{i=0}^d \\frac{\\omega_i n_i}{N_i}}, X[ω1​,…,ωd​]=n1​=0∑N1​−1​⋯nd​=0∑Nd​−1​x[n1​,…,nd​]e−j 2π∑i=0d​Ni​ωi​ni​​, 其中 d d d = signal_ndim是尺寸为信号数目，和 N i的 n_i个 N i的 是信号维度 i的 [大小HTG90 ] i的 [HT G99] i的 。 此方法支持一维，二维和三维复杂到复杂的变换，由signal_ndim表示。 输入必须与尺寸2，代表复数的实和虚分量的最后一维的张量，并应具有至少[H​​TG8] signalndim + 1 尺寸与领先的批量尺寸的任选任意数量。如果归被设定为真，这通过用 [HTG27除以归一化的结果] Π i的 = 1 K N i的 \\ SQRT {\\ prod {I = 1}-1K-n_i个} Π i的 = 1 K [HT G112] N i的 ，使得操作者是一体的。 返回的实部和虚部的输入相同的形状的联为一体张量。 此函数的逆是 IFFT（）。 Note 对于CUDA张量，一个LRU缓存用于CUFFT计划加快与相同配置相同的几何形状的张量重复运行FFT方法。参见[ CUFFT计划缓存 HTG3对于如何监视和控制缓存的更多细节。 Warning 对于CPU张量，这种方法目前只适用于MKL。使用torch.backends.mkl.is_available（）检查是否安装MKL。 Parameters 输入 （ 张量 ） - 的输入张量至少signal_ndim``+ 1尺寸 signal_ndim （ INT ） - 中的每个信号的维数。 signal_ndim只能是1，2或3个 归 （ 布尔 ， 可选 ） - 控制是否返回归一化结果。默认值：假 Returns 将含有复合到复数傅立叶变换结果张量 Return type Tensor Example: >>> # unbatched 2D FFT >>> x = torch.randn(4, 3, 2) >>> torch.fft(x, 2) tensor([[[-0.0876, 1.7835], [-2.0399, -2.9754], [ 4.4773, -5.0119]], [[-1.5716, 2.7631], [-3.8846, 5.2652], [ 0.2046, -0.7088]], [[ 1.9938, -0.5901], [ 6.5637, 6.4556], [ 2.9865, 4.9318]], [[ 7.0193, 1.1742], [-1.3717, -2.1084], [ 2.0289, 2.9357]]]) >>> # batched 1D FFT >>> torch.fft(x, 1) tensor([[[ 1.8385, 1.2827], [-0.1831, 1.6593], [ 2.4243, 0.5367]], [[-0.9176, -1.5543], [-3.9943, -2.9860], [ 1.2838, -2.9420]], [[-0.8854, -0.6860], [ 2.4450, 0.0808], [ 1.3076, -0.5768]], [[-0.1231, 2.7411], [-0.3075, -1.7295], [-0.5384, -2.0299]]]) >>> # arbitrary number of batch dimensions, 2D FFT >>> x = torch.randn(3, 3, 5, 5, 2) >>> y = torch.fft(x, 2) >>> y.shape torch.Size([3, 3, 5, 5, 2]) torch.``ifft( input , signal_ndim , normalized=False ) → Tensor 复杂到复杂的离散傅立叶逆变换 此方法计算复杂到复杂逆离散傅立叶变换。忽略批次尺寸，它计算下面的表达式： X[ω1,…,ωd]=1∏i=1dNi∑n1=0N1−1⋯∑nd=0Nd−1x[n1,…,nd]e j 2π∑i=0dωiniNi,X[\\omega1, \\dots, \\omega_d] = \\frac{1}{\\prod{i=1}^d Ni} \\sum{n1=0}^{N_1-1} \\dots \\sum{nd=0}^{N_d-1} x[n_1, \\dots, n_d] e^{\\ j\\ 2 \\pi \\sum{i=0}^d \\frac{\\omega_i n_i}{N_i}}, X[ω1​,…,ωd​]=∏i=1d​Ni​1​n1​=0∑N1​−1​⋯nd​=0∑Nd​−1​x[n1​,…,nd​]e j 2π∑i=0d​Ni​ωi​ni​​, where ddd = signal_ndimis number of dimensions for the signal, and NiN_iNi​ is the size of signal dimension iii . 的参数规格是与 几乎相同的FFT（）。然而，如果归被设定为真，这而是返回乘以 [结果HTG17] Π i的 = 1 d N i的 \\ SQRT {\\ prod_ {I = 1} ^ d n_i个} Π i的 = 1 d N i的 ，成为一个整体的操作。因此，反转一个 FFT（）时，归参数应该被相同地用于设置 FFT（）。 Returns the real and the imaginary parts together as one tensor of the same shape of input. 此函数的逆是 FFT（）。 Note For CUDA tensors, an LRU cache is used for cuFFT plans to speed up repeatedly running FFT methods on tensors of same geometry with same configuration. See cuFFT plan cache for more details on how to monitor and control the cache. Warning For CPU tensors, this method is currently only available with MKL. Use torch.backends.mkl.is_available()to check if MKL is installed. Parameters input ( Tensor) – the input tensor of at least signal_ndim``+ 1dimensions signal_ndim ( int) – the number of dimensions in each signal. signal_ndimcan only be 1, 2 or 3 normalized ( bool , optional ) – controls whether to return normalized results. Default: False Returns 将含有复合物到复杂傅立叶逆变换结果张量 Return type Tensor Example: >>> x = torch.randn(3, 3, 2) >>> x tensor([[[ 1.2766, 1.3680], [-0.8337, 2.0251], [ 0.9465, -1.4390]], [[-0.1890, 1.6010], [ 1.1034, -1.9230], [-0.9482, 1.0775]], [[-0.7708, -0.8176], [-0.1843, -0.2287], [-1.9034, -0.2196]]]) >>> y = torch.fft(x, 2) >>> torch.ifft(y, 2) # recover x tensor([[[ 1.2766, 1.3680], [-0.8337, 2.0251], [ 0.9465, -1.4390]], [[-0.1890, 1.6010], [ 1.1034, -1.9230], [-0.9482, 1.0775]], [[-0.7708, -0.8176], [-0.1843, -0.2287], [-1.9034, -0.2196]]]) torch.``rfft( input , signal_ndim , normalized=False , onesided=True ) → Tensor 真正到复杂的离散傅立叶变换 该方法可以计算真正到复杂的离散傅立叶变换。它与 数学上是等效的fft（）仅在输入和输出的格式的差异。 此方法支持1D，2D和3D真实到复杂的变换，由signal_ndim表示。 输入必须与至少与领先的批量尺寸的任选任意数量signal_ndim尺寸的张量。如果归被设定为真，这通过用 [HTG23除以归一化的结果] Π i的 = 1 K N i的 \\ SQRT {\\ prod_ {I = 1}-1K-n_i个} Π i的 = 1 K N i的 ，使得操作者是单一的，其中 N i的 n_i个 N i的 是信号维度 i的 i的 [HTG233的大小] i的 。 真正到复杂的傅立叶变换结果如下共轭对称： X[ω1,…,ωd]=X∗[N1−ω1,…,Nd−ωd],X[\\omega_1, \\dots, \\omega_d] = X^*[N_1 - \\omega_1, \\dots, N_d - \\omega_d], X[ω1​,…,ωd​]=X∗[N1​−ω1​,…,Nd​−ωd​], 其中索引算术计算模量的对应尺寸的尺寸， \\ ^ 为共轭算子，并 d d d = signal_ndim [ HTG73。 片面 标志控制，以避免在输出结果的冗余。如果设置为真 `（默认）中，输出将不会被的形状 [HTG88全复数结果]（ ， 2 ） （，2） （ ， 2 ） ，其中 * 为输入的形状，而是最后尺寸将被减半了作为尺寸 的⌊ [H TG160] N d 2 ⌋ + 1 \\ lfloor \\压裂{N_d} {2} \\ rfloor + 1 ⌊ 2 N d ⌋ + 1 。` 此函数的逆是 irfft（）。 Note For CUDA tensors, an LRU cache is used for cuFFT plans to speed up repeatedly running FFT methods on tensors of same geometry with same configuration. See cuFFT plan cache for more details on how to monitor and control the cache. Warning For CPU tensors, this method is currently only available with MKL. Use torch.backends.mkl.is_available()to check if MKL is installed. Parameters 输入 （ 张量 ） - 的输入张量至少signal_ndim尺寸 signal_ndim ( int) – the number of dimensions in each signal. signal_ndimcan only be 1, 2 or 3 normalized ( bool , optional ) – controls whether to return normalized results. Default: False 片面 （ 布尔 ， 可选 ） - 控制是否返回一半的结果，以避免冗余。默认值：真 Returns 将含有实数到复数傅立叶变换结果张量 Return type Tensor Example: >>> x = torch.randn(5, 5) >>> torch.rfft(x, 2).shape torch.Size([5, 3, 2]) >>> torch.rfft(x, 2, onesided=False).shape torch.Size([5, 5, 2]) torch.``irfft( input , signal_ndim , normalized=False , onesided=True , signal_sizes=None ) → Tensor 复杂到真正的离散傅立叶逆变换 此方法计算复杂到实逆离散傅立叶变换。它与数学上等效IFFT（）仅在输入和输出的格式的差异。 的参数规格是与几乎相同IFFT（）。类似于 IFFT（）时，如果归被设定为真，这通过用 乘以归一化结果Π i的 = 1 K N i的 \\ SQRT {\\ prod_ {I = 1}-1K-n_i个} Π i的 = 1 K [HTG1 01] N i的 ，使得操作者是单一的，其中 N i的 n_i个 N i的 是信号维度 [大小HTG226 ] i的 i的 i的 。 Note 由于共轭对称，输入不需要包含完整的复频率值。大致的值的一半将是足够的，因为是当输入由 rfft给定的情况下（）与rfft（信号， 片面=真）。在这种情况下，设置此方法的为真中的片面参数。此外，原来的信号形状的信息有时会丢失，任意设定signal_sizes是原始信号的大小（无批次尺寸，如果在成批模式）与正确恢复它形状。 因此，反转的 rfft（），则归一化`和片面 参数应该被相同地设定为irfft（） 和preferrably一个 signal_sizes`是鉴于以避免大小不匹配。参见尺寸不匹配的情况下的例子。 参见 rfft（）关于共轭对称的细节。 此函数的逆是 rfft（）。 Warning 一般来说，输入这个功能应该包含以下的共轭对称性值。需要注意的是片面 即使是真 ，常为对称性上仍然需要一些部分。当该要求不被满足，的 行为irfft（） 是未定义的。由于[torch.autograd.gradcheck（） ](autograd.html#torch.autograd.gradcheck \"torch.autograd.gradcheck\")估计数值雅可比与点扰动，irfft（） 几乎肯定会失败的检查。 Note For CUDA tensors, an LRU cache is used for cuFFT plans to speed up repeatedly running FFT methods on tensors of same geometry with same configuration. See cuFFT plan cache for more details on how to monitor and control the cache. Warning For CPU tensors, this method is currently only available with MKL. Use torch.backends.mkl.is_available()to check if MKL is installed. Parameters input ( Tensor) – the input tensor of at least signal_ndim``+ 1dimensions signal_ndim ( int) – the number of dimensions in each signal. signal_ndimcan only be 1, 2 or 3 normalized ( bool , optional ) – controls whether to return normalized results. Default: False 片面 （ 布尔 ， 可选 ） - 控制是否输入被减半了避免冗余，例如，通过 rfft（）。默认值：真 signal_sizes （列表或torch.Size，可选） - 原始信号（无批次尺寸）的尺寸。默认值：无 Returns 将含有复合物到实傅立叶逆变换结果张量 Return type Tensor Example: >>> x = torch.randn(4, 4) >>> torch.rfft(x, 2, onesided=True).shape torch.Size([4, 3, 2]) >>> >>> # notice that with onesided=True, output size does not determine the original signal size >>> x = torch.randn(4, 5) >>> torch.rfft(x, 2, onesided=True).shape torch.Size([4, 3, 2]) >>> >>> # now we use the original shape to recover x >>> x tensor([[-0.8992, 0.6117, -1.6091, -0.4155, -0.8346], [-2.1596, -0.0853, 0.7232, 0.1941, -0.0789], [-2.0329, 1.1031, 0.6869, -0.5042, 0.9895], [-0.1884, 0.2858, -1.5831, 0.9917, -0.8356]]) >>> y = torch.rfft(x, 2, onesided=True) >>> torch.irfft(y, 2, onesided=True, signal_sizes=x.shape) # recover x tensor([[-0.8992, 0.6117, -1.6091, -0.4155, -0.8346], [-2.1596, -0.0853, 0.7232, 0.1941, -0.0789], [-2.0329, 1.1031, 0.6869, -0.5042, 0.9895], [-0.1884, 0.2858, -1.5831, 0.9917, -0.8356]]) torch.``stft( input , n_fft , hop_length=None , win_length=None , window=None , center=True , pad_mode='reflect' , normalized=False , onesided=True )[source] 短时傅立叶变换（STFT）。 忽略可选批次尺寸，此方法计算下列表达式： X[m,ω]=∑k=0winlength-1window[k] input[m×hop_length+k] exp⁡(−j2π⋅ωkwin_length),X[m, \\omega] = \\sum{k = 0}^{\\text{win\\_length-1}}% \\text{window}[k]\\ \\text{input}[m \\times \\text{hop\\_length} + k]\\ % \\exp\\left(- j \\frac{2 \\pi \\cdot \\omega k}{\\text{win\\_length}}\\right), X[m,ω]=k=0∑win_length-1​window[k] input[m×hop_length+k] exp(−jwin_length2π⋅ωk​), 其中 M M M 在滑动窗口的索引，和 ω \\的ω ω 是频率 0 ≤ ω & LT ; N_FFT 0 \\当量\\欧米加& LT ; \\文本{N \\ _fft} 0 ≤ ω & LT ; [ H T G94] N_FFT 。当片面为默认值真 输入必须是1-d的时间序列或2- d批次时间序列。 如果hop_length是无（默认），它被视为等于地板（N_FFT / 4）。 如果win_length是无（默认），它被视为等于N_FFT。 窗口可以是大小win_length，例如1-d张量，由 torch。 hann_window（）。如果窗口是无（默认），它被视为好像具有 1 1 1 无处不在的窗口。如果 win_length & LT ; N_FFT \\ {文本赢得\\ _length} & LT ; \\文本{N \\ _fft} win_length & LT ; N_FFT ，窗口将在两侧长度被填充N_FFT之前被施加。 如果中心是真（默认），输入将在两个填充侧，使得所述 T T T 个帧在时间 [HTG40中心] T × hop_length 吨\\倍\\文本{一跳\\ _length} T × hop_length 。否则， T T T 个帧开始于时间 T × hop_length 吨\\倍\\文本{一跳\\ _length} T × hop_length 。 pad_mode确定在输入中使用的填补方法，当中心是真。参见 torch.nn.functional.pad（）所有可用的选项。默认值是“反映”。 如果片面是真（默认）中，仅值 ω \\的ω ω 在 [ 0 ， 1 ， 2 ， ... ， ⌊ N_FFT 2 ⌋ + 1 ] \\左[0，1，2，\\点，\\左\\ lfloor \\压裂{\\文本{N \\ _fft}} {2} \\右\\ rfloor + 1 \\右] [ 0 1 ， 2 ， ... ， ⌊ 2 N_FFT ⌋ + 1 被返回因为真正的到复杂的傅立叶变换满足共轭对称的，即， X [ M ， ω = X [ M ， N_FFT - ω X [米，\\ω= X [米，\\文本{N \\ _fft} - \\ω-^ X [ M ， ω = X [ ​​ M [HTG27 2]， N_FFT - ω * 。 如果归是真（默认设定为假），该函数返回归一化的STFT的结果，即，乘以 （ 帧 ） - 0.5 （\\文本{帧\\ _length}）^ { - 0.5} （ 帧 ） - 0 。 5 。 返回的实部和虚部一起作为大小 （ ×[之一张量HTG11] N × T × 2 ） （ \\次数N \\时间T \\倍2） （ × N × T × 2 ） ，其中 [H TG96] 是可选的批量大小输入， N N N 是其中应用STFT的频率的数量， T T T 是使用的帧的总数量，并且每对在最后一维表示复数作为实部和虚部。 Warning 此功能在0.4.1版本中更改签名。与先前的签名调用可能会导致错误或返回不正确的结果。 Parameters input ( Tensor) – the input tensor N_FFT （ INT ） - 傅立叶变换大小 hop_length （ INT ， 可选 ） - 相邻滑动窗帧之间的距离。默认值：无（视为等于地板（N_FFT / 4）） win_length （ INT ， 可选 ） - 窗框和STFT滤波器的尺寸。默认值：无（视为等于N_FFT） 窗口 （ 张量 ， 可选 ） - 可选的窗口函数。默认值：无（视作的窗口中的所有 1 1 1 S） 中心 （ 布尔 ， 可选 ） - 是否垫输入在两侧，使得 T T T 个帧在时间居中 T × hop_length 吨\\倍\\文本{一跳\\ _length} T × hop_length 。默认值：真 pad_mode （ 串 ， 可选 ） - 控制所使用的填补方法，当中心是真。默认值：“反映” 归 （ 布尔 ， 可选 ） - 控制是否返回的归一化STFT结果默认：假 片面 （ 布尔 ， 可选 ） - 控制是否返回一半的结果，以避免冗余默认值：真 Returns 如上所述包含与形状STFT结果张量 Return type Tensor torch.``bartlett_window( window_length , periodic=True , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 巴特利特窗函数。 w[n]=1−∣2nN−1−1∣={2nN−1if 0≤n≤N−122−2nN−1if N−12 其中 N N N 是全窗口大小。 输入window_length是正整数控制返回窗口大小。 周期性标志确定所返回的窗口是否剪掉从对称窗口中的最后重复的值，并准备用作周期性窗口中包含 [HTG10功能] torch.stft（）。因此，如果周期性为真，则 N N N 在上述式中事实上 window_length + 1 \\文本{窗口\\ _length} + 1 window_length + 1 。另外，我们始终有torch.bartlett_window（L， 周期性=真）等于torch.bartlett_window（L + 1， 周期性=假）[： - 1]）。 Note 如果window_length= 1 = 1 = 1 ，返回的窗口包含一个值1。 Parameters window_length （ INT ） - 返回的窗口的大小 周期性 （ 布尔 ， 可选 ） - 如果为True，返回到被用作周期函数的窗口。如果为False，返回一个对称窗口。 DTYPE （ torch.dtype，可选） - 返回的张量的所希望的数据类型。默认值：如果无，使用全局默认设置（见 torch.set_default_tensor_type（））。只有浮点类型的支持。 布局 （ torch.layout，可选） - 返回的窗口张量的所需布局。只有torch.strided（密集布局）被支撑。 device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Returns 的A 1-d张量大小 （ window_length ， ） （\\文本{窗口\\ _length}，） （ window_length ， ） 包含窗口 Return type Tensor torch.``blackman_window( window_length , periodic=True , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 布莱克曼窗函数。 w[n]=0.42−0.5cos⁡(2πnN−1)+0.08cos⁡(4πnN−1)w[n] = 0.42 - 0.5 \\cos \\left( \\frac{2 \\pi n}{N - 1} \\right) + 0.08 \\cos \\left( \\frac{4 \\pi n}{N - 1} \\right) w[n]=0.42−0.5cos(N−12πn​)+0.08cos(N−14πn​) where NNN is the full window size. 输入window_length是正整数控制返回窗口大小。 周期性标志确定所返回的窗口是否剪掉从对称窗口中的最后重复的值，并准备用作周期性窗口中包含 [HTG10功能] torch.stft（）。因此，如果周期性为真，则 N N N 在上述式中事实上 window_length + 1 \\文本{窗口\\ _length} + 1 window_length + 1 。另外，我们始终有torch.blackman_window（L， 周期性=真）等于torch.blackman_window（L + 1， 周期性=假）[： - 1]）。 Note If window_length=1=1=1 , the returned window contains a single value 1. Parameters window_length ( int) – the size of returned window periodic ( bool , optional ) – If True, returns a window to be used as periodic function. If False, return a symmetric window. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). Only floating point types are supported. layout (torch.layout, optional) – the desired layout of returned window tensor. Only torch.strided(dense layout) is supported. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Returns A 1-D tensor of size (window_length,)(\\text{window\\_length},)(window_length,) containing the window Return type Tensor torch.``hamming_window( window_length , periodic=True , alpha=0.54 , beta=0.46 , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor 海明窗函数。 w[n]=α−β cos⁡(2πnN−1),w[n] = \\alpha - \\beta\\ \\cos \\left( \\frac{2 \\pi n}{N - 1} \\right), w[n]=α−β cos(N−12πn​), where NNN is the full window size. 输入window_length是正整数控制返回窗口大小。 周期性标志确定所返回的窗口是否剪掉从对称窗口中的最后重复的值，并准备用作周期性窗口中包含 [HTG10功能] torch.stft（）。因此，如果周期性为真，则 N N N 在上述式中事实上 window_length + 1 \\文本{窗口\\ _length} + 1 window_length + 1 。另外，我们始终有torch.hamming_window（L， 周期性=真）等于torch.hamming_window（L + 1， 周期性=假）[： - 1]）。 Note If window_length=1=1=1 , the returned window contains a single value 1. Note 这是 的一般化版本torch.hann_window（）。 Parameters window_length ( int) – the size of returned window periodic ( bool , optional ) – If True, returns a window to be used as periodic function. If False, return a symmetric window. 阿尔法 （ 浮动 ， 可选 ） - 系数 α \\阿尔法 α 在上面的等式 的β （ 浮动 ， 可选 ） - 系数 β \\的β β 在上面的等式 dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). Only floating point types are supported. layout (torch.layout, optional) – the desired layout of returned window tensor. Only torch.strided(dense layout) is supported. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Returns A 1-D tensor of size (window_length,)(\\text{window\\_length},)(window_length,) containing the window Return type Tensor torch.``hann_window( window_length , periodic=True , dtype=None , layout=torch.strided , device=None , requires_grad=False ) → Tensor Hann窗函数。 w[n]=12 [1−cos⁡(2πnN−1)]=sin⁡2(πnN−1),w[n] = \\frac{1}{2}\\ \\left[1 - \\cos \\left( \\frac{2 \\pi n}{N - 1} \\right)\\right] = \\sin^2 \\left( \\frac{\\pi n}{N - 1} \\right), w[n]=21​ [1−cos(N−12πn​)]=sin2(N−1πn​), where NNN is the full window size. 输入window_length是正整数控制返回窗口大小。 周期性标志确定所返回的窗口是否剪掉从对称窗口中的最后重复的值，并准备用作周期性窗口中包含 [HTG10功能] torch.stft（）。因此，如果周期性为真，则 N N N 在上述式中事实上 window_length + 1 \\文本{窗口\\ _length} + 1 window_length + 1 。另外，我们始终有torch.hann_window（L， 周期性=真）等于torch.hann_window（L + 1， 周期性=假）[： - 1]）。 Note If window_length=1=1=1 , the returned window contains a single value 1. Parameters window_length ( int) – the size of returned window periodic ( bool , optional ) – If True, returns a window to be used as periodic function. If False, return a symmetric window. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, uses a global default (see torch.set_default_tensor_type()). Only floating point types are supported. layout (torch.layout, optional) – the desired layout of returned window tensor. Only torch.strided(dense layout) is supported. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Returns A 1-D tensor of size (window_length,)(\\text{window\\_length},)(window_length,) containing the window Return type Tensor 其他操作 torch.``bincount( input , weights=None , minlength=0 ) → Tensor 计数每个值的频率在非负整数的数组。 （尺寸1）段的数目会比最大值较大的一个输入除非输入是空的，在这种情况下结果是大小为0的张量如果中指定时MINLENGTH，箱柜的数目至少为MINLENGTH如果输入是空的，那么结果是大小填充 MINLENGTH用零的张量。如果n的在位置值i的，OUT [N] + = 权重[I]如果的权重被别的指定 ``OUT [N] + = 1。 Note 当使用CUDA后端，该操作可以诱导非确定性的行为是不容易断开。请参阅 重复性 为背景的音符。 Parameters 输入 （ 张量 ） - 1-d INT张量 权重 （ 张量 ） - 可选的，重量为输入张量的每个值。应该是相同的大小作为输入张量。 MINLENGTH （ INT ） - 仓的可选的，最小数量。应为非负。 Returns 形状大小的张量（[最大值（输入） + 1]）如果输入非空，否则尺寸（0） Return type 输出（张量） Example: >>> input = torch.randint(0, 8, (5,), dtype=torch.int64) >>> weights = torch.linspace(0, 1, steps=5) >>> input, weights (tensor([4, 3, 6, 3, 4]), tensor([ 0.0000, 0.2500, 0.5000, 0.7500, 1.0000]) >>> torch.bincount(input) tensor([0, 0, 0, 2, 2, 0, 1]) >>> input.bincount(weights) tensor([0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.5000]) torch.``broadcast_tensors( *tensors ) → List of Tensors[source] 根据 广播语义 广播给定的张量。 Parameters *张量 - 任何数量的相同类型的张量的 Warning 广播的张量的多于一个的元件可指代单个存储器位置。其结果是，就地操作（特别是那些有量化的）可能会导致不正确的行为。如果你需要写张量，请先克隆它们。 Example: >>> x = torch.arange(3).view(1, 3) >>> y = torch.arange(2).view(2, 1) >>> a, b = torch.broadcast_tensors(x, y) >>> a.size() torch.Size([2, 3]) >>> a tensor([[0, 1, 2], [0, 1, 2]]) torch.``cartesian_prod( *tensors )[source] 做张量的定序列的笛卡尔乘积。该行为类似于Python的 itertools.product [HTG1。 Parameters *张量 - 任何数量的1维张量。 Returns A tensor equivalent to converting all the input tensors into lists, 做 itertools.product 在这些名单，最后结果列表转换成张量。 Return type Tensor Example: >>> a = [1, 2, 3] >>> b = [4, 5] >>> list(itertools.product(a, b)) [(1, 4), (1, 5), (2, 4), (2, 5), (3, 4), (3, 5)] >>> tensor_a = torch.tensor(a) >>> tensor_b = torch.tensor(b) >>> torch.cartesian_prod(tensor_a, tensor_b) tensor([[1, 4], [1, 5], [2, 4], [2, 5], [3, 4], [3, 5]]) torch.``combinations( input , r=2 , with_replacement=False ) → seq 长度 R R [HTG14的计算组合] R [HTG23给定的张量。该行为类似于Python的 itertools.combinations 当 with_replacement 设置为假和 itertools.combinations_with_replacement 当 with_replacement 设置为真[HTG35。 Parameters 输入 （ 张量 ） - 1D向量。 R （ INT ， 可选 ） - 元素的数目相结合 with_replacement （ 布尔 ， 可选 ） - 是否允许在组合的重复 Returns 张量相当于将所有的输入张量成列表，执行 itertools.combinations 或 itertools.combinations_with_replacement 在这些名单，最后结果列表转换成张量。 Return type Tensor Example: >>> a = [1, 2, 3] >>> list(itertools.combinations(a, r=2)) [(1, 2), (1, 3), (2, 3)] >>> list(itertools.combinations(a, r=3)) [(1, 2, 3)] >>> list(itertools.combinations_with_replacement(a, r=2)) [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)] >>> tensor_a = torch.tensor(a) >>> torch.combinations(tensor_a) tensor([[1, 2], [1, 3], [2, 3]]) >>> torch.combinations(tensor_a, r=3) tensor([[1, 2, 3]]) >>> torch.combinations(tensor_a, with_replacement=True) tensor([[1, 1], [1, 2], [1, 3], [2, 2], [2, 3], [3, 3]]) torch.``cross( input , other , dim=-1 , out=None ) → Tensor 返回向量的叉积的尺寸暗淡的输入和其他。 输入和其他必须具有相同的尺寸，并且它们的暗淡 [HTG11的大小]维应该是3。 如果暗淡没有给出，则默认为与尺寸3找到的第一个维度。 Parameters input ( Tensor) – the input tensor other ( Tensor) – the second input tensor 暗淡 （ INT ， 可选 ） - 的尺寸取跨产品英寸 out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4, 3) >>> a tensor([[-0.3956, 1.1455, 1.6895], [-0.5849, 1.3672, 0.3599], [-1.1626, 0.7180, -0.0521], [-0.1339, 0.9902, -2.0225]]) >>> b = torch.randn(4, 3) >>> b tensor([[-0.0257, -1.4725, -1.2251], [-1.1479, -0.7005, -1.9757], [-1.3904, 0.3726, -1.1836], [-0.9688, -0.7153, 0.2159]]) >>> torch.cross(a, b, dim=1) tensor([[ 1.0844, -0.5281, 0.6120], [-2.4490, -1.5687, 1.9792], [-0.8304, -1.3037, 0.5650], [-1.2329, 1.9883, 1.0551]]) >>> torch.cross(a, b) tensor([[ 1.0844, -0.5281, 0.6120], [-2.4490, -1.5687, 1.9792], [-0.8304, -1.3037, 0.5650], [-1.2329, 1.9883, 1.0551]]) torch.``diag( input , diagonal=0 , out=None ) → Tensor 如果输入是矢量（1-d张量），然后返回一个2-d平方张量与输入为一体的元件对角线。 如果输入是矩阵（2- d张量），则返回1-d张量与输入的``的对角元素。 的参数 对角线控制以考虑其对角： 如果 对角线= 0，它是主对角线。 如果 对角线& GT ; 0，它上面的主对角线。 如果 对角线& LT ; 0，它是下面的主对角线。 Parameters input ( Tensor) – the input tensor 对角线 （ INT ， 可选 ） - 对角线考虑 out ( Tensor , optional ) – the output tensor See also torch.diagonal（）总是返回对角线其输入。 torch.diagflat（）始终构成与由输入指定的对角元素的张量。 Examples: 获取方阵，其中输入向量为对角： >>> a = torch.randn(3) >>> a tensor([ 0.5950,-0.0872, 2.3298]) >>> torch.diag(a) tensor([[ 0.5950, 0.0000, 0.0000], [ 0.0000,-0.0872, 0.0000], [ 0.0000, 0.0000, 2.3298]]) >>> torch.diag(a, 1) tensor([[ 0.0000, 0.5950, 0.0000, 0.0000], [ 0.0000, 0.0000,-0.0872, 0.0000], [ 0.0000, 0.0000, 0.0000, 2.3298], [ 0.0000, 0.0000, 0.0000, 0.0000]]) 获取给定矩阵的第k个对角线： >>> a = torch.randn(3, 3) >>> a tensor([[-0.4264, 0.0255,-0.1064], [ 0.8795,-0.2429, 0.1374], [ 0.1029,-0.6482,-1.6300]]) >>> torch.diag(a, 0) tensor([-0.4264,-0.2429,-1.6300]) >>> torch.diag(a, 1) tensor([ 0.0255, 0.1374]) torch.``diag_embed( input , offset=0 , dim1=-2 , dim2=-1 ) → Tensor 创建一个张量，其一定的2D平面的对角线（由指定DIM1和DIM2）由输入填充。为了便于创建批处理对角矩阵，用返回的张量的最后两个维度形成二维平面默认选中。 的参数偏移HTG2]控制以考虑其对角： 如果offset = 0 ，它是主对角线。 如果偏移HTG2]& GT ; 0，它上面的主对角线。 如果偏移HTG2]& LT ; 0，它是下面的主对角线。 新矩阵的大小将被计算为使最后输入尺寸大小的指定对角线。注意，偏移除 0 0 0 ，的顺序DIM1和DIM2事项。交换它们是等效于改变的偏移HTG38]符号。 施加 torch.diagonal（）该函数的输出与相同参数产生相同的输入的矩阵。然而， torch.diagonal（） 具有不同的默认尺寸，因此这些需要被明确指定。 Parameters 输入 （ 张量 ） - 输入张量。必须至少为1维的。 偏移HTG1]（ INT ， 可选 ） - 考虑哪些对角线。默认值：0（主对角线）。 DIM1 （ INT ， 可选 ） - 相对于第一维度，其采取对角线。默认值：-2。 DIM2 （ INT ， 可选 ） - 相对于第二尺寸，其采取对角线。缺省值：-1。 Example: >>> a = torch.randn(2, 3) >>> torch.diag_embed(a) tensor([[[ 1.5410, 0.0000, 0.0000], [ 0.0000, -0.2934, 0.0000], [ 0.0000, 0.0000, -2.1788]], [[ 0.5684, 0.0000, 0.0000], [ 0.0000, -1.0845, 0.0000], [ 0.0000, 0.0000, -1.3986]]]) >>> torch.diag_embed(a, offset=1, dim1=0, dim2=2) tensor([[[ 0.0000, 1.5410, 0.0000, 0.0000], [ 0.0000, 0.5684, 0.0000, 0.0000]], [[ 0.0000, 0.0000, -0.2934, 0.0000], [ 0.0000, 0.0000, -1.0845, 0.0000]], [[ 0.0000, 0.0000, 0.0000, -2.1788], [ 0.0000, 0.0000, 0.0000, -1.3986]], [[ 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000]]]) torch.``diagflat( input , offset=0 ) → Tensor If inputis a vector (1-D tensor), then returns a 2-D square tensor with the elements of inputas the diagonal. 如果输入是与多于一个的维度的张量，然后返回2-d张量的对角元素等于扁平输入。 The argument offsetcontrols which diagonal to consider: If offset= 0, it is the main diagonal. If offset> 0, it is above the main diagonal. If offset Parameters input ( Tensor) – the input tensor 偏移HTG1]（ INT ， 可选 ） - 对角线来考虑。默认值：0（主对角线）。 Examples: >>> a = torch.randn(3) >>> a tensor([-0.2956, -0.9068, 0.1695]) >>> torch.diagflat(a) tensor([[-0.2956, 0.0000, 0.0000], [ 0.0000, -0.9068, 0.0000], [ 0.0000, 0.0000, 0.1695]]) >>> torch.diagflat(a, 1) tensor([[ 0.0000, -0.2956, 0.0000, 0.0000], [ 0.0000, 0.0000, -0.9068, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.1695], [ 0.0000, 0.0000, 0.0000, 0.0000]]) >>> a = torch.randn(2, 2) >>> a tensor([[ 0.2094, -0.3018], [-0.1516, 1.9342]]) >>> torch.diagflat(a) tensor([[ 0.2094, 0.0000, 0.0000, 0.0000], [ 0.0000, -0.3018, 0.0000, 0.0000], [ 0.0000, 0.0000, -0.1516, 0.0000], [ 0.0000, 0.0000, 0.0000, 1.9342]]) torch.``diagonal( input , offset=0 , dim1=0 , dim2=1 ) → Tensor 返回输入与它的对角元素的局部视图相对于DIM1和DIM2作为附加在所述形状的端部的尺寸。 The argument offsetcontrols which diagonal to consider: If offset= 0, it is the main diagonal. If offset> 0, it is above the main diagonal. If offset torch.diag_embed施加（）该函数的输出与相同的参数产生与所述输入的对角项的对角矩阵。然而， torch.diag_embed（）具有不同的默认尺寸，因此这些需要被明确指定。 Parameters 输入 （ 张量 ） - 输入张量。必须至少2维的。 offset ( int , optional ) – which diagonal to consider. Default: 0 (main diagonal). DIM1 （ INT ， 可选 ） - 相对于第一维度，其采取对角线。默认值：0。 DIM2 （ INT ， 可选 ） - 相对于第二尺寸，其采取对角线。默认值：1。 Note 采取分批对角线，传入DIM1 = -2，DIM2 = -1。 Examples: >>> a = torch.randn(3, 3) >>> a tensor([[-1.0854, 1.1431, -0.1752], [ 0.8536, -0.0905, 0.0360], [ 0.6927, -0.3735, -0.4945]]) >>> torch.diagonal(a, 0) tensor([-1.0854, -0.0905, -0.4945]) >>> torch.diagonal(a, 1) tensor([ 1.1431, 0.0360]) >>> x = torch.randn(2, 5, 4, 2) >>> torch.diagonal(x, offset=-1, dim1=1, dim2=2) tensor([[[-1.2631, 0.3755, -1.5977, -1.8172], [-1.1065, 1.0401, -0.2235, -0.7938]], [[-1.7325, -0.3081, 0.6166, 0.2335], [ 1.0500, 0.7336, -0.3836, -1.1015]]]) torch.``einsum( equation , *operands ) → Tensor[source] 这个功能提供计算多线性表达式的方式使用爱因斯坦求和约定（即乘积的和）。 Parameters 方程 （ 串 ） - 方程式中的小写字母（索引）来给出将与操作数和结果的每个维度相关联。左侧列出了操作数的尺寸，用逗号分开。应该有每张量维度中的一个索引字母。之后的右手边如下 - & GT ; ，并给出了指数的输出。如果 - [ - ] GT ; 和右侧被省略，它含蓄地定义为左侧恰好出现一次所有指数的按字母顺序排序列表。在输出不apprearing该指数的操作数项相乘后求和。如果指数出现几次同样的操作，对角线取。椭圆 ... 代表尺寸的固定数目。如果右侧推断，省略号尺寸在输出的开始。 操作数 （ 张量 的列表中） - 的操作数来计算的爱因斯坦总和。 Examples: >>> x = torch.randn(5) >>> y = torch.randn(4) >>> torch.einsum('i,j->ij', x, y) # outer product tensor([[-0.0570, -0.0286, -0.0231, 0.0197], [ 1.2616, 0.6335, 0.5113, -0.4351], [ 1.4452, 0.7257, 0.5857, -0.4984], [-0.4647, -0.2333, -0.1883, 0.1603], [-1.1130, -0.5588, -0.4510, 0.3838]]) >>> A = torch.randn(3,5,4) >>> l = torch.randn(2,5) >>> r = torch.randn(2,4) >>> torch.einsum('bn,anm,bm->ba', l, A, r) # compare torch.nn.functional.bilinear tensor([[-0.3430, -5.2405, 0.4494], [ 0.3311, 5.5201, -3.0356]]) >>> As = torch.randn(3,2,5) >>> Bs = torch.randn(3,5,4) >>> torch.einsum('bij,bjk->bik', As, Bs) # batch matrix multiplication tensor([[[-1.0564, -1.5904, 3.2023, 3.1271], [-1.6706, -0.8097, -0.8025, -2.1183]], [[ 4.2239, 0.3107, -0.5756, -0.2354], [-1.4558, -0.3460, 1.5087, -0.8530]], [[ 2.8153, 1.8787, -4.3839, -1.2112], [ 0.3728, -2.1131, 0.0921, 0.8305]]]) >>> A = torch.randn(3, 3) >>> torch.einsum('ii->i', A) # diagonal tensor([-0.7825, 0.8291, -0.1936]) >>> A = torch.randn(4, 3, 3) >>> torch.einsum('...ii->...i', A) # batch diagonal tensor([[-1.0864, 0.7292, 0.0569], [-0.9725, -1.0270, 0.6493], [ 0.5832, -1.1716, -1.5084], [ 0.4041, -1.1690, 0.8570]]) >>> A = torch.randn(2, 3, 4, 5) >>> torch.einsum('...ij->...ji', A).shape # batch permute torch.Size([2, 3, 5, 4]) torch.``flatten( input , start_dim=0 , end_dim=-1 ) → Tensor 变平的张量DIMS的连续范围。 Parameters input ( Tensor) – the input tensor start_dim （ INT ） - 第一暗淡变平 end_dim （ INT ） - 最后暗淡变平 Example: >>> t = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]]) >>> torch.flatten(t) tensor([1, 2, 3, 4, 5, 6, 7, 8]) >>> torch.flatten(t, start_dim=1) tensor([[1, 2, 3, 4], [5, 6, 7, 8]]) torch.``flip( input , dims ) → Tensor 反向沿DIMS定轴线正d张量的顺序。 Parameters input ( Tensor) – the input tensor 变暗 （ 列表 或 元组 ） - 轴翻转上 Example: >>> x = torch.arange(8).view(2, 2, 2) >>> x tensor([[[ 0, 1], [ 2, 3]], [[ 4, 5], [ 6, 7]]]) >>> torch.flip(x, [0, 1]) tensor([[[ 6, 7], [ 4, 5]], [[ 2, 3], [ 0, 1]]]) torch.``rot90( input , k , dims ) → Tensor 在通过DIMS轴规定的平面内旋转90度后的正d张量。旋转方向是从第一向第二轴如果k & GT ; 0，并且从第二向第一对于k & LT ; 0。 Parameters input ( Tensor) – the input tensor K （ INT ） - 次数旋转 变暗 （ 列表 或 元组 ） - 轴旋转 Example: >>> x = torch.arange(4).view(2, 2) >>> x tensor([[0, 1], [2, 3]]) >>> torch.rot90(x, 1, [0, 1]) tensor([[1, 3], [0, 2]]) >>> x = torch.arange(8).view(2, 2, 2) >>> x tensor([[[0, 1], [2, 3]], [[4, 5], [6, 7]]]) >>> torch.rot90(x, 1, [1, 2]) tensor([[[1, 3], [0, 2]], [[5, 7], [4, 6]]]) torch.``histc( input , bins=100 , min=0 , max=0 , out=None ) → Tensor 计算张量的柱状图。 这些元件之间 分成相等的宽度仓分钟HTG3]和 MAX。如果 分钟HTG15]和 MAX 均为零，最小和的最大值的数据被使用。 Parameters input ( Tensor) – the input tensor 仓 （ INT ） - 直方图区间的数 分钟HTG1]（ INT ） - 该范围的下端（含） MAX （ INT ） - 该范围的上端（含） out ( Tensor , optional ) – the output tensor Returns 直方图表示为张量 Return type Tensor Example: >>> torch.histc(torch.tensor([1., 2, 1]), bins=4, min=0, max=3) tensor([ 0., 2., 1., 0.]) torch.``meshgrid( *tensors , **kwargs )[source] 取 N N N 张量，其中的每一个可以是标量或1维向量，并创建 N N N N维网格，其中，所述 i的 i的 i的 第网格由扩大 i的 i的 [HTG85定义] i的[H TG93] 第在由其他输入来定义的尺寸输入。 Args: 张量（张量的列表）：标量或1维的张量的列表。标量将被视为的张量大小 （ 1 ， ） （1） （ 1 ， ） 自动 > Returns: SEQ（张量的序列）：如果输入具有 K K K 大小的张量 （ N 1 ， ） ， （ N 2 ， ） ... ， （ N K ， ） （N_1，），（N_2，），\\ ldots，（N_k，） （ N 1 ） ， （ N 2 ， ） ， ... ， （ N K ， ） 则输出也将具有 K K K 张量，其中所有的张量的大小 （ N 1 ， N 2 ， ... ， N K ​​） （N_1，N_2，\\ ldots，N_k） （ N 1 ， N 2 ， ... ， N K [HT G382] ） 。 > Example: >>> x = torch.tensor([1, 2, 3]) >>> y = torch.tensor([4, 5, 6]) >>> grid_x, grid_y = torch.meshgrid(x, y) >>> grid_x tensor([[1, 1, 1], [2, 2, 2], [3, 3, 3]]) >>> grid_y tensor([[4, 5, 6], [4, 5, 6], [4, 5, 6]]) torch.``renorm( input , p , dim , maxnorm , out=None ) → Tensor 返回的张量，其中输入的每个子张量沿着维度暗淡进行归一化，使得 P - 子张量的范数低于值maxnorm Note 如果行的范数大于 maxnorm 下，该行是不变 Parameters input ( Tensor) – the input tensor P （ 浮动 ） - 功率为范数计算 暗淡 （ INT ） - 的尺寸切过，以获得子张量 maxnorm （ 浮动 ） - 最大范保持每个子张量下 out ( Tensor , optional ) – the output tensor Example: >>> x = torch.ones(3, 3) >>> x[1].fill_(2) tensor([ 2., 2., 2.]) >>> x[2].fill_(3) tensor([ 3., 3., 3.]) >>> x tensor([[ 1., 1., 1.], [ 2., 2., 2.], [ 3., 3., 3.]]) >>> torch.renorm(x, 1, 0, 5) tensor([[ 1.0000, 1.0000, 1.0000], [ 1.6667, 1.6667, 1.6667], [ 1.6667, 1.6667, 1.6667]]) torch.``repeat_interleave() torch.``repeat_interleave( input , repeats , dim=None ) → Tensor 重复张量元素。 Warning 这是从torch.repeat（）不同但类似于 numpy.repeat 。 Parameters 输入 （ 张量 ） - 输入张量 重复 （ 张量 或 INT ） - 重复用于每个元件的数目。重复广播到符合给定的轴的形状。 暗淡 （ INT ， 可选 ） - 沿其以重复的值的尺寸。缺省情况下，使用压平输入阵列，并返回一个平坦的输出阵列。 Returns Repeated tensor which has the same shape as input, except along the 定轴。 Return type Tensor Example: >>> x = torch.tensor([1, 2, 3]) >>> x.repeat_interleave(2) tensor([1, 1, 2, 2, 3, 3]) >>> y = torch.tensor([[1, 2], [3, 4]]) >>> torch.repeat_interleave(y, 2) tensor([1, 1, 2, 2, 3, 3, 4, 4]) >>> torch.repeat_interleave(y, 3, dim=1) tensor([[1, 1, 1, 2, 2, 2], [3, 3, 3, 4, 4, 4]]) >>> torch.repeat_interleave(y, torch.tensor([1, 2]), dim=0) tensor([[1, 2], [3, 4], [3, 4]]) torch.``repeat_interleave( repeats ) → Tensor 如果重复是张量（[N1，N2，N3，...]），那么输出将是张量（[0，0，...，1，1， ...，2,2，...，...] 其中 0 出现） N1 ， 1 出现倍 N 2 次， 2 出现 N3 时间等 torch.``roll( input , shifts , dims=None ) → Tensor 一起滚动给定的尺寸（S）的张量。在第一位置被移动超过最后一个位置元素被重新引入。如果没有指定一个尺寸，张量将轧制前的被平坦化，然后恢复到原来的形状。 Parameters input ( Tensor) – the input tensor 移位 （ INT 或 蟒的元组：整数 ） - 的地方数，通过该元件张量移位。如果移位是一个元组，DIMS必须是相同大小的元组，并且每个维度将由相应的值被卷起 变暗 （ INT 或 蟒的元组：整数 ） - 轴沿其滚动 Example: >>> x = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8]).view(4, 2) >>> x tensor([[1, 2], [3, 4], [5, 6], [7, 8]]) >>> torch.roll(x, 1, 0) tensor([[7, 8], [1, 2], [3, 4], [5, 6]]) >>> torch.roll(x, -1, 0) tensor([[3, 4], [5, 6], [7, 8], [1, 2]]) >>> torch.roll(x, shifts=(2, 1), dims=(0, 1)) tensor([[6, 5], [8, 7], [2, 1], [4, 3]]) torch.``tensordot( a , b , dims=2 )[source] 返回的收缩和b在多个维度。 tensordot实现了一个广义矩阵乘积。 Parameters 一 （ 张量 ） - 左张量收缩 B （ 张量 ） - 右张量收缩 变暗 （ INT 或 蟒两个列表的元组：整数 ） - 维数收缩或为一和分别b尺寸的显式列表 当与一个整数参数称为变暗= d d d 和数量的尺寸一和b是 M M M 和 n的 n的 n的 ，分别，它计算 ri0,...,im−d,id,...,in=∑k0,...,kd−1ai0,...,im−d,k0,...,kd−1×bk0,...,kd−1,id,...,in.r{i_0,...,i{m-d}, id,...,i_n} = \\sum{k0,...,k{d-1}} a{i_0,...,i{m-d},k0,...,k{d-1}} \\times b{k_0,...,k{d-1}, i_d,...,i_n}. ri0​,...,im−d​,id​,...,in​​=k0​,...,kd−1​∑​ai0​,...,im−d​,k0​,...,kd−1​​×bk0​,...,kd−1​,id​,...,in​​. 当与所谓变暗列表的形式，给定尺寸将取代过去的 承包 d d d 的一和第一 d d d 的 b b b 。在这些维度的尺寸必须匹配，但是 tensordot将处理广播尺寸。 Examples: >>> a = torch.arange(60.).reshape(3, 4, 5) >>> b = torch.arange(24.).reshape(4, 3, 2) >>> torch.tensordot(a, b, dims=([1, 0], [0, 1])) tensor([[4400., 4730.], [4532., 4874.], [4664., 5018.], [4796., 5162.], [4928., 5306.]]) >>> a = torch.randn(3, 4, 5, device='cuda') >>> b = torch.randn(4, 5, 6, device='cuda') >>> c = torch.tensordot(a, b, dims=2).cpu() tensor([[ 8.3504, -2.5436, 6.2922, 2.7556, -1.0732, 3.2741], [ 3.3161, 0.0704, 5.0187, -0.4079, -4.3126, 4.8744], [ 0.8223, 3.9445, 3.2168, -0.2400, 3.4117, 1.7780]]) torch.``trace( input ) → Tensor 返回对角线输入2-d的矩阵的元素的总和。 Example: >>> x = torch.arange(1., 10.).view(3, 3) >>> x tensor([[ 1., 2., 3.], [ 4., 5., 6.], [ 7., 8., 9.]]) >>> torch.trace(x) tensor(15.) torch.``tril( input , diagonal=0 , out=None ) → Tensor 返回矩阵（2- d张量）或分批矩阵输入的下三角部分，结果张量OUT 的其它元件被设置为0。 矩阵的下三角部分定义为上和下面的对角线的元素。 的参数 对角线控制考虑哪些对角线。如果 对角线= 0，上面和下面的主对角线的所有元素被保留。正值包括正上方的主对角线许多对角线，并且类似地负值排除正下方的主对角线许多对角线。主对角线是该组的索引 { （ i的 i的 ） } \\ lbrace（I，i）的\\ rbrace { （ i的 ， i的 ） } 为 i的 ∈ [ 0 ， 分钟HTG79] ⁡ { d 1 ， d 2 } - 1 I \\在[0，\\分钟\\ {D {1 }，D {2} \\} - 1] i的 ∈ [ 0 ， 分钟HTG137] { d 1 ， d 2 [H TG204]} - 1 其中 d 1 ， d 2 D {1}，D {2} d 1 ​​ ， d 2 是矩阵的维数。 Parameters input ( Tensor) – the input tensor diagonal ( int , optional ) – the diagonal to consider out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(3, 3) >>> a tensor([[-1.0813, -0.8619, 0.7105], [ 0.0935, 0.1380, 2.2112], [-0.3409, -0.9828, 0.0289]]) >>> torch.tril(a) tensor([[-1.0813, 0.0000, 0.0000], [ 0.0935, 0.1380, 0.0000], [-0.3409, -0.9828, 0.0289]]) >>> b = torch.randn(4, 6) >>> b tensor([[ 1.2219, 0.5653, -0.2521, -0.2345, 1.2544, 0.3461], [ 0.4785, -0.4477, 0.6049, 0.6368, 0.8775, 0.7145], [ 1.1502, 3.2716, -1.1243, -0.5413, 0.3615, 0.6864], [-0.0614, -0.7344, -1.3164, -0.7648, -1.4024, 0.0978]]) >>> torch.tril(b, diagonal=1) tensor([[ 1.2219, 0.5653, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.4785, -0.4477, 0.6049, 0.0000, 0.0000, 0.0000], [ 1.1502, 3.2716, -1.1243, -0.5413, 0.0000, 0.0000], [-0.0614, -0.7344, -1.3164, -0.7648, -1.4024, 0.0000]]) >>> torch.tril(b, diagonal=-1) tensor([[ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.4785, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 1.1502, 3.2716, 0.0000, 0.0000, 0.0000, 0.0000], [-0.0614, -0.7344, -1.3164, 0.0000, 0.0000, 0.0000]]) torch.``tril_indices( row , col , offset=0 , dtype=torch.long , device='cpu' , layout=torch.strided ) → Tensor 返回行的下三角部分的索引-by- COL矩阵在一个2-N张量，其中第一行包含所有索引的列坐标和第二行包含列坐标。指数是基于行，然后列排序。 The lower triangular part of the matrix is defined as the elements on and below the diagonal. 的参数偏移HTG2]控制考虑哪些对角线。如果偏移HTG6]= 0，上面和下面的主对角线的所有元素被保留。正值包括正上方的主对角线许多对角线，并且类似地负值排除正下方的主对角线许多对角线。主对角线是该组的索引 { （ i的 i的 ） } \\ lbrace（I，i）的\\ rbrace { （ i的 ， i的 ） } 为 i的 ∈ [ 0 ， 分钟HTG75] ⁡ { d 1 ， d 2 } - 1 I \\在[0，\\分钟\\ {D {1 }，{D 2} \\} - 1] i的 ∈ [ 0 ， 分钟 { d 1 ， d 2 } - 1 其中 d 1 ， d 2 D {1}，D {2} d 1 ​​ ， d 2 是矩阵的维数。 注：在 'CUDA' 运行时，行* COL必须低于 2 59 2 ^ {59} 2 5 9 可以防止计算期间的溢出。 Parameters 在2 d矩阵中的行数 - 行 （INT）。 COL （INT） - 在2-d矩阵的列数。 偏移HTG1]（INT） - 对角线从所述主对角线的偏移。默认值：如果没有提供，0。 DTYPE （ torch.dtype，可选） - 返回的张量的所希望的数据类型。默认值：如果无，torch.long。 device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. 布局 （ torch.layout，可选） - 目前仅支持torch.strided。 Example:: >>> a = torch.tril_indices(3, 3) >>> a tensor([[0, 1, 1, 2, 2, 2], [0, 0, 1, 0, 1, 2]]) >>> a = torch.tril_indices(4, 3, -1) >>> a tensor([[1, 2, 2, 3, 3, 3], [0, 0, 1, 0, 1, 2]]) >>> a = torch.tril_indices(4, 3, 1) >>> a tensor([[0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3], [0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 2]]) torch.``triu( input , diagonal=0 , out=None ) → Tensor 返回一个矩阵（2- d张量）或分批矩阵输入的上三角部分，结果张量OUT 的其它元件被设置为0。 矩阵的上三角部分定义为上和上面的对角线的元素。 的参数 对角线控制考虑哪些对角线。如果 对角线= 0，上面和下面的主对角线的所有元素被保留。正值排除同样多的对角线上方的主对角线，并且类似地负值包括正下方的主对角线许多对角线。主对角线是该组的索引 { （ i的 i的 ） } \\ lbrace（I，i）的\\ rbrace { （ i的 ， i的 ） } 为 i的 ∈ [ 0 ， 分钟HTG79] ⁡ { d 1 ， d 2 } - 1 I \\在[0，\\分钟\\ {D {1 }，D {2} \\} - 1] i的 ∈ [ 0 ， 分钟HTG137] { d 1 ， d 2 [H TG204]} - 1 其中 d 1 ， d 2 D {1}，D {2} d 1 ​​ ， d 2 是矩阵的维数。 Parameters input ( Tensor) – the input tensor diagonal ( int , optional ) – the diagonal to consider out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(3, 3) >>> a tensor([[ 0.2309, 0.5207, 2.0049], [ 0.2072, -1.0680, 0.6602], [ 0.3480, -0.5211, -0.4573]]) >>> torch.triu(a) tensor([[ 0.2309, 0.5207, 2.0049], [ 0.0000, -1.0680, 0.6602], [ 0.0000, 0.0000, -0.4573]]) >>> torch.triu(a, diagonal=1) tensor([[ 0.0000, 0.5207, 2.0049], [ 0.0000, 0.0000, 0.6602], [ 0.0000, 0.0000, 0.0000]]) >>> torch.triu(a, diagonal=-1) tensor([[ 0.2309, 0.5207, 2.0049], [ 0.2072, -1.0680, 0.6602], [ 0.0000, -0.5211, -0.4573]]) >>> b = torch.randn(4, 6) >>> b tensor([[ 0.5876, -0.0794, -1.8373, 0.6654, 0.2604, 1.5235], [-0.2447, 0.9556, -1.2919, 1.3378, -0.1768, -1.0857], [ 0.4333, 0.3146, 0.6576, -1.0432, 0.9348, -0.4410], [-0.9888, 1.0679, -1.3337, -1.6556, 0.4798, 0.2830]]) >>> torch.triu(b, diagonal=1) tensor([[ 0.0000, -0.0794, -1.8373, 0.6654, 0.2604, 1.5235], [ 0.0000, 0.0000, -1.2919, 1.3378, -0.1768, -1.0857], [ 0.0000, 0.0000, 0.0000, -1.0432, 0.9348, -0.4410], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.4798, 0.2830]]) >>> torch.triu(b, diagonal=-1) tensor([[ 0.5876, -0.0794, -1.8373, 0.6654, 0.2604, 1.5235], [-0.2447, 0.9556, -1.2919, 1.3378, -0.1768, -1.0857], [ 0.0000, 0.3146, 0.6576, -1.0432, 0.9348, -0.4410], [ 0.0000, 0.0000, -1.3337, -1.6556, 0.4798, 0.2830]]) torch.``triu_indices( row , col , offset=0 , dtype=torch.long , device='cpu' , layout=torch.strided ) → Tensor 通过返回行 的上三角部分的索引COL矩阵在一个2-N张量，其中，所述第一行包含所有索引的列坐标和第二行包含列坐标。指数是基于行，然后列排序。 The upper triangular part of the matrix is defined as the elements on and above the diagonal. 的参数偏移HTG2]控制考虑哪些对角线。如果偏移HTG6]= 0，上和上方的主对角线的所有元素被保留。正值排除同样多的对角线上方的主对角线，并且类似地负值包括正下方的主对角线许多对角线。主对角线是该组的索引 { （ i的 i的 ） } \\ lbrace（I，i）的\\ rbrace { （ i的 ， i的 ） } 为 i的 ∈ [ 0 ， 分钟HTG75] ⁡ { d 1 ， d 2 } - 1 I \\在[0，\\分钟\\ {D {1 }，{D 2} \\} - 1] i的 ∈ [ 0 ， 分钟 { d 1 ， d 2 } - 1 其中 d 1 ， d 2 D {1}，D {2} d 1 ​​ ， d 2 是矩阵的维数。 NOTE: when running on ‘cuda’, row * col must be less than 2592^{59}259 to prevent overflow during calculation. Parameters row (int) – number of rows in the 2-D matrix. col (int) – number of columns in the 2-D matrix. offset (int) – diagonal offset from the main diagonal. Default: if not provided, 0. dtype (torch.dtype, optional) – the desired data type of returned tensor. Default: if None, torch.long. device (torch.device, optional) – the desired device of returned tensor. Default: if None, uses the current device for the default tensor type (see torch.set_default_tensor_type()). devicewill be the CPU for CPU tensor types and the current CUDA device for CUDA tensor types. layout (torch.layout, optional) – currently only support torch.strided. Example:: >>> a = torch.triu_indices(3, 3) >>> a tensor([[0, 0, 0, 1, 1, 2], [0, 1, 2, 1, 2, 2]]) >>> a = torch.triu_indices(4, 3, -1) >>> a tensor([[0, 0, 0, 1, 1, 1, 2, 2, 3], [0, 1, 2, 0, 1, 2, 1, 2, 2]]) >>> a = torch.triu_indices(4, 3, 1) >>> a tensor([[0, 0, 1], [1, 2, 2]]) BLAS和LAPACK操作 torch.``addbmm( beta=1 , input , alpha=1 , batch1 , batch2 , out=None ) → Tensor 对存储在BATCH1和batch2，具有降低的附加步骤（所有的矩阵乘法得到积累矩阵的批次矩阵矩阵积沿着第一维度）。 输入加到最终结果。 BATCH1和batch2必须各自含有相同数量的矩阵的3-d张量。 如果BATCH1是 （ B × n的 × M ） （b \\ n次\\乘以m） （ b × n的 × M ） 张量，batch2是 （ b × M × p ） （b \\倍米\\倍p） [HT G100] （ B × M × p ） 张量，输入必须 broadcastable 与 （ n的 × p ） （N \\倍p） （ n的 × p ） 几十或并OUT将是 （ n的 × p ） （N \\倍p） （ n的 × p ） 张量。 out=β input+α (∑i=0b−1batch1i@batch2i)out = \\beta\\ \\text{input} + \\alpha\\ (\\sum_{i=0}^{b-1} \\text{batch1}_i \\mathbin{@} \\text{batch2}_i) out=β input+α (i=0∑b−1​batch1i​@batch2i​) 对于类型的输入 FloatTensor 或 DoubleTensor ，自变量的β和阿尔法必须实数，否则他们应该是整数。 Parameters 的β （ 号码 ， 可选 ） - 乘数输入（ β \\的β β ） 输入 （ 张量 ） - 要添加矩阵 阿尔法 （ 号码 ， 可选 ） - 乘数 BATCH1 @ batch2 （ α \\阿尔法 α ） BATCH1 （ 张量 ） - 第一批矩阵的相乘 batch2 （ 张量 ） - 第二批矩阵的相乘 out ( Tensor , optional ) – the output tensor Example: >>> M = torch.randn(3, 5) >>> batch1 = torch.randn(10, 3, 4) >>> batch2 = torch.randn(10, 4, 5) >>> torch.addbmm(M, batch1, batch2) tensor([[ 6.6311, 0.0503, 6.9768, -12.0362, -2.1653], [ -4.8185, -1.4255, -6.6760, 8.9453, 2.5743], [ -3.8202, 4.3691, 1.0943, -1.1109, 5.4730]]) torch.``addmm( beta=1 , input , alpha=1 , mat1 , mat2 , out=None ) → Tensor 执行矩阵MAT1和MAT2的矩阵乘法。矩阵输入加到最终结果。 如果MAT1是 （ n的 × M ） （N \\乘以m） （ n的 × M ） 张量，MAT2是 （ M × p ） （M \\倍p） （ M × p ） 张量，然后输入必须 broadcastable 与 （ n的 × p ） （N \\倍p ） （ n的 × p ） 张量和OUT将是 （ n的 × p ） （N \\倍p） （ n的 × P ） 张量。 阿尔法和的β的之间MAT1和上的矩阵矢量乘积的缩放因子MAT2和分别添加的矩阵输入。 out=β input+α (mat1i@mat2i)\\text{out} = \\beta\\ \\text{input} + \\alpha\\ (\\text{mat1}_i \\mathbin{@} \\text{mat2}_i) out=β input+α (mat1i​@mat2i​) 对于类型的输入 FloatTensor 或 DoubleTensor ，自变量的β和阿尔法必须实数，否则他们应该是整数。 Parameters beta ( Number , optional ) – multiplier for input(β\\betaβ ) input ( Tensor) – matrix to be added 阿尔法 （ 号码 ， 可选 ） - 乘数 M 一 T 1 @ M 一 T 2 MAT1 @ MAT2 M 一 T 1 @ M 一 吨 2 （ α \\阿尔法 α ） MAT1 （ 张量 ） - 要被相乘的第一矩阵 MAT2 （ 张量 ） - 第二矩阵相乘 out ( Tensor , optional ) – the output tensor Example: >>> M = torch.randn(2, 3) >>> mat1 = torch.randn(2, 3) >>> mat2 = torch.randn(3, 3) >>> torch.addmm(M, mat1, mat2) tensor([[-4.8716, 1.4671, -1.3746], [ 0.7573, -3.9555, -2.8681]]) torch.``addmv( beta=1 , input , alpha=1 , mat , vec , out=None ) → Tensor 执行矩阵垫和的矩阵矢量乘积矢量VEC。矢量输入加到最终结果。 如果垫是 （ n的 × M ） （N \\乘以m） （ n的 × M ） 张量，VEC是大小[1-d张量HTG56] M ，然后输入必须 broadcastable 与大小的1-d张量 n的和OUT将大小 n的 1- d张量。 阿尔法和的β是比例上的矩阵矢量乘积因子之间垫和VEC和分别添加的张量输入。 out=β input+α (mat@vec)\\text{out} = \\beta\\ \\text{input} + \\alpha\\ (\\text{mat} \\mathbin{@} \\text{vec}) out=β input+α (mat@vec) 对于类型的输入 FloatTensor 或 DoubleTensor ，自变量的β和阿尔法必须实数，否则他们应该是整数 Parameters beta ( Number , optional ) – multiplier for input(β\\betaβ ) 输入 （ 张量 ） - 要添加矢量 阿尔法 （ 号码 ， 可选 ） - 乘数 M 一 T @ [HTG22】v E C 垫@ VEC M 一 T @ [HTG46】v E C （ α \\阿尔法 α ） 垫 （ 张量 ） - 矩阵相乘 VEC （ 张量 ） - 向量相乘 out ( Tensor , optional ) – the output tensor Example: >>> M = torch.randn(2) >>> mat = torch.randn(2, 3) >>> vec = torch.randn(3) >>> torch.addmv(M, mat, vec) tensor([-0.3768, -5.5565]) torch.``addr( beta=1 , input , alpha=1 , vec1 , vec2 , out=None ) → Tensor 执行的矢量VEC1和VEC2外产物，并将其添加到矩阵输入。 可选值的β和阿尔法是在间外积缩放因子VEC1和VEC2和分别添加的矩阵输入。 out=β input+α (vec1⊗vec2)\\text{out} = \\beta\\ \\text{input} + \\alpha\\ (\\text{vec1} \\otimes \\text{vec2}) out=β input+α (vec1⊗vec2) 如果VEC1是大小 n的的向量和VEC2是大小 M [向量HTG11]，然后输入必须 broadcastable 用的大小 [基质HTG24] （ n的 × M ） （N \\倍米） （ n的 × M ） 和OUT将大小的矩阵 （ n的 × M ） （N \\乘以m）[HTG9 0] （ n的 × M ） 。 For inputs of type FloatTensor or DoubleTensor, arguments betaand alpha must be real numbers, otherwise they should be integers Parameters beta ( Number , optional ) – multiplier for input(β\\betaβ ) input ( Tensor) – matrix to be added 阿尔法 （ 号码 ， 可选 ） - 乘数 VEC1 ⊗ VEC2 \\文本{VEC1} \\ otimes \\文本{VEC2} VEC1 ⊗ VEC2 （ α \\阿尔法 α ） VEC1 （ 张量 ） - 外积的第一向量 VEC2 （ 张量 ） - 外积的第二矢量 out ( Tensor , optional ) – the output tensor Example: >>> vec1 = torch.arange(1., 4.) >>> vec2 = torch.arange(1., 3.) >>> M = torch.zeros(3, 2) >>> torch.addr(M, vec1, vec2) tensor([[ 1., 2.], [ 2., 4.], [ 3., 6.]]) torch.``baddbmm( beta=1 , input , alpha=1 , batch1 , batch2 , out=None ) → Tensor 执行矩阵的批次矩阵矩阵产物BATCH1和batch2。 输入加到最终结果。 BATCH1和batch2必须各自含有相同数量的矩阵的3-d张量。 如果BATCH1是 （ B × n的 × M ） （b \\ n次\\乘以m） （ b × n的 × M ） 张量，batch2是 （ b × M × p ） （b \\倍米\\倍p） [HT G100] （ B × M × p ） 张量，然后输入必须 broadcastable 与 （ b × n的 × p ） （b \\ n次\\倍p） （ b × n的 × P ） 张量和OUT将是 （ b × n的 × p ） （b \\ n次\\倍p） （ b × n的 × p ​​） 张量。既阿尔法和的β意味着相同于 torch.addbmm所使用的比例因子（ ）。 outi=β inputi+α (batch1i@batch2i)\\text{out}_i = \\beta\\ \\text{input}_i + \\alpha\\ (\\text{batch1}_i \\mathbin{@} \\text{batch2}_i) outi​=β inputi​+α (batch1i​@batch2i​) For inputs of type FloatTensor or DoubleTensor, arguments betaand alpha must be real numbers, otherwise they should be integers. Parameters beta ( Number , optional ) – multiplier for input(β\\betaβ ) input ( Tensor) – the tensor to be added 阿尔法 （ 号码 ， 可选 ） - 乘数 BATCH1 @ batch2 \\文本{BATCH1} \\ mathbin {@} \\文本{batch2} BATCH1 @ batch2 （ α \\阿尔法 α ） batch1 ( Tensor) – the first batch of matrices to be multiplied batch2 ( Tensor) – the second batch of matrices to be multiplied out ( Tensor , optional ) – the output tensor Example: >>> M = torch.randn(10, 3, 5) >>> batch1 = torch.randn(10, 3, 4) >>> batch2 = torch.randn(10, 4, 5) >>> torch.baddbmm(M, batch1, batch2).size() torch.Size([10, 3, 5]) torch.``bmm( input , mat2 , out=None ) → Tensor 对存储在输入和MAT2矩阵的批次矩阵矩阵乘积。 输入和MAT2必须各自含有相同数量的矩阵的3-d张量。 如果输入是 （ B × n的 × M ） （b \\ n次\\乘以m） （ b × n的 × M ） 张量，MAT2是 （ b × M × p ） （b \\倍米\\倍p） [HTG10 0] （ B × M × p ） 张量，OUT将是 （ b × n的 × p ） （b \\ n次\\倍p） （ b × n的 × [HTG19 3] P ） 张量。 outi=inputi@mat2i\\text{out}_i = \\text{input}_i \\mathbin{@} \\text{mat2}_i outi​=inputi​@mat2i​ Note 此功能不播[ HTG3。用于广播基质的产品，见 torch.matmul（）。 Parameters 输入 （ 张量 ） - 矩阵的第一批要被乘 MAT2 （ 张量 ） - 第二批矩阵的相乘 out ( Tensor , optional ) – the output tensor Example: >>> input = torch.randn(10, 3, 4) >>> mat2 = torch.randn(10, 4, 5) >>> res = torch.bmm(input, mat2) >>> res.size() torch.Size([10, 3, 5]) torch.``bitwise_not( input , out=None ) → Tensor 计算给定输入张量的位NOT。输入必须是整数或布尔类型。 Parameters input ( Tensor) – the input tensor out ( Tensor , optional ) – the output tensor Example >>> torch.bitwise_not(torch.tensor([-1, -2, 3], dtype=torch.int8)) tensor([ 0, 1, -4], dtype=torch.int8) torch.``chain_matmul( *matrices )[source] 返回的矩阵积的 N N N 2-d张量。此产物用其选择其中招致算术操作方面的成本最低的（ [CLRS] ）的顺序进行矩阵链顺序算法有效地计算。注意，由于这是一个函数来计算的产物， N N N 需要为大于或等于2 ;如果等于2，则一个简单的矩阵矩阵产品退还。如果 N N N 为1，那么这是一个无操作 - 原始矩阵返回原样。 Parameters 矩阵 （ 张量... ） - 2以上2-d张量，其产物是待确定的序列。 Returns 如果 i的 T H I ^ {个} i的 T H 张量是尺寸 p i的 × p i的 + 1 P {I} \\倍P {I + 1} p i的 × p i的 + 1 ，则产品将是尺寸 p的 1 × p N + 1 P {1} \\ TI MES P {N + 1} P 1 × p N + 1 ​​ 。 Return type Tensor Example: >>> a = torch.randn(3, 4) >>> b = torch.randn(4, 5) >>> c = torch.randn(5, 6) >>> d = torch.randn(6, 7) >>> torch.chain_matmul(a, b, c, d) tensor([[ -2.3375, -3.9790, -4.1119, -6.6577, 9.5609, -11.5095, -3.2614], [ 21.4038, 3.3378, -8.4982, -5.2457, -10.2561, -2.4684, 2.7163], [ -0.9647, -5.8917, -2.3213, -5.2284, 12.8615, -12.2816, -2.5095]]) torch.``cholesky( input , upper=False , out=None ) → Tensor 计算对称正定矩阵 A A [的Cholesky分解HTG12] A 或对称正定矩阵的批次。 如果上是真，返回的矩阵U是上三角，和分解的形式为： A=UTUA = U^TUA=UTU 如果上是假，返回的矩阵L是下三角，和分解的形式为： A=LLTA = LL^TA=LLT 如果上是真和 A A A 是分批对称正定矩阵，则返回的张量将组成每个单独的矩阵的上三角的Cholesky因素的。类似地，当上是假，返回的张量将组成的每一个单独的矩阵的下三角的Cholesky因素。 Parameters 输入 （ 张量 ） - 输入张量 A A A 大小的 （ ， n的 ， n的 ） （，N，N） （ ， n的 ， n的 ） 其中 是零个或多个选自由对称正定的批次尺寸矩阵。 上 （ 布尔 ， 可选 ） - 标志，指示是否以返回上或下三角矩阵。默认值：假 OUT （ 张量 ， 可选 ） - 输出矩阵 Example: >>> a = torch.randn(3, 3) >>> a = torch.mm(a, a.t()) # make symmetric positive-definite >>> l = torch.cholesky(a) >>> a tensor([[ 2.4112, -0.7486, 1.4551], [-0.7486, 1.3544, 0.1294], [ 1.4551, 0.1294, 1.6724]]) >>> l tensor([[ 1.5528, 0.0000, 0.0000], [-0.4821, 1.0592, 0.0000], [ 0.9371, 0.5487, 0.7023]]) >>> torch.mm(l, l.t()) tensor([[ 2.4112, -0.7486, 1.4551], [-0.7486, 1.3544, 0.1294], [ 1.4551, 0.1294, 1.6724]]) >>> a = torch.randn(3, 2, 2) >>> a = torch.matmul(a, a.transpose(-1, -2)) + 1e-03 # make symmetric positive-definite >>> l = torch.cholesky(a) >>> z = torch.matmul(l, l.transpose(-1, -2)) >>> torch.max(torch.abs(z - a)) # Max non-zero tensor(2.3842e-07) torch.``cholesky_inverse( input , upper=False , out=None ) → Tensor 计算对称正定矩阵 A 的倒数A A 使用其的Cholesky因数 U U U ：返回矩阵INV。逆使用LAPACK例程dpotri计算和spotri（和相应的MAGMA例程）。 如果上是假， U U U 是下三角使得返回的张量是 inv=(uuT)−1inv = (uu^{T})^{-1} inv=(uuT)−1 如果上是真或没有提供， U U U 是上三角使得返回的张量是 inv=(uTu)−1inv = (u^T u)^{-1} inv=(uTu)−1 Parameters 输入 （ 张量 ） - 输入2-d张量 U U U ，一个上或下三角的Cholesky因数 上 （ 布尔 ， 可选 ） - 是否返回低级（默认）或上三角矩阵 OUT （ 张量 ， 可选 ） - 输出张量为 INV Example: >>> a = torch.randn(3, 3) >>> a = torch.mm(a, a.t()) + 1e-05 * torch.eye(3) # make symmetric positive definite >>> u = torch.cholesky(a) >>> a tensor([[ 0.9935, -0.6353, 1.5806], [ -0.6353, 0.8769, -1.7183], [ 1.5806, -1.7183, 10.6618]]) >>> torch.cholesky_inverse(u) tensor([[ 1.9314, 1.2251, -0.0889], [ 1.2251, 2.4439, 0.2122], [-0.0889, 0.2122, 0.1412]]) >>> a.inverse() tensor([[ 1.9314, 1.2251, -0.0889], [ 1.2251, 2.4439, 0.2122], [-0.0889, 0.2122, 0.1412]]) torch.``cholesky_solve( input , input2 , upper=False , out=None ) → Tensor 解决方程与半正定矩阵的线性系统被倒置给予其的Cholesky因数矩阵 U U U 。 如果上是假， U U U 是和和 C 被返回下三角使得： c=(uuT)−1bc = (u u^T)^{-1} b c=(uuT)−1b 如果上是真或没有提供， U U U 是上三角和 C 被返回，使得： c=(uTu)−1bc = (u^T u)^{-1} b c=(uTu)−1b torch.cholesky_solve（B，U）可以在2D输入 B，U 或是2D矩阵的批输入。如果输入是批次，然后返回成批输出 C Note 的OUT关键字仅支持2D矩阵输入，即， B，U 必须2D矩阵。 Parameters 输入 （ 张量 ） - 输入矩阵 B b b 大小的 （ ， M ， K ） （，M，K） （ ， M ， K ） ，其中 [H TG102] 是零点或多个批次的尺寸 输入2 （ 张量 ） - 输入矩阵 U U U 大小的 （ ， M ， M ） （，M，M） （ ， M ， M ） ，其中 为上限或下三角的Cholesky因数组成多个批处理尺寸的零 上 （ 布尔 ， 可选 ） - 是否考虑的Cholesky因数作为下或上三角矩阵。默认值：假 [HTG13。 OUT （ 张量 ， 可选 ） - 输出张量为 C Example: >>> a = torch.randn(3, 3) >>> a = torch.mm(a, a.t()) # make symmetric positive definite >>> u = torch.cholesky(a) >>> a tensor([[ 0.7747, -1.9549, 1.3086], [-1.9549, 6.7546, -5.4114], [ 1.3086, -5.4114, 4.8733]]) >>> b = torch.randn(3, 2) >>> b tensor([[-0.6355, 0.9891], [ 0.1974, 1.4706], [-0.4115, -0.6225]]) >>> torch.cholesky_solve(b, u) tensor([[ -8.1625, 19.6097], [ -5.8398, 14.2387], [ -4.3771, 10.4173]]) >>> torch.mm(a.inverse(), b) tensor([[ -8.1626, 19.6097], [ -5.8398, 14.2387], [ -4.3771, 10.4173]]) torch.``dot( input , tensor ) → Tensor 计算两个张量的点积（内积）。 Note 此功能不播[ HTG3。 Example: >>> torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1])) tensor(7) torch.``eig( input , eigenvectors=False , out=None) - > (Tensor, Tensor ) 计算实方阵的特征值和特征向量。 Note 因为特征向量可能是复杂的，向后通仅对支持torch.symeig（） Parameters 输入 （ 张量 ） - 的形状 方阵（ n的 × n的 ） （N \\ n次） （ n的 × n的 ） 的量，特征向量将被计算 本征向量 （ 布尔 ） - 真来计算两个特征向量;否则，只有特征值将计算 OUT （ 元组 ， 可选 ） - 输出张量 Returns 将含有namedtuple（本征值，本征矢量） 本征值 （ 张量 ）：形状 （ n的 × 2 ） （N \\次2） （ n的 × 2 ） 。每一行是输入 ，其中，所述第一元件是实部和所述第二元件是虚数部分的的本征值。特征值不一定有序。 > 本征向量 （ 张量 ）：如果本征向量=假，它是一个空的张量。否则，该张量的形状 （ n的 × n的 ） （N \\ n次） （ n的 × n的 ） 可以被用于计算归一化的（单元长度）如下对应的特征值的特征向量。如果相应的本征值[J] 是一个实数，柱本征向量[:, j]的是对应于本征值[j]的本征向量。如果相应的本征值[J] 和本征值[J + 1] 形成的复共轭对，则真正的本征向量可被计算为 真实特征矢量 [ [HTG76：J = E i的 克 E n的 [HTG92】v E C T O R S [ ： ， [ HTG112：J + i的 × E i的 G E n的 [HTG132】v E C T 问题o R S [ ： ， [HTG152：J + 1 \\ {文本特征向量真} [j]的本征向量= [：，j]的+ I \\倍特征向量[：，J + 1] 真实特征矢量 [ [HTG176：J = E i的 克 E n的 [HTG200】v E C T O R S [ ： ， [HTG226：J + i的 × E i的 克 E n的 [HTG262】v E C T ​​ O R S [ ： ， [HTG288：J + 1 ， 真实特征矢量 [ [HTG318：J + 1 = E i的 克 E n的 [HTG338】V E C T O R S [ ： ， [HTG358：J - i的 × E i的 G E n的 [HTG378】v E C T O R S [ ： ， [HTG398：J + 1 \\ {文本特征向量真} [J + 1] =特征向量[:, j]的 - I \\倍特征向量[:, J + 1] [HTG4 16] 真实特征矢量 [ [HTG422：J + 1 = E i的 克 E n的 [HTG458】v E C T O R S [ ： ， [HTG484：J - i的 × E i的 克 E n的 [HTG520】V E C T O R S [ ： ， [HTG546：J + 1 。 > > Return type （张量，张量） torch.``gels( input , A , out=None )[source] 计算的解最小二乘和最小范数问题为满秩矩阵 A A A 大小的 （ M × n的 ） （M \\ n次） （ M × n的 ） 和一个矩阵 B B B 大小的 （ M × K ） （M \\倍K） （ M × K ） 。 有关 torch.gels（）更多信息，请检查 torch.lstsq（）。 Warning torch.gels（）以有利于 torch.lstsq的（废弃），将在未来的版本中删除。请使用 torch.lstsq（） 代替。 torch.``geqrf( input , out=None) - > (Tensor, Tensor ) 这是直接调用LAPACK一个低级别的功能。此函数返回如 LAPACK文档定义geqrf 一个namedtuple（一，tau蛋白）。 您通常需要使用 torch.qr（）代替。 计算输入的QR分解，但没有构建 Q Q Q 和 R R R 作为明确的分离矩阵。 相反，该直接调用底层LAPACK函数 geqrf产生“基本反射”的序列。 参见[HTG0对于geqrf 为进一步的细节LAPACK文档。 Parameters 输入 （ 张量 ） - 输入矩阵 OUT （ 元组 ， 可选 ） - 的输出元组（张量，张量） torch.``ger( input , vec2 , out=None ) → Tensor 的输入和VEC2外积。如果输入是大小为向量 n的 N n的 和VEC2是大小为向量 M M M ，然后OUT必须的大小 （ n的 × [HTG80一个矩阵] M ） （N \\乘以m） （ n的 × M ） 。 Note This function does not broadcast. Parameters 输入 （ 张量 ） - 1-d输入矢量 VEC2 （ 张量 ） - 1-d输入矢量 OUT （ 张量 ， 可选 ） - 可选的输出矩阵 Example: >>> v1 = torch.arange(1., 5.) >>> v2 = torch.arange(1., 4.) >>> torch.ger(v1, v2) tensor([[ 1., 2., 3.], [ 2., 4., 6.], [ 3., 6., 9.], [ 4., 8., 12.]]) torch.``inverse( input , out=None ) → Tensor 取正方形矩阵输入的倒数。 输入可以是2D方形张量，在这种情况下，这函数将返回一个个体逆组成张量的批次。 Note 不管原始进展的，返回的张量将被转置，即具有如步幅input.contiguous（）。转置（-2，-1）.stride（） Parameters 输入 （ 张量 ） - 大小 的输入张量（ ， n的 ， n的 ） （，N，N） （ n的 ， n的 ） 其中 是零点或多个批次的尺寸 OUT （ 张量 ， 可选 ） - 可选输出张量 Example: >>> x = torch.rand(4, 4) >>> y = torch.inverse(x) >>> z = torch.mm(x, y) >>> z tensor([[ 1.0000, -0.0000, -0.0000, 0.0000], [ 0.0000, 1.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, 1.0000, 0.0000], [ 0.0000, -0.0000, -0.0000, 1.0000]]) >>> torch.max(torch.abs(z - torch.eye(4))) # Max non-zero tensor(1.1921e-07) >>> # Batched inverse example >>> x = torch.randn(2, 3, 4, 4) >>> y = torch.inverse(x) >>> z = torch.matmul(x, y) >>> torch.max(torch.abs(z - torch.eye(4).expand_as(x))) # Max non-zero tensor(1.9073e-06) torch.``det( input ) → Tensor 计算方阵或方阵的批次的决定因素。 Note 向后通过 DET（）在内部使用时输入不可逆SVD的结果。在这种情况下，双向后通过 DET（）将在当输入没有不稳定不同奇异值。参见 对于细节SVD（）。 Parameters 输入 （ 张量 ） - 大小的输入张量（ 中，n，n）其中 是零米或多个批次的尺寸。 Example: >>> A = torch.randn(3, 3) >>> torch.det(A) tensor(3.7641) >>> A = torch.randn(3, 2, 2) >>> A tensor([[[ 0.9254, -0.6213], [-0.5787, 1.6843]], [[ 0.3242, -0.9665], [ 0.4539, -0.0887]], [[ 1.1336, -0.4025], [-0.7089, 0.9032]]]) >>> A.det() tensor([1.1990, 0.4099, 0.7386]) torch.``logdet( input ) → Tensor 计算方阵或方阵的批次的日志决定因素。 Note 结果是-INF如果输入具有零日志行列式，并且是楠如果输入具有负的决定因素。 Note 向后通过 logdet（）在内部使用时输入不可逆SVD的结果。在这种情况下，双向后通过 logdet（）将在当输入没有不稳定不同奇异值。参见 对于细节SVD（）。 Parameters 输入 （ 张量 ） - 大小的输入张量（ 中，n，n）其中 是零米或多个批次的尺寸。 Example: >>> A = torch.randn(3, 3) >>> torch.det(A) tensor(0.2611) >>> torch.logdet(A) tensor(-1.3430) >>> A tensor([[[ 0.9254, -0.6213], [-0.5787, 1.6843]], [[ 0.3242, -0.9665], [ 0.4539, -0.0887]], [[ 1.1336, -0.4025], [-0.7089, 0.9032]]]) >>> A.det() tensor([1.1990, 0.4099, 0.7386]) >>> A.det().log() tensor([ 0.1815, -0.8917, -0.3031]) torch.``slogdet( input) - > (Tensor, Tensor ) 计算的符号和记录一个方阵或方阵的批次的行列式（S）的绝对值。 Note 如果输入具有零行列式，这将返回（0， -INF）。 Note 向后通过 slogdet（）在内部使用时输入不可逆SVD的结果。在这种情况下，双向后通过 slogdet（）将在当输入没有不稳定不同奇异值。参见 对于细节SVD（）。 Parameters 输入 （ 张量 ） - 大小的输入张量（ 中，n，n）其中 是零米或多个批次的尺寸。 Returns 将含有行列式的符号namedtuple（标志，logabsdet），并且绝对行列式的log值。 Example: >>> A = torch.randn(3, 3) >>> A tensor([[ 0.0032, -0.2239, -1.1219], [-0.6690, 0.1161, 0.4053], [-1.6218, -0.9273, -0.0082]]) >>> torch.det(A) tensor(-0.7576) >>> torch.logdet(A) tensor(nan) >>> torch.slogdet(A) torch.return_types.slogdet(sign=tensor(-1.), logabsdet=tensor(-0.2776)) torch.``lstsq( input , A , out=None ) → Tensor Computes the solution to the least squares and least norm problems for a full rank matrix AAA of size (m×n)(m \\times n)(m×n) and a matrix BBB of size (m×k)(m \\times k)(m×k) . 如果 M ≥ n的 米\\ GEQÑ M ≥ n的 ， lstsq（）解决了最小平方问题： min⁡X∥AX−B∥2.\\begin{array}{ll} \\min_X & |AX-B|_2. \\end{array}minX​​∥AX−B∥2​.​ 如果 M & LT ; n的 M & LT ; N M & LT ; n的 ， lstsq（）解决了至少范数问题： min⁡X∥X∥2subject toAX=B.\\begin{array}{ll} \\min_X & |X|_2 & \\text{subject to} & AX = B. \\end{array}minX​​∥X∥2​​subject to​AX=B.​ 返回张量 X X X 具有形状 （ MAX ⁡ （ M ， n的 ） × K ） （\\ MAX（M，N）\\倍K） （ MAX （ M ， n的 ） × K ） 。第一 n的 n的 n的 的行 X X X 包含溶液。如果 M ≥ n的 米\\ GEQÑ M ≥ n的 ，正方形的用于每一列中的溶液中的剩余之和由平方和给定在剩余的 M 元素 - n的 米 - N M - n的 该列的行。 Note 的情况下，当 M & LT ; n的 M & LT ; N M & LT ; n的 不支持在GPU上。 Parameters 输入 （ 张量 ） - 矩阵 B B B A （ 张量 ） - 的 M M M 通过 n的 n的 n的 矩阵 A A A OUT （ 元组 ， 可选 ） - 可选的目的地张量 Returns 将含有namedtuple（溶液，QR）： 溶液 （ 张量 ）：最小二乘解 > QR （ 张量 ）：将QR分解的细节 > > Return type (Tensor, Tensor) Note 返回的矩阵总是会换位不论输入矩阵的进步。也就是说，他们将有步幅（1，M）而非（M，1）。 Example: >>> A = torch.tensor([[1., 1, 1], [2, 3, 4], [3, 5, 2], [4, 2, 5], [5, 4, 3]]) >>> B = torch.tensor([[-10., -3], [ 12, 14], [ 14, 12], [ 16, 16], [ 18, 16]]) >>> X, _ = torch.lstsq(B, A) >>> X tensor([[ 2.0000, 1.0000], [ 1.0000, 1.0000], [ 1.0000, 2.0000], [ 10.9635, 4.8501], [ 8.9332, 5.2418]]) torch.``lu( A , pivot=True , get_infos=False , out=None )[source] 计算方阵或方阵A的批次的LU分解。返回包含LU分解和A枢转的元组。如果枢设置为真旋转完成。 Note 由该函数返回的枢轴是1-索引。如果枢轴是假，则返回的枢转是填充有适当大小的零的张量。 Note LU分解与枢= 假不适用于CPU，并试图这样做会引发错误。然而，LU分解与枢轴= 假可用于CUDA。 Note 此功能不检查分解是否成功，如果get_infos是真由于分解的状态出现在返回的元组的第三个元素。 Parameters A （ 张量 ） - 张量对因子大小的 （ ， M ， M ） （，M，M） （ * M ， M ） 枢轴 （ 布尔 ， 可选 ） - 枢转控制是否已完成。默认值：真 get_infos （ 布尔 ， 可选 ） - 如果设定为真，返回一个信息IntTensor。默认值：假 OUT （ 元组 ， 可选 ） - 可选的输出元组。如果get_infos是真，然后在所述元组的元素是张量，IntTensor，和IntTensor。如果get_infos是假，然后在所述元组的元素是张量，IntTensor。默认值：无 Returns 张量的含有A元组 因式分解 （ 张量 ）：的大小 因式分解（ ， M ， M ） （，M，M ） （ * ， M ， M ） > 枢轴 （ IntTensor ）：大小 的枢轴（ ， M ） （，M） （ * ， M ） > 的相关信息 （ IntTensor ， 可选 ）：如果get_infos是真，这是大小 （ ）的张量 （） （ * ） 其中非零值指示因式分解对矩阵或每个minibatch是否成功或失败 > > Return type （张量，IntTensor，IntTensor（可选）） Example: >>> A = torch.randn(2, 3, 3) >>> A_LU, pivots = torch.lu(A) >>> A_LU tensor([[[ 1.3506, 2.5558, -0.0816], [ 0.1684, 1.1551, 0.1940], [ 0.1193, 0.6189, -0.5497]], [[ 0.4526, 1.2526, -0.3285], [-0.7988, 0.7175, -0.9701], [ 0.2634, -0.9255, -0.3459]]]) >>> pivots tensor([[ 3, 3, 3], [ 3, 3, 3]], dtype=torch.int32) >>> A_LU, pivots, info = torch.lu(A, get_infos=True) >>> if info.nonzero().size(0) == 0: ... print('LU factorization succeeded for all samples!') LU factorization succeeded for all samples! torch.``lu_solve( input , LU_data , LU_pivots , out=None ) → Tensor 返回LU求解线性系统 的A × = b Ax = b的 A × = b [HTG43使用来自 torch.lu（） A的部分枢转LU分解。 Parameters 输入 （ 张量 ） - 的大小 的RHS张量（ b ， M ， K ） （b，M，K） （ b M ， K ） LU_data （ 张量 ） - 从 A的枢转LU分解torch.lu（）大小的 （ b ， M ， M ） （b，M，M） （ b ， M ， M ） LU_pivots （ IntTensor ） - 的LU分解的从 枢轴torch.lu（）的大小 （ b ， M ） （b，M） （ b ， M ） out ( Tensor , optional ) – the optional output tensor Example: >>> A = torch.randn(2, 3, 3) >>> b = torch.randn(2, 3, 1) >>> A_LU = torch.lu(A) >>> x = torch.lu_solve(b, *A_LU) >>> torch.norm(torch.bmm(A, x) - b) tensor(1.00000e-07 * 2.8312) torch.``lu_unpack( LU_data , LU_pivots , unpack_data=True , unpack_pivots=True )[source] 从张量的LU分解解包的数据，并枢转。 返回张量的元组为（在 枢转时， 中的 L 张量， 的 U 张量）。 Parameters LU_data （ 张量 ） - 打包LU分解数据 LU_pivots （ 张量 ） - 填充LU分解枢转 unpack_data （ 布尔 ） - 标志，指示如果数据应被解压缩 unpack_pivots （ 布尔 ） - 标志，指示如果枢轴应解压 Example: >>> A = torch.randn(2, 3, 3) >>> A_LU, pivots = A.lu() >>> P, A_L, A_U = torch.lu_unpack(A_LU, pivots) >>> >>> # can recover A from factorization >>> A_ = torch.bmm(P, torch.bmm(A_L, A_U)) torch.``matmul( input , other , out=None ) → Tensor 2张量的矩阵产品。 该行为取决于张量的维数如下： 如果两个张量是1维的，点积（标量）被返回。 如果两个参数是2维的，则返回矩阵，矩阵产品。 如果第一个参数是1维的，并且第二个参数是2维的，一个1被预置到其尺寸为矩阵乘法的目的。的矩阵乘法后，将预谋尺寸被去除。 如果第一个参数是2维的，并且第二个参数是1维的，则返回矩阵矢量乘积。 如果两个参数是至少一维和至少一个参数是N维（N & GT其中; 2），则返回一个批处理矩阵乘法。如果第一个参数是1维的，一个1被预置到其尺寸为成批矩阵乘法的目的，并且之后被去除。如果第二个参数是1维的，1被附加到其尺寸为成批矩阵的多个目的和之后被去除。非矩阵（即批）尺寸 广播 （并因此必须是broadcastable）。例如，如果输入是 （ [HTG16：J × 1 × n的 × M ） （j \\倍1 \\ n次\\乘以m） （ [ HTG44：J × 1 × n的 × M ） 张量和其他是 （ K ×[H TG103] M × P ） （K \\倍米\\倍P） （ K × M × p ） 张量，OUT将是 （ [HTG168：J × K × n的 × p ） （j \\乘K \\ n次\\倍p） （ [HTG196：J × K × n的 × p ） 张量。 Note 该函数的1维的点积版本不支持OUT参数。 Parameters 输入 （ 张量 ） - 要被相乘的第一张量 其他 （ 张量 ） - 要被相乘的第二张量 out ( Tensor , optional ) – the output tensor Example: >>> # vector x vector >>> tensor1 = torch.randn(3) >>> tensor2 = torch.randn(3) >>> torch.matmul(tensor1, tensor2).size() torch.Size([]) >>> # matrix x vector >>> tensor1 = torch.randn(3, 4) >>> tensor2 = torch.randn(4) >>> torch.matmul(tensor1, tensor2).size() torch.Size([3]) >>> # batched matrix x broadcasted vector >>> tensor1 = torch.randn(10, 3, 4) >>> tensor2 = torch.randn(4) >>> torch.matmul(tensor1, tensor2).size() torch.Size([10, 3]) >>> # batched matrix x batched matrix >>> tensor1 = torch.randn(10, 3, 4) >>> tensor2 = torch.randn(10, 4, 5) >>> torch.matmul(tensor1, tensor2).size() torch.Size([10, 3, 5]) >>> # batched matrix x broadcasted matrix >>> tensor1 = torch.randn(10, 3, 4) >>> tensor2 = torch.randn(4, 5) >>> torch.matmul(tensor1, tensor2).size() torch.Size([10, 3, 5]) torch.``matrix_power( input , n ) → Tensor 返回幂n的为方阵矩阵。对于批量矩阵，每个单独的矩阵被升高到功率n的。 如果n的是否定的，则矩阵（如果可逆）的逆被升高到功率n的。对于间歇矩阵，成批的逆（如果可逆）提高到电源n的。如果n的为0，则单位矩阵被返回。 Parameters input ( Tensor) – the input tensor n的 （ INT ） - 功率，以提高基质中以 Example: >>> a = torch.randn(2, 2, 2) >>> a tensor([[[-1.9975, -1.9610], [ 0.9592, -2.3364]], [[-1.2534, -1.3429], [ 0.4153, -1.4664]]]) >>> torch.matrix_power(a, 3) tensor([[[ 3.9392, -23.9916], [ 11.7357, -0.2070]], [[ 0.2468, -6.7168], [ 2.0774, -0.8187]]]) torch.``matrix_rank( input , tol=None , bool symmetric=False ) → Tensor 返回一个2-d张量的数值等级。计算矩阵的秩的方法是使用SVD默认情况下完成的。如果对称是真，然后输入被假设为是对称的，并且排名的计算是通过获取特征值来完成。 TOL是低于该奇异值（或本征值时对称是真阈值）都被认为是0。如果TOL没有指定，TOL被设定为`S.max（） 最大值（S.size（）） * EPS其中 S 为奇异值（或本征值时对称 是真 ）和EPS是用于输入 `的数据类型的ε值。 Parameters 输入 （ 张量 ） - 输入2-d张量 TOL （ 浮动 ， 可选 ） - 公差值。默认值：无 对称 （ 布尔 ， 可选 ） - 指示是否输入是对称的。默认值：假 Example: >>> a = torch.eye(10) >>> torch.matrix_rank(a) tensor(10) >>> b = torch.eye(10) >>> b[0, 0] = 0 >>> torch.matrix_rank(b) tensor(9) torch.``mm( input , mat2 , out=None ) → Tensor 执行矩阵输入和MAT2的矩阵乘法。 如果输入是 （ n的 × M ） （N \\乘以m） （ n的 × M ） 张量，MAT2是 （ M × p ） （M \\倍p） （ M × p ） 张量，OUT将是 （ N × p ） （N \\倍p） （ n的 × p ） 张量。 Note This function does not broadcast. For broadcasting matrix products, see torch.matmul(). Parameters 输入 （ 张量 ） - 要被相乘的第一矩阵 mat2 ( Tensor) – the second matrix to be multiplied out ( Tensor , optional ) – the output tensor Example: >>> mat1 = torch.randn(2, 3) >>> mat2 = torch.randn(3, 3) >>> torch.mm(mat1, mat2) tensor([[ 0.4851, 0.5037, -0.3633], [-0.0760, -3.6705, 2.4784]]) torch.``mv( input , vec , out=None ) → Tensor 执行矩阵输入和的矩阵矢量乘积矢量VEC。 如果输入是 （ n的 × M ） （N \\乘以m） （ n的 × M ） 张量，VEC是大小[1-d张量HTG56] M M [大小的HTG72] M ，OUT将1-d n的 n的 n的 。 Note This function does not broadcast. Parameters 输入 （ 张量 ） - 要被相乘的矩阵 vec ( Tensor) – vector to be multiplied out ( Tensor , optional ) – the output tensor Example: >>> mat = torch.randn(2, 3) >>> vec = torch.randn(3) >>> torch.mv(mat, vec) tensor([ 1.0404, -0.6361]) torch.``orgqr( input , input2 ) → Tensor 计算正交矩阵 Q 一个QR分解的，从（输入，输入2）元组通过返回 torch.geqrf（）。 这直接调用底层的LAPACK函数 orgqr [HTG1。参见[HTG2对于orgqr 为进一步的细节LAPACK文档。 Parameters 输入 （ 张量 ） - 的一从 torch.geqrf（）。 输入2 （ 张量 ） - 的 tau蛋白从 torch.geqrf（）。 torch.``ormqr( input , input2 , input3 , left=True , transpose=False ) → Tensor 乘法垫通过 [形成的QR分解的正交 Q 矩阵HTG10（由输入3给出） ] torch.geqrf（）由（A，tau蛋白）表示（由（输入，[HTG20给出] 输入2 ））。 这直接调用底层的LAPACK函数 ormqr [HTG1。参见 LAPACK文档ormqr 为进一步的细节。 Parameters input ( Tensor) – the a from torch.geqrf(). input2 ( Tensor) – the tau from torch.geqrf(). 输入3 （ 张量 ） - 要相乘的矩阵。 torch.``pinverse( input , rcond=1e-15 ) → Tensor 计算2D张量的伪逆（也被称为Moore-Penrose逆）。请看 Moore- Penrose逆更多细节 Note 该方法是使用奇异值分解来实现。 Note 伪逆不一定是矩阵 [1] 的元素的连续函数。因此，衍生物并不总是存在的，并且存在对于恒定秩只 [2] 。但是，这种方法是backprop，由于能够通过使用SVD结果的执行，可能是不稳定的。双落后也将是不稳定的，由于SVD的使用内部。参见 SVD（）的更多细节。 Parameters 输入 （ 张量 ） - 的输入的2D张量尺寸 M × n的 米\\ n次 M × n的 rcond （ 浮动 ） - 甲浮点值来确定用于小奇异值截止。默认值：1E-15 Returns 的输入尺寸的n的 ×伪逆 M n的\\乘以m n的 × M Example: >>> input = torch.randn(3, 5) >>> input tensor([[ 0.5495, 0.0979, -1.4092, -0.1128, 0.4132], [-1.1143, -0.3662, 0.3042, 1.6374, -0.9294], [-0.3269, -0.5745, -0.0382, -0.5922, -0.6759]]) >>> torch.pinverse(input) tensor([[ 0.0600, -0.1933, -0.2090], [-0.0903, -0.0817, -0.4752], [-0.7124, -0.1631, -0.2272], [ 0.1356, 0.3933, -0.5023], [-0.0308, -0.1725, -0.5216]]) torch.``qr( input , some=True , out=None) - > (Tensor, Tensor ) 计算一个矩阵的QR分解或分批矩阵输入的，并返回张量的namedtuple（Q，R），使得 输入 = Q R \\文本{输入} = QR 输入 = Q R 与 Q Q Q 为正交矩阵的正交矩阵或分批和 R R R 为上三角矩阵或批量上三角矩阵。 如果一些是真，则该函数将返回薄（减小）QR分解。否则，如果一些是假，该函数返回完整的QR分解。 Note 如果输入的元素的量值是大精度可能会丢失 Note 虽然它应该总是给你一个有效的分解，它可能不会给你跨平台的同一个 - 这将取决于你的LAPACK实现。 Parameters 输入 （ 张量 ） - 大小 的输入张量（ ， M ， n的 ） （，M，N） （ M ， n的 ） 其中 是零个或多个由尺寸 M 矩阵[批量尺寸HTG68]× n的 米\\ n次 M × n的 。 一些 （ 布尔 ， 可选 ） - 设置为真 [ HTG13用于减少QR分解和[HTG15用于完整QR分解假 。 OUT （ 元组 ， 可选 ） - 的 Q 和元组 [R 张量满足输入 = torch.matmul（Q， R）。 Q 和的尺寸 R 是 （ ， M ， K ） （，M，K） （ ， M ， K ） 和 （ ， K ， n的 ） （，K，N） （ ， K ， n的 ） 分别，其中 K = 分钟HTG143] ⁡ （ M ， n的 ） K = \\分钟（M，N） K = 分钟HTG179] （ M ， n的 ） 如果一些：是真和 K = M K = M K = M 否则。 Example: >>> a = torch.tensor([[12., -51, 4], [6, 167, -68], [-4, 24, -41]]) >>> q, r = torch.qr(a) >>> q tensor([[-0.8571, 0.3943, 0.3314], [-0.4286, -0.9029, -0.0343], [ 0.2857, -0.1714, 0.9429]]) >>> r tensor([[ -14.0000, -21.0000, 14.0000], [ 0.0000, -175.0000, 70.0000], [ 0.0000, 0.0000, -35.0000]]) >>> torch.mm(q, r).round() tensor([[ 12., -51., 4.], [ 6., 167., -68.], [ -4., 24., -41.]]) >>> torch.mm(q.t(), q).round() tensor([[ 1., 0., 0.], [ 0., 1., -0.], [ 0., -0., 1.]]) >>> a = torch.randn(3, 4, 5) >>> q, r = torch.qr(a, some=False) >>> torch.allclose(torch.matmul(q, r), a) True >>> torch.allclose(torch.matmul(q.transpose(-2, -1), q), torch.eye(5)) True torch.``solve( input , A , out=None) - > (Tensor, Tensor ) 该函数返回溶液到线性方程组由 A X = [所表示的系统HTG11] B AX = B A X = B 和A的LU分解，为了作为namedtuple 溶液，LU 。 LU 包含 L 和 U 因素的 A LU分解。 torch.solve（B，A）可以在那些2D矩阵的批次的2D输入端 B，A 或输入。如果输入是批次，然后返回成批输出溶液，LU 。 Note 不管原始进展的，则返回的矩阵溶液和 LU 将被转置，即具有如步幅B.contiguous（）。转置（-1，-2）。步幅（）和 A.contiguous（）。转置（-1，-2）.stride（）分别。 Parameters 输入 （ 张量 ） - 输入矩阵 B B B 大小的 （ ， M ， K ） （，M，K） （ ， M ， K ） ，其中 是零米或多个批次的尺寸。 A （ 张量 ） - 输入尺寸 的方矩阵（ ， M ， M ） （，M，M） （ M ， M ） ，其中 是零米或多个批次的尺寸。 OUT （ （ 张量 ， 张量 ） ， 可选 ） - 可选的输出元组。 Example: >>> A = torch.tensor([[6.80, -2.11, 5.66, 5.97, 8.23], [-6.05, -3.30, 5.36, -4.44, 1.08], [-0.45, 2.58, -2.70, 0.27, 9.04], [8.32, 2.71, 4.35, -7.17, 2.14], [-9.67, -5.14, -7.26, 6.08, -6.87]]).t() >>> B = torch.tensor([[4.02, 6.19, -8.22, -7.57, -3.03], [-1.56, 4.00, -8.67, 1.75, 2.86], [9.81, -4.09, -4.57, -8.61, 8.99]]).t() >>> X, LU = torch.solve(B, A) >>> torch.dist(B, torch.mm(A, X)) tensor(1.00000e-06 * 7.0977) >>> # Batched solver example >>> A = torch.randn(2, 3, 1, 4, 4) >>> B = torch.randn(2, 3, 1, 4, 6) >>> X, LU = torch.solve(B, A) >>> torch.dist(B, A.matmul(X)) tensor(1.00000e-06 * 3.6386) torch.``svd( input , some=True , compute_uv=True , out=None) - > (Tensor, Tensor , Tensor ) 该函数返回一个namedtuple （U， S， V）这是一个输入实矩阵或批次的奇异值分解实数矩阵输入，使得 i的 n的 p U T = U × d i的 一 克 （ S ） × [HTG51】V T 输入= U \\倍DIAG（S）\\倍于V ^ T i的 n的 p U T = U × d i的 一 克 （ S ） × [HTG123】V T 。 如果一些是真（默认），则该方法返回降低奇异值分解，即，如果[HTG8最后两个维度] 输入 是M和n的，则返回的 U 和[HTG22】V 矩阵将仅包含 M i的 n的 （ n的 ， M ） 分钟（N，M） M i的 n的 （ n的 ， M ） 正交列。 如果compute_uv是假，返回 U 和[HTG10】V 矩阵将是零的形状 （ 米矩阵 × M ） （M \\乘以m） （ M × M ） 和 （ n的 × n的 ） （N \\ n次） （ n的 × n的 ） 分别。 一些将在这里被忽略了。 Note SVD的CPU上的实现使用LAPACK例程 gesdd （分而治之算法）代替 gesvd [HTG3用于速度。类似地，在GPU上的SVD使用MAGMA例程 gesdd 为好。 Note 不管原始进展的，则返回的矩阵 U 将被转置，即具有步幅U.contiguous（）。转置（-2， -1）。步幅（） Note 格外小心需要通过 U 和[HTG2】V 输出时向后服用。这样的操作真的只有稳定时输入与所有不同的奇异值满秩。否则，的NaN可以作为梯度未正确定义出现。此外，请注意双向后通常将通过 U 和做附加的倒V型即使原始向后只在 S 。 Note 当一些= 假，在梯度U [...， ： 分钟（米， N）：]和[HTG19】V [...， ： 分钟（米， N）：]将在向后忽略那些载体可以是子空间的任意碱。 Note 当compute_uv= 假，向后不能因为 U 进行并[HTG10】V 从直传是所必需的向后操作。 Parameters 输入 （ 张量 ） - 大小 的输入张量（ ， M ， n的 ） （，M，N） （ M ， n的 ） 其中 是零个或多个选自由M ×的 批次尺寸 n的 米\\ n次 M × n的 矩阵。 一些 （ 布尔 ， 可选 ） - 控制的返回形状U 和[HTG12】V compute_uv （ 布尔 ， 可选 ） - 选项是否计算 U 和[ HTG12】V 或不 OUT （ 元组 ， 可选 ） - 张量的输出元组 Example: >>> a = torch.randn(5, 3) >>> a tensor([[ 0.2364, -0.7752, 0.6372], [ 1.7201, 0.7394, -0.0504], [-0.3371, -1.0584, 0.5296], [ 0.3550, -0.4022, 1.5569], [ 0.2445, -0.0158, 1.1414]]) >>> u, s, v = torch.svd(a) >>> u tensor([[ 0.4027, 0.0287, 0.5434], [-0.1946, 0.8833, 0.3679], [ 0.4296, -0.2890, 0.5261], [ 0.6604, 0.2717, -0.2618], [ 0.4234, 0.2481, -0.4733]]) >>> s tensor([2.3289, 2.0315, 0.7806]) >>> v tensor([[-0.0199, 0.8766, 0.4809], [-0.5080, 0.4054, -0.7600], [ 0.8611, 0.2594, -0.4373]]) >>> torch.dist(a, torch.mm(torch.mm(u, torch.diag(s)), v.t())) tensor(8.6531e-07) >>> a_big = torch.randn(7, 5, 3) >>> u, s, v = torch.svd(a_big) >>> torch.dist(a_big, torch.matmul(torch.matmul(u, torch.diag_embed(s)), v.transpose(-2, -1))) tensor(2.6503e-06) torch.``symeig( input , eigenvectors=False , upper=True , _out=None) - (Tensor, _Tensor ) 该函数返回一个实对称矩阵输入或间歇实对称矩阵，由namedtuple（本征值，本征矢量）表示的特征向量。 此函数计算所有特征值（和载体）的输入，使得 输入 = [HTG14】V DIAG （ E ） [HTG25】V T \\文本{输入} = V \\文本{DIAG}（E）V ^ T 输入 = [HTG54】V DIAG （ E ） [HTG67 】V T 。 布尔参数本征向量定义了本征向量和本征值仅或特征值的计算。 如果是假，只有特征值计算。如果是真，二者特征向量被计算。 由于输入矩阵输入应该是对称的，仅上三角形部分默认使用。 如果上是假，则使用下三角部分。 Note 不管原始进展的，则返回的矩阵[HTG0】V 将被转置，即，步幅 V.contiguous（）。转置（-1，-2）.stride（）。 Note 格外小心，需要通过输出落后时采取。这样的操作实在是唯一的稳定，当所有特征值是不同的。否则，的NaN可以作为梯度未正确定义出现。 Parameters 输入 （ 张量 ） - 大小 的输入张量（ ， n的 ， n的 ） （，N，N） （ n的 ， n的 ） 其中 是零米或多个由对称矩阵的批次的尺寸。 本征向量 （ 布尔 ， 可选 ） - 控制特征向量是否必须计算 上 （ 布尔 ， 可选 ） - 控制是否考虑上三角或下三角区 out ( tuple , optional ) – the output tuple of (Tensor, Tensor) Returns A namedtuple (eigenvalues, eigenvectors) containing 本征值 （ 张量 ）：形状 （ ， M ） （，M） （ * ， M ） 。按升序排列的特征值。 > 本征向量 （ 张量 ）：形状 （ ， M ， M ） （，M，M） （ * ， M ， M ） 。如果的特征向量=假，它是用零填充的张量。否则，该张量包含输入的正交的特征向量。 > > Return type (Tensor, Tensor) Examples: >>> a = torch.randn(5, 5) >>> a = a + a.t() # To make a symmetric >>> a tensor([[-5.7827, 4.4559, -0.2344, -1.7123, -1.8330], [ 4.4559, 1.4250, -2.8636, -3.2100, -0.1798], [-0.2344, -2.8636, 1.7112, -5.5785, 7.1988], [-1.7123, -3.2100, -5.5785, -2.6227, 3.1036], [-1.8330, -0.1798, 7.1988, 3.1036, -5.1453]]) >>> e, v = torch.symeig(a, eigenvectors=True) >>> e tensor([-13.7012, -7.7497, -2.3163, 5.2477, 8.1050]) >>> v tensor([[ 0.1643, 0.9034, -0.0291, 0.3508, 0.1817], [-0.2417, -0.3071, -0.5081, 0.6534, 0.4026], [-0.5176, 0.1223, -0.0220, 0.3295, -0.7798], [-0.4850, 0.2695, -0.5773, -0.5840, 0.1337], [ 0.6415, -0.0447, -0.6381, -0.0193, -0.4230]]) >>> a_big = torch.randn(5, 2, 2) >>> a_big = a_big + a_big.transpose(-2, -1) # To make a_big symmetric >>> e, v = a_big.symeig(eigenvectors=True) >>> torch.allclose(torch.matmul(v, torch.matmul(e.diag_embed(), v.transpose(-2, -1))), a_big) True torch.``trapz() torch.``trapz( y , x , * , dim=-1 ) → Tensor 估计 ∫ Y d × \\ INT Y \\，DX ∫ Y d × 沿暗淡使用梯形规则。 Parameters Y （ 张量 ） - 该函数的值，以整合 × （ 张量 ） - 在该函数 Y 被采样的点。如果×不是升序排列，间隔在其上降低到估计的积分（即，公约 [负贡献HTG16] ∫ 一 b F = - ∫ b 一 F \\ int_a ^ BF = - \\ int_b ^ AF ∫ 一 b F = [HT G98] - ∫ b 一 F 之后）。 暗淡 （ INT ） - 沿其尺寸集成。默认情况下，使用最后一个维度。 Returns 具有相同形状的输入，除了与一种张量暗淡除去。返回的张量的每个元素代表所估计的积分 ∫ Y d × \\ INT Y \\，DX ∫ Y d × 沿着暗淡。 Example: >>> y = torch.randn((2, 3)) >>> y tensor([[-2.1156, 0.6857, -0.2700], [-1.2145, 0.5540, 2.0431]]) >>> x = torch.tensor([[1, 3, 4], [1, 2, 3]]) >>> torch.trapz(y, x) tensor([-1.2220, 0.9683]) torch.``trapz( y , * , dx=1 , dim=-1 ) → Tensor 如上述，但采样点被均匀地以 DX 的距离间隔开。 Parameters y ( Tensor) – The values of the function to integrate DX （ 浮 ） - 的距离，其中 Y 被采样点之间。 dim ( int) – The dimension along which to integrate. By default, use the last dimension. Returns A Tensor with the same shape as the input, except with dim removed. Each element of the returned tensor represents the estimated integral ∫y dx\\int y\\,dx∫ydx along dim. torch.``triangular_solve( input , A , upper=True , transpose=False , unitriangular=False) - > (Tensor, Tensor ) 解决了方程系统具有三角形系数矩阵 A A A 和多个右手侧 b b b 。 特别是，解决了 A X = B AX = b A X = b 并假定 A A A 是上三角与缺省关键字参数。 torch.triangular_solve（B，A）可以在2D输入 B，A 或是2D矩阵的批输入。如果输入是批次，然后返回成批输出 X Note 的OUT关键字仅支持2D矩阵输入，即， B，A 必须2D矩阵。 Parameters 输入 （ 张量 ） - 大小 [HTG12的多个右手侧]（ ， M ， K ） （，M，K） （ ， M ， K ） 其中 是更批量尺寸的零（ b b B ） A （ 张量 ） - 大小 [的输入三角形系数矩阵HTG12 ]（ ， M ， M ） （，M，M） （ ， M ， M ） 其中 是零点或多个批次的尺寸 上 （ 布尔 ， 可选 ） - 是否求解方程的上三角系统（默认）或方程的下三角系统。默认值：真 [HTG13。 转置 （ 布尔 ， 可选 ） - 是否 A A A 应当被发送到求解器之前被调换。默认值：假 [HTG37。 unitriangular （ 布尔 ， 可选 ） - 是否 A A A 是单位三角形。如果为True，的 A 的对角元素A A 被假设为1，而不是从引用 A A A 。默认值：假 [HTG85。 Returns 甲namedtuple （溶液，cloned_coefficient）其中 cloned_coefficient 是 克隆A A A 和溶液为溶液 X X X 至 A X = b AX = b A X = b （或任何方程系统，根据所述关键字参数的变体）。 Examples: >>> A = torch.randn(2, 2).triu() >>> A tensor([[ 1.1527, -1.0753], [ 0.0000, 0.7986]]) >>> b = torch.randn(2, 3) >>> b tensor([[-0.0210, 2.3513, -1.5492], [ 1.5429, 0.7403, -1.0243]]) >>> torch.triangular_solve(b, A) torch.return_types.triangular_solve( solution=tensor([[ 1.7841, 2.9046, -2.5405], [ 1.9320, 0.9270, -1.2826]]), cloned_coefficient=tensor([[ 1.1527, -1.0753], [ 0.0000, 0.7986]])) 公用事业 torch.``compiled_with_cxx11_abi()[source] 返回PyTorch是否与_GLIBCXX_USE_CXX11_ABI = 1建成 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:20 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"tensors.html":{"url":"tensors.html","title":"torch.Tensor","keywords":"","body":"torch.Tensor Atorch.Tensor是包含单一数据类型的元素的多维矩阵。 Torch 定义了9种CPU类型和九种GPU张量类型： 数据类型 | D型 | CPU张量 | GPU张量 ---|---|---|--- 32位浮点 | torch.float32或torch.float | torch.FloatTensor | torch.cuda.FloatTensor 64位浮点 | torch.float64或torch.double | torch.DoubleTensor | torch.cuda.DoubleTensor 16位浮点 | torch.float16或torch.half | torch.HalfTensor | torch.cuda.HalfTensor 8位整数（无符号） | torch.uint8 | torch.ByteTensor | torch.cuda.ByteTensor 8位整数（签名） | torch.int8 | torch.CharTensor | torch.cuda.CharTensor 16位整数（签名） | torch.int16或torch.short | torch.ShortTensor | torch.cuda.ShortTensor 32位整数（签名） | torch.int32或torch.int | torch.IntTensor | torch.cuda.IntTensor 64位整数（签名） | torch.int64或torch.long | torch.LongTensor | torch.cuda.LongTensor 布尔 | torch.bool | torch.BoolTensor | torch.cuda.BoolTensor torch.Tensor是默认张量类型的别名（torch.FloatTensor）。 张量可以从一个Python 列表或序列使用 torch.tensor（） [HTG10被构造]构造： >>> torch.tensor([[1., -1.], [1., -1.]]) tensor([[ 1.0000, -1.0000], [ 1.0000, -1.0000]]) >>> torch.tensor(np.array([[1, 2, 3], [4, 5, 6]])) tensor([[ 1, 2, 3], [ 4, 5, 6]]) 警告 torch.tensor（）总是副本数据。如果你有一个张量数据，只是想改变它的requires_grad标志，使用 requires_grad_ （）或 分离（），以避免副本。如果你有一个numpy的阵列，并希望避免拷贝，使用[ torch.as_tensor（） HTG35。 特定数据类型的张量可以通过使 torch.dtype和/或 torch.device构建 对构造或张量创建OP： >>> torch.zeros([2, 4], dtype=torch.int32) tensor([[ 0, 0, 0, 0], [ 0, 0, 0, 0]], dtype=torch.int32) >>> cuda0 = torch.device('cuda:0') >>> torch.ones([2, 4], dtype=torch.float64, device=cuda0) tensor([[ 1.0000, 1.0000, 1.0000, 1.0000], [ 1.0000, 1.0000, 1.0000, 1.0000]], dtype=torch.float64, device='cuda:0') 张量的内容可以使用Python的索引和切片符号来访问和修改： >>> x = torch.tensor([[1, 2, 3], [4, 5, 6]]) >>> print(x[1][2]) tensor(6) >>> x[0][1] = 8 >>> print(x) tensor([[ 1, 8, 3], [ 4, 5, 6]]) 使用 torch.Tensor.item（）以获得从含有单个值的张量一个Python数： >>> x = torch.tensor([[1]]) >>> x tensor([[ 1]]) >>> x.item() 1 >>> x = torch.tensor(2.5) >>> x tensor(2.5000) >>> x.item() 2.5 甲张量可以用requires_grad =真，使得 torch.autograd对它们的记录操作的自动创建分化。 >>> x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True) >>> out = x.pow(2).sum() >>> out.backward() >>> x.grad tensor([[ 2.0000, -2.0000], [ 2.0000, 2.0000]]) 各张量具有相关联的torch.Storage，其保持它的数据。张量类提供多维的，存储的跨距视图并在其上限定的数值的操作。 注意 有关 的更多信息torch.dtype， torch.device ，和 torch.layout的属性的 torch.Tensor参见 张量属性 。 Note 其中一个突变的方法张标有下划线的后缀。例如，torch.FloatTensor.abs_（）计算就地绝对值，并返回改性张量，而torch.FloatTensor.abs（）计算结果在一个新的张量。 Note 要更改现有的张量的 torch.device和/或 torch.dtype ，可以考虑使用 至（）关于张量的方法。 Warning 的 torch.Tensor 当前实现引入了内存开销，从而可能导致在许多微小的张量的应用出乎意料的高内存使用情况。如果您遇到这种情况，可以考虑使用一个大的结构。 classtorch.``Tensor 有两种创建一个张量，这取决于你的使用情况的几个主要途径。 要创建具有预先存在的数据的张量，用 torch.tensor（）。 要创建具有特定大小的张量，使用Torch 。*张量创建OPS（见 创建行动 ）。 要创建具有相同的尺寸（以及类似的类型）作为另一张张量，使用Torch 。* _像张量创建OPS（见 创建行动 ）。 要创建具有相似类型但不同大小的另一张张量，使用tensor.new_ *创建欢声笑语。 new_tensor( data , dtype=None , device=None , requires_grad=False ) → Tensor 返回与数据作为张量数据的新的张量。默认情况下，返回的张量具有相同的 torch.dtype 和 torch.device作为本张量。 Warning new_tensor（）总是副本数据。如果你有一个张量数据，并希望避免拷贝，使用 torch.Tensor.requires_grad_（）或 torch.Tensor.detach（） 。如果你有一个numpy的阵列，并希望避免拷贝，使用[ torch.from_numpy（） HTG31。 Warning 当数据是张量×， new_tensor（）读出从不管它是通过 '数据'，并构造一个叶变量。因此tensor.new_tensor（X）等于x.clone（）。分离（）和tensor.new_tensor（X， requires_grad =真）等于x.clone（）。分离（）。requires_grad_（真）。使用克隆（）和分离（）的当量的建议。 Parameters 数据 （ array_like ） - 返回的张量份数据。 DTYPE （ torch.dtype，可选） - 返回的张量的所期望的类型。默认值：如果无，相同 torch.dtype如这个张量。 装置 （ torch.device，可选） - 返回的张量的所需的设备。默认值：如果无，相同 torch.device如这个张量。 requires_grad （ 布尔 ， 可选 ） - 如果autograd应返回的记录张操作。默认值：假 [HTG13。 例： >>> tensor = torch.ones((2,), dtype=torch.int8) >>> data = [[0, 1], [2, 3]] >>> tensor.new_tensor(data) tensor([[ 0, 1], [ 2, 3]], dtype=torch.int8) new_full( size , fill_value , dtype=None , device=None , requires_grad=False ) → Tensor 返回大小 大小的张量填充与fill_value。默认情况下，返回的张量具有相同的 torch.dtype 和 torch.device作为本张量。 Parameters fill_value （ 标量 ） - 的数量来填充与输出张量。 dtype (torch.dtype, optional) – the desired type of returned tensor. Default: if None, same torch.dtype as this tensor. device (torch.device, optional) – the desired device of returned tensor. Default: if None, same torch.device as this tensor. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> tensor = torch.ones((2,), dtype=torch.float64) >>> tensor.new_full((3, 4), 3.141592) tensor([[ 3.1416, 3.1416, 3.1416, 3.1416], [ 3.1416, 3.1416, 3.1416, 3.1416], [ 3.1416, 3.1416, 3.1416, 3.1416]], dtype=torch.float64) new_empty( size , dtype=None , device=None , requires_grad=False ) → Tensor 返回大小 大小填充与未初始化的数据的张量。默认情况下，返回的张量具有相同的 torch.dtype 和 torch.device作为本张量。 Parameters dtype (torch.dtype, optional) – the desired type of returned tensor. Default: if None, same torch.dtype as this tensor. device (torch.device, optional) – the desired device of returned tensor. Default: if None, same torch.device as this tensor. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> tensor = torch.ones(()) >>> tensor.new_empty((2, 3)) tensor([[ 5.8182e-18, 4.5765e-41, -1.0545e+30], [ 3.0949e-41, 4.4842e-44, 0.0000e+00]]) new_ones( size , dtype=None , device=None , requires_grad=False ) → Tensor 返回大小 填充有1``大小的张量。默认情况下，返回的张量具有相同的 torch.dtype 和 torch.device作为本张量。 Parameters 大小 （ INT ... ） - 列表，元组，或torch.Size定义输出张量的形状的整数。 dtype (torch.dtype, optional) – the desired type of returned tensor. Default: if None, same torch.dtype as this tensor. device (torch.device, optional) – the desired device of returned tensor. Default: if None, same torch.device as this tensor. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> tensor = torch.tensor((), dtype=torch.int32) >>> tensor.new_ones((2, 3)) tensor([[ 1, 1, 1], [ 1, 1, 1]], dtype=torch.int32) new_zeros( size , dtype=None , device=None , requires_grad=False ) → Tensor 返回大小 填充有0``大小的张量。默认情况下，返回的张量具有相同的 torch.dtype 和 torch.device作为本张量。 Parameters size ( int... ) – a list, tuple, or torch.Sizeof integers defining the shape of the output tensor. dtype (torch.dtype, optional) – the desired type of returned tensor. Default: if None, same torch.dtype as this tensor. device (torch.device, optional) – the desired device of returned tensor. Default: if None, same torch.device as this tensor. requires_grad ( bool , optional ) – If autograd should record operations on the returned tensor. Default: False. Example: >>> tensor = torch.tensor((), dtype=torch.float64) >>> tensor.new_zeros((2, 3)) tensor([[ 0., 0., 0.], [ 0., 0., 0.]], dtype=torch.float64) is_cuda 为真 [HTG3如果张量存储在GPU，假 [HTG7否则。`` device 是[ torch.deviceHTG5如果本张量。 grad 该属性是无缺省和成为张量在第一时间 呼叫向后（）计算梯度为自。然后，属性将包含计算出的梯度，并 向后（） 将积累（添加）梯度到它将来的呼叫。 ndim 别名 暗淡（） T 这是张量与它的尺寸逆转。 如果n的是尺寸在×的数量，XT等价于x.permute第（n-1， N-2， ...， 0）。 abs() → Tensor 参见 torch.abs（） abs_() → Tensor 就地版本 的ABS（） acos() → Tensor 参见 torch.acos（） acos_() → Tensor 就地版本 ACOS的（） add( value ) → Tensor 添加（值= 1，其他） - & GT ;张量 参见 torch.add（） add_( value ) → Tensor add_（值= 1，其他） - & GT ;张量 就地版本的 添加（） addbmm( beta=1 , alpha=1 , batch1 , batch2 ) → Tensor 参见 torch.addbmm（） addbmm_( beta=1 , alpha=1 , batch1 , batch2 ) → Tensor 就地版本 addbmm的（） addcdiv( value=1 , tensor1 , tensor2 ) → Tensor 参见 torch.addcdiv（​​） addcdiv_( value=1 , tensor1 , tensor2 ) → Tensor 就地版本的 addcdiv（​​） addcmul( value=1 , tensor1 , tensor2 ) → Tensor 参见 torch.addcmul（） addcmul_( value=1 , tensor1 , tensor2 ) → Tensor 就地版本 addcmul的（） addmm( beta=1 , alpha=1 , mat1 , mat2 ) → Tensor 参见 torch.addmm（） addmm_( beta=1 , alpha=1 , mat1 , mat2 ) → Tensor 就地版本 addmm的（） addmv( beta=1 , alpha=1 , mat , vec ) → Tensor 参见 torch.addmv（） addmv_( beta=1 , alpha=1 , mat , vec ) → Tensor 就地版本 addmv的（） addr( beta=1 , alpha=1 , vec1 , vec2 ) → Tensor 参见 torch.addr（） addr_( beta=1 , alpha=1 , vec1 , vec2 ) → Tensor 就地版本 的addr（） allclose( other , rtol=1e-05 , atol=1e-08 , equal_nan=False ) → Tensor 参见 torch.allclose（） apply_( callable ) → Tensor 适用的函数可调用，在张量的每个元件，与由可调用返回的值替换每个元件。 Note 此功能只适用于CPU张量，不应该在要求高性能的代码段中使用。 argmax( dim=None , keepdim=False ) → LongTensor 参见 torch.argmax（） argmin( dim=None , keepdim=False ) → LongTensor 参见 torch.argmin（） argsort( dim=-1 , descending=False ) → LongTensor 参见：FUNC： torch.argsort asin() → Tensor 参见 torch.asin（） asin_() → Tensor 就地版本的 ASIN（） as_strided( size , stride , storage_offset=0 ) → Tensor 参见 torch.as_strided（） atan() → Tensor 参见 torch.atan（） atan2( other ) → Tensor 参见 torch.atan2（） atan2_( other ) → Tensor 就地版本 ATAN2的（） atan_() → Tensor 就地版本 ATAN的（） backward( gradient=None , retain_graph=None , create_graph=False )[source] 计算当前张量w.r.t.的梯度图叶。 该图是使用链式法则区分。如果张量是非标量（即，其数据具有一个以上的元素），并且需要的梯度，所述函数另外需要指定梯度。它应该是匹配的类型和位置的张量，包含有区别的功能w.r.t.的梯度自。 此功能聚集在叶梯度 - 你可能需要调用它之前为零它们。 Parameters 梯度 （ 张量 或 无 ） - 梯度w.r.t.张量。如果它是一个张量，它将被自动转换为不需要研究所除非create_graph为True张量。无值可以用于标量张量或那些不要求毕业生指定。如果没有值是可以接受的，然后这种说法是可选的。 retain_graph （ 布尔 ， 可选 ） - 如果假，用于计算梯度的图表将被释放。请注意，在几乎所有情况下的设置则不需要此选项设置为True，往往可以以更有效的方式围绕工作。默认为create_graph的值。 create_graph （ 布尔 ， 可选 ） - 如果真，所述衍生物的图形将被构建，从而允许计算高阶衍生产品。默认为假 [HTG17。 baddbmm( beta=1 , alpha=1 , batch1 , batch2 ) → Tensor 参见 torch.baddbmm（） baddbmm_( beta=1 , alpha=1 , batch1 , batch2 ) → Tensor 就地版本 baddbmm的（） bernoulli( * , generator=None ) → Tensor 返回一个结果张量，其中每个 导致[I] \\ texttt {结果[I]} 导致[I] 从独立地取样 伯努利 （ 自[I] ） \\文本{伯努利}（\\ texttt {自[I]}） 伯努利 （ 自[I] ） 。 自必须浮点DTYPE，结果将具有相同的DTYPE。 参见 torch.bernoulli（） bernoulli_() bernoulli_( p=0.5 , * , generator=None ) → Tensor 填充的自每个位置与一个独立的样品从 伯努利 （ p ） \\文本{伯努利}（\\ texttt {p}） 伯努利 （ p ） 。 自可以具有积分DTYPE。 bernoulli_( p_tensor , * , generator=None ) → Tensor p_tensor应该是被用于绘制二进制随机数包含概率的张量。 的 i的 T H \\文本{I} ^ {第} I T H 的自张量元件将被设置为从 伯努利 取样的值（ p_tensor [I] ） \\文本{伯努利}（\\ texttt {p \\ _tensor [I]}） 伯努利 （ p_tensor [I] ） 。 自可以有积分D类，而p_tensor必须浮点DTYPE。 另请参见 伯努利（）和 torch.bernoulli（） bfloat16() → Tensor self.bfloat16（）等于self.to（torch.bfloat16）。参见 至（）。 bincount( weights=None , minlength=0 ) → Tensor 参见 torch.bincount（） bitwise_not() → Tensor 参见 torch.bitwise_not（） bitwise_not_() → Tensor 就地版本的 bitwise_not（） bmm( batch2 ) → Tensor 参见 torch.bmm（） bool() → Tensor self.bool（）等于self.to（torch.bool）。参见 至（）。 byte() → Tensor self.byte（）等于self.to（torch.uint8）。参见 至（）。 cauchy_( median=0 , sigma=1 , * , generator=None ) → Tensor 填充与柯西分布中奖号码的张量： f(x)=1πσ(x−median)2+σ2f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}f(x)=π1​(x−median)2+σ2σ​ ceil() → Tensor 参见 torch.ceil（） ceil_() → Tensor 就地版本 小区的（） char() → Tensor self.char（）等于self.to（torch.int8）。参见 至（）。 cholesky( upper=False ) → Tensor 参见 torch.cholesky（） cholesky_inverse( upper=False ) → Tensor 参见 torch.cholesky_inverse（） cholesky_solve( input2 , upper=False ) → Tensor 参见 torch.cholesky_solve（） chunk( chunks , dim=0 ) → List of Tensors 参见 torch.chunk（） clamp( min , max ) → Tensor 参见 torch.clamp（） clamp_( min , max ) → Tensor 就地版本 夹具（） clone() → Tensor 返回自张的副本。使副本具有相同的大小和数据类型为自。 Note 不像 copy_（），该函数被记录在计算图。梯度传播到克隆的张量将传播到原来的张量。 contiguous() → Tensor 返回包含相同的数据自张量的连续张量。如果自张量是连续的，则该函数返回自张量。 copy_( src , non_blocking=False ) → Tensor 拷贝从的元素的src到自张量并返回自。 的SRC张量必须是 broadcastable 与自张量。它可以是不同的数据类型的或驻留在不同设备上。 Parameters SRC （ 张量 ） - 源张量从复制 non_blocking （ 布尔 ） - 如果真，并将该副本是CPU和GPU之间，可能会出现复制异步相对于主机。对于其他情况，这种说法没有任何效果。 cos() → Tensor 参见 torch.cos（） cos_() → Tensor 就地版本 COS的（） cosh() → Tensor 参见 torch.cosh（） cosh_() → Tensor 就地版本 COSH的（） cpu() → Tensor 返回此对象的CPU内存拷贝。 如果该对象已在CPU内存和正确的设备上，则没有执行复制操作，并返回原来的对象。 cross( other , dim=-1 ) → Tensor 参见 torch.cross（） cuda( device=None , non_blocking=False ) → Tensor 返回此对象的CUDA内存的副本。 如果该对象已在CUDA内存和正确的设备上，则没有执行复制操作，并返回原来的对象。 Parameters 装置 （ torch.device） - 目标GPU设备。默认为当前CUDA设备。 non_blocking （ 布尔 ） - 如果真和源极被固定存储器，复制将是异步相对于主机。另外，参数没有任何影响。默认值：假 [HTG13。 cumprod( dim , dtype=None ) → Tensor 参见 torch.cumprod（） cumsum( dim , dtype=None ) → Tensor 参见 torch.cumsum（） data_ptr() → int 返回的自张量的第一个元素的地址。 dequantize() → Tensor 给定一个量化张量，去量化它，并返回去量化的浮动张量。 det() → Tensor 参见 torch.det（） dense_dim() → int 如果自是一个稀疏COO张量（即，与torch.sparse_coo布局），它返回致密的维数。否则，这将引发一个错误。 另请参见 Tensor.sparse_dim（）。 detach() 返回一个新的张量，从当前图形分离。 其结果将永远不需要梯度。 Note 回到张量股与原来相同的存储。就地对它们中的修改可以看出，并可能引发正确性检查错误。重要提示：以前，就地尺寸/步幅/存储的变化（如 resize / resize_as / SET / transpose ）来返回的张量也更新原有的张量。现在，这些就地变化将不再更新原有的张量，而会触发一个错误。对于稀疏张量：就地索引/值的变化（如 zero / copy / add_ ）发送到返回张量将不再更新原始张量，而会触发一个错误。 detach_() 分离从创建它，使其成为一个叶子图表中的张量。意见不能就地分离。 diag( diagonal=0 ) → Tensor 参见 torch.diag（） diag_embed( offset=0 , dim1=-2 , dim2=-1 ) → Tensor 参见 torch.diag_embed（） diagflat( offset=0 ) → Tensor 参见 torch.diagflat（） diagonal( offset=0 , dim1=0 , dim2=1 ) → Tensor 参见 torch.diagonal（） fill_diagonal_( fill_value , wrap=False ) → Tensor 填充有至少2维的张量的主对角线。当变暗& GT ; 2，输入的所有尺寸必须相等的长度。这个函数修改就地输入张量，并返回输入张量。 Parameters fill_value （[HTG2标量） - 填充值 包裹 （ 布尔 ） - 对角N列高层矩阵后“包裹”。 Example: >>> a = torch.zeros(3, 3) >>> a.fill_diagonal_(5) tensor([[5., 0., 0.], [0., 5., 0.], [0., 0., 5.]]) >>> b = torch.zeros(7, 3) >>> b.fill_diagonal_(5) tensor([[5., 0., 0.], [0., 5., 0.], [0., 0., 5.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]) >>> c = torch.zeros(7, 3) >>> c.fill_diagonal_(5, wrap=True) tensor([[5., 0., 0.], [0., 5., 0.], [0., 0., 5.], [0., 0., 0.], [5., 0., 0.], [0., 5., 0.], [0., 0., 5.]]) digamma() → Tensor 参见 torch.digamma（） digamma_() → Tensor 就地版本 digamma的（） dim() → int 返回的自张量的维数。 dist( other , p=2 ) → Tensor 参见 torch.dist（） div( value ) → Tensor 参见 torch.div（） div_( value ) → Tensor 就地版本 的div（） dot( tensor2 ) → Tensor 参见 torch.dot（） double() → Tensor self.double（）等于self.to（torch.float64）。参见 至（）。 eig( eigenvectors=False) - > (Tensor, Tensor ) 参见 torch.eig（） element_size() → int 返回单个元素的字节大小。 Example: >>> torch.tensor([]).element_size() 4 >>> torch.tensor([], dtype=torch.uint8).element_size() 1 eq( other ) → Tensor 参见 torch.eq（） eq_( other ) → Tensor 就地版本 当量的（） equal( other ) → bool 参见 torch.equal（） erf() → Tensor 参见 torch.erf（） erf_() → Tensor 就地版本 ERF的（） erfc() → Tensor 参见 torch.erfc（） erfc_() → Tensor 就地版本 ERFC的（） erfinv() → Tensor 参见 torch.erfinv（） erfinv_() → Tensor 就地版本 erfinv的（） exp() → Tensor 参见 torch.exp（） exp_() → Tensor 就地版本 EXP的（） expm1() → Tensor 参见 torch.expm1（） expm1_() → Tensor 就地版本 的expm1的（） expand( *sizes ) → Tensor 返回自张量具有扩展到更大尺寸单尺寸的新视图。 传递-1作为大小为一个尺寸是指在不改变其尺寸的大小。 张量，也可以扩大到尺寸的数量较多，而新的将在前面追加。对于新的尺寸，大小不能设置为-1。 扩大的张量不分配新的内存，但是仅创建其中大小为一的尺寸是通过设置步幅 [HTG3到0扩展到一个更大的尺寸上的现有张量的新视图。尺寸1的任何尺寸可扩展到任意值而不分配新的内存。 Parameters *的大小 （ torch.Size 或 INT ... ） - 所需的扩展大小 Warning 膨胀张量的多于一个的元件可指代单个存储器位置。其结果是，就地操作（特别是那些有量化的）可能会导致不正确的行为。如果你需要写张量，请先克隆它们。 Example: >>> x = torch.tensor([[1], [2], [3]]) >>> x.size() torch.Size([3, 1]) >>> x.expand(3, 4) tensor([[ 1, 1, 1, 1], [ 2, 2, 2, 2], [ 3, 3, 3, 3]]) >>> x.expand(-1, 4) # -1 means not changing the size of that dimension tensor([[ 1, 1, 1, 1], [ 2, 2, 2, 2], [ 3, 3, 3, 3]]) expand_as( other ) → Tensor 展开，这个张量，以相同的尺寸为其他。 self.expand_as（其他）​​等于self.expand（other.size（））。 请参阅 扩大（）关于更多信息展开 [HTG9。 Parameters 其他 （ torch.Tensor） - 结果张量具有相同的大小为其他 [ HTG11。 exponential_( lambd=1 , * , generator=None ) → Tensor 填充自张量与从指数分布绘制的元素： f(x)=λe−λxf(x) = \\lambda e^{-\\lambda x}f(x)=λe−λx fft( signal_ndim , normalized=False ) → Tensor 参见 torch.fft（） fill_( value ) → Tensor 填充具有指定值自张量。 flatten( input , start_dim=0 , end_dim=-1 ) → Tensor 见 torch.flatten（） flip( dims ) → Tensor 参见 torch.flip（） float() → Tensor self.float（）等于self.to（torch.float32）。参见 至（）。 floor() → Tensor 参见 torch.floor（） floor_() → Tensor 就地版本 地板（） fmod( divisor ) → Tensor 参见 torch.fmod（） fmod_( divisor ) → Tensor 就地版本 FMOD的（） frac() → Tensor 参见 torch.frac（） frac_() → Tensor 就地版本 压裂的（） gather( dim , index ) → Tensor 参见 torch.gather（） ge( other ) → Tensor 参见 torch.ge（） ge_( other ) → Tensor 就地版本的Ge（） gels( A )[source] 参见 torch.lstsq（） geometric_( p , * , generator=None ) → Tensor 填充自张量与来自几何分布绘制的元素： f(X=k)=pk−1(1−p)f(X=k) = p^{k - 1} (1 - p)f(X=k)=pk−1(1−p) geqrf( ) - > (Tensor, Tensor ) 参见 torch.geqrf（） ger( vec2 ) → Tensor 参见 torch.ger（） get_device( ) - > Device ordinal (Integer) 对于CUDA张量，此函数返回在其上驻留张量GPU的设备序号。对于CPU张量，则会引发错误。 Example: >>> x = torch.randn(3, 4, 5, device='cuda:0') >>> x.get_device() 0 >>> x.cpu().get_device() # RuntimeError: get_device is not implemented for type torch.FloatTensor gt( other ) → Tensor 参见 torch.gt（） gt_( other ) → Tensor 就地版本 GT的（） half() → Tensor self.half（）等于self.to（torch.float16）。参见 至（）。 hardshrink( lambd=0.5 ) → Tensor 参见 torch.nn.functional.hardshrink（） histc( bins=100 , min=0 , max=0 ) → Tensor 参见 torch.histc（） ifft( signal_ndim , normalized=False ) → Tensor 参见 torch.ifft（） index_add_( dim , index , tensor ) → Tensor 积累的 的元素张量到自张量通过增加在给定的顺序的索引索引。例如，如果暗淡 == 0和索引[I] = = [HTG27：J，则i的次的 行张量 被添加到[HTG41：J次的自行。 的 暗淡次的 维张量必须具有尺寸为长度相同的索引（它必须是一个矢量），和所有其他的尺寸必须相符自，或错误将被提高。 Note 当使用CUDA后端，该操作可以诱导非确定性的行为是不容易断开。请参阅 重复性 为背景的音符。 Parameters 暗淡 （ INT ） - 维沿着该索引 索引 （ LongTensor ） - 的 索引张量从选择 张量 （ 张量 ） - 包含值张量来添加 Example: >>> x = torch.ones(5, 3) >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float) >>> index = torch.tensor([0, 4, 2]) >>> x.index_add_(0, index, t) tensor([[ 2., 3., 4.], [ 1., 1., 1.], [ 8., 9., 10.], [ 1., 1., 1.], [ 5., 6., 7.]]) index_add( dim , index , tensor ) → Tensor 外的地方的 版本torch.Tensor.index_add_（） index_copy_( dim , index , tensor ) → Tensor 的 拷贝的元素张量成通过在[HTG10给定的顺序选择指数的自张量] 索引 。例如，如果暗淡 == 0和索引[I] = = [HTG27：J，则i的次的 行张量 复制到[HTG41：J次的自行。 The dimth dimension of tensor must have the same size as the length of index(which must be a vector), and all other dimensions must match self, or an error will be raised. Parameters dim ( int) – dimension along which to index index ( LongTensor ) – indices of tensor to select from 张量 （ 张量 ） - 包含值张量来复制 Example: >>> x = torch.zeros(5, 3) >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float) >>> index = torch.tensor([0, 4, 2]) >>> x.index_copy_(0, index, t) tensor([[ 1., 2., 3.], [ 0., 0., 0.], [ 7., 8., 9.], [ 0., 0., 0.], [ 4., 5., 6.]]) index_copy( dim , index , tensor ) → Tensor 外的地方的 版本torch.Tensor.index_copy_（） index_fill_( dim , index , val ) → Tensor 填充自的元素张量与值VAL通过在索引给定的顺序选择所述索引。 Parameters dim ( int) – dimension along which to index 索引 （ LongTensor ） - 的指数自张量，以填补在 VAL （ 浮动 ） - 以填补的值 Example:: >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float) >>> index = torch.tensor([0, 2]) >>> x.index_fill_(1, index, -1) tensor([[-1., 2., -1.], [-1., 5., -1.], [-1., 8., -1.]]) index_fill( dim , index , value ) → Tensor 外的地方的 版本torch.Tensor.index_fill_（） index_put_( indices , value , accumulate=False ) → Tensor 从张量值把值代入张量自使用中指定的索引指数（这是张量的元组）。表达式tensor.index_put_（指数， 值）等于张量[指数] = 值。返回自 [HTG31。 如果积累是真，元素在 张量添加到自。如果累积为假，行为是不确定如果索引包含重复的元素。 Parameters 指数 （ LongTensor 的元组） - 用于索引到自张量。 的值 （ 张量 ） - 相同类型的张量为自。 积累 （ 布尔 ） - 是否积累到自 index_put( indices , value , accumulate=False ) → Tensor 外的地方版本的 index_put_（） index_select( dim , index ) → Tensor 参见 torch.index_select（） indices() → Tensor 如果自是一个稀疏COO张量（即，与torch.sparse_coo布局），它返回所包含的索引张量的图。否则，这将引发一个错误。 另请参见 Tensor.values（）。 Note 这种方法只能在聚结的稀疏张量被调用。参见对于细节Tensor.coalesce（）。 int() → Tensor self.int（）等于self.to（torch.int32）。参见 至（）。 int_repr() → Tensor 给定一个量化的张量，self.int_repr（）返回与uint8_t作为存储给定的张量的底层uint8_t值数据类型的CPU张量。 inverse() → Tensor 参见 torch.inverse（） irfft( signal_ndim , normalized=False , onesided=True , signal_sizes=None ) → Tensor 参见 torch.irfft（） is_contiguous() → bool 返回true如果自张量是在用C顺序存储器中连续。 is_floating_point() → bool 返回true的自的数据类型是一个浮点数据类型。 is_leaf() 有所有的张量 requires_grad是假将叶按约定张量。 对于张量具有 requires_grad，它是真，他们将叶张量如果他们被创建用户。这意味着它们不是一个操作的结果等grad_fn是无。 仅叶张量人员在 GRAD至 向后（在呼叫期间填充）。为了得到 毕业填充的无叶张量，你可以使用 retain_grad（）[ HTG23。 Example: >>> a = torch.rand(10, requires_grad=True) >>> a.is_leaf True >>> b = torch.rand(10, requires_grad=True).cuda() >>> b.is_leaf False # b was created by the operation that cast a cpu Tensor into a cuda Tensor >>> c = torch.rand(10, requires_grad=True) + 2 >>> c.is_leaf False # c was created by the addition operation >>> d = torch.rand(10).cuda() >>> d.is_leaf True # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine) >>> e = torch.rand(10).cuda().requires_grad_() >>> e.is_leaf True # e requires gradients and has no operations creating it >>> f = torch.rand(10, requires_grad=True, device=\"cuda\") >>> f.is_leaf True # f requires grad, has no operation creating it is_pinned()[source] 如果此张驻留在固定的内存，则返回true is_set_to( tensor ) → bool 如果该对象是指从Torch C API作为给定的张量相同THTensor对象返回真。 is_shared()[source] 检查，如果张量是在共享存储器中。 这始终是真 [HTG3对于CUDA张量。 is_signed() → bool 如果自数据类型是有符号的数据类型，则返回True。 is_sparse() item() → number 返回此张量作为标准Python数的值。这仅适用于一个元素张量。对于其它情况，参见 tolist（）。 此操作不可微。 Example: >>> x = torch.tensor([1.0]) >>> x.item() 1.0 kthvalue( k , dim=None , keepdim=False) - > (Tensor, LongTensor ) 参见 torch.kthvalue（） le( other ) → Tensor 参见 torch.le（） le_( other ) → Tensor 就地版本的 乐（） lerp( end , weight ) → Tensor 参见 torch.lerp（） lerp_( end , weight ) → Tensor 就地版本 线性插值的（） log() → Tensor 参见 torch.log（） log_() → Tensor 就地版本 日志（） logdet() → Tensor 参见 torch.logdet（） log10() → Tensor 参见 torch.log10（） log10_() → Tensor 就地版本 LOG10的（） log1p() → Tensor 参见 torch.log1p（） log1p_() → Tensor 就地版本 log1p的（） log2() → Tensor 参见 torch.log2（） log2_() → Tensor 就地版本 的log 2的（） log_normal_( mean=1 , std=2 , * , generator=None ) 填充自张量与从所述给定参数的对数正态分布的数字样本意味着 μ \\亩 μ 和标准偏差 σ \\西格玛 σ 。注意， 意味着 和 STD是平均值和底层的标准偏差正态分布，而不是返回的分布： f(x)=1xσ2π e−(ln⁡x−μ)22σ2f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}f(x)=xσ2π​1​ e−2σ2(lnx−μ)2​ logsumexp( dim , keepdim=False ) → Tensor 参见 torch.logsumexp（） long() → Tensor self.long（）等于self.to（torch.int64）。参见 至（）。 lstsq( A) - > (Tensor, Tensor ) See torch.lstsq() lt( other ) → Tensor 参见 torch.lt（） lt_( other ) → Tensor 就地版本 LT的（） lu( pivot=True , get_infos=False )[source] 参见 torch.lu（） lu_solve( LU_data , LU_pivots ) → Tensor 参见 torch.lu_solve（） map_( tensor , callable ) 适用可调用在自张量的每个元件和给定 张量，并将结果存储在自张量。 自张量和给定的 张量必须 broadcastable 。 在调用应具备的特征： def callable(a, b) -> number masked_scatter_( mask , source ) 从源复制内容纳入自在位置张量，其中掩模为真。的形状掩模必须 broadcastable 与下面的张量的形状。的源应当具有至少一样多的元素的那些中数掩模 Parameters 掩模 （ BoolTensor ） - 布尔掩码 源 （ 张量 ） - 张量从复制 Note 的掩模操作上的自张量，而不是在给定的源张量。 masked_scatter( mask , tensor ) → Tensor 外的地方的 版本torch.Tensor.masked_scatter_（） masked_fill_( mask , value ) 填充的自张量元素与值其中掩模为True。的形状掩模必须 broadcastable 与下面的张量的形状。 Parameters mask ( BoolTensor) – the boolean mask 值 （ 浮动 ） - 的值与填 masked_fill( mask , value ) → Tensor 外的地方的 版本torch.Tensor.masked_fill_（） masked_select( mask ) → Tensor 参见 torch.masked_select（） matmul( tensor2 ) → Tensor 参见 torch.matmul（） matrix_power( n ) → Tensor 参见 torch.matrix_power（） max( dim=None , keepdim=False) - > Tensor or (Tensor, Tensor ) 参见 torch.max（） mean( dim=None , keepdim=False) - > Tensor or (Tensor, Tensor ) 参见 torch.mean（） median( dim=None , keepdim=False) - > (Tensor, LongTensor ) 参见 torch.median（） min( dim=None , keepdim=False) - > Tensor or (Tensor, Tensor ) 参见 torch.min（） mm( mat2 ) → Tensor 参见 torch.mm（） mode( dim=None , keepdim=False) - > (Tensor, LongTensor ) 参见 torch.mode（） mul( value ) → Tensor 参见 torch.mul（） mul_( value ) 就地版本 MUL的（） multinomial( num_samples , replacement=False , * , generator=None ) → Tensor 参见 torch.multinomial（） mv( vec ) → Tensor 参见 torch.mv（） mvlgamma( p ) → Tensor 参见 torch.mvlgamma（） mvlgamma_( p ) → Tensor 就地版本 mvlgamma的（） narrow( dimension , start , length ) → Tensor 参见 torch.narrow（） Example: >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> x.narrow(0, 0, 2) tensor([[ 1, 2, 3], [ 4, 5, 6]]) >>> x.narrow(1, 1, 2) tensor([[ 2, 3], [ 5, 6], [ 8, 9]]) narrow_copy( dimension , start , length ) → Tensor 同 Tensor.narrow（），除了返回一个副本，而不是共享存储。这主要是为稀疏张量，其不具有共享存储窄方法。主叫narrow_copy `与dimemsion & GT ; self.sparse_dim（） 会返回缩小的相关密集维度副本，self.shape 相应更新。 ndimension() → int Alias for dim() ne( other ) → Tensor 参见 torch.ne（） ne_( other ) → Tensor 就地版本 NE的（） neg() → Tensor 参见 torch.neg（） neg_() → Tensor 就地版本 NEG的（） nelement() → int 别名 numel（） nonzero() → LongTensor 参见 torch.nonzero（） norm( p='fro' , dim=None , keepdim=False , dtype=None )[source] 参见 torch.norm（） normal_( mean=0 , std=1 , * , generator=None ) → Tensor 填充自与元素样品张量从正态分布由 参数化的意思是和 STD。 numel() → int 参见 torch.numel（） numpy() → numpy.ndarray 返回自张量作为NumPy的ndarray。这个张量和返回ndarray共享同一基础存储。为自变化张量将反映在ndarray，反之亦然。 orgqr( input2 ) → Tensor 参见 torch.orgqr（） ormqr( input2 , input3 , left=True , transpose=False ) → Tensor 参见 torch.ormqr（） permute( *dims ) → Tensor 置换，这个张量的尺寸。 Parameters *变暗 （ INT ... ） - 尺寸的所需排序 例 >>> x = torch.randn(2, 3, 5) >>> x.size() torch.Size([2, 3, 5]) >>> x.permute(2, 0, 1).size() torch.Size([5, 2, 3]) pin_memory() → Tensor 复制张量固定的内存，如果它不是已经固定。 pinverse() → Tensor 参见 torch.pinverse（） pow( exponent ) → Tensor 参见 torch.pow（） pow_( exponent ) → Tensor 就地版本 POW的（） prod( dim=None , keepdim=False , dtype=None ) → Tensor 参见 torch.prod（） put_( indices , tensor , accumulate=False ) → Tensor 拷贝从 的元素张量到由索引指定的位置。用于索引的目的，自张量就好像它是一个1-d张量处理。 If accumulateis True, the elements in tensor are added to self. If accumulate is False, the behavior is undefined if indices contain duplicate elements. Parameters 指数 （ LongTensor ） - 索引为自 张量 （ 张量 ） - 包含值从复制张量 accumulate ( bool) – whether to accumulate into self Example: >>> src = torch.tensor([[4, 3, 5], [6, 7, 8]]) >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10])) tensor([[ 4, 9, 5], [ 10, 7, 8]]) qr( some=True) - > (Tensor, Tensor ) 参见 torch.qr（） qscheme() → torch.qscheme 返回给定QTensor的量化方案。 q_scale() → float 鉴于线性（仿射）量化量化的张量，返回底层量化器的规模（）。 q_zero_point() → int 鉴于线性（仿射）量化量化的张量，返回底层量化器的zero_point（）。 random_( from=0 , to=None , * , generator=None ) → Tensor 填充自超过[从离散均匀分布采样数张量从 至 - 1]。如果未指定，则这些值通常仅由自张量的数据类型的限制。然而，对于浮点类型，如果未指定，范围将是[0， 2 ^尾数]，以确保每一个值可表示。例如， torch.tensor（1，D型细胞= torch.double）.random_（）将均匀的[0， 2 ^ 53]。 reciprocal() → Tensor 参见 torch.reciprocal（） reciprocal_() → Tensor 就地版本的 倒数（） register_hook( hook )[source] 寄存器向后钩。 钩将被称为每相对于该张量的梯度被计算的时间。钩子应该具有以下特征： hook(grad) -> Tensor or None 钩不应该修改它的参数，但它可以任选地返回一个新的梯度，这将代替 GRAD一起使用。 该函数返回与方法handle.remove手柄（），其去除从所述模块的钩。 Example: >>> v = torch.tensor([0., 0., 0.], requires_grad=True) >>> h = v.register_hook(lambda grad: grad * 2) # double the gradient >>> v.backward(torch.tensor([1., 2., 3.])) >>> v.grad 2 4 6 [torch.FloatTensor of size (3,)] >>> h.remove() # removes the hook remainder( divisor ) → Tensor 参见 torch.remainder（） remainder_( divisor ) → Tensor 就地版本 剩余的（） renorm( p , dim , maxnorm ) → Tensor 参见 torch.renorm（） renorm_( p , dim , maxnorm ) → Tensor 就地版本 重归一化的（） repeat( *sizes ) → Tensor 重复沿着指定的尺寸，这个张量。 不同于 扩大（），该函数将张量的数据。 Warning torch.repeat（）从 numpy.repeat 行为不同，但是更类似于 numpy.tile 。对于类似于操作者numpy.repeat 参见 torch.repeat_interleave（）。 Parameters 尺寸 （ torch.Size 或 INT ... ） - 的次数重复此张量沿着每个维度 Example: >>> x = torch.tensor([1, 2, 3]) >>> x.repeat(4, 2) tensor([[ 1, 2, 3, 1, 2, 3], [ 1, 2, 3, 1, 2, 3], [ 1, 2, 3, 1, 2, 3], [ 1, 2, 3, 1, 2, 3]]) >>> x.repeat(4, 2, 1).size() torch.Size([4, 2, 3]) repeat_interleave( repeats , dim=None ) → Tensor 参见 torch.repeat_interleave（）。 requires_grad() 是真 [HTG3如果梯度需要计算该张量，假 [HTG7否则。`` Note 该梯度需要计算的张量，这一事实并不意味着 毕业属性将被填充，请参阅 is_leaf的更多细节。 requires_grad_( requires_grad=True ) → Tensor 改变，如果autograd应在此张记录操作：设置这个张量的 requires_grad属性原地。返回此张量。 require_grad_（）的主要使用情形是告诉autograd到开始记录的操作的张量张量。如果张量具有requires_grad =假（因为它被通过的DataLoader获得，或者需要预处理或初始化），tensor.requires_grad_（）使得它使autograd将开始记录操作上张 [HTG23。 Parameters requires_grad （ 布尔 ） 如果autograd应在此张记录操作。默认值：真 [HTG9。 Example: >>> # Let's say we want to preprocess some saved weights and use >>> # the result as new weights. >>> saved_weights = [0.1, 0.2, 0.3, 0.25] >>> loaded_weights = torch.tensor(saved_weights) >>> weights = preprocess(loaded_weights) # some function >>> weights tensor([-0.5503, 0.4926, -2.1158, -0.8303]) >>> # Now, start to record operations done to weights >>> weights.requires_grad_() >>> out = weights.pow(2).sum() >>> out.backward() >>> weights.grad tensor([-1.1007, 0.9853, -4.2316, -1.6606]) reshape( *shape ) → Tensor 返回与元素自但具有指定形状的相同的数据和数字的张量。如果定型是与当前的形状相容的此方法返回的图。参见 torch.Tensor.view（）上时，它可以返回的图。 参见 torch.reshape（） Parameters 定型 （ 蟒的元组：整数 或 INT ... ） - 所需的形状 reshape_as( other ) → Tensor 返回该张量为相同的形状，其他。 self.reshape_as（其他）​​等于self.reshape（other.sizes（））。如果other.sizes（）是与当前的形状相容的此方法返回的图。参见 torch.Tensor.view（）上时，它可以返回的图。 请参阅 重塑（）关于更多信息重塑 [HTG9。 Parameters 其他 （ torch.Tensor） - 结果张量具有相同的形状其他 [ HTG11。 resize_( *sizes ) → Tensor 调整大小自张量，以指定的大小。如果元件的数量大于当前存储大小，则底层存储被调整大小，以适应元件的新号码。如果元件的数目较小时，底层的存储不被改变。存在的元素将会保留，但任何新的内存未初始化。 Warning 这是一个低级别的方法。存储被重新解释为C-连续的，忽略当前进展（除非目标大小等于电流的大小，在这种情况下，张量保持不变）。在大多数情况下，你反而要使用 视图（），其检查连续性，或 重塑（），其复制数据如果需要的话。若要更改就地自定义步幅大小，请参阅 SET_（）。 Parameters 尺寸 （ torch.Size 或 INT ... ） - 所需的大小 Example: >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]]) >>> x.resize_(2, 2) tensor([[ 1, 2], [ 3, 4]]) resize_as_( tensor ) → Tensor 调整大小的自张量是大小相同的指定 张量。这等同于self.resize_（tensor.size（））。 retain_grad()[source] 启用了非叶张量.grad属性。 rfft( signal_ndim , normalized=False , onesided=True ) → Tensor 参见 torch.rfft（） roll( shifts , dims ) → Tensor 参见 torch.roll（） rot90( k , dims ) → Tensor 参见 torch.rot90（） round() → Tensor 参见 torch.round（） round_() → Tensor 就地版本的 轮（） rsqrt() → Tensor 参见 torch.rsqrt（） rsqrt_() → Tensor 就地版本 rsqrt的（） scatter( dim , index , source ) → Tensor 外的地方的 版本torch.Tensor.scatter_（） scatter_( dim , index , src ) → Tensor 写入所有值从张量SRC到自在索引 [指定的索引HTG11]张量。对于SRC，它的输出索引是由它的指数SRC为维[HTG22指定在每个值] ！= 暗淡 和在索引 为维 [相应的值HTG35] = 暗淡。 对于3-d张量，自被更新为： self[index[i][j][k]][j][k] = src[i][j][k] # if dim == 0 self[i][index[i][j][k]][k] = src[i][j][k] # if dim == 1 self[i][j][index[i][j][k]] = src[i][j][k] # if dim == 2 这是在 聚集（）所描述的方式相反的操作。 自，索引和SRC（如果它是一个张量）应具有相同的维数。它也要求index.size（d） & LT ; = src.size（d） [HTG19用于所有维度d，以及index.size（d） & LT ; = self.size（d） 针对所有维度d ！= 暗淡 。 此外，对于 聚集（），索引的值必须介于0和self.size（DIM） - 1以下，并且所有在一排值一起指定的尺寸 暗淡必须是唯一的。 Parameters 暗淡 （ INT ） - 的轴，沿着该索引 索引 （ LongTensor ） - 元件以分散的指数，可以是空的或SRC的相同的尺寸。当空，操作返回身份 SRC （ 张量 ） - 源元素（一个或多个）以散射，柜面值未指定被 值 （ 浮动 ） - 源元素（一个或多个）以散射，柜面 SRC 未指定 Example: >>> x = torch.rand(2, 5) >>> x tensor([[ 0.3992, 0.2908, 0.9044, 0.4850, 0.6004], [ 0.5735, 0.9006, 0.6797, 0.4152, 0.1732]]) >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x) tensor([[ 0.3992, 0.9006, 0.6797, 0.4850, 0.6004], [ 0.0000, 0.2908, 0.0000, 0.4152, 0.0000], [ 0.5735, 0.0000, 0.9044, 0.0000, 0.1732]]) >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23) >>> z tensor([[ 0.0000, 0.0000, 1.2300, 0.0000], [ 0.0000, 0.0000, 0.0000, 1.2300]]) scatter_add_( dim , index , other ) → Tensor 将从张量的所有值其他到自在索引 [指定的索引HTG11]张量以类似的方式为scatter_（） 。对于在其他 ，它被添加到索引中自 这是由其索引指定在[HTG27每个值]等 为维 ！= 暗淡 和在索引对应的值 为维 = 暗淡 。 For a 3-D tensor, selfis updated as: self[index[i][j][k]][j][k] += other[i][j][k] # if dim == 0 self[i][index[i][j][k]][k] += other[i][j][k] # if dim == 1 self[i][j][index[i][j][k]] += other[i][j][k] # if dim == 2 自，索引和其他应当具有相同的维数。它也要求index.size（d） & LT ; = other.size（d） [HTG19用于所有维度d，以及index.size（d） & LT ; = self.size（d） 针对所有维度d ！= 暗淡 。 此外，对于 聚集（），索引的值必须介于0和self.size（DIM） - 1以下，并且所有在一排值一起指定的尺寸 暗淡必须是唯一的。 Note When using the CUDA backend, this operation may induce nondeterministic behaviour that is not easily switched off. Please see the notes on Reproducibility for background. Parameters dim ( int) – the axis along which to index 索引 （ LongTensor ） - 元件的散射，并添加，指数可以是空的或SRC的相同的尺寸。当空，操作返回身份。 其他 （ 张量 ） - 源元件散射和添加 Example: >>> x = torch.rand(2, 5) >>> x tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328], [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]]) >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x) tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328], [1.0000, 1.0427, 1.0000, 1.6782, 1.0000], [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]]) scatter_add( dim , index , source ) → Tensor 外的地方的 版本torch.Tensor.scatter_add_（） select( dim , index ) → Tensor 切片的自沿着给定的索引在所选择的尺寸张量。这个函数返回删除了给定尺寸的张量。 Parameters 暗淡 （ INT ） - 的尺寸切 索引 （ INT ） - 索引与选择 Note 选择（）等价于切片。例如，tensor.select（0， 索引）等于张量[指数]和tensor.select（2， 索引）等于张量[：，：，指数]。 set_( source=None , storage_offset=0 , size=None , stride=None ) → Tensor 设置底层存储，大小和进步。如果源是一个张量，自张量将共享相同的存储，并且具有相同的尺寸和步幅为源。在一个张量元素的变化将反映在其他。 如果源是存放，该方法将底层存储，偏移量，大小，和步幅。 Parameters 源 （ 张量 或 存放 ） - 张量或存储使用 storage_offset （ INT ， 可选 ） - 在存储器中的偏移 大小 （ torch.Size ， 可选 ） - 所需的大小。默认为源的大小。 步幅 （ 元组 ， 可选 ） - 所需的步幅。默认为C-连续进展。 share_memory_()[source] 移动底层存储到共享存储器中。 这是如果底层存储已经在共享存储器和用于CUDA张量无操作。在共享存储器中张量不能被调整大小。 short() → Tensor self.short（）等于self.to（torch.int16）。参见 至（）。 sigmoid() → Tensor 参见 torch.sigmoid（） sigmoid_() → Tensor 就地版本 乙状结肠的（） sign() → Tensor 参见 torch.sign（） sign_() → Tensor 就地版本 符号的（） sin() → Tensor 参见 torch.sin（） sin_() → Tensor 就地版本 罪的（） sinh() → Tensor 参见 torch.sinh（） sinh_() → Tensor 就地版本的 的sinh（） size() → torch.Size 返回自张量的大小。返回的值是 元组 的子类。 Example: >>> torch.empty(3, 4, 5).size() torch.Size([3, 4, 5]) slogdet( ) - > (Tensor, Tensor ) 参见 torch.slogdet（） solve( A ) → Tensor, Tensor 参见 torch.solve（） sort( dim=-1 , descending=False) - > (Tensor, LongTensor ) 参见 torch.sort（） split( split_size , dim=0 )[source] 参见 torch.split（） sparse_mask( input , mask ) → Tensor 返回 过滤通过指数与值的新SparseTensor从张量输入掩码 和值将被忽略。输入 和掩模 必须具有相同的形状。 Parameters 输入 （ 张量 ） - 的输入张量 掩模 （ SparseTensor ） - 一个SparseTensor我们筛选根据它的索引输入 Example: >>> nnz = 5 >>> dims = [5, 5, 2, 2] >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)), torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz) >>> V = torch.randn(nnz, dims[2], dims[3]) >>> size = torch.Size(dims) >>> S = torch.sparse_coo_tensor(I, V, size).coalesce() >>> D = torch.randn(dims) >>> D.sparse_mask(S) tensor(indices=tensor([[0, 0, 0, 2], [0, 1, 4, 3]]), values=tensor([[[ 1.6550, 0.2397], [-0.1611, -0.0779]], [[ 0.2326, -1.0558], [ 1.4711, 1.9678]], [[-0.5138, -0.0411], [ 1.9417, 0.5158]], [[ 0.0793, 0.0036], [-0.2569, -0.1055]]]), size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo) sparse_dim() → int 如果自是一个稀疏COO张量（即，与torch.sparse_coo布局），它返回稀疏的维度数目。否则，这将引发一个错误。 另请参见 Tensor.dense_dim（）。 sqrt() → Tensor 参见 torch.sqrt（） sqrt_() → Tensor 就地版本的 SQRT（） squeeze( dim=None ) → Tensor 参见 torch.squeeze（） squeeze_( dim=None ) → Tensor 就地版本 挤压的（） std( dim=None , unbiased=True , keepdim=False ) → Tensor 参见 torch.std（） stft( n_fft , hop_length=None , win_length=None , window=None , center=True , pad_mode='reflect' , normalized=False , onesided=True )[source] 参见 torch.stft（） Warning 此功能在0.4.1版本中更改签名。与先前的签名调用可能会导致错误或返回不正确的结果。 storage() → torch.Storage 返回底层存储。 storage_offset() → int 返回自张量在底层存储的偏移在存储元件（未字节）的数目方面。 Example: >>> x = torch.tensor([1, 2, 3, 4, 5]) >>> x.storage_offset() 0 >>> x[3:].storage_offset() 3 storage_type() → type 返回底层存储的类型。 stride( dim ) → tuple or int 返回自张量步幅。 步幅是必要跳转到从一个元件到下一个指定维度 暗淡。当没有参数在被传递返回所有步幅的元组，否则，一个整数值返回为在特定维度 步幅暗淡。 Parameters 暗淡 （ INT ， 可选 ） - 其中需要步幅所希望的尺寸 Example: >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]) >>> x.stride() (5, 1) >>>x.stride(0) 5 >>> x.stride(-1) 1 sub( value , other ) → Tensor 减去从自张量标量或张量。如果两个值和其他被指定的每个元素等被缩放通过值之前被使用。 当其他是一个张量，的形状其他必须 broadcastable 与底层张量的形状。 sub_( x ) → Tensor 就地版本 子的（） sum( dim=None , keepdim=False , dtype=None ) → Tensor 参见 torch.sum（） sum_to_size( *size ) → Tensor 总和这里张量为 大小。大小必须broadcastable为这里张量的大小。 Parameters 大小 （ INT ... ） - 定义输出张量的形状的整数序列。 svd( some=True , compute_uv=True) - > (Tensor, Tensor , Tensor ) 参见 torch.svd（） symeig( eigenvectors=False , upper=True) - > (Tensor, Tensor ) 参见 torch.symeig（） t() → Tensor 参见 torch.t（） t_() → Tensor 就地版本的 T（） to( *args , **kwargs ) → Tensor 执行张量D型细胞和/或设备的转换。 A torch.dtype 和 torch.device从的参数推断出self.to（*指定参数时， ** kwargs）。 Note 如果自张量已经有了正确的 torch.dtype和 torch.device ，然后自被返回。否则，返回的张量是自与复制所需的 torch.dtype 和 torch.device。 下面是调用至方式： to( dtype , non_blocking=False , copy=False ) → Tensor 返回与指定DTYPE张量 to( device=None , dtype=None , non_blocking=False , copy=False ) → Tensor 返回与指定 装置和张量（可选）DTYPE。如果DTYPE是无它被推断为self.dtype。当non_blocking，尝试如果可能的话，以相对于异步转换到主机，例如，转换CPU张量与固定内存到CUDA张量。当复制设置，即使当已经张量相匹配的所需的转化创建一个新的张量。 to( other , non_blocking=False , copy=False ) → Tensor 返回与相同 torch.dtype和 torch.device 作为一个张量张量其他。当non_blocking，尝试如果可能的话，以相对于异步转换到主机，例如，转换CPU张量与固定内存到CUDA张量。当复制设置，即使当已经张量相匹配的所需的转化创建一个新的张量。 Example: >>> tensor = torch.randn(2, 2) # Initially dtype=float32, device=cpu >>> tensor.to(torch.float64) tensor([[-0.5044, 0.0005], [ 0.3310, -0.0584]], dtype=torch.float64) >>> cuda0 = torch.device('cuda:0') >>> tensor.to(cuda0) tensor([[-0.5044, 0.0005], [ 0.3310, -0.0584]], device='cuda:0') >>> tensor.to(cuda0, dtype=torch.float64) tensor([[-0.5044, 0.0005], [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0') >>> other = torch.randn((), dtype=torch.float64, device=cuda0) >>> tensor.to(other, non_blocking=True) tensor([[-0.5044, 0.0005], [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0') to_mkldnn() → Tensor 返回torch.mkldnn布局张的副本。 take( indices ) → Tensor 参见 torch.take（） tan() → Tensor 参见 torch.tan（） tan_() → Tensor 就地版本的 黄褐色（） tanh() → Tensor 参见 torch.tanh（） tanh_() → Tensor 就地版本 的tanh（） tolist() ” tolist（） - & GT ;列表或数 返回张量为（嵌套）名单。标量，则返回一个标准的Python数目，只是（） 像 项。张量自动移动到CPU首先，如果必要的。 This operation is not differentiable. 例子： >>> a = torch.randn(2, 2) >>> a.tolist() [[0.012766935862600803, 0.5415473580360413], [-0.08909505605697632, 0.7729271650314331]] >>> a[0,0].tolist() 0.012766935862600803 topk( k , dim=None , largest=True , sorted=True) - > (Tensor, LongTensor ) 参见 torch.topk（） to_sparse( sparseDims ) → Tensor 返回张量的稀疏副本。 PyTorch支持 坐标格式 稀疏张量。 Parameters sparseDims （ INT ， 可选 ） - 稀疏维数，以在新的稀疏张量包括 Example: >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]]) >>> d tensor([[ 0, 0, 0], [ 9, 0, 10], [ 0, 0, 0]]) >>> d.to_sparse() tensor(indices=tensor([[1, 1], [0, 2]]), values=tensor([ 9, 10]), size=(3, 3), nnz=2, layout=torch.sparse_coo) >>> d.to_sparse(1) tensor(indices=tensor([[1]]), values=tensor([[ 9, 0, 10]]), size=(3, 3), nnz=1, layout=torch.sparse_coo) trace() → Tensor 参见 torch.trace（） transpose( dim0 , dim1 ) → Tensor 参见 torch.transpose（） transpose_( dim0 , dim1 ) → Tensor 就地版本的 转置（） triangular_solve( A , upper=True , transpose=False , unitriangular=False) - > (Tensor, Tensor ) 参见 torch.triangular_solve（） tril( k=0 ) → Tensor 参见 torch.tril（） tril_( k=0 ) → Tensor 就地版本的 TRIL（） triu( k=0 ) → Tensor 参见 torch.triu（） triu_( k=0 ) → Tensor 就地版本 triu的（） trunc() → Tensor 参见 torch.trunc（） trunc_() → Tensor 就地版本 TRUNC的（） type( dtype=None , non_blocking=False , **kwargs ) → str or Tensor 返回类型，如果 DTYPE 不设置，否则铸件此对象为指定的类型。 如果这是正确的类型已经没有执行复制操作，并返回原来的对象。 Parameters DTYPE （ 输入 或 串 ） - 所需的类型 non_blocking （ 布尔 ） - 如果真，并且源是在固定存储器和目的地是在GPU或反之亦然，副本被相对于所述主机异步地执行。另外，参数没有任何影响。 ** kwargs - 对于相容性，可以含有键异步代替non_blocking参数的。的异步ARG被弃用。 type_as( tensor ) → Tensor 返回此张投给定张的类型。 这是一个无操作，如果张量已经是正确的类型。这等同于self.type（tensor.type（）） Parameters 张量 （ 张量 ） - 具有所需类型的张量 unbind( dim=0 ) → seq 参见 torch.unbind（） unfold( dimension , size , step ) → Tensor 返回一个包含大小 大小的所有片的张量从在尺寸[自 张量HTG11]维。 两片之间的步骤是通过步骤给出。 如果 sizedim 是维度的大小维为自，尺寸[大小HTG11 ]维在返回的张量将是（sizedim - 大小）/步+ 1 。 大小 大小的额外维度在返回的张量追加。 Parameters 维 （ INT ） - 维，其中展开发生 大小 （ INT ） - 其被展开每个切片的大小 步骤 （ INT ） - 每个切片之间的台阶 Example: >>> x = torch.arange(1., 8) >>> x tensor([ 1., 2., 3., 4., 5., 6., 7.]) >>> x.unfold(0, 2, 1) tensor([[ 1., 2.], [ 2., 3.], [ 3., 4.], [ 4., 5.], [ 5., 6.], [ 6., 7.]]) >>> x.unfold(0, 2, 2) tensor([[ 1., 2.], [ 3., 4.], [ 5., 6.]]) uniform_( from=0 , to=1 ) → Tensor 填充自张量与从连续均匀分布采样的数字： P(x)=1to−fromP(x) = \\dfrac{1}{\\text{to} - \\text{from}} P(x)=to−from1​ unique( sorted=True , return_inverse=False , return_counts=False , dim=None )[source] 返回输入张量的独特元素。 参见 torch.unique（） unique_consecutive( return_inverse=False , return_counts=False , dim=None )[source] 消除了所有的但等效从元件的每个连续组的第一个元素。 参见 torch.unique_consecutive（） unsqueeze( dim ) → Tensor 参见 torch.unsqueeze（） unsqueeze_( dim ) → Tensor 就地版本的 unsqueeze（） values() → Tensor 如果自是一个稀疏COO张量（即，与torch.sparse_coo布局），这将返回包含的值张量的图。否则，这将引发一个错误。 另请参见 Tensor.indices（）。 Note This method can only be called on a coalesced sparse tensor. See Tensor.coalesce()for details. var( dim=None , unbiased=True , keepdim=False ) → Tensor 参见 torch.var（） view( *shape ) → Tensor 返回与相同的数据自张量但具有不同的形状的新的张量。 返回的张量共享相同的数据，并且必须有相同数量的元素，但可以具有不同的大小。对于待观察的张量，新视图大小必须与它的原始尺寸和步幅，即兼容，每一个新的视图尺寸必须是一个原始尺寸的子空间，或仅跨跨度原始尺寸 d ， d + 1 ... ， d + K d，d + 1， \\点，d + K d ， d + 1 ， ... ， d + K 满足以下的邻接样条件 ∀ i的 = 0 ， ... ， K - 1 \\ forall的I = 0，\\点，K-1 ∀ i的 = 0 ， ... ， ķ - 1 stride[i]=stride[i+1]×size[i+1]\\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]stride[i]=stride[i+1]×size[i+1] 否则， 连续（）需要被称为可观察的张量之前。参见： 重塑（），如果形状是兼容它返回一个视图，并复制（等效于调用 连续的（））否则。 Parameters 定型 （ torch.Size 或 INT ... ） - 所需的大小 Example: >>> x = torch.randn(4, 4) >>> x.size() torch.Size([4, 4]) >>> y = x.view(16) >>> y.size() torch.Size([16]) >>> z = x.view(-1, 8) # the size -1 is inferred from other dimensions >>> z.size() torch.Size([2, 8]) >>> a = torch.randn(1, 2, 3, 4) >>> a.size() torch.Size([1, 2, 3, 4]) >>> b = a.transpose(1, 2) # Swaps 2nd and 3rd dimension >>> b.size() torch.Size([1, 3, 2, 4]) >>> c = a.view(1, 3, 2, 4) # Does not change tensor layout in memory >>> c.size() torch.Size([1, 3, 2, 4]) >>> torch.equal(b, c) False view_as( other ) → Tensor 查看这个张量为相同的大小为其他。 self.view_as（其他）​​等于self.view（other.size（））。 请参见 视图（）约视图的更多信息。 Parameters other (torch.Tensor) – The result tensor has the same size as other. where( condition , y ) → Tensor self.where（条件， y）的等于torch.where（条件， 自， y）的。参见 torch.where（） zero_() → Tensor 填充自用零张量。 classtorch.``BoolTensor 下面的方法是独特的 torch.BoolTensor。 all() all() → bool 如果张量的所有元素都是真，假，否则返回True。 Example: >>> a = torch.rand(1, 2).bool() >>> a tensor([[False, True]], dtype=torch.bool) >>> a.all() tensor(False, dtype=torch.bool) all( dim , keepdim=False , out=None ) → Tensor 如果张量的每一行中的所有元素在指定维度暗淡是真，假，否则返回True。 如果keepdim是真，输出张量是相同的大小为输入除了在尺寸暗淡其中它是尺寸1的否则，暗淡被挤出（见 torch.squeeze（）），导致具有比1种输入更少尺寸的输出张量。 Parameters 暗淡 （ INT ） - 的尺寸，以减少 keepdim （ 布尔 ） - 输出张量是否有暗淡保留或不 OUT （ 张量 ， 可选 ） - 输出张量 Example: >>> a = torch.rand(4, 2).bool() >>> a tensor([[True, True], [True, False], [True, True], [True, True]], dtype=torch.bool) >>> a.all(dim=1) tensor([ True, False, True, True], dtype=torch.bool) >>> a.all(dim=0) tensor([ True, False], dtype=torch.bool) any() any() → bool 如果在任何张元素是真，假，否则返回True。 Example: >>> a = torch.rand(1, 2).bool() >>> a tensor([[False, True]], dtype=torch.bool) >>> a.any() tensor(True, dtype=torch.bool) any( dim , keepdim=False , out=None ) → Tensor 如果张量的每行中的任何元件在给定的尺寸暗淡是真，假否则返回真。 If keepdimis True, the output tensor is of the same size as input except in the dimension dimwhere it is of size 1. Otherwise, dimis squeezed (see torch.squeeze()), resulting in the output tensor having 1 fewer dimension than input. Parameters dim ( int) – the dimension to reduce keepdim ( bool) – whether the output tensor has dimretained or not out ( Tensor , optional ) – the output tensor Example: >>> a = torch.randn(4, 2) >> a tensor([[ True, True], [False, True], [ True, True], [False, False]]) >>> a.any(1) tensor([ True, True, True, False]) >>> a.any(0) tensor([True, True]) Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"tensor_attributes.html":{"url":"tensor_attributes.html","title":"Tensor Attributes","keywords":"","body":"张量属性 每个torch.Tensor具有 torch.dtype， torch.device和 torch.layout。 torch.dtype classtorch.``dtype Atorch.dtype是表示的数据类型的对象的 torch.Tensor 。 PyTorch有九个不同的数据类型： 数据类型 | D型 | 张量类型 ---|---|--- 32位浮点 | torch.float32或torch.float | torch。*。FloatTensor 64位浮点 | torch.float64或torch.double | torch。*。DoubleTensor 16位浮点 | torch.float16或torch.half | torch。*。HalfTensor 8位整数（无符号） | torch.uint8 | torch。*。ByteTensor 8位整数（签名） | torch.int8 | torch。*。CharTensor 16位整数（签名） | torch.int16或torch.short | torch。*。ShortTensor 32位整数（签名） | torch.int32或torch.int | torch。*。IntTensor 64位整数（签名） | torch.int64或torch.long | torch。*。LongTensor 布尔 | torch.bool | torch。*。BoolTensor 以找出是否一个 torch.dtype是一个浮点数据类型，属性 is_floating_point 可以被使用，它返回真如果数据类型是浮点数据类型。 torch.device classtorch.``device Atorch.device是表示装置的对象在其上 torch.Tensor 或将被分配。 的 torch.device包含一个设备类型（'CPU'或' CUDA”）和用于设备类型任选装置的序号。如果设备序不存在，这个对象将总是代表的设备类型的当前装置中，即使 torch.cuda.set_device后（）被称为;例如， `` 构造torch.Tensor与设备'CUDA'等于'CUDA：X'其中，X是 torch.cuda.current_device的（）的结果 。 A torch.Tensor的设备可以通过 Tensor.device[HTG11被访问]属性。 Atorch.device可以通过一个字符串或经由串和设备序号来构成 通过字符串： >>> torch.device('cuda:0') device(type='cuda', index=0) >>> torch.device('cpu') device(type='cpu') >>> torch.device('cuda') # current cuda device device(type='cuda') 通过串和设备顺序： >>> torch.device('cuda', 0) device(type='cuda', index=0) >>> torch.device('cpu', 0) device(type='cpu', index=0) 注意 的 torch.device在功能参数可以通常与串取代。这使得代码的快速原型。 >>> # Example of a function that takes in a torch.device >>> cuda1 = torch.device('cuda:1') >>> torch.randn((2,3), device=cuda1) >>> # You can substitute the torch.device with a string >>> torch.randn((2,3), device='cuda:1') Note 对于传统的原因，一个设备可以经由单个装置序，这将被视为一个CUDA设备来构建。这符合 Tensor.get_device（） ，它返回CUDA张量的序和不支持CPU张量。 >>> torch.device(1) device(type='cuda', index=1) Note 其采取的装置的方法通常会接受一个（适当格式化的）字符串或（传统）整数装置序，即，以下都是等效的： >>> torch.randn((2,3), device=torch.device('cuda:1')) >>> torch.randn((2,3), device='cuda:1') >>> torch.randn((2,3), device=1) # legacy torch.layout classtorch.``layout Atorch.layout是代表的存储器布局的对象的 torch.Tensor 。目前，我们支持torch.strided（密集张量），并有torch.sparse_coo [HTG19（稀疏COO张量）的实验性支持。 torch.strided代表致密张量，并且是最常用的存储器布局。每个跨距张量具有相关联的torch.Storage，其保持它的数据。这些张量提供多维的，存储的跨距图。跨越式发展是整数的列表：第k个步幅表示从一个元素去的张量的第k个维度上的下一个必要的存储器中的跳跃。这个概念使得它可以有效地进行多张操作。 例： >>> x = torch.Tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]) >>> x.stride() (5, 1) >>> x.t().stride() (1, 5) 有关的更多信息torch.sparse_coo张量，见 torch.sparse 。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"type_info.html":{"url":"type_info.html","title":"Type Info","keywords":"","body":"键入信息 的数值性质的 torch.dtype可通过访问任一 torch.finfo或 torch.iinfo。 torch.finfo classtorch.``finfo Atorch.finfo是表示一个浮点 torch.dtype 的数值性质[对象HTG10]（即torch.float32，torch.float64和torch.float16）。这类似于 numpy.finfo 。 Atorch.finfo提供以下属性： 名称 | 类型 | 描述 ---|---|--- 位 | INT | 由类型所占用的位数。 EPS | 浮动 | 可表示的最小数量，使得1.0 + EPS ！= 1.0。 最大 | float | 最大可表示数。 分 | float | 可表示的最小数目（典型-max）。 小 | float | 最小的正表示数。 注意 的构造 torch.finfo可以被称为无参数，在这种情况下，对于缺省pytorch D类创建的类（由 [作为返回HTG7] torch.get_default_dtype（） ）。 torch.iinfo classtorch.``iinfo Atorch.iinfo是表示一个整数 torch.dtype [HTG10的数值属性的对象]（即torch.uint8，torch.int8，torch.int16，torch.int32和torch.int64）。这类似于 numpy.iinfo 。 Atorch.iinfo提供以下属性： Name | Type | Description ---|---|--- bits | int | The number of bits occupied by the type. max | int | The largest representable number. min | int | 最小可表示数。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:20 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"sparse.html":{"url":"sparse.html","title":"torch.sparse","keywords":"","body":"torch.sparse 警告 这个API目前处于试验阶段，并在不久的将来可能会改变。 Torch 支持COO（rdinate）格式稀疏张量，其可有效地存储和处理张量的量，大部分元素都为零。 稀疏张量被表示为一对密张量：值的张量和指数的2D张量。稀疏张量可以通过提供这两个张量，以及所述稀疏张量的大小来构造（其不能从这些张量推断！）假设我们要定义与在位置的条目3的稀疏张量（0，2） ，条目4在位置（1,0），和条目5在位置（1,2）。然后，我们可以这样写： >>> i = torch.LongTensor([[0, 1, 1], [2, 0, 2]]) >>> v = torch.FloatTensor([3, 4, 5]) >>> torch.sparse.FloatTensor(i, v, torch.Size([2,3])).to_dense() 0 0 3 4 0 5 [torch.FloatTensor of size 2x3] 请注意，输入到LongTensor不是索引元组的列表。如果你想写的指标这样，你应该将它们传递到稀疏的构造函数之前转： >>> i = torch.LongTensor([[0, 2], [1, 0], [1, 2]]) >>> v = torch.FloatTensor([3, 4, 5 ]) >>> torch.sparse.FloatTensor(i.t(), v, torch.Size([2,3])).to_dense() 0 0 3 4 0 5 [torch.FloatTensor of size 2x3] 您还可以构建混合稀疏张量，其中只有第N维稀疏，并且尺寸的其余密集。 >>> i = torch.LongTensor([[2, 4]]) >>> v = torch.FloatTensor([[1, 3], [5, 7]]) >>> torch.sparse.FloatTensor(i, v).to_dense() 0 0 0 0 1 3 0 0 5 7 [torch.FloatTensor of size 5x2] 空稀疏张量可以通过指定其大小来构造： >>> torch.sparse.FloatTensor(2, 3) SparseFloatTensor of size 2x3 with indices: [torch.LongTensor with no dimension] and values: [torch.FloatTensor with no dimension] SparseTensor has the following invariants: sparse_dim + dense_dim = LEN（SparseTensor.shape） SparseTensor._indices（）。形状=（sparse_dim，NNZ） 。SparseTensor._values（）形状=（NNZ，SparseTensor.shape [sparse_dim：]） 由于SparseTensor._indices（）始终是一个2D张量，最小sparse_dim = 1。因此，sparse_dim = 0 SparseTensor的表示仅仅是一个致密的张量。 注意 我们稀疏张量格式许可 未聚 稀疏张量，哪里有可能在指数复制坐标;在这种情况下，解释是该索引的值是所有重复的值项的总和。未聚张量使我们能够更有效地实现某些运营商。 在大多数情况下，你不应该去关心稀疏张量是否被合并与否，大多数操作将工作给予相同的聚结或未聚稀疏张量。然而，有两种情况中，你可能需要关心。 首先，如果你重复执行一个操作，即可以产生重复的条目（例如， torch.sparse.FloatTensor.add（） ），你应该偶尔凝聚你的稀疏张量，以防止它们变得太大。 第二，一些运营商将根据它们是否被合并或不（例如， torch.sparse.FloatTensor._values（）并产生不同的值 torch.sparse.FloatTensor._indices（），以及 torch.Tensor.sparse_mask（） ）。这些运营商正在通过一个下划线前缀，以表明他们露出内部的实现细节，应小心使用，因为这与凝聚的稀疏张量运行的代码可能无法与非联合稀疏张量工作;一般来说，它是最安全的前明确合并与这些运营商合作。 例如，假设我们希望通过直接在 操作以实现操作员torch.sparse.FloatTensor._values（） 。乘以一个标量可以在明显的方式来实现，如乘法分布在另外;然而，平方根不能直接实现的，因为SQRT（一个 + [ HTG11 b） ！= SQRT（一） + SQRT（b）中（这是将如果给你一个未聚张量来计算。） classtorch.sparse.``FloatTensor add() add_() clone() dim() div() div_() get_device() hspmm() mm() mul() mul_() narrow_copy() resizeAs_() size() spadd() spmm() sspaddmm() sspmm() sub() sub_() t_() toDense() transpose() transpose_() zero_() coalesce() is_coalesced() _indices() _values() _nnz() 功能 torch.sparse.``addmm( mat , mat1 , mat2 , beta=1 , alpha=1 )[source] 这个函数完全相同的东西作为 torch.addmm（）在向前，不同之处在于它支持向后对稀疏矩阵MAT1。 MAT1需要有 sparse_dim = 2 。注意，MAT1的梯度是一个聚结的稀疏张量。 Parameters 垫 （ 张量 ） - 要添加致密基质 MAT1 （ SparseTensor ） - 要乘以一个稀疏矩阵 MAT2 （ 张量 ） - 致密的矩阵相乘 的β （ 号码 ， 可选 ） - 乘数垫（ β \\的β β ） 阿尔法 （ 号码 ， 可选 ） - 乘数 M 一 T 1 @ M 一 T 2 MAT1 @ MAT2 M 一 T 1 @ M 一 吨 2 （ α \\阿尔法 α ） torch.sparse.``mm( mat1 , mat2 )[source] 执行稀疏矩阵的矩阵乘法MAT1和稠密矩阵MAT2。类似于 torch.mm（），如果MAT1是 （ n的 × M ） （N \\乘以m） （ n的 × M ） 张量，MAT2是 （ M × p ） （M \\倍p） （ M × P ） 张量，进行将是 （ n的 × p ） （ ñ\\倍p） （ n的 × p ） 密集的张量。 MAT1需要有 sparse_dim = 2 。此功能还支持向后两个矩阵。注意，MAT1的梯度是一个聚结的稀疏张量。 Parameters MAT1 （ SparseTensor ） - 第一稀疏矩阵相乘 MAT2 （ 张量 ） - 要被相乘的第二密集矩阵 例： >>> a = torch.randn(2, 3).to_sparse().requires_grad_(True) >>> a tensor(indices=tensor([[0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 1, 2]]), values=tensor([ 1.5901, 0.0183, -0.6146, 1.8061, -0.0112, 0.6302]), size=(2, 3), nnz=6, layout=torch.sparse_coo, requires_grad=True) >>> b = torch.randn(3, 2, requires_grad=True) >>> b tensor([[-0.6479, 0.7874], [-1.2056, 0.5641], [-1.1716, -0.9923]], requires_grad=True) >>> y = torch.sparse.mm(a, b) >>> y tensor([[-0.3323, 1.8723], [-1.8951, 0.7904]], grad_fn=) >>> y.sum().backward() >>> a.grad tensor(indices=tensor([[0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 1, 2]]), values=tensor([ 0.1394, -0.6415, -2.1639, 0.1394, -0.6415, -2.1639]), size=(2, 3), nnz=6, layout=torch.sparse_coo) torch.sparse.``sum( input , dim=None , dtype=None )[source] 返回在给定尺寸SparseTensor 输入中的每一行的总和暗淡。如果暗淡为维度的列表，减少过度所有的人。当总和在所有sparse_dim，此方法返回一个张量代替SparseTensor。 所有求和暗淡被挤压（见 torch.squeeze（）），从而导致具有输出张量暗淡比尺寸较少输入。 期间落后，仅在梯度NNZ的位置的输入将传播回来。请注意，输入 的梯度被聚结。 Parameters 输入 （ 张量 ） - 输入SparseTensor 暗淡 （ INT 或 蟒的元组：整数 ） - 一个维度或维度列表，以减少。默认值：减少对所有变暗。 DTYPE （torch.dtype，可选） - 所需的数据返回张量的类型。默认：输入D型。 Example: >>> nnz = 3 >>> dims = [5, 5, 2, 3] >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)), torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz) >>> V = torch.randn(nnz, dims[2], dims[3]) >>> size = torch.Size(dims) >>> S = torch.sparse_coo_tensor(I, V, size) >>> S tensor(indices=tensor([[2, 0, 3], [2, 4, 1]]), values=tensor([[[-0.6438, -1.6467, 1.4004], [ 0.3411, 0.0918, -0.2312]], [[ 0.5348, 0.0634, -2.0494], [-0.7125, -1.0646, 2.1844]], [[ 0.1276, 0.1874, -0.6334], [-1.9682, -0.5340, 0.7483]]]), size=(5, 5, 2, 3), nnz=3, layout=torch.sparse_coo) # when sum over only part of sparse_dims, return a SparseTensor >>> torch.sparse.sum(S, [1, 3]) tensor(indices=tensor([[0, 2, 3]]), values=tensor([[-1.4512, 0.4073], [-0.8901, 0.2017], [-0.3183, -1.7539]]), size=(5, 2), nnz=3, layout=torch.sparse_coo) # when sum over all sparse dim, return a dense Tensor # with summed dims squeezed >>> torch.sparse.sum(S, [0, 1, 3]) tensor([-2.6596, -1.1450]) Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"cuda.html":{"url":"cuda.html","title":"torch.cuda","keywords":"","body":"torch.cuda 这个包增加了支持CUDA张类型，实现相同功能的CPU张量，但他们利用了计算的GPU。 据延迟初始化的，所以你可以随时导入它，然后用 is_available（）以确定您的系统支持CUDA。 CUDA语义 有大约使用CUDA的更多细节。 torch.cuda.``current_blas_handle()[source] 返回cublasHandle_t指向当前CUBLAS手柄 torch.cuda.``current_device()[source] 返回当前选择的设备的索引。 torch.cuda.``current_stream( device=None )[source] 返回当前选择的 流对于给定的设备。 Parameters 装置 （ torch.device 或 INT ， 可选 ） - 选定的设备。返回当前选择的 串流用于当前装置中，通过 current_device给出（），如果 装置 是无（默认）。 torch.cuda.``default_stream( device=None )[source] 返回默认 流对于给定的设备。 Parameters 装置 （ torch.device 或 INT ， 可选 ） - 选定的设备。返回默认 流用于当前装置，由下式给出 current_device（）下，如果 装置是无（默认）。 classtorch.cuda.``device( device )[source] 上下文经理改变所选的设备。 Parameters 装置 （ torch.device 或 INT ） 设备索引来选择。它是一个无操作，如果该参数是负整数或无。 torch.cuda.``device_count()[source] 返回可用GPU的数量。 classtorch.cuda.``device_of( obj )[source] 上下文管理器，改变当前设备到给定对象的。 您可以同时使用张量和储存作为参数。如果给定对象不是在GPU上分配的，这是一个空操作。 Parameters OBJ （ 张量 或 存放 ） - 对象所选择的装置上分配。 torch.cuda.``empty_cache()[source] 发布当前由高速缓存分配器保持，使得那些可以在其他的GPU应用中使用，并在可见的所有空闲的缓存内存的NVIDIA-SMI [HTG1。 注意 empty_cache（）不增加GPU存储器可用于PyTorch量。参见 内存管理 关于GPU内存管理的更多细节。 torch.cuda.``get_device_capability( device=None )[source] 获取设备的CUDA能力。 Parameters 装置 （ torch.device 或 INT ， 可选 ） - 装置，其用于归还该设备的能力。这个函数是一个无操作，如果这种说法是一个负整数。它使用当前装置中，通过 current_device给出（）时，如果 装置是无（默认）。 Returns 该设备的主要和次要CUDA能力 Return type 元组（ INT ， INT ） torch.cuda.``get_device_name( device=None )[source] 获取设备的名称。 Parameters 装置 （ torch.device 或 INT ， 可选 ） - 设备要返回的名称。这个函数是一个无操作，如果这种说法是一个负整数。它使用当前装置中，通过 current_device给出（）时，如果 装置是无（默认）。 torch.cuda.``init()[source] 初始化PyTorch的CUDA状态。您可能需要显式调用，如果你是PyTorch通过其C API进行交互，为CUDA功能Python绑定要等到这个初始化发生。普通用户不应该需要这个，因为所有的PyTorch的CUDA方法自动初始化点播CUDA状态。 请问咱这CUDA状态已初始化。 torch.cuda.``ipc_collect()[source] 强制收集GPU内存已经通过CUDA IPC发布之后。 Note 检查是否有任何发送CUDA张量可以从内存中清除。力关闭用于参考计数，如果不存在激活的计数器共享内存文件。有用当生产者进程停止继续发张量和要释放未使用的内存。 torch.cuda.``is_available()[source] 返回一个布尔值，指示是否CUDA是目前已经上市。 torch.cuda.``max_memory_allocated( device=None )[source] 返回通过张量以字节为单位占用一个给定设备的最大GPU内存。 默认情况下，这将返回因为该程序的开始分配的内存峰值。reset_max_memory_allocated（） 可用于起点在跟踪该度量复位。例如，这两个功能可以测量在训练循环每次迭代的峰值分配内存使用情况。 Parameters 装置 （ torch.device 或 INT ， 可选 ） - 选定的设备。通过 current_device给出返回当前设备统计量，（）时，如果 装置是无（默认）。 Note 参见 内存管理 关于GPU内存管理的更多细节。 torch.cuda.``max_memory_cached( device=None )[source] 返回在对于给定的设备的字节高速缓存分配器管理的最大GPU存储器。 默认情况下，这将返回因为该节目的开头缓存内存中的峰值。reset_max_memory_cached（） 可用于起点在跟踪该度量复位。例如，这两个功能可以测量在训练循环每次迭代的峰值高速缓存的存储器的量。 Parameters device ( torch.device or int , optional ) – selected device. Returns statistic for the current device, given by current_device(), if deviceis None(default). Note See Memory management for more details about GPU memory management. torch.cuda.``memory_allocated( device=None )[source] 返回由张量以字节为单位所占用的指定设备的当前GPU内存。 Parameters device ( torch.device or int , optional ) – selected device. Returns statistic for the current device, given by current_device(), if deviceis None(default). Note 这可能是比所示的量较少NVIDIA-SMI 因为一些未使用的存储器可以由高速缓存分配器被保持和一些上下文需要对GPU创建。参见 内存管理 关于GPU内存管理的更多细节。 torch.cuda.``memory_cached( device=None )[source] 返回在对于给定的设备的字节高速缓存分配器管理的当前GPU存储器。 Parameters device ( torch.device or int , optional ) – selected device. Returns statistic for the current device, given by current_device(), if deviceis None(default). Note See Memory management for more details about GPU memory management. torch.cuda.``reset_max_memory_allocated( device=None )[source] 复位在跟踪由张量对于给定的装置所占据最大GPU存储器的起点。 参见 max_memory_allocated（）的详细信息。 Parameters device ( torch.device or int , optional ) – selected device. Returns statistic for the current device, given by current_device(), if deviceis None(default). Note See Memory management for more details about GPU memory management. torch.cuda.``reset_max_memory_cached( device=None )[source] 在复位通过跟踪缓存分配器对于给定的设备所管理的最大GPU存储器的起点。 参见 max_memory_cached（）的详细信息。 Parameters device ( torch.device or int , optional ) – selected device. Returns statistic for the current device, given by current_device(), if deviceis None(default). Note See Memory management for more details about GPU memory management. torch.cuda.``set_device( device )[source] 设置当前设备。 这个功能的用法有利于装置的 气馁。在大多数情况下，最好使用CUDA_VISIBLE_DEVICES环境变量。 Parameters 装置 （ torch.device 或 INT ） 选定的设备。这个函数是一个无操作，如果这个参数为负。 torch.cuda.``stream( stream )[source] 上下文管理器，选择一个给定的流。 其范围内的所有排队CUDA内核将在选定的数据流进行排队。 Parameters 串 （ 串流 ） - 选择的流。这个经理是一个空操作，如果它是无 [HTG9。 Note 流是每设备。如果选定的流不是当前设备上时，该功能也将改变当前设备到流相匹配。 torch.cuda.``synchronize( device=None )[source] 在CUDA设备上的所有数据流都内核等待完成。 Parameters 装置 （ torch.device 或 INT ， 可选 ） - 装置，其同步。它使用当前装置中，通过 current_device给出（）时，如果 装置是无（默认）。 随机数发生器 torch.cuda.``get_rng_state( device='cuda' )[source] 返回指定GPU作为ByteTensor的随机数生成器的状态。 Parameters 装置 （ torch.device 或 INT ， 可选 ） - 该设备返回的RNG状态。默认值：'CUDA'（即torch.device（ 'CUDA'），电流CUDA装置）。 警告 这个函数初始化热切CUDA。 torch.cuda.``get_rng_state_all()[source] 返回ByteTensor代表所有设备的随机数状态的元组。 torch.cuda.``set_rng_state( new_state , device='cuda' )[source] 设置指定GPU的随机数生成器的状态。 Parameters NEW_STATE （ torch.ByteTensor ） - 期望状态 装置 （ torch.device 或 INT ， 可选 ） - 设置RNG状态的装置。默认值：'CUDA'（即torch.device（ 'CUDA'），电流CUDA装置）。 torch.cuda.``set_rng_state_all( new_states )[source] 将所有设备的随机数生成器的状态。 Parameters NEW_STATE （ 的torch.ByteTensor 元组） - 每个设备的所期望的状态 torch.cuda.``manual_seed( seed )[source] 设置为当前GPU产生随机数种子。它是安全的调用这个函数，如果CUDA不可用;在这种情况下，它被忽略。 Parameters 种子 （ INT ） - 所需的种子。 Warning 如果你是一个多GPU模式工作时，这个功能是不足以获得确定性。种子所有的GPU中，用 manual_seed_all（）。 torch.cuda.``manual_seed_all( seed )[source] 设置上所有的GPU产生随机数种子。它是安全的调用这个函数，如果CUDA不可用;在这种情况下，它被忽略。 Parameters seed ( int) – The desired seed. torch.cuda.``seed()[source] 设置用于产生随机数的随机数为当前GPU种子。它是安全的调用这个函数，如果CUDA不可用;在这种情况下，它被忽略。 Warning 如果你是一个多GPU模式工作时，该功能只会初始化一个GPU的种子。初始化所有的GPU中，用 seed_all（）。 torch.cuda.``seed_all()[source] 设置生成随机数在所有GPU的随机数种子。它是安全的调用这个函数，如果CUDA不可用;在这种情况下，它被忽略。 torch.cuda.``initial_seed()[source] 返回当前GPU的电流随机种子。 Warning This function eagerly initializes CUDA. 通信集体 torch.cuda.comm.``broadcast( tensor , devices )[source] 广播张到多个GPU的。 Parameters 张量 （ 张量 ） - 张量来广播。 设备 （ 可迭代 ） - 设备的一个可迭代其中广播。需要注意的是它应该像（SRC，DST1，DST2，...），所述第一元件，其是在源设备从广播。 Returns 含有的拷贝元组中的张量，放置在从设备对应于索引的装置。 torch.cuda.comm.``broadcast_coalesced( tensors , devices , buffer_size=10485760 )[source] 广播顺序张量到指定的GPU。小张量第一合并成一个缓冲区，以减少同步的数量。 Parameters 张量 （ 序列 ） - 张量来广播。 devices ( Iterable ) – an iterable of devices among which to broadcast. Note that it should be like (src, dst1, dst2, …), the first element of which is the source device to broadcast from. BUFFER_SIZE （ INT ） - 用于聚结的缓冲区的最大尺寸 Returns A tuple containing copies of the tensor, placed on devices corresponding to indices from devices. torch.cuda.comm.``reduce_add( inputs , destination=None )[source] 从多个GPU的款项张量。 所有输入应该有匹配的形状。 Parameters 输入 （ 可迭代 [ 张量 __ ） - 张量的一个可迭代添加。 目的地 （ INT ， 可选 ） - 在其上输出将被置于一个设备（默认值：当前设备）。 Returns 含有的所有输入的元素单元的总和张量，放置在目的地装置。 torch.cuda.comm.``scatter( tensor , devices , chunk_sizes=None , dim=0 , streams=None )[source] 跨散射多个GPU张量。 Parameters 张量 （ 张量 ） - 张量散射。 设备 （ 可迭代 [ INT __ ） - 迭代的整数，其中指定哪些设备的张量应散射。 chunk_sizes （ 可迭代 [ INT _ ， 可选的_ ） - 组块的大小，以被放置在每个设备上。它应该匹配设备在长度和总和为tensor.size（DIM）。如果没有指定，张量将被分成相等的块。 暗淡 （ INT ， 可选 ） - 沿着以组块中的张量的尺寸。 Returns 含有跨越给定设备中的张量，传播块元组。 torch.cuda.comm.``gather( tensors , dim=0 , destination=None )[source] 汇集了来自多个GPU张量。 张量大小在比暗淡必须匹配不同所有维度。 Parameters 张量 （ 可迭代 [ 张量 __ ） - 迭代张量的聚集。 暗淡 （ INT ） - 的尺寸沿其张量将是串联的。 目的地 （ INT ， 可选 ） - 输出装置（-1表示CPU，默认：当前装置） Returns 位于目的地设备上的张量，即级联张量的结果沿暗淡 [ HTG11。 流和事件 classtorch.cuda.``Stream[source] 包裹一个CUDA流。 甲CUDA流是执行的线性序列属于特定设备，独立于其他流。参见 CUDA语义 了解详情。 Parameters 装置 （ torch.device 或 INT ， 可选 ） - 在其上分配的流的装置。如果 装置是无（默认）或负整数，这将使用当前设备。 优先权 （ INT ， 可选 ） - 流的优先级。数字越小，代表较高的优先级。 query()[source] 如果所有提交的工作已经完成检查。 Returns 布林值，表示如果在这个流中的所有内核都完成。 record_event( event=None )[source] 记录的事件。 Parameters 活动 （ 事件 ， 可选 ） - 事件记录。如果不给，一个新的将被分配。 Returns 记录的事件。 synchronize()[source] 等待在这个流中的所有内核来完成。 Note 这是周围cudaStreamSynchronize的包装（）：参见 CUDA documentation_ 以获得更多信息。 wait_event( event )[source] 使提交给流等待一个事件的所有未来的工作。 Parameters 活动 （ 事件 ） - 事件等待。 Note 这是周围cudaStreamWaitEvent的包装（）：参见 CUDA documentation_ 以获得更多信息。 该函数返回，而无需等待活动：只有未来的行动受到影响。 wait_stream( stream )[source] 与其他流同步。 提交此流的所有未来的工作将等到调用完成时提交给定流的所有内核。 Parameters 串 （ 串流 ） - 一个流同步。 Note 该函数返回而不 信息流等待当前排队的内核：只有未来的行动受到影响。 classtorch.cuda.``Event[source] 包裹一个CUDA事件。 CUDA事件是可以用于监视设备的进步，以精确地测量定时，并且向CUDA流进行同步的同步标记。 当第一次记录或导出到另一处理的情况下被延迟初始化底层CUDA事件。创建后，只流在同一设备上可以记录事件。然而，任何设备上的流可以等待该事件。 Parameters enable_timing （ 布尔 ， 可选 ） - 表示如果事件应该测量时间（默认值：假） 阻断 （ 布尔 ， 可选 ） - 如果真， 等待（）将被阻断（默认值：假） 间 （ ） - 如果真，则事件可以被处理（默认之间共享：假） elapsed_time( end_event )[source] 返回以毫秒为单位经过的事件记录和end_event记录之前之后的时间。 classmethodfrom_ipc_handle( device , handle )[source] 从给定的设备上的手柄IPC重建的事件。 ipc_handle()[source] 返回此事件的IPC手柄。如果没有记录，该事件将使用当前的设备。 query()[source] 检查当前事件捕获的所有工作已完成。 Returns 布林值，表示如果当前事件捕获的所有工作已完成。 record( stream=None )[source] 记录在给定流的情况下。 使用torch.cuda.current_stream（）如果指定没有流。流的设备必须在事件的设备匹配。 synchronize()[source] 该事件等待完成。 等待，直到所有工作的完成本次活动目前抓获。这可以防止CPU线程继续，直到事件结束。 Note > 这是周围cudaEventSynchronize的包装（）：参见 CUDA documentation_ 以获得更多信息。 wait( stream=None )[source] 使提交给定的流等待此事件的所有未来的工作。 使用torch.cuda.current_stream（）如果没有指定流。 存储器管理 torch.cuda.``empty_cache()[source] Releases all unoccupied cached memory currently held by the caching allocator so that those can be used in other GPU application and visible in nvidia-smi. Note empty_cache()doesn’t increase the amount of GPU memory available for PyTorch. See Memory management for more details about GPU memory management. torch.cuda.``memory_allocated( device=None )[source] Returns the current GPU memory occupied by tensors in bytes for a given device. Parameters device ( torch.device or int , optional ) – selected device. Returns statistic for the current device, given by current_device(), if deviceis None(default). Note This is likely less than the amount shown in nvidia-smi since some unused memory can be held by the caching allocator and some context needs to be created on GPU. See Memory management for more details about GPU memory management. torch.cuda.``max_memory_allocated( device=None )[source] Returns the maximum GPU memory occupied by tensors in bytes for a given device. By default, this returns the peak allocated memory since the beginning of this program. reset_max_memory_allocated()can be used to reset the starting point in tracking this metric. For example, these two functions can measure the peak allocated memory usage of each iteration in a training loop. Parameters device ( torch.device or int , optional ) – selected device. Returns statistic for the current device, given by current_device(), if deviceis None(default). Note See Memory management for more details about GPU memory management. torch.cuda.``reset_max_memory_allocated( device=None )[source] Resets the starting point in tracking maximum GPU memory occupied by tensors for a given device. See max_memory_allocated()for details. Parameters device ( torch.device or int , optional ) – selected device. Returns statistic for the current device, given by current_device(), if deviceis None(default). Note See Memory management for more details about GPU memory management. torch.cuda.``memory_cached( device=None )[source] Returns the current GPU memory managed by the caching allocator in bytes for a given device. Parameters device ( torch.device or int , optional ) – selected device. Returns statistic for the current device, given by current_device(), if deviceis None(default). Note See Memory management for more details about GPU memory management. torch.cuda.``max_memory_cached( device=None )[source] Returns the maximum GPU memory managed by the caching allocator in bytes for a given device. By default, this returns the peak cached memory since the beginning of this program. reset_max_memory_cached()can be used to reset the starting point in tracking this metric. For example, these two functions can measure the peak cached memory amount of each iteration in a training loop. Parameters device ( torch.device or int , optional ) – selected device. Returns statistic for the current device, given by current_device(), if deviceis None(default). Note See Memory management for more details about GPU memory management. torch.cuda.``reset_max_memory_cached( device=None )[source] Resets the starting point in tracking maximum GPU memory managed by the caching allocator for a given device. See max_memory_cached()for details. Parameters device ( torch.device or int , optional ) – selected device. Returns statistic for the current device, given by current_device(), if deviceis None(default). Note See Memory management for more details about GPU memory management. NVIDIA工具扩展（NVTX） torch.cuda.nvtx.``mark( msg )[source] 描述发生在某一时刻的瞬时事件。 Parameters MSG （ 串 ） - ASCII消息到与事件相关联。 torch.cuda.nvtx.``range_push( msg )[source] 推的范围到嵌套范围跨度的堆叠。返回在启动该范围的零为基础的深度。 Parameters MSG （ 串 ） - ASCII消息发送到与相关联的范围 torch.cuda.nvtx.``range_pop()[source] 弹出的范围内关断嵌套范围跨度的堆叠。返回结束范围的从零开始的深度。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"storage.html":{"url":"storage.html","title":"torch.Storage","keywords":"","body":"torch.Storage A torch.Storage是一个单一数据类型的连续，一维阵列。 每 torch.Tensor具有相同的数据类型的一个对应的存储。 classtorch.``FloatStorage[source] bfloat16() 强制转换该存储到bfloat16类型 bool() 强制转换该存储到布尔类型 byte() 强制转换该存储到byte型 char() 强制转换该存储为char类型 clone() 返回此存储的副本 copy_() cpu() 返回此存储的CPU副本，如果它不是已经在CPU上 cuda( device=None , non_blocking=False , **kwargs ) 返回此对象的CUDA内存的副本。 如果该对象已在CUDA内存和正确的设备上，则没有执行复制操作，并返回原来的对象。 Parameters 装置 （ INT ） - 目标GPU ID。默认为当前设备。 non_blocking （ 布尔 ） - 如果真和源极被固定存储器，复制将是异步相对于主机。另外，参数没有任何影响。 ** kwargs - 对于相容性，可以含有键异步代替non_blocking参数的。 data_ptr() device double() 强制转换该存储为double型 dtype element_size() fill_() float() 强制转换该存储浮动型 staticfrom_buffer() staticfrom_file( filename , shared=False , size=0 ) → Storage 如果分享是真，然后存储器被所有进程之间共享。所有的变化写入文件。如果分享是假，然后在存储所做的更改不会影响文件。 大小是在存储元件的数量。如果分享是假，则文件必须包含至少尺寸*的sizeof（类型）字节（类型是存储类型）。如果分享是真该文件将被如果需要创建。 Parameters 文件名 （ STR ） - 文件名映射 分享 （ 布尔 ） - 是否共享存储器 在存储元件的数 - 大小 （ INT ） half() 强制转换该存储一半类型 int() 强制转换该存储为int类型 is_cuda= False is_pinned() is_shared() is_sparse= False long() 强制转换该存储长型 new() pin_memory() 复制存储到固定的内存，如果它不是已经固定。 resize_() share_memory_() 移动存储到共享存储器中。 这是一个无操作为已在共享内存和CUDA储存仓库，这并不需要移动跨进程共享。在共享存储器中存储装置不能调整大小。 返回：自 short() 强制转换该存储短型 size() tolist() 返回包含此存储的元素的列表 type( dtype=None , non_blocking=False , **kwargs ) 返回类型，如果 DTYPE 不设置，否则铸件此对象为指定的类型。 如果这是正确的类型已经没有执行复制操作，并返回原来的对象。 Parameters DTYPE （ 输入 或 串 ） - 所需的类型 non_blocking （ 布尔 ） - 如果真，并且源是在固定存储器和目的地是在GPU或反之亦然，副本被相对于所述主机异步地执行。另外，参数没有任何影响。 ** kwargs - 对于相容性，可以含有键异步代替non_blocking参数的。的异步ARG被弃用。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"nn.html":{"url":"nn.html","title":"torch.nn","keywords":"","body":"torch.nn 参数 classtorch.nn.``Parameter[source] 有种张量将被认为是模块参数。 参数是 张量亚类，具有 模块 [HTG11使用时，是具有一个非常特殊的属性] S - 当他们指定为模块属性，它们会自动添加到其参数列表，并会出现如在 参数（） 迭代器。指定一个张量并没有这样的效果。这是因为人们可能会想缓存一些临时的状态，就像RNN的最后一个隐藏状态，在模型中。如果没有这样的类为 参数 ，这些临时工将获得注册过。 Parameters 数据 （ 张量 ） - 参数张量。 requires_grad （ 布尔 ， 可选 ） - 如果参数需要梯度。看到从向后 不包括子图的更多细节。默认值：真 容器 模块 classtorch.nn.``Module[source] 基类的所有神经网络模块。 你的车型也应该继承这个类。 模块也可以包含其他的模块，允许其嵌套在一个树结构。您可以分配的子模块的常规属性： import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x)) return F.relu(self.conv2(x)) 以这种方式分配的子模块将被注册，并有自己的参数转换过，当你调用 以（）等。 add_module( name , module )[source] 添加一个子模块，当前模块。 该模块可以作为使用给定名称的属性进行访问。 Parameters 名 （ 串 ） - 子模块的名称。子模块可以从该模块使用给定的名称来访问 模块 （ 模块 ） - 子模块被添加到该模块。 apply( fn )[source] 适用FN递归地对每个子模块以及自（如由。儿童（）返回）。典型用途包括初始化一个模型的参数（也见torch-NN-INIT ）。 Parameters FN （ 模块- & GT ;无） - 函数被应用到每个子模块 Returns 自 Return type 模块 例： >>> def init_weights(m): >>> print(m) >>> if type(m) == nn.Linear: >>> m.weight.data.fill_(1.0) >>> print(m.weight) >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2)) >>> net.apply(init_weights) Linear(in_features=2, out_features=2, bias=True) Parameter containing: tensor([[ 1., 1.], [ 1., 1.]]) Linear(in_features=2, out_features=2, bias=True) Parameter containing: tensor([[ 1., 1.], [ 1., 1.]]) Sequential( (0): Linear(in_features=2, out_features=2, bias=True) (1): Linear(in_features=2, out_features=2, bias=True) ) Sequential( (0): Linear(in_features=2, out_features=2, bias=True) (1): Linear(in_features=2, out_features=2, bias=True) ) buffers( recurse=True )[source] 返回在模块缓冲区的迭代器。 Parameters 递归 （ 布尔 ） - 如果为True，则产生该模块和所有子模块的缓冲器。否则，仅产生是该模块的直接成员的缓冲区。 Yields torch.Tensor - 模块缓冲器 Example: >>> for buf in model.buffers(): >>> print(type(buf.data), buf.size()) (20L,) (20L, 1L, 5L, 5L) children()[source] 返回在即时儿童模块的迭代器。 Yields 模块 - 一个子模块 cpu()[source] 移动所有模型参数和缓冲区的CPU。 Returns self Return type Module cuda( device=None )[source] 移动所有模型参数和缓冲区的GPU。 这也使得相关的参数和缓冲区不同的对象。所以应该构建优化模块是否将生活在GPU同时进行优化之前被调用。 Parameters 装置 （ INT ， 可选 ） - 如果指定，所有的参数将被复制到该设备 Returns self Return type Module double()[source] 施放所有浮点参数和缓冲液以双数据类型。 Returns self Return type Module dump_patches= False 这允许更好BC支持load_state_dict（）。在 state_dict（），版本号将被保存为在返回的状态字典的属性 _metadata ，因此酸洗。 _metadata 是与后面状态字典的命名约定键的字典。参见_load_from_state_dict如何在加载使用该信息。 如果添加了新的参数/缓冲器/从模块中取出，这个数字将被碰撞，以及模块的 _load_from_state_dict 方法可以比较的版本号，并做适当的修改，如果状态字典是从改变之前。 eval()[source] 设置在评估模式下的模块。 这只有在某些模块没有任何影响。见特定模块的单证在培训/评估模式，如果他们受到影响，例如他们的行为的细节 降，BatchNorm等 这相当于与 self.train（假）。 Returns self Return type Module extra_repr()[source] 设置模块的额外代表性 要打印定制额外的信息，你应该在你自己的模块重新实现此方法。既单行和多行字符串是可接受的。 float()[source] 施放所有浮点参数和缓冲区浮动数据类型。 Returns self Return type Module forward( *input )[source] 定义在每个呼叫进行计算。 应该由所有子类覆盖。 注意 虽然必须在这个函数中定义的直传食谱，应该叫 模块实例之后，而不是这个，因为前者需要运行的护理注册挂钩，而后者默默地忽略它们。 half()[source] 施放所有浮点参数和缓冲液以一半数据类型。 Returns self Return type Module load_state_dict( state_dict , strict=True )[source] 份参数和缓冲液从 state_dict到这个模块及其后代。如果严格是真，则 键state_dict 必须完全符合本模块的 state_dict（）函数的返回键。 Parameters state_dict （ DICT ） - 包含参数和持久性缓冲区的字典。 严格 （ 布尔 ， 可选 ） - 是否严格执行，在键state_dict匹配由该模块的 state_dict（）函数返回的键。默认值：真 Returns missing_keys 是STR的包含丢失密钥的列表 unexpected_keys 是STR的含有意想不到的键的列表 Return type NamedTuple与missing_keys和unexpected_keys字段 modules()[source] 返回在网络中的所有模块的迭代器。 Yields 网络中的模块 - 模块 Note 重复模块只返回一次。在以下示例中，L将只返回一次。 Example: >>> l = nn.Linear(2, 2) >>> net = nn.Sequential(l, l) >>> for idx, m in enumerate(net.modules()): print(idx, '->', m) 0 -> Sequential( (0): Linear(in_features=2, out_features=2, bias=True) (1): Linear(in_features=2, out_features=2, bias=True) ) 1 -> Linear(in_features=2, out_features=2, bias=True) named_buffers( prefix='' , recurse=True )[source] 返回在模块缓冲区的迭代器，产生缓冲中的两个名字以及缓冲区本身。 Parameters 前缀 （ STR ） - 前缀时，预先准备所有缓冲器的名字。 recurse ( bool) – if True, then yields buffers of this module and all submodules. Otherwise, yields only buffers that are direct members of this module. Yields （字符串，torch.Tensor） - 元组包含名称和缓冲 Example: >>> for name, buf in self.named_buffers(): >>> if name in ['running_var']: >>> print(buf.size()) named_children()[source] 返回在即时儿童模块的迭代器，产生模块的两个名字，以及模块本身。 Yields （字符串，模块） - 含有名称和子模块的Tuple Example: >>> for name, module in model.named_children(): >>> if name in ['conv4', 'conv5']: >>> print(module) named_modules( memo=None , prefix='' )[source] 返回网络，在所有模块的迭代器，产生模块的两个名字，以及模块本身。 Yields （字符串，模块） - 名称和模块的元组 Note Duplicate modules are returned only once. In the following example, lwill be returned only once. Example: >>> l = nn.Linear(2, 2) >>> net = nn.Sequential(l, l) >>> for idx, m in enumerate(net.named_modules()): print(idx, '->', m) 0 -> ('', Sequential( (0): Linear(in_features=2, out_features=2, bias=True) (1): Linear(in_features=2, out_features=2, bias=True) )) 1 -> ('0', Linear(in_features=2, out_features=2, bias=True)) named_parameters( prefix='' , recurse=True )[source] 返回在模块参数的迭代器，产生参数的两个名称以及参数本身。 Parameters 前缀 （ 海峡 ） - 前缀预先考虑到所有的参数名称。 递归 （ 布尔 ） - 如果为True，则产生该模块和所有子模块的参数。否则，仅产生是该模块的直接成员参数。 Yields （字符串，参数） - 包含元组的名称和参数 Example: >>> for name, param in self.named_parameters(): >>> if name in ['bias']: >>> print(param.size()) parameters( recurse=True )[source] 返回在模块参数的迭代器。 这通常是通过给优化。 Parameters recurse ( bool) – if True, then yields parameters of this module and all submodules. Otherwise, yields only parameters that are direct members of this module. Yields 参数 - 模块参数 Example: >>> for param in model.parameters(): >>> print(type(param.data), param.size()) (20L,) (20L, 1L, 5L, 5L) register_backward_hook( hook )[source] 寄存器模块上的向后钩。 钩将被称为每次相对于梯度以模块输入被计算。钩子应该具有以下特征： hook(module, grad_input, grad_output) -> Tensor or None 的grad_input和grad_output可以是元组如果模块具有多个输入或输出。钩不应修改其参数，但它可以任选地返回一个新的梯度相对于输入，将代替grad_input在随后的计算中使用。 Returns 可以使用的一个手柄通过调用handle.remove（）以去除所添加的钩 Return type torch.utils.hooks.RemovableHandle 警告 当前的实现不会对复杂的 模块执行许多操作所呈现的行为。在一些失败的情况下，grad_input和grad_output将只包含对的输入和输出的一个子集的梯度​​。对于这样的 模块，则应该使用 torch.Tensor.register_hook（） 直接在一个特定的输入或输出，以获得所需的梯度。 register_buffer( name , tensor )[source] 添加一个持久缓冲区到模块。 这通常是用于注册不应被认为是一个模型参数的缓冲器。例如，BatchNorm的running_mean不是参数，但是持久状态的一部分。 缓冲区可以为使用给定的名称属性来访问。 Parameters 名称 （ 串 ） - 缓冲的名称。缓冲器可以从该模块使用给定的名称来访问 张量 （ 张量 ） - 缓冲液进行注册。 Example: >>> self.register_buffer('running_mean', torch.zeros(num_features)) register_forward_hook( hook )[source] 寄存器模块上的前钩。 钩将被称为每次之后 向前（）已经计算的输出。它应该具有以下特征： hook(module, input, output) -> None or modified output 钩可以修改的输出。它可以修改输入就地，但它不会对转发的影响，因为这是后 向前称为（）被调用。 Returns a handle that can be used to remove the added hook by calling handle.remove() Return type torch.utils.hooks.RemovableHandle register_forward_pre_hook( hook )[source] 寄存器模块上的前预挂钩。 钩将每次调用之前 向前（）被调用。它应该具有以下特征： hook(module, input) -> None or modified input 钩可以修改输入。用户可以返回的元组或在钩的单个修饰的值。最后，我们将值插入到一个元组如果返回一个值（除非该值已经是一个元组）。 Returns a handle that can be used to remove the added hook by calling handle.remove() Return type torch.utils.hooks.RemovableHandle register_parameter( name , param )[source] 添加一个参数到模块。 该参数可以作为使用定名称的属性来访问。 Parameters 名称 （ 串 ） - 参数的名称。该参数可以从该模块使用给定的名称来访问 PARAM （ 参数 ） - 参数被添加到该模块。 requires_grad_( requires_grad=True )[source] 改变，如果autograd应在此模块中的参数记录等操作。 此方法设置的参数requires_grad就地属性。 此方法是用于微调或单独训练的模型的部分（例如，GAN培训）冷冻所述模块的一部分有帮助的。 Parameters requires_grad （ 布尔 ） autograd是否应该在该模块中的参数记录操作。默认值：真 [HTG9。 Returns self Return type Module state_dict( destination=None , prefix='' , keep_vars=False )[source] 返回包含模块的整体状态的字典。 这两个参数和持久性缓冲液（例如运行平均值）也包括在内。键对应的参数和缓冲区名字。 Returns 包含模块的整个状态的字典 Return type 字典 Example: >>> module.state_dict().keys() ['bias', 'weight'] to( *args , **kwargs )[source] 移动和/或注塑参数和缓冲区。 这可以被称为 to( device=None , dtype=None , non_blocking=False )[source] to( dtype , non_blocking=False )[source] to( tensor , non_blocking=False )[source] 它的签名是类似于 torch.Tensor.to（），但仅接受浮点所需的DTYPE秒。此外，这种方法将只投浮点参数和缓冲液以DTYPE（如有）。积分参数和缓冲液将被移至装置，如果给定，但与dtypes不变。当non_blocking被设定，它会尝试转换/如果可能异步相对于移动到主机，例如，移动CPU张量与固定内存到CUDA设备。 请参见下面的例子。 Note 此方法会修改就地模块。 Parameters 装置 （torch.device） - 的参数和缓冲器在该模块中的所期望的设备 此模块中的浮点参数和缓冲液的所希望的浮点类型 - DTYPE （torch.dtype） 张量 （ torch.Tensor ） - 张量，其D型细胞和装置所需的D型细胞和装置此模块中的所有参数和缓冲器 Returns self Return type Module Example: >>> linear = nn.Linear(2, 2) >>> linear.weight Parameter containing: tensor([[ 0.1913, -0.3420], [-0.5113, -0.2325]]) >>> linear.to(torch.double) Linear(in_features=2, out_features=2, bias=True) >>> linear.weight Parameter containing: tensor([[ 0.1913, -0.3420], [-0.5113, -0.2325]], dtype=torch.float64) >>> gpu1 = torch.device(\"cuda:1\") >>> linear.to(gpu1, dtype=torch.half, non_blocking=True) Linear(in_features=2, out_features=2, bias=True) >>> linear.weight Parameter containing: tensor([[ 0.1914, -0.3420], [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1') >>> cpu = torch.device(\"cpu\") >>> linear.to(cpu) Linear(in_features=2, out_features=2, bias=True) >>> linear.weight Parameter containing: tensor([[ 0.1914, -0.3420], [-0.5112, -0.2324]], dtype=torch.float16) train( mode=True )[source] 设置在训练模式下的模块。 This has any effect only on certain modules. See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g. Dropout, BatchNorm, etc. Parameters 模式 （ 布尔 ） - 是否设定训练模式（真）或评估模式（假）。默认值：真 [HTG17。 Returns self Return type Module type( dst_type )[source] 施放的所有参数和缓冲液以dst_type。 Parameters dst_type （ 输入 或 串 ） - 所需的类型 Returns self Return type Module zero_grad()[source] 将所有模型参数为零的梯度。 序贯 classtorch.nn.``Sequential( *args )[source] 顺序容器。模块将被添加到它在它们在构造函数中传递的顺序。可替代地，模块的有序字典也可以通过。 为了便于理解，这里是一个小例子： # Example of using Sequential model = nn.Sequential( nn.Conv2d(1,20,5), nn.ReLU(), nn.Conv2d(20,64,5), nn.ReLU() ) # Example of using Sequential with OrderedDict model = nn.Sequential(OrderedDict([ ('conv1', nn.Conv2d(1,20,5)), ('relu1', nn.ReLU()), ('conv2', nn.Conv2d(20,64,5)), ('relu2', nn.ReLU()) ])) ModuleList classtorch.nn.``ModuleList( modules=None )[source] 持有列表子模块。 ModuleList可以被索引像一个普通的Python列表，但它包含的模块正确注册，并且将所有 [HTG8可见]模块的方法。 Parameters 模块 （ 可迭代 ， 可选 ） - 模块的一个可迭代添加 Example: class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)]) def forward(self, x): # ModuleList can act as an iterable, or be indexed using ints for i, l in enumerate(self.linears): x = self.linears[i // 2](x) + l(x) return x append( module )[source] 追加给定的模块到列表的末尾。 Parameters 模块 （ nn.Module ） - 模块追加 extend( modules )[source] 从追加一个Python模块可迭代到列表的末尾。 Parameters 模块 （ 可迭代 ） - 模块的可迭代追加 insert( index , module )[source] 列表中的给定索引前插入一个特定的模块。 Parameters 索引 （ INT ） - 要插入的索引。 模块 （ nn.Module ） - 模块插入 ModuleDict classtorch.nn.``ModuleDict( modules=None )[source] 持有字典子模块。 ModuleDict可以被索引像一个普通的Python字典，但它包含的模块正确注册，并且将所有 [HTG8可见]模块的方法。 ModuleDict是尊重了一个 有序 字典 插入的顺序，并 在 更新（）的顺序进行合并OrderedDict或另一个 ModuleDict（将参数 更新（））。 需要注意的是 更新（）与其他无序映射类型（例如，Python的平原快译通）不保留合并后的映射的顺序。 Parameters 模块 （ 可迭代 ， 可选 ） - （字符串：模块）的映射（字典）或键 - 值对的一个可迭代型的（字符串，模块） Example: class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.choices = nn.ModuleDict({ 'conv': nn.Conv2d(10, 10, 3), 'pool': nn.MaxPool2d(3) }) self.activations = nn.ModuleDict([ ['lrelu', nn.LeakyReLU()], ['prelu', nn.PReLU()] ]) def forward(self, x, choice, act): x = self.choices[choice](x) x = self.activations[act](x) return x clear()[source] 取下ModuleDict的所有项目。 items()[source] 返回ModuleDict键/值对的迭代。 keys()[source] 返回ModuleDict键的迭代。 pop( key )[source] 从ModuleDict删除键和返回它的模块。 Parameters 键 （ 串 ） - 键从ModuleDict弹出 update( modules )[source] 更新 ModuleDict与来自映射键值对或可迭代，覆盖现有的密钥。 Note 如果模块是OrderedDict，AModuleDict或键 - 值对的一个可迭代，它在新的元素的顺序被保留。 Parameters 模块 （ 可迭代 ） - 映射（字典）从字符串 模块，或密钥的迭代值对类型（字符串， 模块） values()[source] 返回ModuleDict值的迭代。 参数列表 classtorch.nn.``ParameterList( parameters=None )[source] 持有列表参数。 参数列表可以被索引像一个普通的Python列表，但参数它所包含正确注册，并且将所有 [HTG8可见]模块的方法。 Parameters 参数 （ 可迭代 ， 可选 ） - 的 参数可迭代添加 Example: class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for i in range(10)]) def forward(self, x): # ParameterList can act as an iterable, or be indexed using ints for i, p in enumerate(self.params): x = self.params[i // 2].mm(x) + p.mm(x) return x append( parameter )[source] 附加在列表的最后一个给定的参数。 Parameters 参数 （ nn.Parameter ） - 参数到附加 extend( parameters )[source] 从追加一个Python参数迭代到列表的末尾。 Parameters 参数 （ 可迭代 ） - 的参数可迭代到追加 ParameterDict classtorch.nn.``ParameterDict( parameters=None )[source] 拥有一本字典的参数。 ParameterDict能够被索引像一个普通的Python字典，但参数它所包含正确注册，并且将所有模块的方法可见。 ParameterDict是尊重了一个 有序 字典 the order of insertion, and 在 更新（）的顺序进行合并OrderedDict或另一个 ParameterDict（将参数 更新（））。 需要注意的是 更新（）与其他无序映射类型（例如，Python的平原快译通）不保留合并后的映射的顺序。 Parameters 参数 （ 可迭代 ， 可选 ） - （串的映射（字典）： 参数）或类型的键 - 值对（串的迭代， 参数） Example: class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.params = nn.ParameterDict({ 'left': nn.Parameter(torch.randn(5, 10)), 'right': nn.Parameter(torch.randn(5, 10)) }) def forward(self, x, choice): x = self.params[choice].mm(x) return x clear()[source] 取下ParameterDict的所有项目。 items()[source] 返回ParameterDict键/值对的迭代。 keys()[source] 返回ParameterDict键的迭代。 pop( key )[source] 从ParameterDict删除键和返回它的参数。 Parameters 键 （ 串 ） - 键从ParameterDict弹出 update( parameters )[source] 更新 ParameterDict与来自映射键值对或可迭代，覆盖现有的密钥。 Note 如果参数是OrderedDict，AParameterDict或键 - 值对的一个可迭代，它在新的元素的顺序被保留。 Parameters 参数 （ 可迭代 ） - 一个从串映射（字典）为 参数，或密钥的迭代值对类型（字符串， 参数） values()[source] 返回ParameterDict值的迭代。 卷积层 Conv1d classtorch.nn.``Conv1d( in_channels , out_channels , kernel_size , stride=1 , padding=0 , dilation=1 , groups=1 , bias=True , padding_mode='zeros' )[source] 施加1D卷积在几个输入平面组成的输入信号。 在最简单的情况下，所述层的与输入大小 的输出值（ N C 在 ， L ） （N，C {\\文本{在}}，L） （ N ， C 在 ， L ） 和输出 （ N ， C OUT ， L OUT ） （N，C {\\文本{出}}，L _ {\\文本{出}}） （ N ， C OUT ， 大号 OUT ） 可以精确地描述为： out(Ni,Coutj)=bias(Coutj)+∑k=0Cin−1weight(Coutj,k)⋆input(Ni,k)\\text{out}(Ni, C{\\text{out}j}) = \\text{bias}(C{\\text{out}j}) + \\sum{k = 0}^{C{in} - 1} \\text{weight}(C{\\text{out}_j}, k) \\star \\text{input}(N_i, k) out(Ni​,Coutj​​)=bias(Coutj​​)+k=0∑Cin​−1​weight(Coutj​​,k)⋆input(Ni​,k) 其中 ⋆ \\星 ⋆ 是有效的互相关运算符， N N N 是一个批量大小， C C C 表示的数的信道， L L L 是人信号序列的ength。 步幅控制用于交叉相关，单个数字或一个元素的元组的步幅。 填充控制隐含零填补处理的双方的量为填充点数。 扩张控制内核点之间的间隔;也被称为劈窗算法。这是很难形容，但这种链接有什么扩张做一个很好的可视化。 基团控制输入和输出之间的连接。 in_channels和out_channels必须都是由基团整除。例如， * 在基团= 1，所有的输入被卷积以所有输出。 > * 在组= 2，操作变得等效于具有由一侧上的两个CONV层侧，每个看到一半的输入通道，和产生一半的输出通道，并且两个随后连接在一起。 > * 在基团= `in_channels`中，每个输入信道进行卷积以它自己的一套过滤器，大小的 ⌊ O U T _ C H 一 n的 n的 E L S i的 n的 C H 一 n的 n的 E L S ⌋ \\左\\ lfloor \\压裂{出\\ _channels} {在\\ _channels} \\右\\ rfloor ⌊ i的 n的 C H 一 n的 n的 E L S O U T _ C H 一 n的 n的 E L S ⌋ 。 Note 根据你的内核的大小，几个（最后）输入的列可能会丢失，因为它是一个有效的互相关，而不是一个完整的互相关 。它是由用户添加适当的填充。 Note 当基团== in_channels 和 out_channels == K * in_channels ，其中 K 是一个正整数，该操作也被称为在文献中作为深度方向卷积。 换句话说，为的大小 （ N ，输入 C i的 n的 ， L i的 n的 ） （N，C {IN}，L {在}） （ N ， C i的 n的 ， L 一世 n的 ） ，具有深度方向乘法器深度方向卷积 K ，可通过参数[构造HTG130] （ C 在 = C i的 n的 ， C OUT = C i的 n的 × K ， 。 。 。 ， 基团 = C i的 n的 ） （C \\文本{IN} = C {}中，C \\文本{出} = C {在} \\倍K，.. 。，\\文本{基} = C_ {在}） （ C 在 = C ​​ i的 n的 ， C OUT = C i的 n的 × K ， 。 。 。 ， 基团 = C I n的 ） 。 Note 在使用CUDA后端与CuDNN当某些情况下，这种操作者可以选择不确定性的算法来提高性能。如果这是不可取的，你可以尝试通过设置torch.backends.cudnn.deterministic = 真[使操作确定性（可能以性能为代价） HTG6]。请参阅 重复性 为背景的音符。 Parameters 在输入图像中通道数 - in_channels （ INT ） out_channels （ INT ） - 由卷积产生通道数 kernel_size （ INT 或 元组 ） - 的卷积内核的大小 步幅 （ INT 或 元组 ， 可选的 ） - 卷积的步幅。默认值：1 填充 （ INT 或 元组 ， 可选的 ） - 补零加到输入的两侧。默认值：0 padding_mode （ 串 ， 可选 ） - 零 扩张 （ INT 或 元组 ， 可选的 ） - 内核元件之间的间隔。默认值：1 基团 （ INT ， 可选 ） - 从输入信道到输出通道阻塞的连接的数目。默认值：1 偏压 （ 布尔 ， 可选 ） - 如果真，增加了一个可学习偏压到输出端。默认值：真 Shape: 输入： （ N ， C i的 n的 ， L i的 n的 ） （N，C {IN}，L {在}） （ N ， C i的 n的 ， L i的 n的 ） 输出： （ N ， C O U T ， L O U T ） （N，C {出}，L {出}） （ N ， C O U T ， L [HTG1 05] O U T ） 其中 Lout=⌊Lin+2×padding−dilation×(kernelsize−1)−1stride+1⌋L{out} = \\left\\lfloor\\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation} \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor Lout​=⌊strideLin​+2×padding−dilation×(kernel_size−1)−1​+1⌋ Variables 〜Conv1d.weight （ 张量 ） - 的形状 [该模块的可学习权重HTG11] （ outchannels ， in_channels 基团 ， kernel_size ） （\\文本{出\\ _channels}，\\压裂{\\文本{在\\ _channels}} {\\文本{基}}，\\文本{内核\\ _size}） （ out_channels ， 基团 in_channels [H TG86] ， kernel_size ） 。这些权重的值是从 取样U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K ， K [H TG206] ） 其中 K = 1 C 在 * kernel_size K = \\压裂{1} {C \\文本{IN} \\文本{内核\\ _size}} ​​ K = ç 在 kernel_size 1 〜Conv1d.bias （ 张量 ） - 形状（outchannels）的模块的可学习偏差。如果偏压是真，然后这些权重的值是从 取样 U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K K ） 其中 K = 1 C 在 * kernel_size K = \\压裂{1} {C \\文本{IN} \\文本{内核\\ _size}} K = C 在 kernel_size 1 例子： >>> m = nn.Conv1d(16, 33, 3, stride=2) >>> input = torch.randn(20, 16, 50) >>> output = m(input) Conv2d classtorch.nn.``Conv2d( in_channels , out_channels , kernel_size , stride=1 , padding=0 , dilation=1 , groups=1 , bias=True , padding_mode='zeros' )[source] 施加二维卷积在几个输入平面组成的输入信号。 在最简单的情况下，所述层的与输入大小 的输出值（ N C 在 ， H ， W ） （N，C {\\文本{在}}，H，W） （ N ， C 在 ， H ， W ） 和输出 （ N ， C OUT ， H OUT ， W OUT ） （N，C {\\文本{出}}，H {\\文本{出}}，W {\\文本{出}} ） （ N ， C OUT ， H OUT ， W OUT ） 可以精确地描述为： out(Ni,Coutj)=bias(Coutj)+∑k=0Cin−1weight(Coutj,k)⋆input(Ni,k)\\text{out}(Ni, C{\\text{out}j}) = \\text{bias}(C{\\text{out}j}) + \\sum{k = 0}^{C{\\text{in}} - 1} \\text{weight}(C{\\text{out}_j}, k) \\star \\text{input}(N_i, k) out(Ni​,Coutj​​)=bias(Coutj​​)+k=0∑Cin​−1​weight(Coutj​​,k)⋆input(Ni​,k) 其中 ⋆ \\星 ⋆ 是有效的2D 互相关运算符， N N N 是一个批量大小， C C C 表示的数信道， H H H 是以像素为单位输入平面的高度，并 W W W 是以像素为单位的宽度。 步幅控制用于交叉相关，单个数字或一个元组的步幅。 填充控制隐含零填补处理的双方的量为填充点数为每个维度。 dilationcontrols the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilationdoes. groupscontrols the connections between inputs and outputs. in_channelsand out_channelsmust both be divisible by groups. For example, * At groups=1, all inputs are convolved to all outputs. > * At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated. > * 在基团= `in_channels`中，每个输入信道进行卷积以它自己的一套过滤器，大小： ⌊ O U T _ C H 一 n的 n的 E L S i的 n的 C H 一 n的 n的 E L S ⌋ \\左\\ lfloor \\压裂{出\\ _channels} {在\\ _channels} \\右\\ rfloor ⌊ [HTG9 1] i的 n的 C H 一 N n的 E L S O U T _ C H 一 n的 n的 E L S ⌋ 。 参数kernel_size，步幅，填充，扩张可以是： 单一INT- 在这种情况下相同的值被用于高度和宽度尺寸 > 一个元组的两个整数 - 在这种情况下，第一个 INT用来为高度尺寸，并且所述第二 INT 为宽度尺寸 > > Note 根据你的内核的大小，几个（最后）输入的列可能会丢失，因为它是一个有效的互相关，而不是一个完整的互相关 。它是由用户添加适当的填充。 Note When groups == in_channels and out_channels == K * in_channels, where K is a positive integer, this operation is also termed in literature as depthwise convolution. 换句话说，为的大小 （ N ，输入 C i的 n的 ， H i的 n的 ， W i的 n的 ） （N，C {IN}，H {IN}，W {在}） （ N ， ç i的 n的 ， H i的 n的 ， W i的 n的 ） ，具有深度方向乘法器深度方向卷积 K ，可由参数 （ i的 n的 [H构建TG191] C H 一 n的 n的 E L S = C i的 n的 ， O U T C H 一个 n的 n的 E L S = C i的 n的 × K ， 。 。 。 ​​， 克 R O U P S = C i的 n的 ） （在\\ _channels = C {}中，出\\ channels = C {在} \\倍K，...，组= C {在}） （ i的 n的 C H 一 n的 n的 E L S = C i的 n的 O U T _ C H 一 n的 n的 E L S = C i的 n的 × K ， 。 。 。 ， 克 R O U P S = C i的 n的 ） 。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters in_channels ( int) – Number of channels in the input image out_channels ( int) – Number of channels produced by the convolution kernel_size ( int or tuple) – Size of the convolving kernel stride ( int or tuple , optional ) – Stride of the convolution. Default: 1 填充 （ INT 或 元组 ， 可选的 ） - 补零加到输入的两侧。默认值：0 padding_mode ( string , optional ) – zeros 扩张 （ INT 或 元组 ， 可选的 ） - 内核元件之间的间隔。默认值：1 基团 （ INT ， 可选 ） - 从输入信道到输出通道阻塞的连接的数目。默认值：1 bias ( bool , optional ) – If True, adds a learnable bias to the output. Default: True Shape: 输入： （ N ， C i的 n的 ， H i的 n的 ， W i的 n的 ） （N，C {IN}，H {IN}，W_ {在}） （ N ， C i的 n的 ， H i的 n的 ， W i的 N ） 输出： （ N ， C O U T ， H O U T ， W O U T ） （N，C {出}，H {出} ，W_ {出}） （ N ， C O U T [HT G104] ， H O U T ， W O U T ） 其中 Hout=⌊Hin+2×padding[0]−dilation[0]×(kernelsize[0]−1)−1stride[0]+1⌋H{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0] \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor Hout​=⌊stride[0]Hin​+2×padding[0]−dilation[0]×(kernel_size[0]−1)−1​+1⌋ Wout=⌊Win+2×padding[1]−dilation[1]×(kernelsize[1]−1)−1stride[1]+1⌋W{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1] \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor Wout​=⌊stride[1]Win​+2×padding[1]−dilation[1]×(kernel_size[1]−1)−1​+1⌋ Variables 〜Conv2d.weight （ 张量 ） - 的形状 [该模块的可学习权重HTG11] （ outchannels ， in_channels 基团 ， （\\文本{出\\ _channels}，\\压裂{\\文本{在\\ _channels}} {\\文本{基}}， （ out_channels ， 基团 in_channels [HTG8 9] ， kernel_size [0] ， kernel_size [1] ） \\文本{内核\\ _size [0]}，\\文本{内核\\ _size [1]}） kernel_size [0] ， kernel_size [1] ） 。这些权重的值是从 取样U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K ， K [H TG236] ） 其中 ​​ K = 1 C 在 * Π i的 = 0 1 kernel_size [ i的 K = \\压裂{1} {C \\文本{IN} \\ prod_ {I = 0} ^ {1} \\文本{内核\\ _size} [I]} K = C 在 Π i的 = 0 1 kernel_size [ i的 1 〜Conv2d.bias （ 张量 ） - 形状（outchannels）的模块的可学习偏差。如果偏压是真，然后这些权重的值是从 取样 U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K K ） 其中 K = 1 C 在 * Π i的 = 0 1 kernel_size [ i的 K = \\压裂{1} {C \\文本{IN} \\ prod_ {I = 0} ^ {1} \\文本{内核\\ _size} [I]} K = C 在 Π i的 = 0 ​​ 1 kernel_size [ i的 1 Examples: >>> # With square kernels and equal stride >>> m = nn.Conv2d(16, 33, 3, stride=2) >>> # non-square kernels and unequal stride and with padding >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2)) >>> # non-square kernels and unequal stride and with padding and dilation >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1)) >>> input = torch.randn(20, 16, 50, 100) >>> output = m(input) Conv3d classtorch.nn.``Conv3d( in_channels , out_channels , kernel_size , stride=1 , padding=0 , dilation=1 , groups=1 , bias=True , padding_mode='zeros' )[source] 施加三维卷积在几个输入平面组成的输入信号。 在最简单的情况下，所述层的与输入大小 的输出值（ N C i的 n的 ， d ， H ， W ） （N，C {IN}，d ，H，W） （ N ， C i的 n的 ， d ， H [H T G99] W ） 和输出 （ N ， C O U T ， d O U T ， H O U 吨 ， W O U T ） （N，C {出}，D {出}，H {出}，W_ {出}） （ N [HTG1 91] ， C O U T ， d O U T ， ​​ H O U T ， W O U T ） 可以精确地描述为： out(Ni,Coutj)=bias(Coutj)+∑k=0Cin−1weight(Coutj,k)⋆input(Ni,k)out(Ni, C{outj}) = bias(C{outj}) + \\sum{k = 0}^{C{in} - 1} weight(C{out_j}, k) \\star input(N_i, k) out(Ni​,Coutj​​)=bias(Coutj​​)+k=0∑Cin​−1​weight(Coutj​​,k)⋆input(Ni​,k) 其中 ⋆ \\星 ⋆ 是有效的3D 互相关操作者 步幅控制用于互相关的步幅。 paddingcontrols the amount of implicit zero-paddings on both sides for paddingnumber of points for each dimension. 扩张控制内核点之间的间隔;也被称为劈窗算法。这是很难形容，但这种链接有什么扩张做一个很好的可视化。 groupscontrols the connections between inputs and outputs. in_channelsand out_channelsmust both be divisible by groups. For example, * At groups=1, all inputs are convolved to all outputs. > * At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated. > * 在基团= `in_channels`中，每个输入信道进行卷积以它自己的一套过滤器，大小的 ⌊ O U T _ C H 一 n的 n的 E L S i的 n的 C H 一 n的 n的 E L S ⌋ \\左\\ lfloor \\压裂{出\\ _channels} {在\\ _channels} \\右\\ rfloor ⌊ i的 n的 C H 一 n的 n的 E L S O U T _ C H 一 n的 n的 E L S ⌋ 。 The parameters kernel_size, stride, padding, dilationcan either be: 单一INT- 在这种情况下相同的值被用于深度，高度和宽度尺寸 > 一个元组三个整数 - 在这种情况下，第一个 INT用于深度尺寸，所述第二 INT 为高度维度和第三 INT 为宽度尺寸 > > Note Depending of the size of your kernel, several (of the last) columns of the input might be lost, because it is a valid cross- correlation, and not a full cross-correlation. It is up to the user to add proper padding. Note When groups == in_channels and out_channels == K * in_channels, where K is a positive integer, this operation is also termed in literature as depthwise convolution. 换句话说，为的大小 （ N ，输入 C i的 n的 ， d i的 n的 ， H i的 n的 ， W i的 n的 ） （N，C {IN}，D {IN}，H {IN}，W {在}） （ N ， C i的 n的 ， d i的 n的 ， H i的 N ， W i的[H TG199] n的 ） ，具有深度方向乘法器深度方向卷积 K ，可以通过参构造 （ i的 n的 C H 一 n的 n的 E L S = C i的 n的 ， 问题o U T C H 一 n的 n的 E L S = C i的 n的 × K ， 。 。 。 ， 克 R O U P S = C i的 n的 ） （在\\ channels = C {}中，出\\ channels = C {在} \\倍K，...，组= C {在}） （ i的 n的 C H 一 n的 n的 E L S = C i的 n的 O U T _ C H 一 n的 n的 E L S = C i的 n的 × K ， 。 。 。 ， 克 R O U P S = C i的 n的 ） 。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters in_channels ( int) – Number of channels in the input image out_channels ( int) – Number of channels produced by the convolution kernel_size ( int or tuple) – Size of the convolving kernel stride ( int or tuple , optional ) – Stride of the convolution. Default: 1 填充 （ INT 或 元组 ， 可选的 ） - 补零加到输入的所有三个侧面。默认值：0 padding_mode ( string , optional ) – zeros dilation ( int or tuple , optional ) – Spacing between kernel elements. Default: 1 groups ( int , optional ) – Number of blocked connections from input channels to output channels. Default: 1 bias ( bool , optional ) – If True, adds a learnable bias to the output. Default: True Shape: 输入： （ N ， C i的 n的 ， d i的 n的 ， H i的 n的 ， W i的 n的 ） （N，C {IN}，D {IN}，H {IN}，W {在}） （ N ， C i的 n的 ， d i的 n的 ， H i的 n的 ， W i的 n的 ） 输出： （ N ， C O U T ， d O U T ， H O U T ， W O U T ） （N，C {出}，D {出}，H {出}，W {出}） （ N C O U 吨[H TG103] ， d O U T ， H O U T ， [H TG201] W O U T ） 其中 Dout=⌊Din+2×padding[0]−dilation[0]×(kernelsize[0]−1)−1stride[0]+1⌋D{out} = \\left\\lfloor\\frac{D_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0] \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor Dout​=⌊stride[0]Din​+2×padding[0]−dilation[0]×(kernel_size[0]−1)−1​+1⌋ Hout=⌊Hin+2×padding[1]−dilation[1]×(kernelsize[1]−1)−1stride[1]+1⌋H{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1] \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor Hout​=⌊stride[1]Hin​+2×padding[1]−dilation[1]×(kernel_size[1]−1)−1​+1⌋ Wout=⌊Win+2×padding[2]−dilation[2]×(kernelsize[2]−1)−1stride[2]+1⌋W{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[2] - \\text{dilation}[2] \\times (\\text{kernel\\_size}[2] - 1) - 1}{\\text{stride}[2]} + 1\\right\\rfloor Wout​=⌊stride[2]Win​+2×padding[2]−dilation[2]×(kernel_size[2]−1)−1​+1⌋ Variables 〜Conv3d.weight （ 张量 ） - 的形状 [该模块的可学习权重HTG11] （ outchannels ， in_channels 基团 ， （\\文本{出\\ _channels}，\\压裂{\\文本{在\\ _channels}} {\\文本{基}}， （ out_channels ， 基团 in_channels [HTG8 9] ， kernel_size [0] ， kernel_size [1] ， kernel_size [2] ） \\文本{内核\\ _size [0]}，\\文本{内核\\ _size [1]}，\\文本{内核\\ _size [2 ]}） kernel_size [0] ， kernel_size [1] ， kernel_size [2] ） 。这些权重的值是从 取样U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K ， K [H TG248] ​​ ） 其中 K = 1 C 在 * Π i的 = 0 2 kernel_size [ i的 K = \\压裂{1} {C \\文本{IN} \\ prod_ {I = 0} ^ {2} \\文本{内核\\ _size} [I]} K = C 在 Π i的 = 0 2 kernel_size [ i的 1 〜Conv3d.bias （ 张量 ） - 形状（outchannels）的模块的可学习偏差。如果偏压是真，然后这些权重的值是从 取样 U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K K ） 其中 K = 1 C 在 * Π i的 = 0 2 kernel_size [ i的 K = \\压裂{1} {C \\文本{IN} \\ prod_ {I = 0} ^ {2} \\文本{内核\\ _size} [I]} K = C 在 Π i的 = 0 ​​ 2 kernel_size [ i的 1 Examples: >>> # With square kernels and equal stride >>> m = nn.Conv3d(16, 33, 3, stride=2) >>> # non-square kernels and unequal stride and with padding >>> m = nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(4, 2, 0)) >>> input = torch.randn(20, 16, 10, 50, 100) >>> output = m(input) ConvTranspose1d classtorch.nn.``ConvTranspose1d( in_channels , out_channels , kernel_size , stride=1 , padding=0 , output_padding=0 , groups=1 , bias=True , dilation=1 , padding_mode='zeros' )[source] 应用在多个输入平面构成的输入图像的1D换位卷积运算。 此模块可以被视为Conv1d的梯度相对于它的输入。它也被称为一分级-跨距卷积或去卷积（尽管它不是一个实际的去卷积运算）。 stridecontrols the stride for the cross-correlation. 填充控制隐含零补白的两侧为的量扩张 * （kernel_size - 1） - 填充数量的点。请参阅下面注释详情。 output_padding控制添加到输出形状的一侧上的额外尺寸。请参阅下面注释详情。 dilationcontrols the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilationdoes. groupscontrols the connections between inputs and outputs. in_channelsand out_channelsmust both be divisible by groups. For example, * At groups=1, all inputs are convolved to all outputs. > * At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated. > * 在基团= `in_channels`中，每个输入信道进行卷积以它自己的一套滤波器（大小[的 HTG10]⌊ O U T _ C H 一 n的 n的 E L S i的 n的 C H 一 n的 n的 E L S ⌋ \\左\\ lfloor \\压裂{出\\ _channels} {在\\ _channels} \\右\\ rfloor ⌊ i的 n的 C H 一 n的 n的 E L S O U T _ C H 一 n的 n的 E L S ⌋ ）。 Note Depending of the size of your kernel, several (of the last) columns of the input might be lost, because it is a valid cross- correlation, and not a full cross-correlation. It is up to the user to add proper padding. Note 的填充参数有效地增加了扩张 * （kernel_size - 1） - 填充零填充的量与输入的两个尺寸。此被设置成使得当一个 Conv1d和aConvTranspose1d与初始化相同的参数，它们是在考虑到输入和输出形状彼此的逆。然而，当步幅 & GT ; 1， Conv1d映射多个输入的形状，以相同的输出的形状。 output_padding提供一种通过有效地增加在一侧上所计算出的输出的形状来解决此模糊性。需要注意的是output_padding仅用于查找输出的形状，但实际上并没有增加零填充输出。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters in_channels ( int) – Number of channels in the input image out_channels ( int) – Number of channels produced by the convolution kernel_size ( int or tuple) – Size of the convolving kernel stride ( int or tuple , optional ) – Stride of the convolution. Default: 1 填充 （ INT 或 元组 ， 可选的 ） - 扩张 * （kernel_size - 1） - 填充零填充将被添加到输入的两侧。默认值：0 output_padding （ INT 或 元组 ， 可选的 ） - 添加到输出形状的一侧的其他尺寸。默认值：0 groups ( int , optional ) – Number of blocked connections from input channels to output channels. Default: 1 bias ( bool , optional ) – If True, adds a learnable bias to the output. Default: True dilation ( int or tuple , optional ) – Spacing between kernel elements. Default: 1 Shape: Input: (N,Cin,Lin)(N, C{in}, L{in})(N,Cin​,Lin​) Output: (N,Cout,Lout)(N, C{out}, L{out})(N,Cout​,Lout​) where Lout=(Lin−1)×stride−2×padding+dilation×(kernelsize−1)+output_padding+1L{out} = (L_{in} - 1) \\times \\text{stride} - 2 \\times \\text{padding} + \\text{dilation} \\times (\\text{kernel\\_size} - 1) + \\text{output\\_padding} + 1 Lout​=(Lin​−1)×stride−2×padding+dilation×(kernel_size−1)+output_padding+1 Variables 〜ConvTranspose1d.weight （ 张量 ） - 的形状 [该模块的可学习权重HTG11] （ inchannels ， out_channels 基团 ， （\\文本{在\\ _channels}，\\压裂{\\文本{出\\ _channels}} {\\文本{基}}， （ in_channels ， 基团 out_channels [HTG8 8] ， kernel_size ） \\文本{内核\\ _size}） kernel_size ） 。这些权重的值是从 取样U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K ， K [H TG224] ） 其中 K = 1 C ​​ 在 * kernel_size K = \\压裂{1} {C \\文本{IN} \\文本{内核\\ _size}} K = ç 在 kernel_size 1 〜ConvTranspose1d.bias （ 张量 ） - 形状（outchannels）的模块的可学习偏差。如果偏压是真，然后这些权重的值是从 取样 U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K K ） 其中 K = 1 C 在 * kernel_size K = \\压裂{1} {C \\文本{IN} \\文本{内核\\ _size}} K = C 在 kernel_size 1 ConvTranspose2d classtorch.nn.``ConvTranspose2d( in_channels , out_channels , kernel_size , stride=1 , padding=0 , output_padding=0 , groups=1 , bias=True , dilation=1 , padding_mode='zeros' )[source] 应用在多个输入平面构成的输入图像的2D转卷积运算。 此模块可以被视为Conv2d的梯度相对于它的输入。它也被称为一分级-跨距卷积或去卷积（尽管它不是一个实际的去卷积运算）。 stridecontrols the stride for the cross-correlation. paddingcontrols the amount of implicit zero-paddings on both sides for dilation * (kernel_size - 1) - paddingnumber of points. See note below for details. output_paddingcontrols the additional size added to one side of the output shape. See note below for details. dilationcontrols the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilationdoes. groupscontrols the connections between inputs and outputs. in_channelsand out_channelsmust both be divisible by groups. For example, * At groups=1, all inputs are convolved to all outputs. > * At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated. > * At groups= `in_channels`, each input channel is convolved with its own set of filters (of size ⌊out_channelsin_channels⌋\\left\\lfloor\\frac{out\\_channels}{in\\_channels}\\right\\rfloor⌊in_channelsout_channels​⌋ ). 参数kernel_size，步幅，填充，output_padding可以是： 单一INT- 在这种情况下相同的值被用于高度和宽度尺寸 > a tupleof two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension > > Note Depending of the size of your kernel, several (of the last) columns of the input might be lost, because it is a valid cross- correlation, and not a full cross-correlation. It is up to the user to add proper padding. Note 的填充参数有效地增加了扩张 * （kernel_size - 1） - 填充零填充的量与输入的两个尺寸。此被设置成使得当一个 Conv2d和aConvTranspose2d与初始化相同的参数，它们是在考虑到输入和输出形状彼此的逆。然而，当步幅 & GT ; 1， Conv2d映射多个输入的形状，以相同的输出的形状。 output_padding提供一种通过有效地增加在一侧上所计算出的输出的形状来解决此模糊性。需要注意的是output_padding仅用于查找输出的形状，但实际上并没有增加零填充输出。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters in_channels ( int) – Number of channels in the input image out_channels ( int) – Number of channels produced by the convolution kernel_size ( int or tuple) – Size of the convolving kernel stride ( int or tuple , optional ) – Stride of the convolution. Default: 1 填充 （ INT 或 元组 ， 可选的 ） - 扩张 * （kernel_size - 1） - 填充零填充将被添加到输入中的每个维度的两侧。默认值：0 output_padding （ INT 或 元组 ， 可选的 ） - 加入到每个维度中的一个侧的输出形状的其他尺寸。默认值：0 groups ( int , optional ) – Number of blocked connections from input channels to output channels. Default: 1 bias ( bool , optional ) – If True, adds a learnable bias to the output. Default: True dilation ( int or tuple , optional ) – Spacing between kernel elements. Default: 1 Shape: Input: (N,Cin,Hin,Win)(N, C{in}, H{in}, W_{in})(N,Cin​,Hin​,Win​) Output: (N,Cout,Hout,Wout)(N, C{out}, H{out}, W_{out})(N,Cout​,Hout​,Wout​) where Hout=(Hin−1)×stride[0]−2×padding[0]+dilation[0]×(kernelsize[0]−1)+output_padding[0]+1H{out} = (H_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0] \\times (\\text{kernel\\_size}[0] - 1) + \\text{output\\_padding}[0] + 1 Hout​=(Hin​−1)×stride[0]−2×padding[0]+dilation[0]×(kernel_size[0]−1)+output_padding[0]+1 Wout=(Win−1)×stride[1]−2×padding[1]+dilation[1]×(kernelsize[1]−1)+output_padding[1]+1W{out} = (W_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1] \\times (\\text{kernel\\_size}[1] - 1) + \\text{output\\_padding}[1] + 1 Wout​=(Win​−1)×stride[1]−2×padding[1]+dilation[1]×(kernel_size[1]−1)+output_padding[1]+1 Variables 〜ConvTranspose2d.weight （ 张量 ） - 的形状 [该模块的可学习权重HTG11] （ inchannels ， out_channels 基团 ， （\\文本{在\\ _channels}，\\压裂{\\文本{出\\ _channels}} {\\文本{基}}， （ in_channels ， 基团 out_channels [HTG8 8] ， kernel_size [0] ， kernel_size [1] ） \\文本{内核\\ _size [0]}，\\文本{内核\\ _size [1]}） kernel_size [0] ， kernel_size [1] ） 。这些权重的值是从 取样U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K ， K [H TG236] ） 其中 ​​ K = 1 C 在 * Π i的 = 0 1 kernel_size [ i的 K = \\压裂{1} {C \\文本{IN} \\ prod_ {I = 0} ^ {1} \\文本{内核\\ _size} [I]} K = C 在 Π i的 = 0 1 kernel_size [ i的 1 〜ConvTranspose2d.bias （ 张量 ） - 形状（outchannels）的模块的可学习偏压如果偏压是真，然后这些权重的值从采样 U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K ， K ） 其中 K = 1 C 在 * Π i的 = 0 1 kernel_size [ i的 ķ = \\压裂{1} {C \\文本{IN} \\ prod_ {I = 0} ^ {1} \\文本{内核\\ _size} [I]} K = C 在 Π i的 = 0 ​​ 1 kernel_size [ i的 1 Examples: >>> # With square kernels and equal stride >>> m = nn.ConvTranspose2d(16, 33, 3, stride=2) >>> # non-square kernels and unequal stride and with padding >>> m = nn.ConvTranspose2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2)) >>> input = torch.randn(20, 16, 50, 100) >>> output = m(input) >>> # exact output size can be also specified as an argument >>> input = torch.randn(1, 16, 12, 12) >>> downsample = nn.Conv2d(16, 16, 3, stride=2, padding=1) >>> upsample = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1) >>> h = downsample(input) >>> h.size() torch.Size([1, 16, 6, 6]) >>> output = upsample(h, output_size=input.size()) >>> output.size() torch.Size([1, 16, 12, 12]) ConvTranspose3d classtorch.nn.``ConvTranspose3d( in_channels , out_channels , kernel_size , stride=1 , padding=0 , output_padding=0 , groups=1 , bias=True , dilation=1 , padding_mode='zeros' )[source] 应用在多个输入平面构成的输入图像的3D换位卷积运算。转置卷积运算符乘以在从所有输入特征平面输出每个输入值逐元素由一个可学习的内核，和求和。 此模块可以被视为Conv3d的梯度相对于它的输入。它也被称为一分级-跨距卷积或去卷积（尽管它不是一个实际的去卷积运算）。 stridecontrols the stride for the cross-correlation. paddingcontrols the amount of implicit zero-paddings on both sides for dilation * (kernel_size - 1) - paddingnumber of points. See note below for details. output_paddingcontrols the additional size added to one side of the output shape. See note below for details. dilationcontrols the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilationdoes. groupscontrols the connections between inputs and outputs. in_channelsand out_channelsmust both be divisible by groups. For example, * At groups=1, all inputs are convolved to all outputs. > * At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated. > * At groups= `in_channels`, each input channel is convolved with its own set of filters (of size ⌊out_channelsin_channels⌋\\left\\lfloor\\frac{out\\_channels}{in\\_channels}\\right\\rfloor⌊in_channelsout_channels​⌋ ). The parameters kernel_size, stride, padding, output_paddingcan either be: 单一INT- 在这种情况下相同的值被用于深度，高度和宽度尺寸 > a tupleof three ints – in which case, the first int is used for the depth dimension, the second int for the height dimension and the third int for the width dimension > > Note Depending of the size of your kernel, several (of the last) columns of the input might be lost, because it is a valid cross- correlation, and not a full cross-correlation. It is up to the user to add proper padding. Note 的填充参数有效地增加了扩张 * （kernel_size - 1） - 填充零填充的量与输入的两个尺寸。此被设置成使得当一个 Conv3d和aConvTranspose3d与初始化相同的参数，它们是在考虑到输入和输出形状彼此的逆。然而，当步幅 & GT ; 1， Conv3d映射多个输入的形状，以相同的输出的形状。 output_padding提供一种通过有效地增加在一侧上所计算出的输出的形状来解决此模糊性。需要注意的是output_padding仅用于查找输出的形状，但实际上并没有增加零填充输出。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters in_channels ( int) – Number of channels in the input image out_channels ( int) – Number of channels produced by the convolution kernel_size ( int or tuple) – Size of the convolving kernel stride ( int or tuple , optional ) – Stride of the convolution. Default: 1 padding ( int or tuple , optional ) – dilation * (kernel_size - 1) - paddingzero-padding will be added to both sides of each dimension in the input. Default: 0 output_padding ( int or tuple , optional ) – Additional size added to one side of each dimension in the output shape. Default: 0 groups ( int , optional ) – Number of blocked connections from input channels to output channels. Default: 1 bias ( bool , optional ) – If True, adds a learnable bias to the output. Default: True dilation ( int or tuple , optional ) – Spacing between kernel elements. Default: 1 Shape: Input: (N,Cin,Din,Hin,Win)(N, C{in}, D{in}, H{in}, W{in})(N,Cin​,Din​,Hin​,Win​) Output: (N,Cout,Dout,Hout,Wout)(N, C{out}, D{out}, H{out}, W{out})(N,Cout​,Dout​,Hout​,Wout​) where Dout=(Din−1)×stride[0]−2×padding[0]+dilation[0]×(kernelsize[0]−1)+output_padding[0]+1D{out} = (D_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0] \\times (\\text{kernel\\_size}[0] - 1) + \\text{output\\_padding}[0] + 1 Dout​=(Din​−1)×stride[0]−2×padding[0]+dilation[0]×(kernel_size[0]−1)+output_padding[0]+1 Hout=(Hin−1)×stride[1]−2×padding[1]+dilation[1]×(kernelsize[1]−1)+output_padding[1]+1H{out} = (H_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1] \\times (\\text{kernel\\_size}[1] - 1) + \\text{output\\_padding}[1] + 1 Hout​=(Hin​−1)×stride[1]−2×padding[1]+dilation[1]×(kernel_size[1]−1)+output_padding[1]+1 Wout=(Win−1)×stride[2]−2×padding[2]+dilation[2]×(kernelsize[2]−1)+output_padding[2]+1W{out} = (W_{in} - 1) \\times \\text{stride}[2] - 2 \\times \\text{padding}[2] + \\text{dilation}[2] \\times (\\text{kernel\\_size}[2] - 1) + \\text{output\\_padding}[2] + 1 Wout​=(Win​−1)×stride[2]−2×padding[2]+dilation[2]×(kernel_size[2]−1)+output_padding[2]+1 Variables 〜ConvTranspose3d.weight （ 张量 ） - 的形状 [该模块的可学习权重HTG11] （ inchannels ， out_channels 基团 ， （\\文本{在\\ _channels}，\\压裂{\\文本{出\\ _channels}} {\\文本{基}}， （ in_channels ， 基团 out_channels [HTG8 8] ， kernel_size [0] ， kernel_size [1] ， kernel_size [2] ） \\文本{内核\\ _size [0]}，\\文本{内核\\ _size [1]}，\\文本{内核\\ _size [2]}） kernel_size [0] kernel_size [1] ， kernel_size [2] ） 。这些权重的值是从 取样U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K ， K [H TG248] ​​ ） 其中 K = 1 C 在 * Π i的 = 0 2 kernel_size [ i的 K = \\压裂{1} {C \\文本{IN} \\ prod_ {I = 0} ^ {2} \\文本{内核\\ _size} [I]} K = C 在 Π i的 = 0 2 kernel_size [ i的 1 〜ConvTranspose3d.bias （ 张量 ） - 形状（outchannels）的模块的可学习偏压如果偏压是真，然后这些权重的值从采样 U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K ， K ） 其中 K = 1 C 在 * Π i的 = 0 2 kernel_size [ i的 ķ = \\压裂{1} {C \\文本{IN} \\ prod_ {I = 0} ^ {2} \\文本{内核\\ _size} [I]} K = C 在 Π i的 = 0 ​​ 2 kernel_size [ i的 1 Examples: >>> # With square kernels and equal stride >>> m = nn.ConvTranspose3d(16, 33, 3, stride=2) >>> # non-square kernels and unequal stride and with padding >>> m = nn.ConvTranspose3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(0, 4, 2)) >>> input = torch.randn(20, 16, 10, 50, 100) >>> output = m(input) 展开 classtorch.nn.``Unfold( kernel_size , dilation=1 , padding=0 , stride=1 )[source] 提取物成批输入张量滑动局部块。 考虑一个成批输入的张量形状 （ N ， C ， ） （N，C，） （ N ， C ， ） ，其中 N N N 是批处理尺寸， ç C C 是信道尺寸，并 表示任意的空间尺寸。该操作变平的输入的空间尺寸中的每个滑动kernel_size尺度的块划分成的列（即，最后的尺寸） 3-d 输出形状的张量 （ N ， C × Π （ kernel_size ） ， L ） （N，C \\倍\\ PROD（\\文本{内核\\ _size}），L） （ N ， C × Π （[H TG203] kernel_size ） ， L ） ，其中 C × Π （ kernel_size ） ç\\倍\\ PROD（\\文本{内核\\ _size}） C × Π （ kernel_size ​​） 是值的每个块内的总数目（一个块具有 Π （ kernel_size ） \\ PROD（\\文本{内核\\ _size}） Π （ kernel_size ） 的空间位置每一个包含 C C C -channeled矢量），和 L L L 是这样的块的总数： L=∏d⌊spatial_size[d]+2×padding[d]−dilation[d]×(kernel_size[d]−1)−1stride[d]+1⌋,L = \\prod_d \\left\\lfloor\\frac{\\text{spatial\\_size}[d] + 2 \\times \\text{padding}[d] % - \\text{dilation}[d] \\times (\\text{kernel\\_size}[d] - 1) 1}{\\text{stride}[d]} + 1\\right\\rfloor, L=d∏​⌊stride[d]spatial_size[d]+2×padding[d]−dilation[d]×(kernel_size[d]−1)−1​+1⌋, 其中 spatial_size \\文本{空间\\ _size} spatial_size 是由[HTG27空间尺寸形成]输入（ * 段），和 d d d 是所有空间维度。 因此，索引输出在最后一维（列维度）给出特定块内的所有值。 的填充，步幅和扩张参数指定的滑动块如何检索。 步幅控制用于所述滑动块的步幅。 填充控制隐含零填补处理的双方的量为填充点数重塑之前每个维度。 dilationcontrols the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilationdoes. Parameters kernel_size （ INT 或 元组 ） - 滑动块的大小 步幅 （ INT 或 元组 ， 可选的 ） - 在输入空间维度的滑动块的步幅。默认值：1 填充 （ INT 或 元组 ， 可选的 ） - 隐式零填充到上输入的两侧添加。默认值：0 扩张 （ INT 或 元组 ， 可选的 ） - 一个控制邻域内的元素的步幅的参数。默认值：1 如果kernel_size，扩张，填充或步幅是一个int或长度为1的元组，它们的值将在所有空间维度上复制。 对于两个输入空间维度的情况下，该操作有时被称为im2col。 Note 折通过从含有所有块中的所有值求和来计算在所得到的大张量的每个组合的值。展开 通过从大张量提​​取复制在局部块中的值。所以，如果块重叠，它们不是彼此的逆。 Warning 目前，只有4-d的输入张量（成批图像样张量）的支持。 Shape: 输入： （ N ， C ， ） （N，C，） （ N ， C ， * ） 输出： （ N ， C × Π （ kernel_size ） ， L ） （N，C \\倍\\ PROD（\\文本{内核\\ _size}），L） （ N ， C × Π （ kernel_size ） ， L ） 如上所述 Examples: >>> unfold = nn.Unfold(kernel_size=(2, 3)) >>> input = torch.randn(2, 5, 3, 4) >>> output = unfold(input) >>> # each patch contains 30 values (2x3=6 vectors, each of 5 channels) >>> # 4 blocks (2x3 kernels) in total in the 3x4 input >>> output.size() torch.Size([2, 30, 4]) >>> # Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape) >>> inp = torch.randn(1, 3, 10, 12) >>> w = torch.randn(2, 3, 4, 5) >>> inp_unf = torch.nn.functional.unfold(inp, (4, 5)) >>> out_unf = inp_unf.transpose(1, 2).matmul(w.view(w.size(0), -1).t()).transpose(1, 2) >>> out = torch.nn.functional.fold(out_unf, (7, 8), (1, 1)) >>> # or equivalently (and avoiding a copy), >>> # out = out_unf.view(1, 2, 7, 8) >>> (torch.nn.functional.conv2d(inp, w) - out).abs().max() tensor(1.9073e-06) 折叠 classtorch.nn.``Fold( output_size , kernel_size , dilation=1 , padding=0 , stride=1 )[source] 结合滑动局部块到大量含有张量的阵列。 考虑包含滑动局部块，例如分批输入张量，图像的补丁，的形状 （ N ， C × Π （ kernel_size ） ， L ） （N，C \\倍\\ PROD（\\文本{内核\\ _size}），L） （ N C × Π （ kernel_size ） ， L ） ，其中 N N N 是批次尺寸， C × Π （ kernel_size ） ç\\倍\\ PROD（\\文本{内核\\ _size}） C × Π （ kernel_size ） 是值的块内（数的那种块具有 Π （ 柯rnel_size ） \\ PROD（\\文本{内核\\ _size}） Π （ kernel_size ） 的空间位置每一个包含 C C C -channeled矢量），和 L L L 是块的总数。 （这是完全一样的说明书中的 展开 的输出的形状。）此操作这些局部块结合到大输出的张量形状 （ N ​​， C ， output_size [ 0 ， output_size [ 1 ， ... ） （N，C，\\文本{输出\\ _size} [0]，\\文本{输出\\ _size} [1]，\\点） （ N ， C ， output_size [ 0 ， output_size [ 1 ， ... ） 由重叠值求和。类似于 展开，参数必须满足 L=∏d⌊output_size[d]+2×padding[d]−dilation[d]×(kernel_size[d]−1)−1stride[d]+1⌋,L = \\prod_d \\left\\lfloor\\frac{\\text{output\\_size}[d] + 2 \\times \\text{padding}[d] % - \\text{dilation}[d] \\times (\\text{kernel\\_size}[d] - 1) 1}{\\text{stride}[d]} + 1\\right\\rfloor, L=d∏​⌊stride[d]output_size[d]+2×padding[d]−dilation[d]×(kernel_size[d]−1)−1​+1⌋, 其中 d d d 是所有空间维度。 output_size描述的滑动局部块的大含有张量的空间形状。它当多个输入形状地图到相同数量的滑动块，例如，具有来解决多义性是有用的步幅 & GT ; 0。 The padding, strideand dilationarguments specify how the sliding blocks are retrieved. stridecontrols the stride for the sliding blocks. paddingcontrols the amount of implicit zero-paddings on both sides for paddingnumber of points for each dimension before reshaping. dilationcontrols the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilationdoes. Parameters output_size （ INT 或 元组 ） - 的空间尺寸的形状该输出（即，output.sizes（）[2：]） kernel_size ( int or tuple) – the size of the sliding blocks 步幅 （ INT 或 元组 ） - 滑动块的步幅输入的空间尺寸。默认值：1 padding ( int or tuple , optional ) – implicit zero padding to be added on both sides of input. Default: 0 dilation ( int or tuple , optional ) – a parameter that controls the stride of elements within the neighborhood. Default: 1 如果output_size，kernel_size，扩张，填充或步幅是int或然后它们的值将在所有空间维度上复制长度为1的元组。 对于两个输出空间维度的情况下，该操作有时被称为col2im。 Note Foldcalculates each combined value in the resulting large tensor by summing all values from all containing blocks. Unfoldextracts the values in the local blocks by copying from the large tensor. So, if the blocks overlap, they are not inverses of each other. Warning 目前，只有4-d输出张量（成批图像样张量）的支持。 Shape: 输入： （ N ， C × Π （ kernel_size ） ， L ） （N，C \\倍\\ PROD（\\文本{内核\\ _size}），L） （ N ， C × Π （ kernel_size ） ， L ） 输出： （ N ， C ， output_size [ 0 ， output_size [ 1 ， ... ） （N，C，\\文本{输出\\ _size} [0]，\\文本{输出\\ _size} [1]，\\点） （ N ， C ， output_size [ 0 ， output_size [ 1 ， ... [HTG9 5] ） 如上所述 Examples: >>> fold = nn.Fold(output_size=(4, 5), kernel_size=(2, 2)) >>> input = torch.randn(1, 3 * 2 * 2, 12) >>> output = fold(input) >>> output.size() torch.Size([1, 3, 4, 5]) 池层 MaxPool1d classtorch.nn.``MaxPool1d( kernel_size , stride=None , padding=0 , dilation=1 , return_indices=False , ceil_mode=False )[source] 应用于一维的最大汇集了多个输入飞机组成的输入信号。 在最简单的情况下，所述层的与输入大小 的输出值（ N C ， L ） （N，C，L） （ N ， C ， L ） 和输出 （ N ， C ， L O U T ） （ N，C，L_ {出}） （ N C ， L O U T ） 可以精确地描述为： out(Ni,Cj,k)=max⁡m=0,…,kernelsize−1input(Ni,Cj,stride×k+m)out(N_i, C_j, k) = \\max{m=0, \\ldots, \\text{kernel\\_size} - 1} input(N_i, C_j, stride \\times k + m) out(Ni​,Cj​,k)=m=0,…,kernel_size−1max​input(Ni​,Cj​,stride×k+m) 如果填充是非零，则输入是隐式地在两侧上用零填充为填充点数。 扩张控制内核点之间的间隔。这是很难形容，但这种链接有什么扩张做一个很好的可视化。 Parameters kernel_size - 窗口的大小，以采取最大过 步幅 - 窗口的步幅。默认值为kernel_size 填充 - 隐含零填充到在两侧被添加 扩张 - 一个控制元件的步幅在窗口的参数 return_indices - 如果真，将返回最大指数中，产出一起。有用的 torch.nn.MaxUnpool1d以后 ceil_mode - 真时，将使用小区而非地板来计算输出形状 Shape: 输入： （ N ， C ， L i的 n的 ） （N，C，L_ {在}） （ N ， C ， L i的 n的 ） 输出： （ N ， C ， L O U T ） （N，C，L_ {出}） （ N ， C ， L O U T ） ，其中 Lout=⌊Lin+2×padding−dilation×(kernelsize−1)−1stride+1⌋L{out} = \\left\\lfloor \\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation} \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor Lout​=⌊strideLin​+2×padding−dilation×(kernel_size−1)−1​+1⌋ Examples: >>> # pool of size=3, stride=2 >>> m = nn.MaxPool1d(3, stride=2) >>> input = torch.randn(20, 16, 50) >>> output = m(input) MaxPool2d classtorch.nn.``MaxPool2d( kernel_size , stride=None , padding=0 , dilation=1 , return_indices=False , ceil_mode=False )[source] 施加最大的2D汇集在几个输入平面组成的输入信号。 在最简单的情况下，所述层的与输入大小 的输出值（ N C ， H ， W ） （N，C，H，W） （ N ， C ， H ， W ） ，输出 （ N ， C ， H O U T ， W O U T ） （N，C，H {出}，W {出}） （ N ， ç ， H O U T ， W O U T [H TG194] ） 和kernel_size（ K H ， K W ） （KH，千瓦） （ K H ， K W ） 可以精确地描述为： out(Ni,Cj,h,w)=max⁡m=0,…,kH−1max⁡n=0,…,kW−1input(Ni,Cj,stride[0]×h+m,stride[1]×w+n)\\begin{aligned} out(Ni, C_j, h, w) ={} & \\max{m=0, \\ldots, kH-1} \\max_{n=0, \\ldots, kW-1} \\\\ & \\text{input}(N_i, C_j, \\text{stride[0]} \\times h + m, \\text{stride[1]} \\times w + n) \\end{aligned} out(Ni​,Cj​,h,w)=​m=0,…,kH−1max​n=0,…,kW−1max​input(Ni​,Cj​,stride[0]×h+m,stride[1]×w+n)​ If paddingis non-zero, then the input is implicitly zero-padded on both sides for paddingnumber of points. dilationcontrols the spacing between the kernel points. It is harder to describe, but this link has a nice visualization of what dilationdoes. The parameters kernel_size, stride, padding, dilationcan either be: a single int– in which case the same value is used for the height and width dimension > a tupleof two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension > > Parameters kernel_size – the size of the window to take a max over stride – the stride of the window. Default value is kernel_size padding – implicit zero padding to be added on both sides dilation – a parameter that controls the stride of elements in the window return_indices - 如果真，将返回最大指数中，产出一起。有用的 torch.nn.MaxUnpool2d以后 ceil_mode – when True, will use ceil instead of floor to compute the output shape Shape: 输入： （ N ， C ， H i的 n的 ， W i的 n的 ） （N，C，H {IN} ，W {在}） （ N ， C ， H i的 n的 ， W i的 n的 ） 输出： （ N ， C ， H O U T ， W O U T ） （N，C，H {出}，W {出}） （ N ， C ， H O U T ， W O U T ） ，其中 Hout=⌊Hin+2∗padding[0]−dilation[0]×(kernelsize[0]−1)−1stride[0]+1⌋H{out} = \\left\\lfloor\\frac{H_{in} + 2 * \\text{padding[0]} - \\text{dilation[0]} \\times (\\text{kernel\\_size[0]} - 1) - 1}{\\text{stride[0]}} + 1\\right\\rfloor Hout​=⌊stride[0]Hin​+2∗padding[0]−dilation[0]×(kernel_size[0]−1)−1​+1⌋ Wout=⌊Win+2∗padding[1]−dilation[1]×(kernelsize[1]−1)−1stride[1]+1⌋W{out} = \\left\\lfloor\\frac{W_{in} + 2 * \\text{padding[1]} - \\text{dilation[1]} \\times (\\text{kernel\\_size[1]} - 1) - 1}{\\text{stride[1]}} + 1\\right\\rfloor Wout​=⌊stride[1]Win​+2∗padding[1]−dilation[1]×(kernel_size[1]−1)−1​+1⌋ Examples: >>> # pool of square window of size=3, stride=2 >>> m = nn.MaxPool2d(3, stride=2) >>> # pool of non-square window >>> m = nn.MaxPool2d((3, 2), stride=(2, 1)) >>> input = torch.randn(20, 16, 50, 32) >>> output = m(input) MaxPool3d classtorch.nn.``MaxPool3d( kernel_size , stride=None , padding=0 , dilation=1 , return_indices=False , ceil_mode=False )[source] 应用了3D最大汇集了多个输入飞机组成的输入信号。 在最简单的情况下，所述层的与输入大小 的输出值（ N C ， d ， H ， W ） （N，C，d，H，W） （ N ， C ， d ， H ， W ） ，输出 （ N C ， d O U T [HT G98] ， H O U T ， W O U T ） （N，C，D {出}，H {出}，W_ {出}） （ N ， C ， d O U T ， H O U T ， W O U T ） 和​​ kernel_size（ K d ķ H ， K W ） （KD，KH，千瓦） （ K d K H ， K W ） 可以精确地描述为： out(Ni,Cj,d,h,w)=max⁡k=0,…,kD−1max⁡m=0,…,kH−1max⁡n=0,…,kW−1input(Ni,Cj,stride[0]×d+k,stride[1]×h+m,stride[2]×w+n)\\begin{aligned} \\text{out}(Ni, C_j, d, h, w) ={} & \\max{k=0, \\ldots, kD-1} \\max{m=0, \\ldots, kH-1} \\max{n=0, \\ldots, kW-1} \\\\ & \\text{input}(N_i, C_j, \\text{stride[0]} \\times d + k, \\text{stride[1]} \\times h + m, \\text{stride[2]} \\times w + n) \\end{aligned} out(Ni​,Cj​,d,h,w)=​k=0,…,kD−1max​m=0,…,kH−1max​n=0,…,kW−1max​input(Ni​,Cj​,stride[0]×d+k,stride[1]×h+m,stride[2]×w+n)​ If paddingis non-zero, then the input is implicitly zero-padded on both sides for paddingnumber of points. dilationcontrols the spacing between the kernel points. It is harder to describe, but this link has a nice visualization of what dilationdoes. The parameters kernel_size, stride, padding, dilationcan either be: a single int– in which case the same value is used for the depth, height and width dimension > a tupleof three ints – in which case, the first int is used for the depth dimension, the second int for the height dimension and the third int for the width dimension > > Parameters kernel_size – the size of the window to take a max over stride – the stride of the window. Default value is kernel_size 填充 - 隐含零填充在所有三个侧被添加 dilation – a parameter that controls the stride of elements in the window return_indices - 如果真，将返回最大指数中，产出一起。有用的 torch.nn.MaxUnpool3d以后 ceil_mode – when True, will use ceil instead of floor to compute the output shape Shape: 输入： （ N ， C ， d i的 n的 ， H i的 n的 ， W i的 n的 ） （N，C，D {IN}，H {IN}，W_ {IN} ） （ N ， C ， d i的 n的 ， H i的 n的 ， W i的 n的 ） 输出： （ N ， C ， d O U T ， H O U T ， W O U T ） （N，C，D {出}，H {出}，W_ {出}） （ N ， C ， d O U T ， H O U T ， W O U T ） ，其中 Dout=⌊Din+2×padding[0]−dilation[0]×(kernelsize[0]−1)−1stride[0]+1⌋D{out} = \\left\\lfloor\\frac{D_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0] \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor Dout​=⌊stride[0]Din​+2×padding[0]−dilation[0]×(kernel_size[0]−1)−1​+1⌋ Hout=⌊Hin+2×padding[1]−dilation[1]×(kernelsize[1]−1)−1stride[1]+1⌋H{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1] \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor Hout​=⌊stride[1]Hin​+2×padding[1]−dilation[1]×(kernel_size[1]−1)−1​+1⌋ Wout=⌊Win+2×padding[2]−dilation[2]×(kernelsize[2]−1)−1stride[2]+1⌋W{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[2] - \\text{dilation}[2] \\times (\\text{kernel\\_size}[2] - 1) - 1}{\\text{stride}[2]} + 1\\right\\rfloor Wout​=⌊stride[2]Win​+2×padding[2]−dilation[2]×(kernel_size[2]−1)−1​+1⌋ Examples: >>> # pool of square window of size=3, stride=2 >>> m = nn.MaxPool3d(3, stride=2) >>> # pool of non-square window >>> m = nn.MaxPool3d((3, 2, 2), stride=(2, 1, 2)) >>> input = torch.randn(20, 16, 50,44, 31) >>> output = m(input) MaxUnpool1d classtorch.nn.``MaxUnpool1d( kernel_size , stride=None , padding=0 )[source] 计算的 MaxPool1d的局部逆。 MaxPool1d不是完全可逆的，因为非极大值都将丢失。 MaxUnpool1d取入作为输入 输出MaxPool1d包括的索引极大值，并计算其中所有非极大值都设置为零的局部逆。 Note MaxPool1d 可以映射多个输入大小，以相同的输出大小。因此，反演过程可以得到明确。为了适应这种情况，可以提供所需的输出尺寸为前向呼叫的附加自变量output_size。看到输入和下面的实施例。 Parameters kernel_size （ INT 或 元组 ） - 最大池窗口的大小。 步幅 （ INT 或 元组 ） - 最大池窗口的步幅。它的默认设置为kernel_size。 这是添加到输入填充 - 填充 （ INT 或 元组 ） Inputs: 输入：将输入张量反转 指数：由给出了索引MaxPool1d output_size （可选）：目标输出大小 Shape: 输入： （ N ， C ， H i的 n的 ） （N，C，H_ {在}） （ N ， C ， H i的 n的 ） 输出： （ N ， C ， H O U T ） （N，C，H_ {出}） （ N ， C ， H O U T ） ，其中 Hout=(Hin−1)×stride[0]−2×padding[0]+kernelsize[0]H{out} = (H_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{kernel\\_size}[0] Hout​=(Hin​−1)×stride[0]−2×padding[0]+kernel_size[0] 或由output_size在呼叫操作员给定的 Example: >>> pool = nn.MaxPool1d(2, stride=2, return_indices=True) >>> unpool = nn.MaxUnpool1d(2, stride=2) >>> input = torch.tensor([[[1., 2, 3, 4, 5, 6, 7, 8]]]) >>> output, indices = pool(input) >>> unpool(output, indices) tensor([[[ 0., 2., 0., 4., 0., 6., 0., 8.]]]) >>> # Example showcasing the use of output_size >>> input = torch.tensor([[[1., 2, 3, 4, 5, 6, 7, 8, 9]]]) >>> output, indices = pool(input) >>> unpool(output, indices, output_size=input.size()) tensor([[[ 0., 2., 0., 4., 0., 6., 0., 8., 0.]]]) >>> unpool(output, indices) tensor([[[ 0., 2., 0., 4., 0., 6., 0., 8.]]]) MaxUnpool2d classtorch.nn.``MaxUnpool2d( kernel_size , stride=None , padding=0 )[source] 计算的 MaxPool2d的局部逆。 MaxPool2d不是完全可逆的，因为非极大值都将丢失。 MaxUnpool2d取入作为输入 输出MaxPool2d包括的索引极大值，并计算其中所有非极大值都设置为零的局部逆。 Note MaxPool2d 可以映射多个输入大小，以相同的输出大小。因此，反演过程可以得到明确。为了适应这种情况，可以提供所需的输出尺寸为前向呼叫的附加自变量output_size。看到输入和下面的实施例。 Parameters kernel_size ( int or tuple) – Size of the max pooling window. stride ( int or tuple) – Stride of the max pooling window. It is set to kernel_sizeby default. padding ( int or tuple) – Padding that was added to the input Inputs: input: the input Tensor to invert 指数：由给出了索引MaxPool2d output_size (optional): the targeted output size Shape: Input: (N,C,Hin,Win)(N, C, H{in}, W{in})(N,C,Hin​,Win​) Output: (N,C,Hout,Wout)(N, C, H{out}, W{out})(N,C,Hout​,Wout​) , where Hout=(Hin−1)×stride[0]−2×padding[0]+kernelsize[0]H{out} = (H_{in} - 1) \\times \\text{stride[0]} - 2 \\times \\text{padding[0]} + \\text{kernel\\_size[0]} Hout​=(Hin​−1)×stride[0]−2×padding[0]+kernel_size[0] Wout=(Win−1)×stride[1]−2×padding[1]+kernelsize[1]W{out} = (W_{in} - 1) \\times \\text{stride[1]} - 2 \\times \\text{padding[1]} + \\text{kernel\\_size[1]} Wout​=(Win​−1)×stride[1]−2×padding[1]+kernel_size[1] or as given by output_sizein the call operator Example: >>> pool = nn.MaxPool2d(2, stride=2, return_indices=True) >>> unpool = nn.MaxUnpool2d(2, stride=2) >>> input = torch.tensor([[[[ 1., 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12], [13, 14, 15, 16]]]]) >>> output, indices = pool(input) >>> unpool(output, indices) tensor([[[[ 0., 0., 0., 0.], [ 0., 6., 0., 8.], [ 0., 0., 0., 0.], [ 0., 14., 0., 16.]]]]) >>> # specify a different output size than input size >>> unpool(output, indices, output_size=torch.Size([1, 1, 5, 5])) tensor([[[[ 0., 0., 0., 0., 0.], [ 6., 0., 8., 0., 0.], [ 0., 0., 0., 14., 0.], [ 16., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0.]]]]) MaxUnpool3d classtorch.nn.``MaxUnpool3d( kernel_size , stride=None , padding=0 )[source] 计算的 MaxPool3d的局部逆。 MaxPool3d不是完全可逆的，因为非极大值都将丢失。MaxUnpool3d取入作为输入 输出MaxPool3d 包括的索引极大值，并计算其中所有非极大值都设置为零的局部逆。 Note MaxPool3d 可以映射多个输入大小，以相同的输出大小。因此，反演过程可以得到明确。为了适应这种情况，可以提供所需的输出尺寸为前向呼叫的附加自变量output_size。请参阅下面的输入部分。 Parameters kernel_size ( int or tuple) – Size of the max pooling window. stride ( int or tuple) – Stride of the max pooling window. It is set to kernel_sizeby default. padding ( int or tuple) – Padding that was added to the input Inputs: input: the input Tensor to invert 指数：由给出了索引MaxPool3d output_size (optional): the targeted output size Shape: Input: (N,C,Din,Hin,Win)(N, C, D{in}, H{in}, W_{in})(N,C,Din​,Hin​,Win​) Output: (N,C,Dout,Hout,Wout)(N, C, D{out}, H{out}, W_{out})(N,C,Dout​,Hout​,Wout​) , where Dout=(Din−1)×stride[0]−2×padding[0]+kernelsize[0]D{out} = (D_{in} - 1) \\times \\text{stride[0]} - 2 \\times \\text{padding[0]} + \\text{kernel\\_size[0]} Dout​=(Din​−1)×stride[0]−2×padding[0]+kernel_size[0] Hout=(Hin−1)×stride[1]−2×padding[1]+kernelsize[1]H{out} = (H_{in} - 1) \\times \\text{stride[1]} - 2 \\times \\text{padding[1]} + \\text{kernel\\_size[1]} Hout​=(Hin​−1)×stride[1]−2×padding[1]+kernel_size[1] Wout=(Win−1)×stride[2]−2×padding[2]+kernelsize[2]W{out} = (W_{in} - 1) \\times \\text{stride[2]} - 2 \\times \\text{padding[2]} + \\text{kernel\\_size[2]} Wout​=(Win​−1)×stride[2]−2×padding[2]+kernel_size[2] or as given by output_sizein the call operator Example: >>> # pool of square window of size=3, stride=2 >>> pool = nn.MaxPool3d(3, stride=2, return_indices=True) >>> unpool = nn.MaxUnpool3d(3, stride=2) >>> output, indices = pool(torch.randn(20, 16, 51, 33, 15)) >>> unpooled_output = unpool(output, indices) >>> unpooled_output.size() torch.Size([20, 16, 51, 33, 15]) AvgPool1d classtorch.nn.``AvgPool1d( kernel_size , stride=None , padding=0 , ceil_mode=False , count_include_pad=True )[source] 适用在几个输入平面组成的输入信号的平均1D池。 在最简单的情况下，所述层的与输入大小 的输出值（ N C ， L ） （N，C，L） （ N ， C ， L ） ，输出 （ N ， C ， L O U T ） （ N，C，L_ {出}） （ N C ， L O U T ） 和kernel_sizeK K K 可以精确地描述为： out(Ni,Cj,l)=1k∑m=0k−1input(Ni,Cj,stride×l+m)\\text{out}(Ni, C_j, l) = \\frac{1}{k} \\sum{m=0}^{k-1} \\text{input}(N_i, C_j, \\text{stride} \\times l + m)out(Ni​,Cj​,l)=k1​m=0∑k−1​input(Ni​,Cj​,stride×l+m) 如果填充是非零，则输入是隐式地在两侧上用零填充为填充点数。 参数kernel_size，步幅，填充可各自为一个INT或一个元素的元组。 Parameters kernel_size - 窗口的大小 stride – the stride of the window. Default value is kernel_size padding – implicit zero padding to be added on both sides ceil_mode – when True, will use ceil instead of floor to compute the output shape count_include_pad - 真时，将包括在平均计算补零 Shape: Input: (N,C,Lin)(N, C, L_{in})(N,C,Lin​) Output: (N,C,Lout)(N, C, L_{out})(N,C,Lout​) , where Lout=⌊Lin+2×padding−kernelsizestride+1⌋L{out} = \\left\\lfloor \\frac{L_{in} + 2 \\times \\text{padding} - \\text{kernel\\_size}}{\\text{stride}} + 1\\right\\rfloor Lout​=⌊strideLin​+2×padding−kernel_size​+1⌋ Examples: >>> # pool with window of size=3, stride=2 >>> m = nn.AvgPool1d(3, stride=2) >>> m(torch.tensor([[[1.,2,3,4,5,6,7]]])) tensor([[[ 2., 4., 6.]]]) AvgPool2d classtorch.nn.``AvgPool2d( kernel_size , stride=None , padding=0 , ceil_mode=False , count_include_pad=True , divisor_override=None )[source] 适用在几个输入平面组成的输入信号的2D平均池。 In the simplest case, the output value of the layer with input size (N,C,H,W)(N, C, H, W)(N,C,H,W) , output (N,C,Hout,Wout)(N, C, H{out}, W{out})(N,C,Hout​,Wout​) and kernel_size(kH,kW)(kH, kW)(kH,kW) can be precisely described as: out(Ni,Cj,h,w)=1kH∗kW∑m=0kH−1∑n=0kW−1input(Ni,Cj,stride[0]×h+m,stride[1]×w+n)out(Ni, C_j, h, w) = \\frac{1}{kH * kW} \\sum{m=0}^{kH-1} \\sum_{n=0}^{kW-1} input(N_i, C_j, stride[0] \\times h + m, stride[1] \\times w + n)out(Ni​,Cj​,h,w)=kH∗kW1​m=0∑kH−1​n=0∑kW−1​input(Ni​,Cj​,stride[0]×h+m,stride[1]×w+n) If paddingis non-zero, then the input is implicitly zero-padded on both sides for paddingnumber of points. 参数kernel_size，步幅，填充可以是： a single int– in which case the same value is used for the height and width dimension > a tupleof two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension > > Parameters kernel_size – the size of the window stride – the stride of the window. Default value is kernel_size padding – implicit zero padding to be added on both sides ceil_mode – when True, will use ceil instead of floor to compute the output shape count_include_pad – when True, will include the zero-padding in the averaging calculation divisor_override - 如果指定的话，它将被用作除数，否则ATTR： kernel_size 将用于 Shape: Input: (N,C,Hin,Win)(N, C, H{in}, W{in})(N,C,Hin​,Win​) Output: (N,C,Hout,Wout)(N, C, H{out}, W{out})(N,C,Hout​,Wout​) , where Hout=⌊Hin+2×padding[0]−kernelsize[0]stride[0]+1⌋H{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[0] - \\text{kernel\\_size}[0]}{\\text{stride}[0]} + 1\\right\\rfloor Hout​=⌊stride[0]Hin​+2×padding[0]−kernel_size[0]​+1⌋ Wout=⌊Win+2×padding[1]−kernelsize[1]stride[1]+1⌋W{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[1] - \\text{kernel\\_size}[1]}{\\text{stride}[1]} + 1\\right\\rfloor Wout​=⌊stride[1]Win​+2×padding[1]−kernel_size[1]​+1⌋ Examples: >>> # pool of square window of size=3, stride=2 >>> m = nn.AvgPool2d(3, stride=2) >>> # pool of non-square window >>> m = nn.AvgPool2d((3, 2), stride=(2, 1)) >>> input = torch.randn(20, 16, 50, 32) >>> output = m(input) AvgPool3d classtorch.nn.``AvgPool3d( kernel_size , stride=None , padding=0 , ceil_mode=False , count_include_pad=True , divisor_override=None )[source] 适用在几个输入平面组成的输入信号的平均三维池。 In the simplest case, the output value of the layer with input size (N,C,D,H,W)(N, C, D, H, W)(N,C,D,H,W) , output (N,C,Dout,Hout,Wout)(N, C, D{out}, H{out}, W_{out})(N,C,Dout​,Hout​,Wout​) and kernel_size (kD,kH,kW)(kD, kH, kW)(kD,kH,kW) can be precisely described as: out(Ni,Cj,d,h,w)=∑k=0kD−1∑m=0kH−1∑n=0kW−1input(Ni,Cj,stride[0]×d+k,stride[1]×h+m,stride[2]×w+n)kD×kH×kW\\begin{aligned} \\text{out}(Ni, C_j, d, h, w) ={} & \\sum{k=0}^{kD-1} \\sum{m=0}^{kH-1} \\sum{n=0}^{kW-1} \\\\ & \\frac{\\text{input}(N_i, C_j, \\text{stride}[0] \\times d k, \\text{stride}[1] \\times h + m, \\text{stride}[2] \\times w + n)} {kD \\times kH \\times kW} \\end{aligned} out(Ni​,Cj​,d,h,w)=​k=0∑kD−1​m=0∑kH−1​n=0∑kW−1​kD×kH×kWinput(Ni​,Cj​,stride[0]×d+k,stride[1]×h+m,stride[2]×w+n)​​ 如果填充是非零，则输入是隐式地在所有三个侧面零填充为填充数量的点。 参数kernel_size，步幅可以是： a single int– in which case the same value is used for the depth, height and width dimension > a tupleof three ints – in which case, the first int is used for the depth dimension, the second int for the height dimension and the third int for the width dimension > > Parameters kernel_size – the size of the window stride – the stride of the window. Default value is kernel_size padding – implicit zero padding to be added on all three sides ceil_mode – when True, will use ceil instead of floor to compute the output shape count_include_pad – when True, will include the zero-padding in the averaging calculation divisor_override – if specified, it will be used as divisor, otherwise attr:kernel_size will be used Shape: Input: (N,C,Din,Hin,Win)(N, C, D{in}, H{in}, W_{in})(N,C,Din​,Hin​,Win​) Output: (N,C,Dout,Hout,Wout)(N, C, D{out}, H{out}, W_{out})(N,C,Dout​,Hout​,Wout​) , where Dout=⌊Din+2×padding[0]−kernelsize[0]stride[0]+1⌋D{out} = \\left\\lfloor\\frac{D_{in} + 2 \\times \\text{padding}[0] - \\text{kernel\\_size}[0]}{\\text{stride}[0]} + 1\\right\\rfloor Dout​=⌊stride[0]Din​+2×padding[0]−kernel_size[0]​+1⌋ Hout=⌊Hin+2×padding[1]−kernelsize[1]stride[1]+1⌋H{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[1] - \\text{kernel\\_size}[1]}{\\text{stride}[1]} + 1\\right\\rfloor Hout​=⌊stride[1]Hin​+2×padding[1]−kernel_size[1]​+1⌋ Wout=⌊Win+2×padding[2]−kernelsize[2]stride[2]+1⌋W{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[2] - \\text{kernel\\_size}[2]}{\\text{stride}[2]} + 1\\right\\rfloor Wout​=⌊stride[2]Win​+2×padding[2]−kernel_size[2]​+1⌋ Examples: >>> # pool of square window of size=3, stride=2 >>> m = nn.AvgPool3d(3, stride=2) >>> # pool of non-square window >>> m = nn.AvgPool3d((3, 2, 2), stride=(2, 1, 2)) >>> input = torch.randn(20, 16, 50,44, 31) >>> output = m(input) FractionalMaxPool2d classtorch.nn.``FractionalMaxPool2d( kernel_size , output_size=None , output_ratio=None , return_indices=False , _random_samples=None )[source] 适用在几个输入平面组成的输入信号的2D分数最大池。 分数MaxPooling中详细纸张分数MaxPooling 通过格雷厄姆描述 最大-池操作在施加 K H × K W 的kH \\倍千瓦 K H × K W 区域通过由目标输出尺寸决定的随机步长。的输出特征的数量等于输入平面的数量。 Parameters kernel_size - 窗口的大小，以采取最大过来。可以是单一的数k（对于k X k的平方内核）或元组（KH，千瓦） output_size - 形式哦X OW 的图像的目标输出大小。可以是一个元组（OH，OW）或正方形图像的单个数字喔哦X哦 output_ratio - 如果一个人希望有一个输出大小为输入大小的比率，这个选项可以给出。这必须是在范围内的数或元组（0，1） return_indices - 如果真，将返回指数中，产出一起。有用传递给nn.MaxUnpool2d（）。默认值：假 例子 >>> # pool of square window of size=3, and target output size 13x12 >>> m = nn.FractionalMaxPool2d(3, output_size=(13, 12)) >>> # pool of square window and target output size being half of input image size >>> m = nn.FractionalMaxPool2d(3, output_ratio=(0.5, 0.5)) >>> input = torch.randn(20, 16, 50, 32) >>> output = m(input) LPPool1d classtorch.nn.``LPPool1d( norm_type , kernel_size , stride=None , ceil_mode=False )[source] 适用在几个输入平面组成的输入信号的功率1D平均池。 在每个窗口中，计算出的函数是： f(X)=∑x∈Xxppf(X) = \\sqrt[p]{\\sum_{x \\in X} x^{p}} f(X)=p​x∈X∑​xp​ 在P = ∞ \\ infty ∞ ，可以得到最大池 在p = 1时，可以得到萨姆池（其正比于平均池） Note 如果总和至p的功率为零时，该函数的梯度没有定义。此实现会在这种情况下，设置渐变至零。 Parameters kernel_size - 单个int，窗口的大小 步幅 - 一个单一的在，窗口的步幅。默认值为kernel_size ceil_mode – when True, will use ceil instead of floor to compute the output shape Shape: Input: (N,C,Lin)(N, C, L_{in})(N,C,Lin​) Output: (N,C,Lout)(N, C, L_{out})(N,C,Lout​) , where Lout=⌊Lin+2×padding−kernelsizestride+1⌋L{out} = \\left\\lfloor\\frac{L_{in} + 2 \\times \\text{padding} - \\text{kernel\\_size}}{\\text{stride}} + 1\\right\\rfloor Lout​=⌊strideLin​+2×padding−kernel_size​+1⌋ Examples:: >>> # power-2 pool of window of length 3, with stride 2. >>> m = nn.LPPool1d(2, 3, stride=2) >>> input = torch.randn(20, 16, 50) >>> output = m(input) LPPool2d classtorch.nn.``LPPool2d( norm_type , kernel_size , stride=None , ceil_mode=False )[source] 适用在几个输入平面组成的输入信号的2D功率平均池。 On each window, the function computed is: f(X)=∑x∈Xxppf(X) = \\sqrt[p]{\\sum_{x \\in X} x^{p}} f(X)=p​x∈X∑​xp​ At p = ∞\\infty∞ , one gets Max Pooling 在p = 1时，可以得到萨姆池（其正比于平均池） The parameters kernel_size, stridecan either be: a single int– in which case the same value is used for the height and width dimension > a tupleof two ints – in which case, the first int is used for the height dimension, and the second int for the width dimension > > Note If the sum to the power of p is zero, the gradient of this function is not defined. This implementation will set the gradient to zero in this case. Parameters kernel_size – the size of the window stride – the stride of the window. Default value is kernel_size ceil_mode – when True, will use ceil instead of floor to compute the output shape Shape: Input: (N,C,Hin,Win)(N, C, H{in}, W{in})(N,C,Hin​,Win​) Output: (N,C,Hout,Wout)(N, C, H{out}, W{out})(N,C,Hout​,Wout​) , where Hout=⌊Hin+2×padding[0]−dilation[0]×(kernelsize[0]−1)−1stride[0]+1⌋H{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0] \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor Hout​=⌊stride[0]Hin​+2×padding[0]−dilation[0]×(kernel_size[0]−1)−1​+1⌋ Wout=⌊Win+2×padding[1]−dilation[1]×(kernelsize[1]−1)−1stride[1]+1⌋W{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1] \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor Wout​=⌊stride[1]Win​+2×padding[1]−dilation[1]×(kernel_size[1]−1)−1​+1⌋ Examples: >>> # power-2 pool of square window of size=3, stride=2 >>> m = nn.LPPool2d(2, 3, stride=2) >>> # pool of non-square window of power 1.2 >>> m = nn.LPPool2d(1.2, (3, 2), stride=(2, 1)) >>> input = torch.randn(20, 16, 50, 32) >>> output = m(input) AdaptiveMaxPool1d classtorch.nn.``AdaptiveMaxPool1d( output_size , return_indices=False )[source] 适用在几个输入平面组成的输入信号的1D自适应最大池。 输出尺寸是H，任何输入的大小。的输出特征的数量等于输入平面的数量。 Parameters output_size - 目标输出口径H return_indices - 如果真，将返回指数中，产出一起。有用传递给nn.MaxUnpool1d。默认值：假 Examples >>> # target output size of 5 >>> m = nn.AdaptiveMaxPool1d(5) >>> input = torch.randn(1, 64, 8) >>> output = m(input) AdaptiveMaxPool2d classtorch.nn.``AdaptiveMaxPool2d( output_size , return_indices=False )[source] 适用在几个输入平面组成的输入信号的2D自适应最大池。 输出是尺寸高×宽的，对于任何输入大小。的输出特征的数量等于输入平面的数量。 Parameters output_size - 的形式高x W的图像的目标输出大小可以是一个元组（H，W）或对于方形图像高x H.单个H H和W可以是INT或无这意味着大小将是相同的，输入的。 return_indices - 如果真，将返回指数中，产出一起。有用传递给nn.MaxUnpool2d。默认值：假 Examples >>> # target output size of 5x7 >>> m = nn.AdaptiveMaxPool2d((5,7)) >>> input = torch.randn(1, 64, 8, 9) >>> output = m(input) >>> # target output size of 7x7 (square) >>> m = nn.AdaptiveMaxPool2d(7) >>> input = torch.randn(1, 64, 10, 9) >>> output = m(input) >>> # target output size of 10x7 >>> m = nn.AdaptiveMaxPool2d((None, 7)) >>> input = torch.randn(1, 64, 10, 9) >>> output = m(input) AdaptiveMaxPool3d classtorch.nn.``AdaptiveMaxPool3d( output_size , return_indices=False )[source] 适用在几个输入平面组成的输入信号的3D自适应最大池。 输出是尺寸d x高x W的，对于任何输入大小。的输出特征的数量等于输入平面的数量。 Parameters output_size - 形式d×高×W的图像的目标输出大小可以是一个元组（d，H，W）或多维数据集d X d X D. d单个d， H和W可以是INT或无这意味着大小将是相同的，输入的。 return_indices - 如果真，将返回指数中，产出一起。有用传递给nn.MaxUnpool3d。默认值：假 Examples >>> # target output size of 5x7x9 >>> m = nn.AdaptiveMaxPool3d((5,7,9)) >>> input = torch.randn(1, 64, 8, 9, 10) >>> output = m(input) >>> # target output size of 7x7x7 (cube) >>> m = nn.AdaptiveMaxPool3d(7) >>> input = torch.randn(1, 64, 10, 9, 8) >>> output = m(input) >>> # target output size of 7x9x8 >>> m = nn.AdaptiveMaxPool3d((7, None, None)) >>> input = torch.randn(1, 64, 10, 9, 8) >>> output = m(input) AdaptiveAvgPool1d classtorch.nn.``AdaptiveAvgPool1d( output_size )[source] 适用在几个输入平面组成的输入信号的1D自适应平均池。 The output size is H, for any input size. The number of output features is equal to the number of input planes. Parameters output_size – the target output size H Examples >>> # target output size of 5 >>> m = nn.AdaptiveAvgPool1d(5) >>> input = torch.randn(1, 64, 8) >>> output = m(input) AdaptiveAvgPool2d classtorch.nn.``AdaptiveAvgPool2d( output_size )[source] 适用在几个输入平面组成的输入信号的2D自适应平均池。 The output is of size H x W, for any input size. The number of output features is equal to the number of input planes. Parameters output_size – the target output size of the image of the form H x W. Can be a tuple (H, W) or a single H for a square image H x H. H and W can be either a int, or Nonewhich means the size will be the same as that of the input. Examples >>> # target output size of 5x7 >>> m = nn.AdaptiveAvgPool2d((5,7)) >>> input = torch.randn(1, 64, 8, 9) >>> output = m(input) >>> # target output size of 7x7 (square) >>> m = nn.AdaptiveAvgPool2d(7) >>> input = torch.randn(1, 64, 10, 9) >>> output = m(input) >>> # target output size of 10x7 >>> m = nn.AdaptiveMaxPool2d((None, 7)) >>> input = torch.randn(1, 64, 10, 9) >>> output = m(input) AdaptiveAvgPool3d classtorch.nn.``AdaptiveAvgPool3d( output_size )[source] 适用在几个输入平面组成的输入信号的3D自适应平均池。 The output is of size D x H x W, for any input size. The number of output features is equal to the number of input planes. Parameters output_size - 形式d×高×W的目标输出大小可以是用于立方体d X d X D. d，H和元组（d，H，W）或单数d W可以是无论是INT或无这意味着大小将是相同的，输入的。 Examples >>> # target output size of 5x7x9 >>> m = nn.AdaptiveAvgPool3d((5,7,9)) >>> input = torch.randn(1, 64, 8, 9, 10) >>> output = m(input) >>> # target output size of 7x7x7 (cube) >>> m = nn.AdaptiveAvgPool3d(7) >>> input = torch.randn(1, 64, 10, 9, 8) >>> output = m(input) >>> # target output size of 7x9x8 >>> m = nn.AdaptiveMaxPool3d((7, None, None)) >>> input = torch.randn(1, 64, 10, 9, 8) >>> output = m(input) 填充层 ReflectionPad1d classtorch.nn.``ReflectionPad1d( padding )[source] 焊盘使用输入边界的反射输入张量。 对于 N 维填充，用 torch.nn.functional.pad（） 。 Parameters 填充 （ INT ， 元组 ） 填充的大小。如果是 INT ，使用在所有边界相同的填充。如果2- 元组，使用（ padding_left \\ {文本填充\\ _Left} padding_left ， padding_right \\文本{填充\\ _right} padding_right ） Shape: 输入： （ N ， C ， W i的 n的 ） （N，C，W_ {在}） （ N ， C ， W i的 n的 ） 输出： （ N ， C ， W O U T ） （N，C，W_ {出}） （ N ， C ， W O U T ） 其中 W O U T = W i的 n的 + paddingleft + padding_right W {出} = W_ {在} + \\文本{填充\\ _Left} + \\文本{填充\\ _right} W O U T = W [HT G100] i的 n的 + padding_left + padding_right Examples: >>> m = nn.ReflectionPad1d(2) >>> input = torch.arange(8, dtype=torch.float).reshape(1, 2, 4) >>> input tensor([[[0., 1., 2., 3.], [4., 5., 6., 7.]]]) >>> m(input) tensor([[[2., 1., 0., 1., 2., 3., 2., 1.], [6., 5., 4., 5., 6., 7., 6., 5.]]]) >>> # using different paddings for different sides >>> m = nn.ReflectionPad1d((3, 1)) >>> m(input) tensor([[[3., 2., 1., 0., 1., 2., 3., 2.], [7., 6., 5., 4., 5., 6., 7., 6.]]]) ReflectionPad2d classtorch.nn.``ReflectionPad2d( padding )[source] Pads the input tensor using the reflection of the input boundary. For N-dimensional padding, use torch.nn.functional.pad(). Parameters 填充 （ INT ， 元组 ） 填充的大小。如果是 INT ，使用在所有边界相同的填充。如果4- 元组，使用（ padding_left \\ {文本填充\\ _Left} padding_left ， padding_right \\文本{填充\\ _right} padding_right ， padding_top \\文本{填充\\ _top} padding_top ， padding_bottom \\ {文本paddi纳克\\ _bottom} padding_bottom ） Shape: Input: (N,C,Hin,Win)(N, C, H{in}, W{in})(N,C,Hin​,Win​) 输出： （ N ， C ， H O U T ， W O U T ） （N，C，H {出}，W {出}） （ N ， C ， H O U T ， W O U T ） 其中 H O U T = H i的 n的 + paddingtop + padding_bottom H {出} = H_ {在} + \\文本{填充\\ _top} + \\文本{填充\\ _bottom} H O U T = H [HT G100] i的 n的 + padding_top + padding_bottom Wout=Win+paddingleft+padding_rightW{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout​=Win​+padding_left+padding_right Examples: >>> m = nn.ReflectionPad2d(2) >>> input = torch.arange(9, dtype=torch.float).reshape(1, 1, 3, 3) >>> input tensor([[[[0., 1., 2.], [3., 4., 5.], [6., 7., 8.]]]]) >>> m(input) tensor([[[[8., 7., 6., 7., 8., 7., 6.], [5., 4., 3., 4., 5., 4., 3.], [2., 1., 0., 1., 2., 1., 0.], [5., 4., 3., 4., 5., 4., 3.], [8., 7., 6., 7., 8., 7., 6.], [5., 4., 3., 4., 5., 4., 3.], [2., 1., 0., 1., 2., 1., 0.]]]]) >>> # using different paddings for different sides >>> m = nn.ReflectionPad2d((1, 1, 2, 0)) >>> m(input) tensor([[[[7., 6., 7., 8., 7.], [4., 3., 4., 5., 4.], [1., 0., 1., 2., 1.], [4., 3., 4., 5., 4.], [7., 6., 7., 8., 7.]]]]) ReplicationPad1d classtorch.nn.``ReplicationPad1d( padding )[source] 垫使用输入边界的复制输入张量。 For N-dimensional padding, use torch.nn.functional.pad(). Parameters padding ( int , tuple) – the size of the padding. If is int, uses the same padding in all boundaries. If a 2-tuple, uses (padding_left\\text{padding\\_left}padding_left , padding_right\\text{padding\\_right}padding_right ) Shape: Input: (N,C,Win)(N, C, W_{in})(N,C,Win​) Output: (N,C,Wout)(N, C, W_{out})(N,C,Wout​) where Wout=Win+paddingleft+padding_rightW{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout​=Win​+padding_left+padding_right Examples: >>> m = nn.ReplicationPad1d(2) >>> input = torch.arange(8, dtype=torch.float).reshape(1, 2, 4) >>> input tensor([[[0., 1., 2., 3.], [4., 5., 6., 7.]]]) >>> m(input) tensor([[[0., 0., 0., 1., 2., 3., 3., 3.], [4., 4., 4., 5., 6., 7., 7., 7.]]]) >>> # using different paddings for different sides >>> m = nn.ReplicationPad1d((3, 1)) >>> m(input) tensor([[[0., 0., 0., 0., 1., 2., 3., 3.], [4., 4., 4., 4., 5., 6., 7., 7.]]]) ReplicationPad2d classtorch.nn.``ReplicationPad2d( padding )[source] Pads the input tensor using replication of the input boundary. For N-dimensional padding, use torch.nn.functional.pad(). Parameters padding ( int , tuple) – the size of the padding. If is int, uses the same padding in all boundaries. If a 4-tuple, uses (padding_left\\text{padding\\_left}padding_left , padding_right\\text{padding\\_right}padding_right , padding_top\\text{padding\\_top}padding_top , padding_bottom\\text{padding\\_bottom}padding_bottom ) Shape: Input: (N,C,Hin,Win)(N, C, H{in}, W{in})(N,C,Hin​,Win​) Output: (N,C,Hout,Wout)(N, C, H{out}, W{out})(N,C,Hout​,Wout​) where Hout=Hin+paddingtop+padding_bottomH{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}Hout​=Hin​+padding_top+padding_bottom Wout=Win+paddingleft+padding_rightW{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout​=Win​+padding_left+padding_right Examples: >>> m = nn.ReplicationPad2d(2) >>> input = torch.arange(9, dtype=torch.float).reshape(1, 1, 3, 3) >>> input tensor([[[[0., 1., 2.], [3., 4., 5.], [6., 7., 8.]]]]) >>> m(input) tensor([[[[0., 0., 0., 1., 2., 2., 2.], [0., 0., 0., 1., 2., 2., 2.], [0., 0., 0., 1., 2., 2., 2.], [3., 3., 3., 4., 5., 5., 5.], [6., 6., 6., 7., 8., 8., 8.], [6., 6., 6., 7., 8., 8., 8.], [6., 6., 6., 7., 8., 8., 8.]]]]) >>> # using different paddings for different sides >>> m = nn.ReplicationPad2d((1, 1, 2, 0)) >>> m(input) tensor([[[[0., 0., 1., 2., 2.], [0., 0., 1., 2., 2.], [0., 0., 1., 2., 2.], [3., 3., 4., 5., 5.], [6., 6., 7., 8., 8.]]]]) ReplicationPad3d classtorch.nn.``ReplicationPad3d( padding )[source] Pads the input tensor using replication of the input boundary. For N-dimensional padding, use torch.nn.functional.pad(). Parameters 填充 （ INT ， 元组 ） 填充的大小。如果是 INT ，使用在所有边界相同的填充。如果6- 元组，使用（ padding_left \\ {文本填充\\ _Left} padding_left ， padding_right \\文本{填充\\ _right} padding_right ， padding_top \\文本{填充\\ _top} padding_top ， padding_bottom \\ {文本paddi纳克\\ _bottom} padding_bottom ， padding_front \\文本{填充\\ _front} padding_front ， padding_back \\文本{填充\\ _back} padding_back ） Shape: Input: (N,C,Din,Hin,Win)(N, C, D{in}, H{in}, W_{in})(N,C,Din​,Hin​,Win​) 输出： （ N ， C ， d O U T ， H O U T ， W O U T ） （N，C，D {出}，H {出}，W_ {出}） （ N ， C ， d O U T ， H O U T ， W O U T ） 其中 d O U T = d i的 n的 + paddingfront + padding_back D {出} = D_ {在} + \\文本{填充\\ _front} + \\文本{填充\\ _back} d O U T = d [HT G100] i的 n的 + padding_front + padding_back Hout=Hin+paddingtop+padding_bottomH{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}Hout​=Hin​+padding_top+padding_bottom Wout=Win+paddingleft+padding_rightW{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout​=Win​+padding_left+padding_right Examples: >>> m = nn.ReplicationPad3d(3) >>> input = torch.randn(16, 3, 8, 320, 480) >>> output = m(input) >>> # using different paddings for different sides >>> m = nn.ReplicationPad3d((3, 3, 6, 6, 1, 1)) >>> output = m(input) ZeroPad2d classtorch.nn.``ZeroPad2d( padding )[source] 零垫输入张量边界。 For N-dimensional padding, use torch.nn.functional.pad(). Parameters padding ( int , tuple) – the size of the padding. If is int, uses the same padding in all boundaries. If a 4-tuple, uses (padding_left\\text{padding\\_left}padding_left , padding_right\\text{padding\\_right}padding_right , padding_top\\text{padding\\_top}padding_top , padding_bottom\\text{padding\\_bottom}padding_bottom ) Shape: Input: (N,C,Hin,Win)(N, C, H{in}, W{in})(N,C,Hin​,Win​) Output: (N,C,Hout,Wout)(N, C, H{out}, W{out})(N,C,Hout​,Wout​) where Hout=Hin+paddingtop+padding_bottomH{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}Hout​=Hin​+padding_top+padding_bottom Wout=Win+paddingleft+padding_rightW{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout​=Win​+padding_left+padding_right Examples: >>> m = nn.ZeroPad2d(2) >>> input = torch.randn(1, 1, 3, 3) >>> input tensor([[[[-0.1678, -0.4418, 1.9466], [ 0.9604, -0.4219, -0.5241], [-0.9162, -0.5436, -0.6446]]]]) >>> m(input) tensor([[[[ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, -0.1678, -0.4418, 1.9466, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.9604, -0.4219, -0.5241, 0.0000, 0.0000], [ 0.0000, 0.0000, -0.9162, -0.5436, -0.6446, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]]) >>> # using different paddings for different sides >>> m = nn.ZeroPad2d((1, 1, 2, 0)) >>> m(input) tensor([[[[ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [ 0.0000, -0.1678, -0.4418, 1.9466, 0.0000], [ 0.0000, 0.9604, -0.4219, -0.5241, 0.0000], [ 0.0000, -0.9162, -0.5436, -0.6446, 0.0000]]]]) ConstantPad1d classtorch.nn.``ConstantPad1d( padding , value )[source] 具有恒定值垫输入张量的界限。 For N-dimensional padding, use torch.nn.functional.pad(). Parameters 填充 （ INT ， 元组 ） 填充的大小。如果是 INT ，使用在两个边界相同的填充。如果2- 元组，使用（ padding_left \\ {文本填充\\ _Left} padding_left ， padding_right \\文本{填充\\ _right} padding_right ） Shape: Input: (N,C,Win)(N, C, W_{in})(N,C,Win​) Output: (N,C,Wout)(N, C, W_{out})(N,C,Wout​) where Wout=Win+paddingleft+padding_rightW{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout​=Win​+padding_left+padding_right Examples: >>> m = nn.ConstantPad1d(2, 3.5) >>> input = torch.randn(1, 2, 4) >>> input tensor([[[-1.0491, -0.7152, -0.0749, 0.8530], [-1.3287, 1.8966, 0.1466, -0.2771]]]) >>> m(input) tensor([[[ 3.5000, 3.5000, -1.0491, -0.7152, -0.0749, 0.8530, 3.5000, 3.5000], [ 3.5000, 3.5000, -1.3287, 1.8966, 0.1466, -0.2771, 3.5000, 3.5000]]]) >>> m = nn.ConstantPad1d(2, 3.5) >>> input = torch.randn(1, 2, 3) >>> input tensor([[[ 1.6616, 1.4523, -1.1255], [-3.6372, 0.1182, -1.8652]]]) >>> m(input) tensor([[[ 3.5000, 3.5000, 1.6616, 1.4523, -1.1255, 3.5000, 3.5000], [ 3.5000, 3.5000, -3.6372, 0.1182, -1.8652, 3.5000, 3.5000]]]) >>> # using different paddings for different sides >>> m = nn.ConstantPad1d((3, 1), 3.5) >>> m(input) tensor([[[ 3.5000, 3.5000, 3.5000, 1.6616, 1.4523, -1.1255, 3.5000], [ 3.5000, 3.5000, 3.5000, -3.6372, 0.1182, -1.8652, 3.5000]]]) ConstantPad2d classtorch.nn.``ConstantPad2d( padding , value )[source] Pads the input tensor boundaries with a constant value. For N-dimensional padding, use torch.nn.functional.pad(). Parameters padding ( int , tuple) – the size of the padding. If is int, uses the same padding in all boundaries. If a 4-tuple, uses (padding_left\\text{padding\\_left}padding_left , padding_right\\text{padding\\_right}padding_right , padding_top\\text{padding\\_top}padding_top , padding_bottom\\text{padding\\_bottom}padding_bottom ) Shape: Input: (N,C,Hin,Win)(N, C, H{in}, W{in})(N,C,Hin​,Win​) Output: (N,C,Hout,Wout)(N, C, H{out}, W{out})(N,C,Hout​,Wout​) where Hout=Hin+paddingtop+padding_bottomH{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}Hout​=Hin​+padding_top+padding_bottom Wout=Win+paddingleft+padding_rightW{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout​=Win​+padding_left+padding_right Examples: >>> m = nn.ConstantPad2d(2, 3.5) >>> input = torch.randn(1, 2, 2) >>> input tensor([[[ 1.6585, 0.4320], [-0.8701, -0.4649]]]) >>> m(input) tensor([[[ 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000], [ 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000], [ 3.5000, 3.5000, 1.6585, 0.4320, 3.5000, 3.5000], [ 3.5000, 3.5000, -0.8701, -0.4649, 3.5000, 3.5000], [ 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000], [ 3.5000, 3.5000, 3.5000, 3.5000, 3.5000, 3.5000]]]) >>> # using different paddings for different sides >>> m = nn.ConstantPad2d((3, 0, 2, 1), 3.5) >>> m(input) tensor([[[ 3.5000, 3.5000, 3.5000, 3.5000, 3.5000], [ 3.5000, 3.5000, 3.5000, 3.5000, 3.5000], [ 3.5000, 3.5000, 3.5000, 1.6585, 0.4320], [ 3.5000, 3.5000, 3.5000, -0.8701, -0.4649], [ 3.5000, 3.5000, 3.5000, 3.5000, 3.5000]]]) ConstantPad3d classtorch.nn.``ConstantPad3d( padding , value )[source] Pads the input tensor boundaries with a constant value. For N-dimensional padding, use torch.nn.functional.pad(). Parameters padding ( int , tuple) – the size of the padding. If is int, uses the same padding in all boundaries. If a 6-tuple, uses (padding_left\\text{padding\\_left}padding_left , padding_right\\text{padding\\_right}padding_right , padding_top\\text{padding\\_top}padding_top , padding_bottom\\text{padding\\_bottom}padding_bottom , padding_front\\text{padding\\_front}padding_front , padding_back\\text{padding\\_back}padding_back ) Shape: Input: (N,C,Din,Hin,Win)(N, C, D{in}, H{in}, W_{in})(N,C,Din​,Hin​,Win​) Output: (N,C,Dout,Hout,Wout)(N, C, D{out}, H{out}, W_{out})(N,C,Dout​,Hout​,Wout​) where Dout=Din+paddingfront+padding_backD{out} = D_{in} + \\text{padding\\_front} + \\text{padding\\_back}Dout​=Din​+padding_front+padding_back Hout=Hin+paddingtop+padding_bottomH{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}Hout​=Hin​+padding_top+padding_bottom Wout=Win+paddingleft+padding_rightW{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}Wout​=Win​+padding_left+padding_right Examples: >>> m = nn.ConstantPad3d(3, 3.5) >>> input = torch.randn(16, 3, 10, 20, 30) >>> output = m(input) >>> # using different paddings for different sides >>> m = nn.ConstantPad3d((3, 3, 6, 6, 0, 1), 3.5) >>> output = m(input) 非线性激活（加权和，非线性） ELU classtorch.nn.``ELU( alpha=1.0 , inplace=False )[source] 适用逐元素的功能： ELU(x)=max⁡(0,x)+min⁡(0,α∗(exp⁡(x)−1))\\text{ELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1)) ELU(x)=max(0,x)+min(0,α∗(exp(x)−1)) Parameters 阿尔法 - 的 α \\阿尔法 α 为ELU制剂值。默认值：1.0 就地 - 可以任选地执行操作就地。默认值：假 Shape: 输入： （ N ， ） （N，） （ N ， ） 其中 的装置，任意数量的附加维度的 输出： （ N ， ） （N，） （ N ， * ） ，相同形状的输入 Examples: >>> m = nn.ELU() >>> input = torch.randn(2) >>> output = m(input) Hardshrink classtorch.nn.``Hardshrink( lambd=0.5 )[source] 适用硬收缩功能元素方面： HardShrink(x)={x, if x>λx, if x \\lambda \\\\ x, & \\text{ if } x λ if x Parameters lambd - 的 λ \\拉姆达 λ 为Hardshrink制剂值。默认值：0.5 Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.Hardshrink() >>> input = torch.randn(2) >>> output = m(input) Hardtanh classtorch.nn.``Hardtanh( min_val=-1.0 , max_val=1.0 , inplace=False , min_value=None , max_value=None )[source] 应用HardTanh功能逐元素 HardTanh定义为： HardTanh(x)={1 if x>1−1 if x 1 \\\\ -1 & \\text{ if } x 1 if x 线性区域 [ 的范围内 - 1 ， 1 [1,1] [ - 1 ， 1 ] 可以用被调整MIN_VAL和MAX_VAL。 Parameters MIN_VAL - 线性区域范围的最小值。默认值：-1 MAX_VAL - 线性区域范围的最大值。默认值：1 inplace – can optionally do the operation in-place. Default: False 关键字参数MIN_VALUE和MAX_VALUE已经被弃用，取而代之的MIN_VAL和MAX_VAL。 Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.Hardtanh(-2, 2) >>> input = torch.randn(2) >>> output = m(input) LeakyReLU classtorch.nn.``LeakyReLU( negative_slope=0.01 , inplace=False )[source] Applies the element-wise function: LeakyReLU(x)=max⁡(0,x)+negative_slope∗min⁡(0,x)\\text{LeakyReLU}(x) = \\max(0, x) + \\text{negative\\_slope} * \\min(0, x) LeakyReLU(x)=max(0,x)+negative_slope∗min(0,x) 要么 LeakyRELU(x)={x, if x≥0negative_slope×x, otherwise \\text{LeakyRELU}(x) = \\begin{cases} x, & \\text{ if } x \\geq 0 \\\\ \\text{negative\\_slope} \\times x, & \\text{ otherwise } \\end{cases} LeakyRELU(x)={x,negative_slope×x,​ if x≥0 otherwise ​ Parameters negative_slope - 控制负斜率的角度。默认值：1E-2 inplace – can optionally do the operation in-place. Default: False Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.LeakyReLU(0.1) >>> input = torch.randn(2) >>> output = m(input) LogSigmoid classtorch.nn.``LogSigmoid[source] Applies the element-wise function: LogSigmoid(x)=log⁡(11+exp⁡(−x))\\text{LogSigmoid}(x) = \\log\\left(\\frac{ 1 }{ 1 \\exp(-x)}\\right) LogSigmoid(x)=log(1+exp(−x)1​) Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.LogSigmoid() >>> input = torch.randn(2) >>> output = m(input) MultiheadAttention classtorch.nn.``MultiheadAttention( embed_dim , num_heads , dropout=0.0 , bias=True , add_bias_kv=False , add_zero_attn=False , kdim=None , vdim=None )[source] 允许模型共同出席，从不同的表示子空间的信息。见参考文献：注意是所有你需要 MultiHead(Q,K,V)=Concat(head1,…,headh)WOwhereheadi=Attention(QWiQ,KWiK,VWiV)\\text{MultiHead}(Q, K, V) = \\text{Concat}(head_1,\\dots,head_h)W^O \\text{where} head_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V) MultiHead(Q,K,V)=Concat(head1​,…,headh​)WOwhereheadi​=Attention(QWiQ​,KWiK​,VWiV​) Parameters embed_dim - 模型的总尺寸。 num_heads - 平行注意头。 滤除 - 关于attn_output_weights一个漏失层。默认值：0.0。 偏压 - 加偏压作为模块参数。默认值：true。 add_bias_kv - 在昏暗= 0添加偏置的键和值的序列。 add_zero_attn - 在昏暗= 1添加新的批次零到的键和值的序列。 kdim - 的关键特征总数。默认值：无。 VDIM - 的关键特征总数。默认值：无。 [HTG0注意 - 如果kdim和VDIM都没有，它们将被设置为embed_dim这样 键，值具有相同数目的特征。 （ 查询 ， ） - Examples: >>> multihead_attn = nn.MultiheadAttention(embed_dim, num_heads) >>> attn_output, attn_output_weights = multihead_attn(query, key, value) forward( query , key , value , key_padding_mask=None , need_weights=True , attn_mask=None )[source] Parameters 键，值 （ 查询 ，[5 HTG） - 映射的查询和一组键 - 值对到输出。请参阅“注意是所有你需要”更多的细节。 key_padding_mask - 如果提供的话，在键配置的填充元件将被受瞩目忽略。这是一个二进制掩码。当值为True，关注层上的相应值将充满-INF。 need_weights - 输出attn_output_weights。 attn_mask - 掩模，防止注意某些位置。这是一种添加剂掩模（即，值将被添加到关注层）。 Shape: 输入： 查询： （ L ， N ， E ） （L，N，E） （ L ， N ， E ） 其中，L是所述靶序列的长度，N是批量大小，E是嵌入维数。 键： （ S ， N ， E ） （S，N，E） （ S ， N ， E ） ，其中S是源序列长度，N是批量大小，E是嵌入维数。 值： （ S ， N ， E ） （S，N，E） （ S ， N ， E ） 其中，S是源序列长度，N是批量大小，E是嵌入维数。 key_padding_mask： （ N ， S ） （N，S） （ N ， S ） ，ByteTensor，其中N是批量大小，S是源序列长度。 attn_mask： （ L ， S ） （L，S） （ L ， S ） 其中，L是所述靶序列的长度，S是源序列长度。 输出： attn_output： （ L ， N ， E ） （L，N，E） （ L ， N ， E ） 其中，L是所述靶序列的长度，N是批量大小，E是嵌入维数。 attn_output_weights： （ N ， L ， S ） （N，L，S） （ N ， L ， S ） 其中，N是批量大小，L是所述靶序列的长度，S是源序列长度。 PReLU classtorch.nn.``PReLU( num_parameters=1 , init=0.25 )[source] Applies the element-wise function: PReLU(x)=max⁡(0,x)+a∗min⁡(0,x)\\text{PReLU}(x) = \\max(0,x) + a * \\min(0,x) PReLU(x)=max(0,x)+a∗min(0,x) or PReLU(x)={x, if x≥0ax, otherwise \\text{PReLU}(x) = \\begin{cases} x, & \\text{ if } x \\geq 0 \\\\ ax, & \\text{ otherwise } \\end{cases} PReLU(x)={x,ax,​ if x≥0 otherwise ​ 此处 一 一 一 是一个可以学习的参数。当不带参数调用， nn.PReLU（）使用单个参数 一 A 一 所有输入通道。如果调用 nn.PReLU（nChannels），单独的 一 一 一 用于每个输入通道。 Note 权衰减不应该被用来当学习 一 一 A 获得良好的性能。 Note 昏暗的通道输入的第二暗淡。当输入具有变暗& LT ; 2，那么就没有信道暗淡和通道= 1的数。 Parameters num_parameters （ INT ） - 的 数目的 一 一 学习。虽然采用int作为输入，仅存在两个值是合法的：1，或通道中的输入的数目。默认值：1 INIT （ 浮动 ） - 的 一[初始值HTG13] 一 一 [ HTG29。默认值：0.25 Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Variables 〜PReLU.weight （ 张量 ） - 形状的可学习权重（num_parameters）。 Examples: >>> m = nn.PReLU() >>> input = torch.randn(2) >>> output = m(input) RELU classtorch.nn.``ReLU( inplace=False )[source] 施加整流的线性单元函数逐元素： RELU （ × ） = MAX ⁡ （ 0 ， × ） \\文本{RELU}（X）= \\ MAX（0，x）的 RELU （ × ） = MAX （ 0 ， X ） Parameters inplace – can optionally do the operation in-place. Default: False Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.ReLU() >>> input = torch.randn(2) >>> output = m(input) An implementation of CReLU - https://arxiv.org/abs/1603.05201 >>> m = nn.ReLU() >>> input = torch.randn(2).unsqueeze(0) >>> output = torch.cat((m(input),m(-input))) ReLU6 classtorch.nn.``ReLU6( inplace=False )[source] Applies the element-wise function: ReLU6(x)=min⁡(max⁡(0,x),6)\\text{ReLU6}(x) = \\min(\\max(0,x), 6) ReLU6(x)=min(max(0,x),6) Parameters inplace – can optionally do the operation in-place. Default: False Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.ReLU6() >>> input = torch.randn(2) >>> output = m(input) RReLU classtorch.nn.``RReLU( lower=0.125 , upper=0.3333333333333333 , inplace=False )[source] 应用随机漏泄整流衬垫单元的功能，逐元素，如在论文中描述： 整流的激活的实证评价卷积网络。 该函数被定义为： RReLU(x)={xif x≥0ax otherwise \\text{RReLU}(x) = \\begin{cases} x & \\text{if } x \\geq 0 \\\\ ax & \\text{ otherwise } \\end{cases} RReLU(x)={xax​if x≥0 otherwise ​ 其中 一 一 一 被随机地从取样的均匀分布 U （ 下 ， 上 ） \\ mathcal 【U}（\\文本{低}，\\文本{上部}） U （ 下 ， 上 ） 。 请参阅： https://arxiv.org/pdf/1505.00853.pdf Parameters 下 - 下界的均匀分布的。默认值： 1 8 \\压裂{1 } {8} 8 1 上 - 上限的均匀分布的。默认值： 1 3 \\压裂{1 } {3} 3 1 inplace – can optionally do the operation in-place. Default: False Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.RReLU(0.1, 0.3) >>> input = torch.randn(2) >>> output = m(input) 九色鹿 classtorch.nn.``SELU( inplace=False )[source] 应用元素方面，如： SELU(x)=scale∗(max⁡(0,x)+min⁡(0,α∗(exp⁡(x)−1)))\\text{SELU}(x) = \\text{scale} (\\max(0,x) + \\min(0, \\alpha (\\exp(x) - 1))) SELU(x)=scale∗(max(0,x)+min(0,α∗(exp(x)−1))) 与 α = 1.6732632423543772848170429916717 \\阿尔法= 1.6732632423543772848170429916717 α = 1 。 6 7 3 2 6 3 2 4 2 3 5 4 3 7 7 2 8 4 8 1 7 0 4 2 9 9 1 6 7 1 7 和 规模 = 1.0507009873554804934193349852946 \\文本{规模} = 1.0507009873554804934193349852946 规模 = 1 。 0 5 0 7 0 0 9 8 7 3 5 5 4 8 0 4 9 3 4 1 9 3 3 4 9 8 5 2 9 4 6 。 更多详细信息可在本文中找到[自正火神经网络HTG1。 Parameters 就地 （ 布尔 ， 可选 ） - 可任选地执行操作就地。默认值：假 Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.SELU() >>> input = torch.randn(2) >>> output = m(input) CELU classtorch.nn.``CELU( alpha=1.0 , inplace=False )[source] Applies the element-wise function: CELU(x)=max⁡(0,x)+min⁡(0,α∗(exp⁡(x/α)−1))\\text{CELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x/\\alpha) - 1)) CELU(x)=max(0,x)+min(0,α∗(exp(x/α)−1)) 更多细节可以在文献的连续可微指数直线单元中找到。 Parameters 阿尔法 - 的 α \\阿尔法 α 为CELU制剂值。默认值：1.0 inplace – can optionally do the operation in-place. Default: False Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.CELU() >>> input = torch.randn(2) >>> output = m(input) 乙状结肠 classtorch.nn.``Sigmoid[source] Applies the element-wise function: Sigmoid(x)=11+exp⁡(−x)\\text{Sigmoid}(x) = \\frac{1}{1 + \\exp(-x)} Sigmoid(x)=1+exp(−x)1​ Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.Sigmoid() >>> input = torch.randn(2) >>> output = m(input) Softplus classtorch.nn.``Softplus( beta=1 , threshold=20 )[source] Applies the element-wise function: Softplus(x)=1β∗log⁡(1+exp⁡(β∗x))\\text{Softplus}(x) = \\frac{1}{\\beta} * \\log(1 \\exp(\\beta * x)) Softplus(x)=β1​∗log(1+exp(β∗x)) SoftPlus是光滑逼近RELU功能，并且可以用于约束的机器的输出以始终是正的。 对于数值稳定性的执行恢复到线性函数对于高于某个值的输入。 Parameters 的β - 的 β \\的β β 为Softplus制剂值。默认值：1 阈 - 高于此值恢复到一个线性函数。默认值：20 Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.Softplus() >>> input = torch.randn(2) >>> output = m(input) Softshrink classtorch.nn.``Softshrink( lambd=0.5 )[source] 应用软收缩功能的elementwise： SoftShrinkage(x)={x−λ, if x>λx+λ, if x \\lambda \\\\ x + \\lambda, & \\text{ if } x λ if x Parameters lambd - 的 λ \\拉姆达 λ 为Softshrink制剂值。默认值：0.5 Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.Softshrink() >>> input = torch.randn(2) >>> output = m(input) Softsign classtorch.nn.``Softsign[source] Applies the element-wise function: SoftSign(x)=x1+∣x∣\\text{SoftSign}(x) = \\frac{x}{ 1 + |x|} SoftSign(x)=1+∣x∣x​ Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.Softsign() >>> input = torch.randn(2) >>> output = m(input) 双曲正切 classtorch.nn.``Tanh[source] Applies the element-wise function: Tanh(x)=tanh⁡(x)=ex−e−xex+e−x\\text{Tanh}(x) = \\tanh(x) = \\frac{e^x - e^{-x}} {e^x + e^{-x}} Tanh(x)=tanh(x)=ex+e−xex−e−x​ Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.Tanh() >>> input = torch.randn(2) >>> output = m(input) Tanhshrink classtorch.nn.``Tanhshrink[source] Applies the element-wise function: Tanhshrink(x)=x−Tanh(x)\\text{Tanhshrink}(x) = x - \\text{Tanh}(x) Tanhshrink(x)=x−Tanh(x) Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.Tanhshrink() >>> input = torch.randn(2) >>> output = m(input) 阈值 classtorch.nn.``Threshold( threshold , value , inplace=False )[source] 阈值输入张量的每个元素。 阈值定义为： y={x, if x>thresholdvalue, otherwise y = \\begin{cases} x, &\\text{ if } x > \\text{threshold} \\\\ \\text{value}, &\\text{ otherwise } \\end{cases} y={x,value,​ if x>threshold otherwise ​ Parameters 阈 - 在该值的阈值 值 - 该值与替换 inplace – can optionally do the operation in-place. Default: False Shape: Input: (N,∗)(N, )(N,∗) where means, any number of additional dimensions Output: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> m = nn.Threshold(0.1, 20) >>> input = torch.randn(2) >>> output = m(input) 非线性激活（其他） Softmin classtorch.nn.``Softmin( dim=None )[source] 施加Softmin功能的n维输入张量重新缩放它们，使得所述n维输出张量谎言的范围在 [0,1] 和总和为1的元素。 Softmin定义为： Softmin(xi)=exp⁡(−xi)∑jexp⁡(−xj)\\text{Softmin}(x_{i}) = \\frac{\\exp(-x_i)}{\\sum_j \\exp(-x_j)} Softmin(xi​)=∑j​exp(−xj​)exp(−xi​)​ Shape: 输入： （ ） （） （ ） 其中 手段，任意数量的附加维度的 输出： （ ） （） （ * ） ，相同形状的输入 Parameters 暗淡 （ INT ） - 沿其Softmin将被计算的尺寸（因此沿暗淡每片将总结为1）。 Returns 相同的尺寸和形状作为输入的范围内的张量，其值[0，1] Examples: >>> m = nn.Softmin() >>> input = torch.randn(2, 3) >>> output = m(input) 使用SoftMax classtorch.nn.``Softmax( dim=None )[source] 应用使用SoftMax功能的n维输入张量重新缩放它们，使得所述n维输出张量谎言在范围[0,1]和总和为1的元素。 使用SoftMax定义为： Softmax(xi)=exp⁡(xi)∑jexp⁡(xj)\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)} Softmax(xi​)=∑j​exp(xj​)exp(xi​)​ Shape: Input: (∗)()(∗) where means, any number of additional dimensions Output: (∗)(*)(∗) , same shape as the input Returns 相同的尺寸和形状作为输入的与值的范围内的张量[0，1] Parameters 暗淡 （ INT ） - 沿其使用SoftMax将被计算的尺寸（因此沿暗淡每片将总结为1）。 Note 此模块不与NLLLoss，其预计使用SoftMax和自身之间要计算日志直接工作。使用 LogSoftmax 代替（它的速度更快，具有更好的数值属性）。 Examples: >>> m = nn.Softmax(dim=1) >>> input = torch.randn(2, 3) >>> output = m(input) Softmax2d classtorch.nn.``Softmax2d[source] 适用使用SoftMax在功能，每个空间位置。 当给定的的图像频道 × 高度 × 宽度，它将应用使用SoftMax 到每个位置 （ C H 一 n的 n的 E L S ， H i的 ， W [HTG51：J ） （频道，h_i，w_j） （ ç H 一 n的 n的 E L S ， H i的 ， W [HTG131：J ） Shape: 输入： （ N ， C ， H ， W ） （N，C，H，W） （ N ， C ， H ， W ） 输出： （ N ， C ， H ， W ） （N，C，H，W） （ N ， C ， H ， W ） （相同形状的输入） Returns a Tensor of the same dimension and shape as the input with values in the range [0, 1] Examples: >>> m = nn.Softmax2d() >>> # you softmax over the 2nd dimension >>> input = torch.randn(2, 3, 12, 13) >>> output = m(input) LogSoftmax classtorch.nn.``LogSoftmax( dim=None )[source] 应用 日志 ⁡ （ 使用SoftMax （ × ） ） \\日志（\\文本{使用SoftMax}（X）） LO G （ 使用SoftMax （ × ） ） 功能的n维输入张量。所述LogSoftmax制剂可以被简化为： LogSoftmax(xi)=log⁡(exp⁡(xi)∑jexp⁡(xj))\\text{LogSoftmax}(x_{i}) = \\log\\left(\\frac{\\exp(x_i) }{ \\sum_j \\exp(x_j)} \\right) LogSoftmax(xi​)=log(∑j​exp(xj​)exp(xi​)​) Shape: Input: (∗)()(∗) where means, any number of additional dimensions Output: (∗)(*)(∗) , same shape as the input Parameters 暗淡 （ INT ） - 沿其LogSoftmax将被计算的尺寸。 Returns 相同的尺寸和形状作为输入的与值的范围内的张量[-INF，0） Examples: >>> m = nn.LogSoftmax() >>> input = torch.randn(2, 3) >>> output = m(input) AdaptiveLogSoftmaxWithLoss classtorch.nn.``AdaptiveLogSoftmaxWithLoss( in_features , n_classes , cutoffs , div_value=4.0 , head_bias=False )[source] 作为用于GPU的由爱德华墓，阿芒Joulin穆斯塔法西塞，大卫Grangier和埃尔韦Jégou在高效SOFTMAX近似描述高效SOFTMAX近似。 自适应SOFTMAX是与产量大空间的培训模式近似的策略。当标签分布极不平衡，例如，在自然语言建模，这里所说的频率分布大致如下齐普夫定律这是最有效的。 自适应SOFTMAX划分标签分成几个集群，根据自己的频率。这些集群可以包含不同数量的每一个目标。另外，将含有较不频繁的标签的集群分配低维的嵌入到这些标签，从而加快了计算。对于每个minibatch，只为其中至少一个目标是本簇进行评估。 这个想法是，这是经常访问的集群（如第一个，包含最常见的标签），也应该是廉价的计算 - 也就是，包含少量分配的标签。 我们强烈建议您考虑看看原来的文件的更多细节。 截断值应在增加顺序排序整数的有序序列。它控制集群的数量和目标分割成集群。例如设置截断值 = [10， 100， 1000]表示第一 10 目标将被分配到所述自适应SOFTMAX的 '头部'，目标 11，12，...，100 将被分配到所述第一群集，和目标 101 ，102，...，1000 将被分配到所述第二群集，而目标 1001，1002，...，n_classes - 1 将被分配到最后，第三集群。 div_value被用来计算每个附加簇的大小，它被给定为 ⌊ i的 n的 F E 一 T U R E S d i的 [HTG42】v [HTG46】v 一 L U E i的 d × ⌋ \\左\\ lfloor \\压裂{在\\ features} {DIV \\ _value ^ {IDX}} \\右\\ rfloor ⌊ d i的 [HTG101】V [HTG105】V 一 L U E i的 d × i的 n的 _ F E 一 T U R E S [HTG19 0] ⌋ ，其中 i的 d × IDX i的 d × 是群集索引（与集群以较少具有较大索引频繁字和索引起始从 1 1 1 ）。 head_bias如果设置为True，增加了一个偏项到自适应SOFTMAX的“头”。有关详细信息，请参阅纸张。设置为False正式执行。 Warning 作为输入传递给此模块的标签应被分类accoridng自己的频率。这意味着，最频繁的标签应该由指数 0 ，和至少频繁标签应该由指数 n_classes来表示来表示 - 1 。 Note 这个模块返回NamedTuple与输出和损失字段。详情请参见更多文档。 Note 为了计算对数概率的所有类，则log_prob可以使用的方法。 Parameters 在输入张量的特征数 - in_features （ INT ） 在数据集的类的数量 - n_classes （ INT ） 截断值 （ 序号 ） - 用于分配的目标，以他们的水桶保险丝 div_value （ 浮动 ， 可选 ） - 用来作为指数来计算集群的大小值。默认值：4.0 head_bias （ 布尔 ， 可选 ） - 如果真，增加了一个偏项到自适应SOFTMAX的“头”。默认值：假 Returns 输出 是大小的张量N [HTG5含有计算目标数概率对于每个实施例 损失 是表示所计算的负对数似然损耗的标量 Return type NamedTuple与输出和损失字段 Shape: 输入： （ N ， i的 n的 F E 一 T U [R E S ） （N，在\\ _features） （ N ， i的 n的 F E 一 T U R E S ） 目标： （ N ） （N） （ N ） 其中，每个值满足 0 & LT ; = T 一 R 克 E T [ i的 & LT ; = n的 C L 一 S S E S 0 & LT ; =目标[I] & LT ; = N \\ _classes 0 [H TG97] & LT ; = T 一 R 克 E T [ i的 & LT ; = n的 C 升 一 S S E S 输出1： （ N ） （N） （ N ） OUTPUT2：[HTG1标量 log_prob( input )[source] 计算对数概率对于所有 n的 C L 一 S S E S n的\\ _classes n的 C L 一个 S S E S Parameters 输入 （ 张量 ） - 的例子的minibatch Returns 对数概率为每个类 C C C 在范围 0 & LT ; = C & LT ; = n的 C L 一 S S E S 0 & LT ; = C & LT ; = N \\ _classes 0 & LT ; = C & LT ; = n的 C L 一 S S E S ，其中 n的 C 升 一 S S E S n的\\ _classes n的 C L 一 S S E S 的参数传递为AdaptiveLogSoftmaxWithLoss [HTG1 86]构造。 Shape: 输入： （ N ， i的 n的 F E 一 T U [R E S ） （N，在\\ _features） （ N ， i的 n的 F E 一 T U R E S ） 输出： （ N ， n的 C L 一 S S E S ） （N，N- \\ _classes） （ N ， n的 C 升 一 S S E S ） predict( input )[source] 这等同于 self.log_pob（输入）.argmax（暗= 1），但是在某些情况下更为有效。 Parameters input ( Tensor) – a minibatch of examples Returns 用对于每个实施例的概率最高的类 Return type 输出（张量） Shape: Input: (N,in_features)(N, in\\_features)(N,in_features) 输出： （ N ） （N） （ N ） 归一化的层 BatchNorm1d classtorch.nn.``BatchNorm1d( num_features , eps=1e-05 , momentum=0.1 , affine=True , track_running_stats=True )[source] 适用批标准化在2D或如在文献批标准化描述3D输入（带有可选的附加的信道尺寸的小批量的1D输入）：通过减少内部协变量移位加速深网络训练。 y=x−E[x]Var[x]+ϵ∗γ+βy = \\frac{x - \\mathrm{E}[x]}{\\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\betay=Var[x]+ϵ​x−E[x]​∗γ+β 的平均值和标准偏差是每个尺寸来计算放置在迷你批次和 γ \\伽马 γ 和 β \\的β β 是大小的可学习的参数矢量 C （其中 C 是输入大小）。默认情况下，γ \\伽马 的 的元素 γ 被设置为1和 的元素 β \\的β β 被设置为0。 此外，默认情况，在培训过程中这层继续运行其计算的均值和方差，然后再评估期间用于标准化的估计。正在运行的估计是保持了默认的势头0.1。 如果track_running_stats设置为假，这一层则不会继续运行的估计，和批量统计过程中的评估时间，而不是作为好。 Note 此动量参数是从一个在优化器中使用的类和动量的常规概念不同。在数学上，这里运行统计数据的更新规则为 × ^ 新 = （ 1 - 动量 ） × × ^ + 动量 × × T \\帽子{X} _ \\文本{新} =（1 - \\文本{动量}）\\倍\\帽子{X} + \\文本{动量} \\倍X_T × ^ 新 = （ 1 - 动量 ） × × ^ + 动量 × × T ，其中 × ^ \\帽子{X} × ^ ​​ 是估计的统计量和 X T X_T × T 是新的观测值。 因为批标准化是在 C 维完成的，在（N，L）切片计算统计数据，这是共同的术语来调用这个时空批标准化。 Parameters NUM_FEATURES - C C C 从大小的预期输入 （ N ， C ， L ） （N，C，L） （ N ， C ， L ） 或 L L L 从的输入大小 （ N ， L ） （N，L） （ N ， L ） EPS - 的值添加到分母数值稳定性。默认值：1E-5 动量 - 用于running_mean和running_var计算的值。可以被设置为无 [HTG5用于累积移动平均（即简单平均）。默认值：0.1 仿射 - 一个布尔值，当设置为真，该模块具有可学习的仿射参数。默认值：真 track_running_stats - 当设置为真，此模块跟踪的运行均值和方差，和一个布尔值，当设置为假，该模块不跟踪这样的统计并始终使用在训练和eval模式批次的统计数据。默认值：真 Shape: 输入： （ N ， C ） （N，C） （ N ， C ） 或 （ N ， C ， L ） （N，C，L） （ N ， C ， L ） 输出： （ N ， C ） （N，C） （ N ， C ） 或 （ N ， C ， L ） （N，C，L） （ N ， C ， L ） （相同形状的输入） Examples: >>> # With Learnable Parameters >>> m = nn.BatchNorm1d(100) >>> # Without Learnable Parameters >>> m = nn.BatchNorm1d(100, affine=False) >>> input = torch.randn(20, 100) >>> output = m(input) BatchNorm2d classtorch.nn.``BatchNorm2d( num_features , eps=1e-05 , momentum=0.1 , affine=True , track_running_stats=True )[source] 适用作为纸批标准化描述在4D输入批标准化（用另外的通道尺寸的小批量的2D输入）：通过减少内部协变量移位加速深网络训练。 y=x−E[x]Var[x]+ϵ∗γ+βy = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\betay=Var[x]+ϵ​x−E[x]​∗γ+β The mean and standard-deviation are calculated per-dimension over the mini- batches and γ\\gammaγ and β\\betaβ are learnable parameter vectors of size C (where C is the input size). By default, the elements of γ\\gammaγ are set to 1 and the elements of β\\betaβ are set to 0. Also by default, during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default momentumof 0.1. If track_running_statsis set to False, this layer then does not keep running estimates, and batch statistics are instead used during evaluation time as well. Note This momentumargument is different from one used in optimizer classes and the conventional notion of momentum. Mathematically, the update rule for running statistics here is x^new=(1−momentum)×x^+momentum×xt\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_tx^new​=(1−momentum)×x^+momentum×xt​ , where x^\\hat{x}x^ is the estimated statistic and xtx_txt​ is the new observed value. 因为批标准化是在 C 维完成的，在（N，H，W）切片计算统计数据，这是共同的术语来调用这个空间批标准化。 Parameters NUM_FEATURES - C C C 从大小的预期输入 （ N ， C ， H ， W ） （N，C，H，W） （ N ， C ， H ， W ） eps – a value added to the denominator for numerical stability. Default: 1e-5 momentum – the value used for the running_mean and running_var computation. Can be set to Nonefor cumulative moving average (i.e. simple average). Default: 0.1 affine – a boolean value that when set to True, this module has learnable affine parameters. Default: True track_running_stats – a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: True Shape: Input: (N,C,H,W)(N, C, H, W)(N,C,H,W) Output: (N,C,H,W)(N, C, H, W)(N,C,H,W) (same shape as input) Examples: >>> # With Learnable Parameters >>> m = nn.BatchNorm2d(100) >>> # Without Learnable Parameters >>> m = nn.BatchNorm2d(100, affine=False) >>> input = torch.randn(20, 100, 35, 45) >>> output = m(input) BatchNorm3d classtorch.nn.``BatchNorm3d( num_features , eps=1e-05 , momentum=0.1 , affine=True , track_running_stats=True )[source] 适用作为纸批标准化描述在5D输入批标准化（用另外的通道尺寸的小批量的3D输入）：通过减少内部协变量移位加速深网络训练。 y=x−E[x]Var[x]+ϵ∗γ+βy = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\betay=Var[x]+ϵ​x−E[x]​∗γ+β The mean and standard-deviation are calculated per-dimension over the mini- batches and γ\\gammaγ and β\\betaβ are learnable parameter vectors of size C (where C is the input size). By default, the elements of γ\\gammaγ are set to 1 and the elements of β\\betaβ are set to 0. Also by default, during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default momentumof 0.1. If track_running_statsis set to False, this layer then does not keep running estimates, and batch statistics are instead used during evaluation time as well. Note This momentumargument is different from one used in optimizer classes and the conventional notion of momentum. Mathematically, the update rule for running statistics here is x^new=(1−momentum)×x^+momentum×xt\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_tx^new​=(1−momentum)×x^+momentum×xt​ , where x^\\hat{x}x^ is the estimated statistic and xtx_txt​ is the new observed value. 因为批标准化是在 C 维，在计算统计数据（N，d，H，W）切片，它是常见的术语做调用此体积批标准化或时空批标准化。 Parameters NUM_FEATURES - C C C 从大小的预期输入 （ N ， C ， d ， H ， W ） （N，C，d，H，W ） （ N ， C ， d ， H ， W ） eps – a value added to the denominator for numerical stability. Default: 1e-5 momentum – the value used for the running_mean and running_var computation. Can be set to Nonefor cumulative moving average (i.e. simple average). Default: 0.1 affine – a boolean value that when set to True, this module has learnable affine parameters. Default: True track_running_stats – a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: True Shape: 输入： （ N ， C ， d ， H ， W ） （N，C，d，H，W） （ N ， C ， d ， H ， W ） 输出： （ N ， C ， d ， H ， W ） （N，C，d，H，W） （ N ， C ， d ， H ， W ） （相同形状的输入） Examples: >>> # With Learnable Parameters >>> m = nn.BatchNorm3d(100) >>> # Without Learnable Parameters >>> m = nn.BatchNorm3d(100, affine=False) >>> input = torch.randn(20, 100, 35, 45, 10) >>> output = m(input) GroupNorm classtorch.nn.``GroupNorm( num_groups , num_channels , eps=1e-05 , affine=True )[source] 如在文献组规范化中描述的应用组规范化在小批量的输入。 y=x−E[x]Var[x]+ϵ∗γ+βy = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta y=Var[x]+ϵ​x−E[x]​∗γ+β 输入通道分离成NUM_GROUPS组，每组包含NUM_CHANNELS / NUM_GROUPS通道。的平均值和标准偏差在各组分别计算。 γ \\伽马 γ 和 β \\的β β 是可学习的每个信道的仿射变换大小的参数矢量NUM_CHANNELS如果仿射是真。 该层使用在训练和评价模式从输入数据计算的统计信息。 Parameters NUM_GROUPS （ INT ） - 基团的数目的信道分离成 NUM_CHANNELS （ INT ） - 预计在输入信道数 EPS - 的值添加到分母数值稳定性。默认值：1E-5 仿射 - 一个布尔值，当设置为真，该模块具有初始化为一（用于权重）和零可学习每个信道的仿射参数（偏差）。默认值：真 [HTG9。 Shape: 输入： （ N ， C ， ） （N，C，） （ N ， C ， * ） 其中 C = NUM_CHANNELS C = \\文本{NUM \\ _channels} C = NUM_CHANNELS 输出： （ N ， C ， ） （N，C，） （ N ， C ， * ） （相同形状的输入） Examples: >>> input = torch.randn(20, 6, 10, 10) >>> # Separate 6 channels into 3 groups >>> m = nn.GroupNorm(3, 6) >>> # Separate 6 channels into 6 groups (equivalent with InstanceNorm) >>> m = nn.GroupNorm(6, 6) >>> # Put all 6 channels into a single group (equivalent with LayerNorm) >>> m = nn.GroupNorm(1, 6) >>> # Activating the module >>> output = m(input) SyncBatchNorm classtorch.nn.``SyncBatchNorm( num_features , eps=1e-05 , momentum=0.1 , affine=True , track_running_stats=True , process_group=None )[source] 适用在N维输入批标准化（一小批量的[N-2]用另外的通道尺寸d的输入），如文献批标准化描述：通过减少内部协变量移加速深网络训练 。 y=x−E[x]Var[x]+ϵ∗γ+βy = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\betay=Var[x]+ϵ​x−E[x]​∗γ+β 平均值和标准偏差每个维度在同一过程组的所有小批量计算。 γ \\伽马 γ 和 β \\的β β 是大小的可学习的参数矢量 C （其中 C 被输入大小）。默认情况下，γ \\伽马 的 的元素 γ 是从 取样 U （ 0 ， 1 ） \\ mathcal {U】（0，1） U （ 0 ， 1 ） 和 的元素β \\的β β 被设置为0。 Also by default, during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default momentumof 0.1. If track_running_statsis set to False, this layer then does not keep running estimates, and batch statistics are instead used during evaluation time as well. Note 此动量参数是从一个在优化器中使用的类和动量的常规概念不同。在数学上，这里运行统计数据的更新规则为 × ^ 新 = （ 1 - 动量 ） × × ^ + momemtum × × T \\帽子{X} _ \\文本{新} =（1 - \\文本{动量}）\\倍\\帽子{X} + \\文本{momemtum} \\倍X_T × ^ 新 = （ 1 - 动量 ） × × ^ + momemtum × × T ，其中 × ^ \\帽子{X} × ^ ​​ 是估计的统计量和 X T X_T × T 是新的观测值。 因为批标准化是在 C 维完成的，在（N，+）切片计算统计数据，这是共同的术语来调用这个体积批标准化或时空批标准化。 目前SyncBatchNorm仅支持DistributedDataParallel每个进程单GPU。使用torch.nn.SyncBatchNorm.convert_sync_batchnorm（）与DDP包装网前BatchNorm层转换为SyncBatchNorm。 Parameters NUM_FEATURES - C C C 从大小的预期输入 （ N ， C ， + ） （N，C，+） （ N ， C ， + ） eps – a value added to the denominator for numerical stability. Default: 1e-5 momentum – the value used for the running_mean and running_var computation. Can be set to Nonefor cumulative moving average (i.e. simple average). Default: 0.1 affine – a boolean value that when set to True, this module has learnable affine parameters. Default: True track_running_stats – a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: True process_group - 统计的同步每个进程组内发生独立。默认行为是在整个世界同步 Shape: 输入： （ N ， C ， + ） （N，C，+） （ N ， C ， + ） 输出： （ N ， C ， + ） （N，C，+） （ N ， C ， + ） （相同形状的输入） Examples: >>> # With Learnable Parameters >>> m = nn.SyncBatchNorm(100) >>> # creating process group (optional) >>> # process_ids is a list of int identifying rank ids. >>> process_group = torch.distributed.new_group(process_ids) >>> # Without Learnable Parameters >>> m = nn.BatchNorm3d(100, affine=False, process_group=process_group) >>> input = torch.randn(20, 100, 35, 45, 10) >>> output = m(input) >>> # network is nn.BatchNorm layer >>> sync_bn_network = nn.SyncBatchNorm.convert_sync_batchnorm(network, process_group) >>> # only single gpu per process is currently supported >>> ddp_sync_bn_network = torch.nn.parallel.DistributedDataParallel( >>> sync_bn_network, >>> device_ids=[args.local_rank], >>> output_device=args.local_rank) classmethodconvert_sync_batchnorm( module , process_group=None )[source] 辅助函数来在模型为 torch.nn.SyncBatchNorm 层 torch.nn.BatchNormND 层转换。 Parameters 模块 （ nn.Module ） - 包含模块 process_group （ 可选 ） - 处理组范围的同步， 默认是整个世界 Returns 原始模块与转化 torch.nn.SyncBatchNorm 层 Example: >>> # Network with nn.BatchNorm layer >>> module = torch.nn.Sequential( >>> torch.nn.Linear(20, 100), >>> torch.nn.BatchNorm1d(100) >>> ).cuda() >>> # creating process group (optional) >>> # process_ids is a list of int identifying rank ids. >>> process_group = torch.distributed.new_group(process_ids) >>> sync_bn_module = convert_sync_batchnorm(module, process_group) InstanceNorm1d classtorch.nn.``InstanceNorm1d( num_features , eps=1e-05 , momentum=0.1 , affine=False , track_running_stats=False )[source] 适用实例正常化了作为在纸实例规范化描述的3D输入（带有可选的附加的信道尺寸的小批量的1D输入）：用于快速程式化失踪的成分。 y=x−E[x]Var[x]+ϵ∗γ+βy = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\betay=Var[x]+ϵ​x−E[x]​∗γ+β 的平均值和标准偏差是每个维度分别计算用于在小批量的每个对象。 γ \\伽马 γ 和 β \\的β β 是大小的可学习的参数矢量 C （其中 C 被输入尺寸）如果仿射是真。 默认情况下，该层使用在训练和评价模式从输入数据计算实例的统计数据。 如果track_running_stats被设定为真，在训练期间该层保持运行而其计算均值和方差，然后将其用于估计评估期间正常化。正在运行的估计是保持了默认的势头0.1。 Note This momentumargument is different from one used in optimizer classes and the conventional notion of momentum. Mathematically, the update rule for running statistics here is x^new=(1−momentum)×x^+momemtum×xt\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momemtum} \\times x_tx^new​=(1−momentum)×x^+momemtum×xt​ , where x^\\hat{x}x^ is the estimated statistic and xtx_txt​ is the new observed value. Note InstanceNorm1d和 LayerNorm非常相似，但有一些细微的差别。InstanceNorm1d 加到等多维时间序列引导数据的每个信道，但 LayerNorm通常施加在整个样本并经常在NLP任务。 Additionaly， LayerNorm适用的elementwise仿射变换，而 InstanceNorm1d通常不应用仿射变换。 Parameters num_features – CCC from an expected input of size (N,C,L)(N, C, L)(N,C,L) or LLL from input of size (N,L)(N, L)(N,L) eps – a value added to the denominator for numerical stability. Default: 1e-5 动量 - 用于running_mean和running_var计算的值。默认值：0.1 仿射 - 为完成一个布尔值，当设置为真，该模块具有可学习仿射参数，初始化的相同的方式进行批量标准化。默认值：假 [HTG9。 track_running_stats - 当设置为真，此模块跟踪的运行均值和方差，和一个布尔值，当设置为假，该模块不跟踪这样的统计并始终使用在训练和eval模式批次的统计数据。默认值：假 Shape: 输入： （ N ， C ， L ） （N，C，L） （ N ， C ， L ） 输出： （ N ， C ， L ） （N，C，L） （ N ， C ， L ） （相同形状的输入） Examples: >>> # Without Learnable Parameters >>> m = nn.InstanceNorm1d(100) >>> # With Learnable Parameters >>> m = nn.InstanceNorm1d(100, affine=True) >>> input = torch.randn(20, 100, 40) >>> output = m(input) InstanceNorm2d classtorch.nn.``InstanceNorm2d( num_features , eps=1e-05 , momentum=0.1 , affine=False , track_running_stats=False )[source] 适用实例正常化了作为在纸实例规范化描述的4D输入（用另外的通道尺寸的小批量的2D输入）：用于快速程式化失踪的成分。 y=x−E[x]Var[x]+ϵ∗γ+βy = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\betay=Var[x]+ϵ​x−E[x]​∗γ+β The mean and standard-deviation are calculated per-dimension separately for each object in a mini-batch. γ\\gammaγ and β\\betaβ are learnable parameter vectors of size C (where C is the input size) if affineis True. By default, this layer uses instance statistics computed from input data in both training and evaluation modes. If track_running_statsis set to True, during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default momentumof 0.1. Note This momentumargument is different from one used in optimizer classes and the conventional notion of momentum. Mathematically, the update rule for running statistics here is x^new=(1−momentum)×x^+momemtum×xt\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momemtum} \\times x_tx^new​=(1−momentum)×x^+momemtum×xt​ , where x^\\hat{x}x^ is the estimated statistic and xtx_txt​ is the new observed value. Note InstanceNorm2d和 LayerNorm非常相似，但有一些细微的差别。InstanceNorm2d 加到像RGB图像引导数据的每个信道，但 LayerNorm通常施加在整个样本并经常在NLP任务。 Additionaly， LayerNorm适用的elementwise仿射变换，而 InstanceNorm2d通常不应用仿射变换。 Parameters num_features – CCC from an expected input of size (N,C,H,W)(N, C, H, W)(N,C,H,W) eps – a value added to the denominator for numerical stability. Default: 1e-5 momentum – the value used for the running_mean and running_var computation. Default: 0.1 affine – a boolean value that when set to True, this module has learnable affine parameters, initialized the same way as done for batch normalization. Default: False. track_running_stats – a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: False Shape: Input: (N,C,H,W)(N, C, H, W)(N,C,H,W) Output: (N,C,H,W)(N, C, H, W)(N,C,H,W) (same shape as input) Examples: >>> # Without Learnable Parameters >>> m = nn.InstanceNorm2d(100) >>> # With Learnable Parameters >>> m = nn.InstanceNorm2d(100, affine=True) >>> input = torch.randn(20, 100, 35, 45) >>> output = m(input) InstanceNorm3d classtorch.nn.``InstanceNorm3d( num_features , eps=1e-05 , momentum=0.1 , affine=False , track_running_stats=False )[source] 适用实例正常化了作为在纸实例规范化描述的5D输入（用另外的通道尺寸的小批量的3D输入）：用于快速程式化失踪的成分。 y=x−E[x]Var[x]+ϵ∗γ+βy = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\betay=Var[x]+ϵ​x−E[x]​∗γ+β 的平均值和标准偏差是每个维度分别计算用于在小批量的每个对象。 γ \\伽马 γ 和 β \\的β β 是尺寸为C的可学习的参数向量（其中C是输入大小）如果仿射是真。 By default, this layer uses instance statistics computed from input data in both training and evaluation modes. If track_running_statsis set to True, during training this layer keeps running estimates of its computed mean and variance, which are then used for normalization during evaluation. The running estimates are kept with a default momentumof 0.1. Note This momentumargument is different from one used in optimizer classes and the conventional notion of momentum. Mathematically, the update rule for running statistics here is x^new=(1−momentum)×x^+momemtum×xt\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momemtum} \\times x_tx^new​=(1−momentum)×x^+momemtum×xt​ , where x^\\hat{x}x^ is the estimated statistic and xtx_txt​ is the new observed value. Note InstanceNorm3d和 LayerNorm非常相似，但有一些细微的差别。InstanceNorm3d 加到像的三维模型与RGB彩色引导数据的每个信道，但 LayerNorm通常施加在整个样本并经常在NLP任务。 Additionaly， LayerNorm适用的elementwise仿射变换，而 InstanceNorm3d通常不应用仿射变换。 Parameters num_features – CCC from an expected input of size (N,C,D,H,W)(N, C, D, H, W)(N,C,D,H,W) eps – a value added to the denominator for numerical stability. Default: 1e-5 momentum – the value used for the running_mean and running_var computation. Default: 0.1 affine – a boolean value that when set to True, this module has learnable affine parameters, initialized the same way as done for batch normalization. Default: False. track_running_stats – a boolean value that when set to True, this module tracks the running mean and variance, and when set to False, this module does not track such statistics and always uses batch statistics in both training and eval modes. Default: False Shape: Input: (N,C,D,H,W)(N, C, D, H, W)(N,C,D,H,W) Output: (N,C,D,H,W)(N, C, D, H, W)(N,C,D,H,W) (same shape as input) Examples: >>> # Without Learnable Parameters >>> m = nn.InstanceNorm3d(100) >>> # With Learnable Parameters >>> m = nn.InstanceNorm3d(100, affine=True) >>> input = torch.randn(20, 100, 35, 45, 10) >>> output = m(input) LayerNorm classtorch.nn.``LayerNorm( normalized_shape , eps=1e-05 , elementwise_affine=True )[source] 作为纸张图层规范化上述适用图层规范化在小批量的输入。 y=x−E[x]Var[x]+ϵ∗γ+βy = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta y=Var[x]+ϵ​x−E[x]​∗γ+β 的平均值和标准偏差都在其必须由normalized_shape中指定的形状的最后若干尺寸分别计算。 γ \\伽马 γ 和 β \\的β β 是可学习的仿射变换的参数normalized_shape如果elementwise_affine是真。 Note 不像批量规范化与实例标准化，它适用标量比例和偏压用于与仿射选项，层正常化应用于每个元素的规模和偏压[每个整个信道/平面HTG5] elementwise_affine。 This layer uses statistics computed from input data in both training and evaluation modes. Parameters normalized_shape （ INT 或 列表 或 torch.Size ） - 从尺寸的期望的输入的输入形状 [∗×normalized_shape[0]×normalized_shape[1]×…×normalized_shape[−1]][* \\times \\text{normalized\\_shape}[0] \\times \\text{normalized\\_shape}[1] \\times \\ldots \\times \\text{normalized\\_shape}[-1]] [∗×normalized_shape[0]×normalized_shape[1]×…×normalized_shape[−1]] 如果使用一个整数，它被视为一个单独列表，并且该模块将在正常化，预计将特定大小的最后一个维度。 eps – a value added to the denominator for numerical stability. Default: 1e-5 elementwise_affine - 一个布尔值，当设置为真，该模块具有初始化为一（用于权重）和零可学习每个元素的仿射参数（偏差）。默认值：真 [HTG9。 Shape: 输入： （ N ， ） （N，） （ N ， * ） 输出： （ N ， ） （N，） （ N ， * ） （相同形状的输入） Examples: >>> input = torch.randn(20, 5, 10, 10) >>> # With Learnable Parameters >>> m = nn.LayerNorm(input.size()[1:]) >>> # Without Learnable Parameters >>> m = nn.LayerNorm(input.size()[1:], elementwise_affine=False) >>> # Normalize over last two dimensions >>> m = nn.LayerNorm([10, 10]) >>> # Normalize over last dimension of size 10 >>> m = nn.LayerNorm(10) >>> # Activating the module >>> output = m(input) LocalResponseNorm classtorch.nn.``LocalResponseNorm( size , alpha=0.0001 , beta=0.75 , k=1.0 )[source] 适用在几个输入平面，其中信道占用所述第二维组成的输入信号响应的本地归一化。适用跨渠道正常化。 bc=ac(k+αn∑c′=max⁡(0,c−n/2)min⁡(N−1,c+n/2)ac′2)−βb{c} = a{c}\\left(k + \\frac{\\alpha}{n} \\sum{c'=\\max(0, c-n/2)}^{\\min(N-1,c+n/2)}a{c'}^2\\right)^{-\\beta} bc​=ac​⎝⎛​k+nα​c′=max(0,c−n/2)∑min(N−1,c+n/2)​ac′2​⎠⎞​−β Parameters 大小 - 用于标准化相邻信道的量 阿尔法 - 乘法因子。默认值：0.0001 的β - 指数。默认值：0.75 K - 加法因子。默认值：1 Shape: Input: (N,C,∗)(N, C, *)(N,C,∗) Output: (N,C,∗)(N, C, *)(N,C,∗) (same shape as input) Examples: >>> lrn = nn.LocalResponseNorm(2) >>> signal_2d = torch.randn(32, 5, 24, 24) >>> signal_4d = torch.randn(16, 5, 7, 7, 7, 7) >>> output_2d = lrn(signal_2d) >>> output_4d = lrn(signal_4d) 复发性层 RNN classtorch.nn.``RNN( *args , **kwargs )[source] 适用的多层埃尔曼RNN与 T 一 n的 H 的tanh T 一 n的 H 或 R E L U RELU R E L U 非线性到输入序列。 在输入序列中的每个元件中，每个层计算下面的函数： ht=tanh(Wihxt+bih+Whhh(t−1)+bhh)ht = \\text{tanh}(W{ih} xt + b{ih} + W{hh} h{(t-1)} + b_{hh}) ht​=tanh(Wih​xt​+bih​+Whh​h(t−1)​+bhh​) 其中 H T ht H T 是在时刻 T 隐藏状态， × T X_T × T 是在时刻 T 的输入，并 H （ T - 1 ） [HTG135 1 H {（T-1）} H （ T - 1 ） 是以前的层中的时间的隐藏状态 T-1 或在时间的初始隐藏状态 0 。如果非线性是'RELU'，则使用 RELU 而非的tanh 。 Parameters input_size - 的预期功能在输入×个数 hidden_​​size - 的特征在隐藏状态 h将数 num_layers - 复发层数。例如，设置num_layers = 2将意味着堆叠两个RNNs在一起以形成层叠RNN ，与第二RNN取入第一RNN的输出和计算所述最后的结果。默认值：1 非线性 - 非线性使用。可以是'的tanh'或'RELU'。默认值：'的tanh' 偏压 - 若假，则该层不使用偏压权重 b_ih 和 b_hh 。默认值：真 batch_first - 若真，则输入和输出张量被设置为（分批，SEQ，特征）。默认值：假 差 - 如果不为零，介绍等于漏失一个降上除了最后层各RNN层的输出层，用差概率。默认值：0 双向 - 若真，成为双向RNN。默认值：假 Inputs: input, h_0 输入 的形状（seq_len，分批，input_size）：张量包含输入序列的特征。输入也可以是填充可变长度序列。参见 torch.nn.utils.rnn.pack_padded_sequence（）或 torch.nn.utils.rnn.pack_sequence（ ）的详细信息。 H_0 的形状（numlayers * num_directions，分批，hidden​​size）：张量包含所述初始状态隐藏在批次中的每个元件。默认为零，如果不提供。如果RNN是双向的，num_directions应该是2，否则它应该是1。 Outputs: output, h_n 输出 形状的（seqlen，分批，num_directions * hidden​​size）：张量含有来自RNN的最后一层的输出特征（ h_t ），对于每一个 T 。如果 torch.nn.utils.rnn.PackedSequence已被给定为输入，输出也将是一个拥挤的序列。 对于解压缩的情况下，该方向可使用output.view分离（seq_len， 批次， num_directions， hidden_​​size），与向前和向后方向为 0 和 1 分别。类似地，方向可以在堆积的情况下被分离。 h_n 的形状（numlayers * num_directions，分批，hidden​​size）：张量含有 T = seq_len 隐藏状态。 像 输出 时，层可使用h_n.view（num_layers分离， num_directions， 批次， hidden_​​size ）。 Shape: 输入1： （ L ， N ， H i的 n的 ） （L，N，H {在}） （ L ， N ， H i的 n的 ） [HTG89含有张量输入功能，其中 H i的 [HT G102] n的 = input_size H {IN} = \\文本{输入\\ _size} H i的 n的 = input_size 和 L 表示序列长度。 输入2： （ S ， N ， H O U T ） （S，N，H {出}） （ S ， N ， H O U T ） [HTG93含有初始隐藏状态在批次中的每个元件张量。 H O U T = hidden​​size H {出} = \\文本{隐藏\\ _size} H O U T = hidden​​size 如果不设置缺省值为零。其中 S = num_layers num_directions S = \\文本{NUM \\ _layers} \\文本{NUM \\ _directions} S = num_layers * num_directions [HTG237如果RNN是双向的，num_directions应该是2，否则它应为1。 输出1： （ L ， N ， H 一 L L ） （L，N，H {所有}） （ L ， N ， H 一 L L ） 其中 H 一个[H TG105] L L = num_directions * hidden​​size H {所有} = \\文本{NUM \\ _directions} \\文本{隐藏\\ _size} H 一 L L = num_directions hidden​​size [HT G193] OUTPUT2： （ S ， N ， H O U T ） （S，N，H_ {出}） （ S ， N ， H O U T ） 包含下一个隐藏状态在批次中的每个元件张量 Variables 〜RNN.weight_ih_l [k]的 - 第k层的可学习输入隐藏重量，形状（hidden​​size，input_size）的为 K = 0 。否则，该形状是（hidden​​size，numdirections * hidden​​size） 〜RNN.weight_hh_l [k]的 - 第k层的可学习隐藏的权重，形状的（hidden​​size，hidden​​size） 〜RNN.bias_ih_l [k]的 - 第k层的可学习输入隐藏偏压，形状的（hidden_​​size） 〜RNN.bias_hh_l [k]的 - 第k层的可学习隐藏偏压，形状的（hidden_​​size） Note 所有的重量和偏见从 初始化U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K ， K ） 其中 K = 1 hidden​​size K = \\压裂{1} {\\文本{隐藏\\ _size}} K = hidden​​size 1 [HTG19 3] Note 如果满足以下条件：1）使能cudnn，2）输入的数据是在GPU上3）的输入数据已经DTYPE torch.float164）V100 GPU时，5 ）输入数据不是在PackedSequence格式持续算法可经选择以提高性能。 Examples: >>> rnn = nn.RNN(10, 20, 2) >>> input = torch.randn(5, 3, 10) >>> h0 = torch.randn(2, 3, 20) >>> output, hn = rnn(input, h0) LSTM classtorch.nn.``LSTM( *args , **kwargs )[source] 适用的多层长短期记忆（LSTM）RNN到输入序列。 For each element in the input sequence, each layer computes the following function: it=σ(Wiixt+bii+Whih(t−1)+bhi)ft=σ(Wifxt+bif+Whfh(t−1)+bhf)gt=tanh⁡(Wigxt+big+Whgh(t−1)+bhg)ot=σ(Wioxt+bio+Whoh(t−1)+bho)ct=ft∗c(t−1)+it∗gtht=ot∗tanh⁡(ct)\\begin{array}{ll} \\\\ it = \\sigma(W{ii} xt + b{ii} + W{hi} h{(t-1)} + b{hi}) \\\\ f_t = \\sigma(W{if} xt + b{if} + W{hf} h{(t-1)} + b{hf}) \\\\ g_t = \\tanh(W{ig} xt + b{ig} + W{hg} h{(t-1)} + b{hg}) \\\\ o_t = \\sigma(W{io} xt + b{io} W{ho} h{(t-1)} + b{ho}) \\\\ c_t = f_t * c{(t-1)} + i_t g_t \\\\ h_t = o_t \\tanh(c_t) \\\\ \\end{array} it​=σ(Wii​xt​+bii​+Whi​h(t−1)​+bhi​)ft​=σ(Wif​xt​+bif​+Whf​h(t−1)​+bhf​)gt​=tanh(Wig​xt​+big​+Whg​h(t−1)​+bhg​)ot​=σ(Wio​xt​+bio​+Who​h(t−1)​+bho​)ct​=ft​∗c(t−1)​+it​∗gt​ht​=ot​∗tanh(ct​)​ 其中 H T ht H T 是在时刻 T 隐藏状态， C T C_T C T 是在时刻 T 小区状态， × T X_T × T 是输入时刻 T ， H （ T - 1 ） [HTG191 1 H {（T-1）} [HTG19 6] H （ T - 1 ） 是的隐藏状态层时刻 T-1 或时刻 0 初始隐藏状态，和 i的 T I_T i的​​ T [HTG2 85] ， F T F_T F T ， 克 T G_T 克 [HT G383] T ， O T O_t同 O T 是输入，忘记，细胞，和输出门，分别。 σ \\西格玛 σ 是S形函数，并 * 为Hadamard乘积。 在多层LSTM，输入 × T （ L ） ×^ {（L）} T × T （ L ） 的 L L L 第层（ L & GT ; = 2 L & GT ; = 2 L & GT ; = 2 ）是隐藏状态 H T （ L - 1 ） H ^ {（L-1）} T H T （ L - 1 ） 先前层乘以的脱落 δ T （ L - 1 ） \\增量^ {（L-1）} T δ ​​ T （ L - 1 ） 其中各HTG316 ] δ T （ L - 1 ） \\增量^ {（L-1）} T δ T （ L - 1 ） 是伯努利随机变量，它是 0 0 0 的概率漏失。 Parameters input_size – The number of expected features in the input x hidden_size – The number of features in the hidden state h num_layers - 复发层数。例如，设置num_layers = 2将意味着堆叠两个LSTMs在一起以形成层叠LSTM ，与第二LSTM取入输出第一LSTM的和计算的最后的结果。默认值：1 bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True batch_first - 若真，则输入和输出张量被设置为（批次，SEQ，特征）。默认值：假 差 - 如果不为零，介绍等于漏失一个降上除了最后层各LSTM层的输出层，用差概率。默认值：0 双向 - 若真，成为双向LSTM。默认值：假 Inputs: input, (h_0, c_0) 输入 的形状（seq_len，分批，input_size）：张量包含输入序列的特征。输入也可以是填充可变长度序列。参见 torch.nn.utils.rnn.pack_padded_sequence（）或 torch.nn.utils.rnn.pack_sequence（ ）的详细信息。 H_0 的形状（numlayers * num_directions，分批，hidden​​size）：张量包含所述初始状态隐藏在批次中的每个元件。如果LSTM是双向的，num_directions应该是2，否则它应该是1。 的形状（numlayers * num_directions，分批，hidden​​size） C_0 ：张量包含所述初始小区状态为批中每个元件。 如果（H_0，C_0）不设置，二者 H_0 和 C_0 默认为零。 Outputs: output, (h_n, c_n) 输出 形状的（seqlen，分批，num_directions * hidden​​size）：张量包含输出特征（h_t）从LSTM的最后一层，对于每个 T 。如果 torch.nn.utils.rnn.PackedSequence已被给定为输入，输出也将是一个拥挤的序列。 For the unpacked case, the directions can be separated using output.view(seq_len, batch, num_directions, hidden_size), with forward and backward being direction 0 and 1 respectively. Similarly, the directions can be separated in the packed case. h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len. 像 输出 时，层可使用h_n.view（num_layers分离， num_directions， 批次， hidden_​​size ）同样地，对于 C_N 。 C_N 的形状（numlayers * num_directions，分批，hidden​​size）：张量含有 T = seq_len 小区状态。 Variables 〜LSTM.weight_ih_l [k]的 - 的 k是可学习输入隐藏权重 T H \\文本{K} ^ {第} K T H 层（Wii | W_if | W_ig | W_io），形状的（4 * hidden​​size，inputsize）为 K = 0 。否则，该形状是（4 * hidden​​size，numdirections * hidden​​size） 〜LSTM.weight_hh_l [k]的 - 的 k是可学习隐藏权重 T H \\文本{K} ^ {第} K T H 层（Whi | W_hf | W_hg | W_ho），形状的（4 * hidden​​size，hidden_​​size） 〜LSTM.bias_ih_l [k]的 - 的可学习输入隐藏偏置 K T H \\文本{K} ^ {第} K T H 层形状的（bii | b_if | | b_ig b_io），（4 * hidden​​size） 〜LSTM.bias_hh_l [k]的 - 的可学习隐藏偏压 K T H \\文本{K} ^ {第} K T H 层形状的（bhi | b_hf | | b_hg b_ho），（4 * hidden​​size） Note All the weights and biases are initialized from U(−k,k)\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})U(−k​,k​) where k=1hidden_sizek = \\frac{1}{\\text{hidden\\_size}}k=hidden_size1​ Note If the following conditions are satisfied: 1) cudnn is enabled, 2) input data is on the GPU 3) input data has dtype torch.float164) V100 GPU is used, 5) input data is not in PackedSequenceformat persistent algorithm can be selected to improve performance. Examples: >>> rnn = nn.LSTM(10, 20, 2) >>> input = torch.randn(5, 3, 10) >>> h0 = torch.randn(2, 3, 20) >>> c0 = torch.randn(2, 3, 20) >>> output, (hn, cn) = rnn(input, (h0, c0)) GRU classtorch.nn.``GRU( *args , **kwargs )[source] 适用门控重复单元（GRU）RNN到输入序列的多层。 For each element in the input sequence, each layer computes the following function: rt=σ(Wirxt+bir+Whrh(t−1)+bhr)zt=σ(Wizxt+biz+Whzh(t−1)+bhz)nt=tanh⁡(Winxt+bin+rt∗(Whnh(t−1)+bhn))ht=(1−zt)∗nt+zt∗h(t−1)\\begin{array}{ll} rt = \\sigma(W{ir} xt + b{ir} + W{hr} h{(t-1)} + b{hr}) \\\\ z_t = \\sigma(W{iz} xt + b{iz} + W{hz} h{(t-1)} + b{hz}) \\\\ n_t = \\tanh(W{in} xt + b{in} + rt * (W{hn} h{(t-1)}+ b{hn})) \\\\ ht = (1 - z_t) n_t + z_t h{(t-1)} \\end{array} rt​=σ(Wir​xt​+bir​+Whr​h(t−1)​+bhr​)zt​=σ(Wiz​xt​+biz​+Whz​h(t−1)​+bhz​)nt​=tanh(Win​xt​+bin​+rt​∗(Whn​h(t−1)​+bhn​))ht​=(1−zt​)∗nt​+zt​∗h(t−1)​​ 其中 H T ht H T 是在时刻 T 隐藏状态， × T X_T × T 是在时刻 T 的输入， H （ T - 1 ） [HTG135 1 H {（T-1）} H （ T - 1 ） 是该层的在时间的隐藏状态 T-1 或在时间的初始隐藏状态 0 和[HTG19 0] R T r_t R T ， Z 吨 z_t Z ​​ T [HT G288] ， n的 T N_T n的 T 是复位，更新和新的大门，分别。 σ \\西格玛 σ 是S形函数，并 * 为Hadamard乘积。 在多层GRU，输入 × T （ L ） ×^ {（L）} T × T （ L ） 的 L L L 第层（ L & GT ; = 2 升& GT ; = 2 L & GT ; = 2 ）是隐藏状态 [HTG155 1 H T （ L - 1 ） H ^ {（L-1）} T H T [HTG1 94] （ L - 1 ） 先前层乘以的脱落 δ T （ L - 1 ） \\增量^ {（L-1）} T δ ​​ T （ L - 1 ） 其中各HTG316 ] δ T （ L - 1 ） \\增量^ {（L-1）} T δ T （ L - 1 ） 是伯努利随机变量，它是 0 0 0 的概率差。 Parameters input_size – The number of expected features in the input x hidden_size – The number of features in the hidden state h num_layers - 复发层数。例如，设置num_layers = 2将意味着堆叠两个越冬在一起以形成层叠GRU ，与第二GRU取入第一GRU的输出和计算所述最后的结果。默认值：1 bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True batch_first – If True, then the input and output tensors are provided as (batch, seq, feature). Default: False 差 - 如果不为零，介绍了除了最后层各GRU层的输出降层，用差概率等于差。默认值：0 双向 - 若真，成为双向的GRU。默认值：假 Inputs: input, h_0 输入 的形状（seq_len，分批，input_size）：张量包含输入序列的特征。输入也可以是填充可变长度序列。参见 对于细节torch.nn.utils.rnn.pack_padded_sequence（）。 h_0 of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided. If the RNN is bidirectional, num_directions should be 2, else it should be 1. Outputs: output, h_n 输出 形状（seqlen，分批，num_directions * hidden​​size）的：张量包含输出特征从GRU的最后一层ht，对于每个 T 。如果 torch.nn.utils.rnn.PackedSequence已被给定为输入，输出也将是一个拥挤的序列。对于解压缩的情况下，该方向可使用`output.view分离（seq_len， 批次， num_directions， hidden​​size） `，与向前和向后方向为 0 和 1 分别。 类似地，方向可以在堆积的情况下被分离。 h_n 形状（numlayers * num_directions，分批，hidden​​size）的：张量包含隐藏状态 T = seq_len Like output , the layers can be separated using h_n.view(num_layers, num_directions, batch, hidden_size). Shape: Input1: (L,N,Hin)(L, N, H{in})(L,N,Hin​) tensor containing input features where Hin=input_sizeH{in}=\\text{input\\_size}Hin​=input_size and L represents a sequence length. Input2: (S,N,Hout)(S, N, H{out})(S,N,Hout​) tensor containing the initial hidden state for each element in the batch. Hout=hidden_sizeH{out}=\\text{hidden\\_size}Hout​=hidden_size Defaults to zero if not provided. where S=num_layers∗num_directionsS=\\text{num\\_layers} * \\text{num\\_directions}S=num_layers∗num_directions If the RNN is bidirectional, num_directions should be 2, else it should be 1. Output1: (L,N,Hall)(L, N, H{all})(L,N,Hall​) where Hall=num_directions∗hidden_sizeH{all}=\\text{num\\_directions} * \\text{hidden\\_size}Hall​=num_directions∗hidden_size Output2: (S,N,Hout)(S, N, H_{out})(S,N,Hout​) tensor containing the next hidden state for each element in the batch Variables 〜GRU.weight_ih_l [k]的 - 的 k是可学习输入隐藏权重 T H \\文本{K} ^ {第} K T H 层（Wir | W_iz | W_IN），形状（3 * hidden​​size，inputsize）为中的k = 0 。否则，该形状是（3 * hidden​​size，numdirections * hidden​​size） 〜GRU.weight_hh_l [k]的 - 的 k是可学习隐藏权重 T H \\文本{K} ^ {第} K T H 层（Whr | W_hz | W_hn），形状的（3 * hidden​​size，hidden_​​size） 〜GRU.bias_ih_l [k]的 - 的可学习输入隐藏偏置 K T H \\文本{K} ^ {第} K T H 层形状的（bir | | b_iz B_IN），（3 * hidden​​size） 〜GRU.bias_hh_l [k]的 - 的可学习隐藏偏压 K T H \\文本{K} ^ {第} K T H 层形状的（bhr | | b_hz b_hn），（3 * hidden​​size） Note All the weights and biases are initialized from U(−k,k)\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})U(−k​,k​) where k=1hidden_sizek = \\frac{1}{\\text{hidden\\_size}}k=hidden_size1​ Note If the following conditions are satisfied: 1) cudnn is enabled, 2) input data is on the GPU 3) input data has dtype torch.float164) V100 GPU is used, 5) input data is not in PackedSequenceformat persistent algorithm can be selected to improve performance. Examples: >>> rnn = nn.GRU(10, 20, 2) >>> input = torch.randn(5, 3, 10) >>> h0 = torch.randn(2, 3, 20) >>> output, hn = rnn(input, h0) RNNCell classtorch.nn.``RNNCell( input_size , hidden_size , bias=True , nonlinearity='tanh' )[source] 一个埃尔曼RNN细胞与双曲正切或RELU非线性。 h′=tanh⁡(Wihx+bih+Whhh+bhh)h' = \\tanh(W{ih} x + b{ih} + W{hh} h + b{hh})h′=tanh(Wih​x+bih​+Whh​h+bhh​) 如果非线性是“RELU” ，然后RELU代替的tanh的使用。 Parameters input_size – The number of expected features in the input x hidden_size – The number of features in the hidden state h bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True nonlinearity – The non-linearity to use. Can be either 'tanh'or 'relu'. Default: 'tanh' Inputs: input, hidden 输入 形状的（分批，input_size）：张量含有输入特征 隐藏形状 （分批，hidden_​​size）的：张量包含所述初始状态隐藏在批次中的每个元件。默认为零，如果不提供。 Outputs: h’ H” 形状（分批，hidden_​​size）的：张量包含下一隐藏状态为批中每个元件 Shape: 输入1： （ N ， H i的 n的 ） （N，H {在}） （ N ， H i的 n的 ） [HTG79含有张量输入功能，其中 H i的 n的 H {IN} [HT G102] H i的 n的 = input_size 输入2： （ N ， H O U T ） （N，H {出}） （ N ， H O U T ） [HTG83含有初始隐藏状态批中每个元件张量，其中 H O U T H {出} H O U T = hidden_​​size 如果不设置缺省值为零。 输出： （ N ， H O U T ） （N，H_ {出}） （ N ， H O U T ） 包含下一个隐藏状态在批次中的每个元件张量 Variables 〜RNNCell.weight_ih - 的可学习输入隐藏重量，形状的（hidden_​​size，input_size） 〜RNNCell.weight_hh - 的可学习隐藏的权重，形状的（hidden​​size，hidden​​size） 〜RNNCell.bias_ih - 的可学习输入隐藏偏压，形状的（hidden_​​size） 〜RNNCell.bias_hh - 的可学习隐藏偏压，形状的（hidden_​​size） Note All the weights and biases are initialized from U(−k,k)\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})U(−k​,k​) where k=1hidden_sizek = \\frac{1}{\\text{hidden\\_size}}k=hidden_size1​ Examples: >>> rnn = nn.RNNCell(10, 20) >>> input = torch.randn(6, 3, 10) >>> hx = torch.randn(3, 20) >>> output = [] >>> for i in range(6): hx = rnn(input[i], hx) output.append(hx) LSTMCell classtorch.nn.``LSTMCell( input_size , hidden_size , bias=True )[source] 长短期记忆（LSTM）细胞。 i=σ(Wiix+bii+Whih+bhi)f=σ(Wifx+bif+Whfh+bhf)g=tanh⁡(Wigx+big+Whgh+bhg)o=σ(Wiox+bio+Whoh+bho)c′=f∗c+i∗gh′=o∗tanh⁡(c′)\\begin{array}{ll} i = \\sigma(W{ii} x + b{ii} + W{hi} h + b{hi}) \\\\ f = \\sigma(W{if} x + b{if} + W{hf} h + b{hf}) \\\\ g = \\tanh(W{ig} x + b{ig} + W{hg} h + b{hg}) \\\\ o = \\sigma(W{io} x + b{io} + W{ho} h + b{ho}) \\\\ c' = f c + i g \\\\ h' = o * \\tanh(c') \\\\ \\end{array}i=σ(Wii​x+bii​+Whi​h+bhi​)f=σ(Wif​x+bif​+Whf​h+bhf​)g=tanh(Wig​x+big​+Whg​h+bhg​)o=σ(Wio​x+bio​+Who​h+bho​)c′=f∗c+i∗gh′=o∗tanh(c′)​ 其中 σ \\西格玛 σ 是S形函数，并 * 为Hadamard乘积。 Parameters input_size – The number of expected features in the input x hidden_size – The number of features in the hidden state h 偏压 - 若假，则该层不使用偏压权重 b_ih 和 b_hh 。默认值：真 Inputs: input, (h_0, c_0) input of shape (batch, input_size): tensor containing input features H_0 形状（分批，hidden_​​size）的：张量包含所述初始状态隐藏在批次中的每个元件。 C_0 形状（分批，hidden_​​size）的：张量包含所述初始小区状态为批中每个元件。 If (h_0, c_0) is not provided, both h_0 and c_0 default to zero. Outputs: (h_1, c_1) H_1 的形状（分批，hidden_​​size）：张量含有批处理每个元素的下一个隐藏状态 C_1 形状（分批，hidden_​​size）的：张量含有批处理每个元素的下一个小区状态 Variables 〜LSTMCell.weight_ih - 的可学习输入隐藏重量，形状的（4 * hidden_​​size，input_size） 〜LSTMCell.weight_hh - 的可学习隐藏的权重，形状的（4 * hidden​​size，hidden​​size） 〜LSTMCell.bias_ih - 的可学习输入隐藏偏压，形状的（4 * hidden_​​size） 〜LSTMCell.bias_hh - 的可学习隐藏偏压，形状的（4 * hidden_​​size） Note All the weights and biases are initialized from U(−k,k)\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})U(−k​,k​) where k=1hidden_sizek = \\frac{1}{\\text{hidden\\_size}}k=hidden_size1​ Examples: >>> rnn = nn.LSTMCell(10, 20) >>> input = torch.randn(6, 3, 10) >>> hx = torch.randn(3, 20) >>> cx = torch.randn(3, 20) >>> output = [] >>> for i in range(6): hx, cx = rnn(input[i], (hx, cx)) output.append(hx) GRUCell classtorch.nn.``GRUCell( input_size , hidden_size , bias=True )[source] 门控重复单元（GRU）细胞 r=σ(Wirx+bir+Whrh+bhr)z=σ(Wizx+biz+Whzh+bhz)n=tanh⁡(Winx+bin+r∗(Whnh+bhn))h′=(1−z)∗n+z∗h\\begin{array}{ll} r = \\sigma(W{ir} x + b{ir} + W{hr} h + b{hr}) \\\\ z = \\sigma(W{iz} x + b{iz} + W{hz} h + b{hz}) \\\\ n = \\tanh(W{in} x + b{in} + r (W{hn} h + b{hn})) \\\\ h' = (1 - z) n + z * h \\end{array}r=σ(Wir​x+bir​+Whr​h+bhr​)z=σ(Wiz​x+biz​+Whz​h+bhz​)n=tanh(Win​x+bin​+r∗(Whn​h+bhn​))h′=(1−z)∗n+z∗h​ where σ\\sigmaσ is the sigmoid function, and ∗*∗ is the Hadamard product. Parameters input_size – The number of expected features in the input x hidden_size – The number of features in the hidden state h bias – If False, then the layer does not use bias weights b_ih and b_hh. Default: True Inputs: input, hidden input of shape (batch, input_size): tensor containing input features hidden of shape (batch, hidden_size): tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided. Outputs: h’ h’ of shape (batch, hidden_size): tensor containing the next hidden state for each element in the batch Shape: Input1: (N,Hin)(N, H{in})(N,Hin​) tensor containing input features where HinH{in}Hin​ = input_size Input2: (N,Hout)(N, H{out})(N,Hout​) tensor containing the initial hidden state for each element in the batch where HoutH{out}Hout​ = hidden_size Defaults to zero if not provided. Output: (N,Hout)(N, H_{out})(N,Hout​) tensor containing the next hidden state for each element in the batch Variables 〜GRUCell.weight_ih - 的可学习输入隐藏重量，形状的（3 * hidden_​​size，input_size） 〜GRUCell.weight_hh - 的可学习隐藏的权重，形状的（3 * hidden​​size，hidden​​size） 〜GRUCell.bias_ih - 的可学习输入隐藏偏压，形状的（3 * hidden_​​size） 〜GRUCell.bias_hh - 的可学习隐藏偏压，形状的（3 * hidden_​​size） Note All the weights and biases are initialized from U(−k,k)\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})U(−k​,k​) where k=1hidden_sizek = \\frac{1}{\\text{hidden\\_size}}k=hidden_size1​ Examples: >>> rnn = nn.GRUCell(10, 20) >>> input = torch.randn(6, 3, 10) >>> hx = torch.randn(3, 20) >>> output = [] >>> for i in range(6): hx = rnn(input[i], hx) output.append(hx) 变压器层 变压器 classtorch.nn.``Transformer( d_model=512 , nhead=8 , num_encoder_layers=6 , num_decoder_layers=6 , dim_feedforward=2048 , dropout=0.1 , custom_encoder=None , custom_decoder=None )[source] 变压器模型。用户可以根据需要修改其属性。该architechture是基于纸“注意是所有你需要”。阿希什瓦斯瓦尼，诺姆Shazeer，尼基帕尔马雅各布Uszkoreit，Llion琼斯，艾Ñ戈麦斯，卢卡斯凯泽，和Illia Polosukhin。 2017注意力是你所需要的。在神经信息处理系统的进步，6000-6010页。 Parameters d_model - 的预期功能在编码器/解码器的输入的数量（缺省值= 512）。 NHEAD - 的头在multiheadattention模型数（默认= 8）。 num_encoder_layers - 在编码器（默认= 6）子编码器的层的数目。 num_decoder_layers - 在解码器（默认= 6）子译码器层的数量。 dim_feedforward - 前馈网络模型（缺省值= 2048）的维数。 差 - 漏失值（缺省值= 0.1）。 custom_encoder - 定制的编码器（默认=无）。 custom_decoder - 定制解码器（默认=无）。 Examples:: >>> transformer_model = nn.Transformer(src_vocab, tgt_vocab) >>> transformer_model = nn.Transformer(src_vocab, tgt_vocab, nhead=16, num_encoder_layers=12) forward( src , tgt , src_mask=None , tgt_mask=None , memory_mask=None , src_key_padding_mask=None , tgt_key_padding_mask=None , memory_key_padding_mask=None )[source] 采取在与过程掩蔽源/靶序列。 Parameters SRC - （必需）序列与编码器。 TGT - 的顺序向解码器（必需）。 src_mask - 为对SRC序列（任选的）添加剂掩模。 tgt_mask - 添加剂掩码TGT序列（可选）。 memory_mask - 为对编码器输出（可选）添加剂掩模。 src_key_padding_mask - 对于每批次（可选）SRC键ByteTensor掩模。 tgt_key_padding_mask - 的ByteTensor掩模每批（可选）TGT密钥。 memory_key_padding_mask - 对于每批次（可选）存储器键ByteTensor掩模。 Shape: SRC： （ S ， N ， E ） （S，N，E） （ S ， N ， E ） 。 TGT： （ T ， N ， E ） （T，N，E） （ T ， N ， E ） 。 src_mask： （ S ， S ） （S，S） （ S ， S ） 。 tgt_mask： （ T ， T ） （T，T） （ T ， T ） 。 memory_mask： （ T ， S ） （T，S） （ T ， S ） 。 src_key_padding_mask： （ N ， S ） （N，S） （ N ， S ） 。 tgt_key_padding_mask： （ N ， T ） （N，T） （ N ， T ） 。 memory_key_padding_mask： （ N ， S ） （N，S） （ N ， S ） 。 注意：[SRC / TGT /存储器] _mask应与浮子（“ - INF”）被填充在掩蔽位置和浮动（0.0）其他。这些面具确保了位置预测我只取决于东窗事发j和是相同的批处理中的每个序列应用。 [SRC / TGT /存储器] _key_padding_mask应该是一个ByteTensor其中真值应与浮子（“ - INF”）被掩蔽的位置值和假值将保持不变。该掩模可确保没有信息将从位置采取i如果它被屏蔽，并且具有用于批处理中的每个序列的单独的掩模。 输出： （ T ， N ， E ） （T，N，E） （ T ， N ， E ） 。 注意：由于在变压器模型中的多磁头关注架构中，变压器的输出序列的长度是一样的解码器的输入序列（即目标）的长度。 其中，S是源序列长度，T是所述靶序列的长度，N是批量大小，E是功能号码 Examples >>> output = transformer_model(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask) generate_square_subsequent_mask( sz )[source] 生成序列的方形面具。蒙面位置都充满了浮动（“ - INF”）。未掩蔽的位置被填充有浮子（0.0）。 TransformerEncoder classtorch.nn.``TransformerEncoder( encoder_layer , num_layers , norm=None )[source] TransformerEncoder是N个编码器的层的叠层 Parameters encoder_layer - （必需）TransformerEncoderLayer（）的类的实例。 num_layers - 在编码器中的子编码器的层的数量（需要）。 规范 - 层归一部件（可选）。 Examples:: >>> encoder_layer = nn.TransformerEncoderLayer(d_model, nhead) >>> transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers) forward( src , mask=None , src_key_padding_mask=None )[source] 通过依次endocder层传递输入。 Parameters SRC - （必需）序列给解码器。 掩模 - 为对SRC序列（任选的）掩模。 src_key_padding_mask - 对于每批次（可选）在src键掩模。 Shape: 看到变压器类的文档。 TransformerDecoder classtorch.nn.``TransformerDecoder( decoder_layer , num_layers , norm=None )[source] TransformerDecoder是N解码器的层的叠层 Parameters decoder_layer - 的TransformerDecoderLayer（）的类的实例（必需）。 num_layers - 在解码器中的子译码器，层的数量（需要）。 norm – the layer normalization component (optional). Examples:: >>> decoder_layer = nn.TransformerDecoderLayer(d_model, nhead) >>> transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers) forward( tgt , memory , tgt_mask=None , memory_mask=None , tgt_key_padding_mask=None , memory_key_padding_mask=None )[source] 通过依次解码器层传递的输入（和掩模）。 Parameters tgt – the sequence to the decoder (required). 存储器 - 来自编码器的最后一层的序列（必需）。 tgt_mask - 掩模为TGT序列（可选）。 memory_mask - 为对存储器序列（任选的）掩模。 tgt_key_padding_mask - 掩模每批次（可选）在tgt密钥。 memory_key_padding_mask - 对于每批次（可选）存储键掩模。 Shape: see the docs in Transformer class. TransformerEncoderLayer classtorch.nn.``TransformerEncoderLayer( d_model , nhead , dim_feedforward=2048 , dropout=0.1 )[source] TransformerEncoderLayer由自经办人及前馈网络。该标准编码层是基于纸“注意是所有你需要”。阿希什瓦斯瓦尼，诺姆Shazeer，尼基帕尔马雅各布Uszkoreit，Llion琼斯，艾Ñ戈麦斯，卢卡斯凯泽，和Illia Polosukhin。 2017注意力是你所需要的。在神经信息处理系统的进步，6000-6010页。用户可以修改或应用程序中以不同的方式实现。 Parameters d_model - 在输入预期特征的数量（需要）。 NHEAD - （必需）在multiheadattention模型头的数目。 dim_feedforward – the dimension of the feedforward network model (default=2048). dropout – the dropout value (default=0.1). Examples:: >>> encoder_layer = nn.TransformerEncoderLayer(d_model, nhead) forward( src , src_mask=None , src_key_padding_mask=None )[source] 通过endocder层传递输入。 Parameters SRC - （必需）序列提供给编码器层。 src_mask - 为对SRC序列（任选的）掩模。 src_key_padding_mask – the mask for the src keys per batch (optional). Shape: see the docs in Transformer class. TransformerDecoderLayer classtorch.nn.``TransformerDecoderLayer( d_model , nhead , dim_feedforward=2048 , dropout=0.1 )[source] TransformerDecoderLayer由自经办人，多头经办人及前馈网络。该标准解码器层是基于纸“注意是所有你需要”。阿希什瓦斯瓦尼，诺姆Shazeer，尼基帕尔马雅各布Uszkoreit，Llion琼斯，艾Ñ戈麦斯，卢卡斯凯泽，和Illia Polosukhin。 2017注意力是你所需要的。在神经信息处理系统的进步，6000-6010页。用户可以修改或应用程序中以不同的方式实现。 Parameters d_model – the number of expected features in the input (required). nhead – the number of heads in the multiheadattention models (required). dim_feedforward – the dimension of the feedforward network model (default=2048). dropout – the dropout value (default=0.1). Examples:: >>> decoder_layer = nn.TransformerDecoderLayer(d_model, nhead) forward( tgt , memory , tgt_mask=None , memory_mask=None , tgt_key_padding_mask=None , memory_key_padding_mask=None )[source] 通过解码器层传递的输入（和掩模）。 Parameters TGT - 的顺序向解码器层（必需）。 memory – the sequnce from the last layer of the encoder (required). tgt_mask – the mask for the tgt sequence (optional). memory_mask – the mask for the memory sequence (optional). tgt_key_padding_mask – the mask for the tgt keys per batch (optional). memory_key_padding_mask – the mask for the memory keys per batch (optional). Shape: see the docs in Transformer class. 线性层 身份 classtorch.nn.``Identity( *args , **kwargs )[source] 占位符的身份操作符是参数不敏感。 Parameters ARGS - 任何参数（未使用） kwargs - 任何关键字参数（未使用） Examples: >>> m = nn.Identity(54, unused_argument1=0.1, unused_argument2=False) >>> input = torch.randn(128, 20) >>> output = m(input) >>> print(output.size()) torch.Size([128, 20]) 线性 classtorch.nn.``Linear( in_features , out_features , bias=True )[source] 适用的线性变换，以将输入数据： Y = × A T + b Y = XA ^ T + b Y = × A T + b Parameters in_features - 每个输入样本的大小 out_features - 每个输出样本的大小 偏压 - 如果设置为假，该层不会学添加剂偏压。默认值：真 Shape: 输入： （ N ， ， H i的 n的 ） （N，，H {在}） （ N ， ， H i的 n的 ） 其中 是指任何数量的附加维度和 H i的 n的 = in_features H {IN} = \\文本{在\\ _features} H i的 n的 = in_features 输出： （ N ， ， H O U T ） （N，，H {出}） （ N ， * ， H O U T ） 其中除了最后尺寸是相同的形状的输入，并 H O U T = out_features H {出} = \\文本{出\\ _features} H O U T = out_features 。 Variables 〜Linear.weight - 形状 （ out_features的模块[的可学习权重HTG11 ] ， in_features ） （\\文本{出\\ _features}，\\文本{在\\ _features}） （ out_features ， in_features ） 。的值是从 初始化U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT { ķ}，\\ SQRT {K}） U （ - K ， K ） ，其中 K = 1 in_features K = \\压裂{1} {\\文本{在\\ _features}} K = in_features 1 [HT G237] 〜Linear.bias - 形状 （ out_features的模块[的可学习偏压HTG11 ] ） （\\文本{出\\ _features}） （ out_features ） 。如果偏压是真时，值被初始化从 U （ - K ， ķ ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K ， [HT G132] K ） 其中 K = 1 in_features K = \\压裂{1} {\\文本{在\\ _features}} K = in_features 1 Examples: >>> m = nn.Linear(20, 30) >>> input = torch.randn(128, 20) >>> output = m(input) >>> print(output.size()) torch.Size([128, 30]) 双线性 classtorch.nn.``Bilinear( in1_features , in2_features , out_features , bias=True )[source] 适用双线性变换到传入数据： Y = × 1 A × 2 + b Y = X_1甲X_2 + b Y = × 1 A × 2 + b Parameters in1_features - 每个第一输入样本的大小 in2_features - 每个第二输入样本的大小 out_features – size of each output sample 偏压 - 如果设置为False，该层不会学添加剂偏压。默认值：真 Shape: 输入1： （ N ， ， H i的 n的 1 ） （N，，H {IN1}） （ N ， * ， H i的 n的 1 ） 其中 H 一世 n的 1 = in1_features H {IN1} = \\文本{IN1 \\ _features} H i的 n的 1 = in1_features 和 * [HT G197] 是指任何数量的附加的维度。但所有的输入的最后一个维度应该是相同的。 输入2： （ N ， ， H i的 n的 2 ） （N，，H {平方英寸}） （ N ， * ， H i的 n的 2 ） 其中 H 一世 n的 2 = in2_features H {平方英寸} = \\文本{平方英寸\\ _features} H i的 n的 2 = in2_features 。 输出： （ N ， ， H O U T ） （N，，H {出}） （ N ， * ， H O U T ） 其中 H Ø U T = out_features H {出} = \\文本{出\\ _features} H O U T = out_features 和所有，但最后一个维度是相同的形状的输入。 Variables 〜Bilinear.weight - 形状 （ out_features的模块[的可学习权重HTG11 ] ， in1_features ， in2_features ） （\\文本{出\\ _features} ，\\文本{IN1 \\ _features}，\\文本{平方英寸\\ _features}） （ out_features ， in1_features ， in2_features ） 。的值是从 初始化U （ - K ， K ） \\ mathcal【U}（ - \\ SQRT { ķ}，\\ SQRT {K}） U （ - K ， K [HTG1 55] ） ，其中 ķ = 1 in1_features K = \\压裂{1} {\\文本{IN1 \\ _features }} K = in1_features 1 ​​ 〜Bilinear.bias - 形状 （ out_features的模块[的可学习偏压HTG11 ] ） （\\文本{出\\ _features}） （ out_features ） 。如果偏压是真时，值被初始化从 U （ - K ， ķ ） \\ mathcal【U}（ - \\ SQRT {K}，\\ SQRT {K}） U （ - K ， [HT G132] K ） ，其中 K = 1 in1_features K = \\压裂{1} {\\文本{IN1 \\ _features}} K = in1_features [HTG22 4] 1 Examples: >>> m = nn.Bilinear(20, 30, 40) >>> input1 = torch.randn(128, 20) >>> input2 = torch.randn(128, 30) >>> output = m(input1, input2) >>> print(output.size()) torch.Size([128, 40]) 漏失层 降 classtorch.nn.``Dropout( p=0.5 , inplace=False )[source] 在训练期间，随机归零一些输入张量与概率P使用样品从贝努利分布元件。每个通道将独立于每前行调用清零。 这已被证明是用于正则化和防止神经元的共适应通过防止特征检测器的互相适应的文件提高神经网络中描述的有效的技术。 此外，输出由一个因素 1 1 [HTG12缩放] - p \\压裂{1} {1-p} 1 - p 1 [HTG83训练期间。这意味着，在评估期间模块简单计算标识功能。 Parameters P - 元素的概率将被归零。默认值：0.5 就地 - 如果设置为真，会做此操作就地。默认值：假 Shape: 输入： （ ） （） （ * ） 。输入可以是任何形状的 输出： （ ） （） （ * ） 。输出是相同的形状作为输入 Examples: >>> m = nn.Dropout(p=0.2) >>> input = torch.randn(20, 16) >>> output = m(input) Dropout2d classtorch.nn.``Dropout2d( p=0.5 , inplace=False )[source] 随机零出整个信道（信道是2D特征映射，例如， [HTG6：J [HTG9：J [HTG18：J 的第信道 i的 i的 i的 在成批输入第样品是二维张量 输入 [ i的 ， [HTG62：J \\文本{输入} [I，J] 输入 [ i的 ， [HTG88：J [H TG91] ）。每个信道将与使用的样品从一个伯努利分布概率P独立地置零在每一个前向呼叫。 通常情况下，输入来自nn.Conv2d模块。 正如在论文高效对象定位使用卷积网络，如果特征映射内的相邻像素是强相关的描述（如通常在早期卷积层的情况下），那么独立同分布辍学不会正规化的激活和否则将只是导致一个有效的学习速度下降。 在这种情况下，nn.Dropout2d（）将有利于促进功能的地图之间的独立性，并应改为使用。 Parameters P （ 浮动 ， 可选 ） - 的元素的概率是零-ED。 就地 （ 布尔 ， 可选 ） - 如果设定为真，会做就地这种操作 Shape: Input: (N,C,H,W)(N, C, H, W)(N,C,H,W) Output: (N,C,H,W)(N, C, H, W)(N,C,H,W) (same shape as input) Examples: >>> m = nn.Dropout2d(p=0.2) >>> input = torch.randn(20, 16, 32, 32) >>> output = m(input) Dropout3d classtorch.nn.``Dropout3d( p=0.5 , inplace=False )[source] 随机零出整个信道（信道是3D特征地图，例如， [HTG6：J [HTG9：J [HTG18：J 的第信道 i的 i的 i的 在成批输入第样品是三维张量 输入 [ i的 ， [HTG62：J \\文本{输入} [I，J] 输入 [ i的 ， [HTG88：J [H TG91] ）。每个信道将与使用的样品从一个伯努利分布概率P独立地置零在每一个前向呼叫。 通常情况下，输入来自nn.Conv3d模块。 As described in the paper Efficient Object Localization Using Convolutional Networks , if adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then i.i.d. dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. 在这种情况下，nn.Dropout3d（）将有利于促进功能的地图之间的独立性，并应改为使用。 Parameters P （ 浮动 ， 可选 ） - 的元素的概率将被归零。 inplace ( bool , optional ) – If set to True, will do this operation in-place Shape: Input: (N,C,D,H,W)(N, C, D, H, W)(N,C,D,H,W) Output: (N,C,D,H,W)(N, C, D, H, W)(N,C,D,H,W) (same shape as input) Examples: >>> m = nn.Dropout3d(p=0.2) >>> input = torch.randn(20, 16, 4, 32, 32) >>> output = m(input) AlphaDropout classtorch.nn.``AlphaDropout( p=0.5 , inplace=False )[source] 适用阿尔法差超过输入。 阿尔法差是一种差的维持自正火财产。对于具有零均值和单位标准差的输入，阿尔法差的输出保持原始平均值和输入的标准偏差。阿尔法降去手在手与活化九色鹿函数，这确保了输出具有零均值和单位标准偏差。 在训练期间，它随机掩模一些输入张量与概率 使用样品从伯努利分布p 的元素。到屏蔽元件被随机化在每个前向呼叫，并缩放和移动以保持零均值和单位标准偏差。 在评估过程中的模块简单地计算一个身份功能。 More details can be found in the paper Self-Normalizing Neural Networks . Parameters P （ 浮动 ） - 的元素的概率被丢弃。默认值：0.5 inplace ( bool , optional ) – If set to True, will do this operation in-place Shape: Input: (∗)(*)(∗) . Input can be of any shape Output: (∗)(*)(∗) . Output is of the same shape as input Examples: >>> m = nn.AlphaDropout(p=0.2) >>> input = torch.randn(20, 16) >>> output = m(input) 稀疏层 嵌入 classtorch.nn.``Embedding( num_embeddings , embedding_dim , padding_idx=None , max_norm=None , norm_type=2.0 , scale_grad_by_freq=False , sparse=False , _weight=None )[source] 存储一个固定字典和尺寸的嵌入简单的查找表。 该模块通常用于存储字的嵌入，并使用索引进行检索。输入到模块是指数列表，并且输出是对应的字的嵌入。 Parameters num_embeddings （ INT ） - 的嵌入的词典的大小 embedding_dim （ INT ） - 各嵌入矢量的大小 padding_idx （ INT ， 可选 ） - 如果给定的，垫在与嵌入矢量输出padding_idx（初始化为零）每当遇到的索引。 max_norm （ 浮动 ， 可选 ） - 如果给定的，具有范数大于各嵌入矢量max_norm被重新归一化，以具有规范max_norm。 norm_type （ 浮动 ， 可选 ） - 的p范数的p来计算用于max_norm选项。默认2。 scale_grad_by_freq （ 布尔 ， 可选 ） - 如果给出，这将通过的话频率在微型逆扩展梯度批量。默认的假 [HTG11。 稀疏 （ 布尔 ， 可选 ） - 如果真，梯度WRT 重量矩阵将是稀疏张量。请参阅有关稀疏梯度更多细节说明。 Variables 〜Embedding.weight （ 张量 ） - 形状的模块的可学习权重（num_embeddings，embedding_dim）从 初始化 N （ 0 ， 1 ） \\ mathcal {N}（0，1） N （ 0 ， 1 ） Shape: 输入： （ ） （） （ * ） ，任意形状的LongTensor包含的索引来提取 输出： （ ， H ） （，H） （ ， H ） ，其中 是输入形状和 H = embedding_dim H = \\文本{嵌入\\ _dim} H = embedding_dim Note 请记住，只有优化的数量有限支持稀疏梯度：目前它的optim.SGD（ CUDA 和 CPU ），optim.SparseAdam（ CUDA 和 CPU ）和optim.Adagrad（ CPU ） Note 与padding_idx组，在的嵌入矢量padding_idx被初始化为全零。然而，注意，这载体可随后使用定制初始化方法来修饰，例如，从而改变用于垫的输出矢量。从 嵌入本矢量梯度始终为零。 Examples: >>> # an Embedding module containing 10 tensors of size 3 >>> embedding = nn.Embedding(10, 3) >>> # a batch of 2 samples of 4 indices each >>> input = torch.LongTensor([[1,2,4,5],[4,3,2,9]]) >>> embedding(input) tensor([[[-0.0251, -1.6902, 0.7172], [-0.6431, 0.0748, 0.6969], [ 1.4970, 1.3448, -0.9685], [-0.3677, -2.7265, -0.1685]], [[ 1.4970, 1.3448, -0.9685], [ 0.4362, -0.4004, 0.9400], [-0.6431, 0.0748, 0.6969], [ 0.9124, -2.3616, 1.1151]]]) >>> # example with padding_idx >>> embedding = nn.Embedding(10, 3, padding_idx=0) >>> input = torch.LongTensor([[0,2,0,5]]) >>> embedding(input) tensor([[[ 0.0000, 0.0000, 0.0000], [ 0.1535, -2.0309, 0.9315], [ 0.0000, 0.0000, 0.0000], [-0.1655, 0.9897, 0.0635]]]) classmethodfrom_pretrained( embeddings , freeze=True , padding_idx=None , max_norm=None , norm_type=2.0 , scale_grad_by_freq=False , sparse=False )[source] 创建一个从给定的2维FloatTensor嵌入实例。 Parameters 的嵌入 （ 张量 ） - FloatTensor含有用于嵌入权重。第一维度被传递给嵌入为num_embeddings，第二为embedding_dim。 冻结 （ 布尔 ， 可选 ） - 如果真时，张量不在学习过程中得到更新。等价于embedding.weight.requires_grad = 假。默认值：真 padding_idx （ INT ， 可选 ） - 参见模块的初始化文档。 max_norm （ 浮动 ， 可选 ） - 参见模块的初始化文档。 norm_type （ 浮动 ， 可选 ） - 参见模块的初始化文档。默认2。 scale_grad_by_freq （ 布尔 ， 可选 ） - 参见模块的初始化文档。默认的假 [HTG11。 稀疏 （ 布尔 ， 可选 ） - 参见模块的初始化文档。 Examples: >>> # FloatTensor containing pretrained weights >>> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]]) >>> embedding = nn.Embedding.from_pretrained(weight) >>> # Get embeddings for index 1 >>> input = torch.LongTensor([1]) >>> embedding(input) tensor([[ 4.0000, 5.1000, 6.3000]]) EmbeddingBag classtorch.nn.``EmbeddingBag( num_embeddings , embedding_dim , max_norm=None , norm_type=2.0 , scale_grad_by_freq=False , mode='mean' , sparse=False , _weight=None )[source] 计算的的嵌入的“袋”，和或装置没有实例的中间的嵌入。 恒定长度的袋和无per_sample_weights，这个类 与模式= “总和”等于 `接着torch嵌入 `。总和（暗= 0） > 接着torch与模式= “意指” 等于嵌入 。平均（暗淡= 0） > 与模式= “最大”等于 `接着torch嵌入 `。最大（暗= 0） 。 > > 然而， EmbeddingBag做花费更多时间和存储器不是使用这些操作中的一个链高效。 EmbeddingBag还支持每个样品重量作为参数传递给直传。这个缩放嵌入的输出作为由模式中指定执行的加权还原之前。如果per_sample_weights``通过，仅支持模式 是“总和” ，其中根据per_sample_weights `计算的加权和。 Parameters num_embeddings ( int) – size of the dictionary of embeddings embedding_dim ( int) – the size of each embedding vector max_norm ( float , optional ) – If given, each embedding vector with norm larger than max_normis renormalized to have norm max_norm. norm_type ( float , optional ) – The p of the p-norm to compute for the max_normoption. Default 2. scale_grad_by_freq （ 布尔 ， 可选 ） - 如果给定的，这将通过的话频率在微型逆扩展梯度批量。默认的假 [HTG11。注意：不支持此选项时模式= “MAX” [HTG15。`` 模式 （ 串 ， 可选 ） - “总和”，“的意思是”或“最大”。指定要降低袋的方式。 “总和”计算的加权和，以per_sample_weights考虑在内。 “的意思是”计算在袋中的值的平均值，“最大”计算在每个袋中的最大值。默认值：“的意思是” 稀疏 （ 布尔 ， 可选 ） - 如果真，梯度WRT 重量矩阵将是稀疏张量。请参阅有关稀疏梯度更多细节说明。注意：不支持此选项时模式= “MAX” [HTG21。 Variables EmbeddingBag.weight （ 张量 ）〜 （num_embeddings，embedding_dim）从初始化形状的模块的可学习权重 N （ 0 ， 1 ） \\ mathcal {N}（0，1） N （ 0 ， 1 ） 。 Inputs: input(LongTensor), offsets(LongTensor, optional), and per_index_weights（张量，可选） 如果输入是形状的2D （B，N） 它会被视为B袋（序列）各固定长度的N，这将返回B值在某种程度上取决于模式聚合。 偏移被忽略，并且需要为无在这种情况下。 如果输入是形状的1D （N） 它会被视为多个袋（序列）的级联。 偏移需要为含有输入每个袋子的起始索引位置的1D张量。因此，对于偏移形状的（B），输入将被视为具有B袋。空袋通过零填充（即，具有长度为0的）将已经返回向量。 per_sample_weights (Tensor, optional): a tensor of float / double weights, or None 以指示所有的权重应取为1。如果已指定，per_sample_weights必须具有完全相同的形状作为输入，被视为具有相同的偏移，如果这些都没有无。仅支持模式= '总和'。 输出形状：（B，embedding_dim） Examples: >>> # an Embedding module containing 10 tensors of size 3 >>> embedding_sum = nn.EmbeddingBag(10, 3, mode='sum') >>> # a batch of 2 samples of 4 indices each >>> input = torch.LongTensor([1,2,4,5,4,3,2,9]) >>> offsets = torch.LongTensor([0,4]) >>> embedding_sum(input, offsets) tensor([[-0.8861, -5.4350, -0.0523], [ 1.1306, -2.5798, -1.0044]]) classmethodfrom_pretrained( embeddings , freeze=True , max_norm=None , norm_type=2.0 , scale_grad_by_freq=False , mode='mean' , sparse=False )[source] 从给定的2维FloatTensor创建EmbeddingBag实例。 Parameters 的嵌入 （ 张量 ） - FloatTensor含有用于EmbeddingBag权重。第一维度被传递给EmbeddingBag为“num_embeddings”，第二为“embedding_dim”。 冻结 （ 布尔 ， 可选 ） - 如果真时，张量不在学习过程中得到更新。等价于embeddingbag.weight.requires_grad = 假。默认值：真 max_norm （ 浮动 ， 可选 ） - 参见模块的初始化文档。默认值：无 norm_type ( float , optional ) – See module initialization documentation. Default 2. scale_grad_by_freq ( boolean , optional ) – See module initialization documentation. Default False. 模式 （ 串 ， 可选 ） - 参见模块的初始化文档。默认值：“的意思是” 稀疏 （ 布尔 ， 可选 ） - 参见模块的初始化文档。默认值：假 [HTG13。 Examples: >>> # FloatTensor containing pretrained weights >>> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]]) >>> embeddingbag = nn.EmbeddingBag.from_pretrained(weight) >>> # Get embeddings for index 1 >>> input = torch.LongTensor([[1, 0]]) >>> embeddingbag(input) tensor([[ 2.5000, 3.7000, 4.6500]]) 距离函数 余弦相似性 classtorch.nn.``CosineSimilarity( dim=1 , eps=1e-08 )[source] 返回之间的余弦相似度 × 1 X_1 × 1 和 × 2 X_2 × 2 ，沿着昏暗计算。 similarity=x1⋅x2max⁡(∥x1∥2⋅∥x2∥2,ϵ).\\text{similarity} = \\dfrac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2 \\cdot \\Vert x_2 \\Vert _2, \\epsilon)}. similarity=max(∥x1​∥2​⋅∥x2​∥2​,ϵ)x1​⋅x2​​. Parameters 暗淡 （ INT ， 可选 ） - 维其中余弦相似度进行计算。默认值：1 EPS （ 浮动 ， 可选 ） - 小值由零避免分裂。默认值：1E-8 Shape: 输入1： （ 1 d ， 2 ） （\\ ast_1，d，\\ ast_2） （ 1 ， d ， 2 ） 其中d是在位置暗淡 输入2： （ 1 d ， 2 ） （\\ ast_1，d，\\ ast_2） （ 1 ， d ， 2 ） ，相同形状的输入1 输出： （ 1 2 ） （\\ ast_1，\\ ast_2） （ 1 ， 2 ） Examples:: >>> input1 = torch.randn(100, 128) >>> input2 = torch.randn(100, 128) >>> cos = nn.CosineSimilarity(dim=1, eps=1e-6) >>> output = cos(input1, input2) PairwiseDistance classtorch.nn.``PairwiseDistance( p=2.0 , eps=1e-06 , keepdim=False )[source] 计算之间的载体 [HTG7】V 1 [HTG13分批成对距离] V_1 [HTG23】v 1 ， v 2 V_2 [HTG77 】v 2 使用 的p范数： ∥x∥p=(∑i=1n∣xi∣p)1/p.\\Vert x \\Vert p = \\left( \\sum{i=1}^n \\vert x_i \\vert ^ p \\right) ^ {1/p}. ∥x∥p​=(i=1∑n​∣xi​∣p)1/p. Parameters P （ 真实 ） - 范数度。默认值：2 EPS （ 浮动 ， 可选 ） - 小值由零避免分裂。默认值：1E-6 keepdim （ 布尔 ， 可选 ） - 确定是否要保持向量维度。默认值：false Shape: 输入1： （ N ， d ） （N，d） （ N ， d ） 其中 d =载体尺寸 输入2： （ N ， d ） （N，d） （ N ， d ） ，相同形状的输入1 输出： （ N ） （N） （ N ） 。如果keepdim是真，然后 （ N ， 1 ） （N，1） （ N ， 1 ） 。 Examples:: >>> pdist = nn.PairwiseDistance(p=2) >>> input1 = torch.randn(100, 128) >>> input2 = torch.randn(100, 128) >>> output = pdist(input1, input2) 损失函数 L1Loss classtorch.nn.``L1Loss( size_average=None , reduce=None , reduction='mean' )[source] 创建在输入 × ×各元件之间测量的平均绝对误差（MAE）的标准 × 和目标 Y Y Y 。 未还原的（即，具有还原设置为 '无'）损耗可以被描述为： ℓ(x,y)=L={l1,…,lN}⊤,ln=∣xn−yn∣,\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = \\left| x_n - y_n \\right|, ℓ(x,y)=L={l1​,…,lN​}⊤,ln​=∣xn​−yn​∣, 其中 N N N 是批量大小。如果还原不是'无'（默认'平均'），然后： ℓ(x,y)={mean⁡(L),if reduction=’mean’;sum⁡(L),if reduction=’sum’.\\ell(x, y) = \\begin{cases} \\operatorname{mean}(L), & \\text{if reduction} = \\text{'mean';}\\\\ \\operatorname{sum}(L), & \\text{if reduction} = \\text{'sum'.} \\end{cases} ℓ(x,y)={mean(L),sum(L),​if reduction=’mean’;if reduction=’sum’.​ × × × 和 Y Y Y 是任意形状的张量，总的 n的 n的 n的 每个元件。 求和操作仍然工作在所有元素，并除以 n的 n的 n的 。 除以 n的 n的 n的 可避免如果一个集还原 = '和'。 Parameters size_average （ 布尔 ， 可选 ） - 已过时（见还原）。默认情况下，损失平均超过批中每个元素的损失。请注意，对于一些损失，有每个样品的多个元素。如果该字段size_average被设定为假时，损失代替求和每个minibatch。当减少是假忽略。默认值：真 减少 （ 布尔 ， 可选 ） - 已过时（见还原）。默认情况下，损耗进行平均或求和观测为视size_average每个minibatch。当减少是假，返回每批元件的损耗，而不是并忽略size_average。默认值：真 还原 （ 串 ， 可选 ） - 指定还原应用到输出：'无'| '的意思是'| '和'。 '无'：不降低将被应用，'意味'：将输出的总和将通过的数量来划分在输出中，'和'元素：输出将被累加。注意：size_average和减少处于被淘汰，并且在此同时，指定是这两个参数的个数将覆盖还原。默认值：'平均' Shape: 输入： （ N ， ） （N，） （ N ， ） 其中 手段，任意数量的附加维度的 目标： （ N ， ） （N，） （ N ， * ） ，相同形状的输入 输出：标量。如果还原是'无'，然后 （ N ， ） （N，） （ N ， * ） ，相同形状的输入 Examples: >>> loss = nn.L1Loss() >>> input = torch.randn(3, 5, requires_grad=True) >>> target = torch.randn(3, 5) >>> output = loss(input, target) >>> output.backward() MSELoss classtorch.nn.``MSELoss( size_average=None , reduce=None , reduction='mean' )[source] 创建在输入 × [HTG9各元件之间测量均方误差（平方L2范数）的标准]× × 和目标 Y Y Y 。 The unreduced (i.e. with reductionset to 'none') loss can be described as: ℓ(x,y)=L={l1,…,lN}⊤,ln=(xn−yn)2,\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = \\left( x_n - y_n \\right)^2, ℓ(x,y)=L={l1​,…,lN​}⊤,ln​=(xn​−yn​)2, where NNN is the batch size. If reductionis not 'none'(default 'mean'), then: ℓ(x,y)={mean⁡(L),if reduction=’mean’;sum⁡(L),if reduction=’sum’.\\ell(x, y) = \\begin{cases} \\operatorname{mean}(L), & \\text{if reduction} = \\text{'mean';}\\\\ \\operatorname{sum}(L), & \\text{if reduction} = \\text{'sum'.} \\end{cases} ℓ(x,y)={mean(L),sum(L),​if reduction=’mean’;if reduction=’sum’.​ xxx and yyy are tensors of arbitrary shapes with a total of nnn elements each. The sum operation still operates over all the elements, and divides by nnn . The division by nnn can be avoided if one sets reduction = 'sum'. Parameters size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: Input: (N,∗)(N, )(N,∗) where ∗∗ means, any number of additional dimensions Target: (N,∗)(N, *)(N,∗) , same shape as the input Examples: >>> loss = nn.MSELoss() >>> input = torch.randn(3, 5, requires_grad=True) >>> target = torch.randn(3, 5) >>> output = loss(input, target) >>> output.backward() CrossEntropyLoss classtorch.nn.``CrossEntropyLoss( weight=None , size_average=None , ignore_index=-100 , reduce=None , reduction='mean' )[source] 该标准结合nn.LogSoftmax（）和nn.NLLLoss（）在一个单独的类。 训练与 C 类分类问题时是有用的。如果提供的话，可选的参数重量应该是一个1D 张量重量分配到每个类。当你有一个不平衡的训练集这是特别有用。 的输入预计包含生的，非归一化的分数为每个类。 输入必须是尺寸的张量为 （ M I n的 i的 b 一 T C [HTG26 1 H ， C ） （minibatch，C） （ M i的 n的 i的 b 一 T C H ， C ） 或 （ M i的 n的 i的 b 一 T C H [HTG1 01] ， C ， d 1 ， d 2 ， 。 。 。 ， d K ） （minibatch，C，D_1， D_2，...，d_K） （ M i的 n的 i的 b 一 T C H ， C ， d 1 ， d [H TG223] 2 ， 。 。 。 ， d K ​​ ） 与 K ≥ 1 ķ\\ GEQ 1 ķ ≥ 1 为 K 维情况下（后述）。 该标准需要一个类指数在范围 [ 0 ， C - 1 [0，C-1] [ 0 ， C - 1 作为用于大小 minibatch [的一维张量的每个值的目标;]如果 ignore_index 被指定时，该标准也接受这个类索引（此索引可以不一定是在类范围内）。 损失可以被描述为： loss(x,class)=−log⁡(exp⁡(x[class])∑jexp⁡(x[j]))=−x[class]+log⁡(∑jexp⁡(x[j]))\\text{loss}(x, class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])}\\right) = -x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right) loss(x,class)=−log(∑j​exp(x[j])exp(x[class])​)=−x[class]+log(j∑​exp(x[j])) 或在重量参数的情况下被指定的： loss(x,class)=weightclass))\\text{loss}(x, class) = weight[class] \\left(-x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right)\\right) loss(x,class)=weightclass)) 这些损失是整个观测平均每个minibatch。 也可以用于更高的尺寸的输入，如2D图像，通过提供尺寸 （ M [的输入HTG9] i的 n的 i的 b 一 T C H ， C ， d 1 ， d 2 ， 。 。 ， d K ） （minibatch，C，D_1 ，D_2，...，d_K） （ M I n的 i的 b 一 T C [HTG92 1 H ， C ， d 1 ， d 2 ， 。 。 。 ， d K ） 与 K ≥ 1 ķ\\ GEQ 1 ķ ≥ 1 ，其中 K K ​​ K 是维数，和适当形状的目标（见下文）。 Parameters 重量 （ 张量 ， 可选 ） - 给每个类的手动重新缩放权重。如果给定的，必须是尺寸℃的张量 size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True ignore_index （ INT ， 可选 ） - 指定将被忽略，并且不向目标值输入梯度。当size_average是真，损失平均超过非忽略的目标。 reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: 输入： （ N ， C ） （N，C） （ N ， C ） 其中 C =号码类或 （ N ， ç ， d 1 ， d 2 ， 。 。 。 ， d K ） （N，C，D_1，D_2，...，d_K） （ N ， C ， d 1 ， d 2 ， 。 。 。 ， d K ） 与 K ≥ 1 ķ\\ GEQ 1 ķ ≥ 1 如的情况下K 维损失。 目标： （ N ） （N） （ N ） 其中每个值是 0 ≤ 目标 [ i的 ≤ C - 1 0 \\当量\\文本{目标} [I] \\当量C-1 0 ≤ 目标 [ i的 ≤ C - 1 或 （ N ， d 1 ， d 2 ， 。 。 。 ， d K ） （N，D_1，D_2， ...，d_K） （ N ， d 1 ， d 2 ， 。 [HTG246 。 ， d K ​​ ） 与 K ≥ 1 ķ\\ GEQ 1 ķ ≥ 1 在K维损失的情况下。 输出：标量。如果还原是'无'，然后相同的尺寸为目标： （ N ） （N） （ N ） 或 （ N ， d 1 ， d 2 ， 。 。 。 ， d K ） （N，D_1，D_2，...，d_K） （ N ，[HT G99] d 1 ， d 2 ， 。 。 。 ， d K ） 与 K ≥ 1 ķ\\ GEQ 1 ķ ≥ 1 在K维损失的情况下。 Examples: >>> loss = nn.CrossEntropyLoss() >>> input = torch.randn(3, 5, requires_grad=True) >>> target = torch.empty(3, dtype=torch.long).random_(5) >>> output = loss(input, target) >>> output.backward() CTCLoss classtorch.nn.``CTCLoss( blank=0 , reduction='mean' , zero_infinity=False )[source] 该联结颞分类损失。 计算连续的（不分段）的时间序列和靶序列之间的损耗。 CTCLoss总结以上输入的可能的对准目标的概率，产生其是可微分的相对于每个输入节点的损耗值。输入到目标的取向被假定为“多到一”，这限制了靶序列的长度，使得它必须是 ≤ \\当量 ≤ 输入长度。 Parameters 空白 （ INT ， 可选 ） - 空白标签。默认 0 0 0 。 还原 （ 串 ， 可选 ） - 指定还原应用到输出：'无'| '的意思是'| '和'。 '无'：不降低将被应用，'意味'：输出损耗将由目标长度，然后被划分平均超过该批次取。默认值：'平均' zero_infinity （ 布尔 ， 可选 ） - 是否为零无限损失和相关联的梯度。默认值：假主要是当输入太短，无法对准目标出现无限损失。 Shape: Log_probs：的张量大小 （ T ， N ， C ） （T，N，C） （ T ， N ， C ） ，其中 T = 输入长度 T = \\文本{输入长度} T = 输入长度 ， N = 批量大小 N = \\文本{批量大小} N = 批量大小 和 ç = 的类（包括空白） C = \\文本{的类（包括坯件）数}数 C = 的类号码（包括空格） 。的输出的取对数概率（例如，用 获得torch.nn.functional.log_softmax（））。 目标：大小 （ N ， S的张量 ） （N，S） （ N ， S ） 或 （ 总结 ⁡ （ target_lengths ） ） （\\ operatorname {总和}（\\文本{目标\\ _lengths}）） （ S U M （ target_lengths ） ） ，其中[H TG96] N = 批量大小 N = \\文本{批量大小} N = 批量大小 和 S = 最大目标长度，如果形状是 （ N ， S ） S = \\文本{最大目标长度，如果形状为}（N，S） S = 最大目标长度，如果形状是 （ N ， S ） 。它代表了靶序列。在靶序列中的每个元素是一个类的索引。和目标索引不能为空（缺省值= 0）。在 （ N ， S ） （N，S） （ N ， S ） 形式，目标被填充到最长的序列的长度，并堆叠。在 （ 总和 ⁡ （ target_lengths ） ） （\\ operatorname {总和}（\\文本{目标\\ _lengths}）） ​​ （ S U M （ target_lengths ） ） 的形式中，目标是假定为未填充的和1名维中串联。 Input_lengths：元组或的大小 （ N ）张量 （N） （ N ） ，其中 N = 批次大小 N = \\文本{批量大小} N = 批量大小 。它表示的输入长度（每一个都必须 ≤ T \\当量T ≤ T ）。和长度为每个序列，以实现该序列被填充到长度相等的假设下掩蔽指定。 Target_lengths：元组或的大小 （ N ）张量 （N） （ N ） ，其中 N = 批次大小 N = \\文本{批量大小} N = 批量大小 。它代表了目标的长度。长度对于每个序列，以实现该序列被填充到长度相等的假设下掩蔽指定。如果目标形状为 （ N ， S ） （N，S） （ N ， S ） ，target_lengths是有效的停止指数 S n的 S_N S n的 [H TG167] 对于每个靶序列，从而使得TARGET_N = 目标[N，0：S_N] [HTG177用于批处理中的每个目标。长度每一个都必须 ≤ S \\当量S ≤ S [HTG211如果目标被给定为一维张量是单个目标的级联，所述target_lengths必须加起来张量的总长度。 输出：标量。如果还原是'无'，然后 （ N ） （N） （ N ） ，其中 N = 批量大小 N = \\文本{批量大小} N = 批量大小 。 Example: >>> T = 50 # Input sequence length >>> C = 20 # Number of classes (including blank) >>> N = 16 # Batch size >>> S = 30 # Target sequence length of longest target in batch >>> S_min = 10 # Minimum target length, for demonstration purposes >>> >>> # Initialize random batch of input vectors, for *size = (T,N,C) >>> input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_() >>> >>> # Initialize random batch of targets (0 = blank, 1:C = classes) >>> target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long) >>> >>> input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long) >>> target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long) >>> ctc_loss = nn.CTCLoss() >>> loss = ctc_loss(input, target, input_lengths, target_lengths) >>> loss.backward() Reference: A. Graves等人：联结颞分类：与回归神经网络的标注未分段序列数据： https://www.cs.toronto.edu/~graves/icml_2006.pdf Note 为了使用CuDNN时，必须满足以下条件：HTG0] 目标 必须在级联格式，所有input_lengths必须 T 。 B L 一 n的 ķ = 0 空白= 0 b L 一 n的 K = 0 ，target_lengths≤ 256 \\当量256 ≤ 2 5 6 ，整数参数必须是D型细胞的torch.int32。 常规实现使用（多见于PyTorch） torch.long D型。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. NLLLoss classtorch.nn.``NLLLoss( weight=None , size_average=None , ignore_index=-100 , reduce=None , reduction='mean' )[source] 负对数似然的损失。重要的是要培养具有 C 类分类问题是有用的。 如果提供的话，可选的参数重量应该是张量1D重量分配给每个类。当你有一个不平衡的训练集这是特别有用。 的输入通过前向呼叫给出预计包含每个类的对数概率。 输入必须是尺寸的张量为 （ M I n的 i的 b 一 T C [HTG28 1 H ， C ） （minibatch，C） （ M i的 n的 i的 b 一 T C H ， C ） 或 （ M i的 n的 i的 b 一 T C H ， C ， d 1 ， d 2 ， 。 。 。 ， d K ） （minibatch，C，D_1， D_2，...，d_K） （ M i的 n的 i的 b 一 T C H ， C ， d 1 ， d [H TG225] 2 ， 。 。 。 ， d K ​​ ） 与 K ≥ 1 ķ\\ GEQ 1 ķ ≥ 1 为 K 维情况下（后述）。 在神经网络中获取数的概率是很容易在你的网络的最后一层添加 LogSoftmax 层来实现。您可以使用 CrossEntropyLoss 相反，如果你不喜欢添加额外的层。 的目标，这一损失预计应该是在范围 [ 0 [一类索引HTG11] ， C - 1 [0，C-1] [ 0 ， C - 1 ] 其中 C =班数 ;如果 ignore_index 被指定时，这个损失也接受这个类别的索引（此索引可以不一定是在类范围内）。 The unreduced (i.e. with reductionset to 'none') loss can be described as: ℓ(x,y)=L={l1,…,lN}⊤,ln=−wynxn,yn,wc=weight[c]⋅1{c≠ignoreindex},\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = - w{yn} x{n,yn}, \\quad w{c} = \\text{weight}[c] \\cdot \\mathbb{1}\\{c \\not= \\text{ignore\\_index}\\}, ℓ(x,y)=L={l1​,…,lN​}⊤,ln​=−wyn​​xn,yn​​,wc​=weight[c]⋅1{c​=ignore_index}, 其中 N N N 是批量大小。如果还原不是'无'（默认'平均'），然后 ℓ(x,y)={∑n=1N1∑n=1Nwynln,if reduction=’mean’;∑n=1Nln,if reduction=’sum’.\\ell(x, y) = \\begin{cases} \\sum{n=1}^N \\frac{1}{\\sum{n=1}^N w{y_n}} l_n, & \\text{if reduction} = \\text{'mean';}\\\\ \\sum{n=1}^N l_n, & \\text{if reduction} = \\text{'sum'.} \\end{cases} ℓ(x,y)={∑n=1N​∑n=1N​wyn​​1​ln​,∑n=1N​ln​,​if reduction=’mean’;if reduction=’sum’.​ 也可以用于更高的尺寸的输入，如2D图像，通过提供尺寸 （ M [的输入HTG9] i的 n的 i的 b 一 T C H ， C ， d 1 ， d 2 ， 。 。 ， d K ） （minibatch，C，D_1 ，D_2，...，d_K） （ M I n的 i的 b 一 T C [HTG92 1 H ， C ， d 1 ， d 2 ， 。 。 。 ， d K ） 与 K ≥ 1 ķ\\ GEQ 1 ķ ≥ 1 ，其中 K K ​​ K 是维数，和适当形状的目标（见下文）。在图像的情况下，它计算每像素NLL损失。 Parameters 重量 （ 张量 ， 可选 ） - 给每个类的手动重新缩放权重。如果给定的，它必须是尺寸 C 的张量。否则，将被视为有，如果所有的人。 size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True ignore_index （ INT ， 可选 ） - 指定将被忽略，并且不向目标值输入梯度。当size_average是真，损失平均超过非忽略的目标。 reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: Input: (N,C)(N, C)(N,C) where C = number of classes, or (N,C,d1,d2,...,dK)(N, C, d_1, d_2, ..., d_K)(N,C,d1​,d2​,...,dK​) with K≥1K \\geq 1K≥1 in the case of K-dimensional loss. Target: (N)(N)(N) where each value is 0≤targets[i]≤C−10 \\leq \\text{targets}[i] \\leq C-10≤targets[i]≤C−1 , or (N,d1,d2,...,dK)(N, d_1, d_2, ..., d_K)(N,d1​,d2​,...,dK​) with K≥1K \\geq 1K≥1 in the case of K-dimensional loss. 输出：标量。如果还原是'无'，然后相同的尺寸为目标： （ N ） （N） （ N ） 或 （ N ， d 1 ， d 2 ， 。 。 。 ， d K ） （N，D_1，D_2，...，d_K） （ N ，[HT G99] d 1 ， d 2 ， 。 。 。 ， d K ） 与 K ≥ 1 ķ\\ GEQ 1 ķ ≥ 1 在K维损失的情况下。 Examples: >>> m = nn.LogSoftmax(dim=1) >>> loss = nn.NLLLoss() >>> # input is of size N x C = 3 x 5 >>> input = torch.randn(3, 5, requires_grad=True) >>> # each element in target has to have 0 >> target = torch.tensor([1, 0, 4]) >>> output = loss(m(input), target) >>> output.backward() >>> >>> >>> # 2D loss example (used, for example, with image inputs) >>> N, C = 5, 4 >>> loss = nn.NLLLoss() >>> # input is of size N x C x height x width >>> data = torch.randn(N, 16, 10, 10) >>> conv = nn.Conv2d(16, C, (3, 3)) >>> m = nn.LogSoftmax(dim=1) >>> # each element in target has to have 0 >> target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C) >>> output = loss(m(conv(data)), target) >>> output.backward() PoissonNLLLoss classtorch.nn.``PoissonNLLLoss( log_input=True , full=False , size_average=None , eps=1e-08 , reduce=None , reduction='mean' )[source] 负对数似然损失与目标的泊松分布。 The loss can be described as: target∼Poisson(input)loss(input,target)=input−target∗log⁡(input)+log⁡(target!)\\text{target} \\sim \\mathrm{Poisson}(\\text{input}) \\text{loss}(\\text{input}, \\text{target}) = \\text{input} - \\text{target} * \\log(\\text{input}) + \\log(\\text{target!})target∼Poisson(input)loss(input,target)=input−target∗log(input)+log(target!) 的最后一项可被省略或用斯特林式近似。用于靶的近似值超过1.对于目标小于或等于1个零添加到损失。 Parameters log_input （ 布尔 ， 可选 ） - 如果真损耗被计算为 EXP ⁡ （ 输入 ） - 目标 输入 \\ EXP（\\文本{输入}） - \\文本{目标} \\文本{输入} EXP （ 输入 ） - 目标 输入 时，如果假损失 输入 - 目标 日志 ⁡ （ 输入 + EPS ） \\文本{输入} - \\文本{目标} \\日志（\\文本{输入} + \\文本{EPS}） 输入 - 目标 LO G （ 输入 + EPS ） 。 充满 （ 布尔 ， 可选 ） - 是否计算全部损失，我。即添加的斯特林近似术语 target∗log⁡(target)−target+0.5∗log⁡(2πtarget).\\text{target}*\\log(\\text{target}) \\text{target} + 0.5 * \\log(2\\pi\\text{target}). target∗log(target)−target+0.5∗log(2πtarget). size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True EPS （ 浮动 ， 可选 ） - 小值，以避免的 [评价HTG12] 日志 ⁡ （ 0 ） \\日志（0） LO G （ 0 ） 时log_input = 假。默认值：1E-8 reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Examples: >>> loss = nn.PoissonNLLLoss() >>> log_input = torch.randn(5, 2, requires_grad=True) >>> target = torch.randn(5, 2) >>> output = loss(log_input, target) >>> output.backward() Shape: Input: (N,∗)(N, )(N,∗) where ∗∗ means, any number of additional dimensions Target: (N,∗)(N, *)(N,∗) , same shape as the input 输出：在默认情况下标。如果还原是'无'，然后 （ N ， ） （N，） （ N ， * ） ，相同的形状作为输入 KLDivLoss classtorch.nn.``KLDivLoss( size_average=None , reduce=None , reduction='mean' )[source] 在相对熵损失 KL散度是连续分布的有用距离度量和过（离散采样）连续输出分布的空间执行直接回归时是经常有益的。 与 NLLLoss时，输入中给出预计包含 对数概率 ，并且不限制于2D张量。各项指标均给定为 概率 （即没有取对数）。 该标准需要一个目标 张量相同尺寸与输入 张量的。 The unreduced (i.e. with reductionset to 'none') loss can be described as: l(x,y)=L={l1,…,lN},ln=yn⋅(log⁡yn−xn)l(x,y) = L = \\{ l_1,\\dots,l_N \\}, \\quad l_n = y_n \\cdot \\left( \\log y_n - x_n \\right) l(x,y)=L={l1​,…,lN​},ln​=yn​⋅(logyn​−xn​) 其中，索引 N N N 跨越输入的所有尺寸和 L L L 具有相同的形状输入。如果还原不是'无'（默认'平均'），然后： ℓ(x,y)={mean⁡(L),if reduction=’mean’;sum⁡(L),if reduction=’sum’.\\ell(x, y) = \\begin{cases} \\operatorname{mean}(L), & \\text{if reduction} = \\text{'mean';} \\\\ \\operatorname{sum}(L), & \\text{if reduction} = \\text{'sum'.} \\end{cases} ℓ(x,y)={mean(L),sum(L),​if reduction=’mean’;if reduction=’sum’.​ 在默认还原模式'平均'时，损耗超过观测平均每个minibatch 以及 在尺寸。 'batchmean'模式给出正确的KL散度，其中损耗进行平均仅批次的尺寸。 '平均'模式的行为将被更改为与'batchmean'在接下来的主要版本。 Parameters size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True 还原 （ 串 ， 可选 ） - 指定还原应用到输出：'无'| 'batchmean'| '和'| '意味'。 '无'：不降低将被应用。 'batchmean'：将输出的总和将通过BATCHSIZE进行划分。 '和'：输出将被累加。 “意味”：输出将通过在输出元件的数目来划分。默认值：'平均' Note size_average和减少处于被淘汰，并且在此同时，指定是这两个参数的个数将覆盖还原。 Note 还原= '平均'不回真正的KL散度值，请使用还原= 'batchmean'与KL数学定义对齐。在接下来的主要版本，'的意思是'将改为同'batchmean' [HTG23。 Shape: Input: (N,∗)(N, )(N,∗) where ∗∗ means, any number of additional dimensions Target: (N,∗)(N, *)(N,∗) , same shape as the input 输出：在默认情况下标。如果：ATTR：还原是'无'，然后 （ N ， ） （N，） （ N ， * ） ，相同的形状作为输入 BCELoss classtorch.nn.``BCELoss( weight=None , size_average=None , reduce=None , reduction='mean' )[source] 创建一个测量目标与输出之间的二进制交叉熵的标准： The unreduced (i.e. with reductionset to 'none') loss can be described as: ℓ(x,y)=L={l1,…,lN}⊤,ln=−wn[yn⋅log⁡xn+(1−yn)⋅log⁡(1−xn)],\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = - w_n \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right], ℓ(x,y)=L={l1​,…,lN​}⊤,ln​=−wn​[yn​⋅logxn​+(1−yn​)⋅log(1−xn​)], where NNN is the batch size. If reductionis not 'none'(default 'mean'), then ℓ(x,y)={mean⁡(L),if reduction=’mean’;sum⁡(L),if reduction=’sum’.\\ell(x, y) = \\begin{cases} \\operatorname{mean}(L), & \\text{if reduction} = \\text{'mean';}\\\\ \\operatorname{sum}(L), & \\text{if reduction} = \\text{'sum'.} \\end{cases} ℓ(x,y)={mean(L),sum(L),​if reduction=’mean’;if reduction=’sum’.​ 这是用于测量一个重建的误差在例如一个自动编码器。请注意，目标 Y Y Y 应该是0和1之间的数字。 Parameters 重量 （ 张量 ， 可选 ） - 给予每个批次元素的损失的手动重新缩放权重。如果给定的，必须是尺寸 nbatch 的张量。 size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: Input: (N,∗)(N, )(N,∗) where ∗∗ means, any number of additional dimensions Target: (N,∗)(N, *)(N,∗) , same shape as the input 输出：标量。如果还原是'无'，然后 （ N ， ） （N，） （ N ， * ） ，相同的形状作为输入。 Examples: >>> m = nn.Sigmoid() >>> loss = nn.BCELoss() >>> input = torch.randn(3, requires_grad=True) >>> target = torch.empty(3).random_(2) >>> output = loss(m(input), target) >>> output.backward() BCEWithLogitsLoss classtorch.nn.``BCEWithLogitsLoss( weight=None , size_average=None , reduce=None , reduction='mean' , pos_weight=None )[source] 这种损失结合了乙状结肠层和 BCELoss 在一个单独的类。这个版本比使用纯更数值稳定乙状结肠接着对数和-EXP特技进行数值的 BCELoss 如，通过操作组合为一个层，我们利用稳定性。 The unreduced (i.e. with reductionset to 'none') loss can be described as: ℓ(x,y)=L={l1,…,lN}⊤,ln=−wn[yn⋅log⁡σ(xn)+(1−yn)⋅log⁡(1−σ(xn))],\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = - w_n \\left[ y_n \\cdot \\log \\sigma(x_n) + (1 - y_n) \\cdot \\log (1 - \\sigma(x_n)) \\right], ℓ(x,y)=L={l1​,…,lN​}⊤,ln​=−wn​[yn​⋅logσ(xn​)+(1−yn​)⋅log(1−σ(xn​))], where NNN is the batch size. If reductionis not 'none'(default 'mean'), then ℓ(x,y)={mean⁡(L),if reduction=’mean’;sum⁡(L),if reduction=’sum’.\\ell(x, y) = \\begin{cases} \\operatorname{mean}(L), & \\text{if reduction} = \\text{'mean';}\\\\ \\operatorname{sum}(L), & \\text{if reduction} = \\text{'sum'.} \\end{cases} ℓ(x,y)={mean(L),sum(L),​if reduction=’mean’;if reduction=’sum’.​ 这是用于测量一个重建的误差在例如一个自动编码器。注意，目标 T [1] 应该是0和1之间的数字。 这可以通过增加配重，以积极的例子权衡召回和精度。在多标签分类的情况下的损失可以被描述为： ℓc(x,y)=Lc={l1,c,…,lN,c}⊤,ln,c=−wn,c[pcyn,c⋅log⁡σ(xn,c)+(1−yn,c)⋅log⁡(1−σ(xn,c))],\\ellc(x, y) = L_c = \\{l{1,c},\\dots,l{N,c}\\}^\\top, \\quad l{n,c} = - w{n,c} \\left[ p_c y{n,c} \\cdot \\log \\sigma(x{n,c}) + (1 - y{n,c}) \\cdot \\log (1 - \\sigma(x_{n,c})) \\right], ℓc​(x,y)=Lc​={l1,c​,…,lN,c​}⊤,ln,c​=−wn,c​[pc​yn,c​⋅logσ(xn,c​)+(1−yn,c​)⋅log(1−σ(xn,c​))], 其中 C C C 是类数（HTG24] C & GT ; 1 C & GT ; 1 C & GT ; 1 [HTG63用于多标签二元分类， C = 1 C = 1 C = 1 为单标签二元分类）， n的 n的 n的 是在批处理的样品的数目和 p C P_C p C 是肯定的回答，为类 [重量HTG183] C C C 。 P C & GT ; 1 P_C & GT ; 1 p C [ - - ] GT ; 1 增加召回， p C & LT ; 1 P_C & LT ; 1 p C & LT ; 1 提高精度。 例如，如果数据集包含单个类的100个的正和300反面的例子，则 pos_weight 为类应等于 300 100 = 3 \\压裂{300} {100} = 3 1 0 0 3 0 0 = 3 。损失将充当如果数据集包含 3 × 100 = 300 3 \\倍100 = 300 3 × 1 0 0 = 3 0 0 正例。 Examples: >>> target = torch.ones([10, 64], dtype=torch.float32) # 64 classes, batch size = 10 >>> output = torch.full([10, 64], 0.999) # A prediction (logit) >>> pos_weight = torch.ones([64]) # All weights are equal to 1 >>> criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight) >>> criterion(output, target) # -log(sigmoid(0.999)) tensor(0.3135) Parameters weight ( Tensor , optional ) – a manual rescaling weight given to the loss of each batch element. If given, has to be a Tensor of size nbatch. size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' pos_weight （ 张量 ， 可选 ） - 正例的权重。必须与长度等于类的数量的矢量。 Shape: 输入： （ N ， ） （N，） （ N ， ） 其中 手段，任意数量的附加维度的 > Target: (N,∗)(N, *)(N,∗) , same shape as the input > Output: scalar. If reductionis 'none', then (N,∗)(N, *)(N,∗) , same shape as input. > > Examples: >>> loss = nn.BCEWithLogitsLoss() >>> input = torch.randn(3, requires_grad=True) >>> target = torch.empty(3).random_(2) >>> output = loss(input, target) >>> output.backward() MarginRankingLoss classtorch.nn.``MarginRankingLoss( margin=0.0 , size_average=None , reduce=None , reduction='mean' )[source] 创建测量损耗给定的输入 × 1 X1 [HTG12一个标准] × 1 ， × 2 X2 × 2 ，两个一维小批量张量，和标签1D小批量张量 Y Y Y （含有1或-1）。 如果 Y = 1 Y = 1 Y = 1 然后将其假定第一输入应该被排名更高（具有更大的值）大于第二输入，反之亦然为 Y = - 1 Y = -1 Y = - 1 。 在小批量每个样品的损失函数是： loss(x,y)=max⁡(0,−y∗(x1−x2)+margin)\\text{loss}(x, y) = \\max(0, -y * (x1 - x2) \\text{margin}) loss(x,y)=max(0,−y∗(x1−x2)+margin) Parameters 余量 （ 浮动 ， 可选 ） - 具有的 默认值 0 0 0 。 size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: 输入： （ N ， d ） （N，d） （ N ， d ） 其中 N 是批量大小和 d 是一个样品的大小。 目标： （ N ） （N） （ N ） 输出：标量。如果还原是'无'，然后 （ N ） （N） （ N ） 。 HingeEmbeddingLoss classtorch.nn.``HingeEmbeddingLoss( margin=1.0 , size_average=None , reduce=None , reduction='mean' )[source] 措施的损失给定的输入张量 × × × 和标签张量 Y Y Y （含有1或-1）。这通常是用于测量两个输入是否是相似或不相似，例如使用L1成对距离为 × × × ，并且通常用于学习的嵌入的非线性或半监督学习。 损耗函数为 n的 n的 n的 在迷你批次号的抽样是 ln={xn,if yn=1,max⁡{0,Δ−xn},if yn=−1,l_n = \\begin{cases} x_n, & \\text{if}\\; y_n = 1,\\\\ \\max \\{0, \\Delta - x_n\\}, & \\text{if}\\; y_n = -1, \\end{cases} ln​={xn​,max{0,Δ−xn​},​ifyn​=1,ifyn​=−1,​ 和总损耗函数是 ℓ(x,y)={mean⁡(L),if reduction=’mean’;sum⁡(L),if reduction=’sum’.\\ell(x, y) = \\begin{cases} \\operatorname{mean}(L), & \\text{if reduction} = \\text{'mean';}\\\\ \\operatorname{sum}(L), & \\text{if reduction} = \\text{'sum'.} \\end{cases} ℓ(x,y)={mean(L),sum(L),​if reduction=’mean’;if reduction=’sum’.​ 其中 L = { L 1 ， ... ， L N } ⊤ L = \\ {L_1，\\点，L_N \\} ^ \\顶 L = { L 1 ， ... ， L N } ⊤ 。 Parameters 余量 （ 浮动 ， 可选 ） - 具有的 1 的默认值。 size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: 输入： （ ） （） （ ） 其中 手段，任意维数。总和操作过的所有元素进行操作。 目标： （ ） （） （ * ） ，相同形状的输入 输出：标量。如果还原是'无'，然后相同的形状作为输入 MultiLabelMarginLoss classtorch.nn.``MultiLabelMarginLoss( size_average=None , reduce=None , reduction='mean' )[source] 创建优化输入 × 之间的多级多分类铰链损失（基于容限的损失）的标准× × （二维小批量张量）和输出 Y Y Y （这是一个2D 张量目标类指数）。对于在小批量每个样品： loss(x,y)=∑ijmax⁡(0,1−(x[y[j]]−x[i]))x.size(0)\\text{loss}(x, y) = \\sum_{ij}\\frac{\\max(0, 1 - (x[y[j]] - x[i]))}{\\text{x.size}(0)} loss(x,y)=ij∑​x.size(0)max(0,1−(x[y[j]]−x[i]))​ 其中 × ∈ { 0 ， ⋯ ， x.size （ 0 ） - 1 } × \\在\\左\\ {0，\\ [] \\ cdots，\\ [] \\ {文本} x.size（0） - 1 \\右\\} × ∈ { 0 ， ⋯ ， x.size （ 0 ） - 1 } ， Y ∈ { 0 ， ⋯ ， y.size （ 0 ） - 1 } 在\\ Y \\左\\ {0，\\ [] \\ cdots，\\ [] \\ {文本} y.size（0） - 1 \\右\\} Y ∈ { 0 ， [H TG186] ⋯ ， y.size （ 0 ） - 1 } ， 0 ≤ Y [ [HTG238：J ≤ x.size （ 0 ） - 1 0 \\当量Y [j]的\\当量\\文本{x.size}（0）-1 0 ​​≤ Y [ [HTG282：J ≤ x.size （ 0 ） - 1 和 i的 ≠ Y [ [HTG336：J I \\ NEQ Y [j]的 i的  = Y [ [HTG400：J 所有 i的 i的 i的 和 [HTG438：J [HTG441：J [HTG450：J 。 Y Y Y 和 × × × 必须具有相同的大小。 该标准仅考虑的非负目标的连续的块开始于前面。 这允许不同的样品，以具有可变的量的靶类。 Parameters size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: 输入： （ C ） （C） （ C ） 或 （ N ， C ） （N，C） （ N ， C ） 其中 N 是批量大小和 C 是类的数量。 目标： （ C ） （C） （ C ） 或 （ N ， C ） （N，C） （ N ， C ） 标签的目标-1保证相同形状的输入填充。 Output: scalar. If reductionis 'none', then (N)(N)(N) . Examples: >>> loss = nn.MultiLabelMarginLoss() >>> x = torch.FloatTensor([[0.1, 0.2, 0.4, 0.8]]) >>> # for target y, only consider labels 3 and 0, not after label -1 >>> y = torch.LongTensor([[3, 0, -1, 1]]) >>> loss(x, y) >>> # 0.25 * ((1-(0.1-0.2)) + (1-(0.1-0.4)) + (1-(0.8-0.2)) + (1-(0.8-0.4))) tensor(0.8500) SmoothL1Loss classtorch.nn.``SmoothL1Loss( size_average=None , reduce=None , reduction='mean' )[source] 创建一个使用平方项如果绝对逐元素误差低于1和L1术语否则的标准。这是异常值比 MSELoss 在某些情况下较不敏感防止爆炸梯度（例如，请参见由Ross Girshick快速R-CNN 纸）。又称胡贝尔损失： loss(x,y)=1n∑izi\\text{loss}(x, y) = \\frac{1}{n} \\sum{i} z{i} loss(x,y)=n1​i∑​zi​ 其中 Z i的 Z_ {I} Z i的 由下式给出： zi={0.5(xi−yi)2,if ∣xi−yi∣ × × × 和 Y Y Y 的任意形状，总的 n的 n的 n的 每个求和操作仍然工作在所有的元素，并且通过分割元素 n的 n的 n的 。 除以 n的 n的 n的 可避免如果集还原 = '和'。 Parameters size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: Input: (N,∗)(N, )(N,∗) where ∗∗ means, any number of additional dimensions Target: (N,∗)(N, *)(N,∗) , same shape as the input Output: scalar. If reductionis 'none', then (N,∗)(N, *)(N,∗) , same shape as the input SoftMarginLoss classtorch.nn.``SoftMarginLoss( size_average=None , reduce=None , reduction='mean' )[source] 创建优化之间的二类别分类的物流损失的标准输入张量 × × × 和目标张量 Y Y Y （含有1或-1）。 loss(x,y)=∑ilog⁡(1+exp⁡(−y[i]∗x[i]))x.nelement()\\text{loss}(x, y) = \\sum_i \\frac{\\log(1 + \\exp(-y[i]*x[i]))}{\\text{x.nelement}()} loss(x,y)=i∑​x.nelement()log(1+exp(−y[i]∗x[i]))​ Parameters size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: 输入： （ ） （） （ ） 其中 手段，任意数量的附加维度的 Target: (∗)(*)(∗) , same shape as the input Output: scalar. If reductionis 'none', then same shape as the input MultiLabelSoftMarginLoss classtorch.nn.``MultiLabelSoftMarginLoss( weight=None , size_average=None , reduce=None , reduction='mean' )[source] 创建优化的多标签一个抗所有基于最大熵损失的标准，之间输入 × × × 和目标 Y Y Y 的大小 （ N ， C ） （N，C） （ N ， C ） 。对于在minibatch每个样品： loss(x,y)=−1C∗∑iy[i]∗log⁡((1+exp⁡(−x[i]))−1)+(1−y[i])∗log⁡(exp⁡(−x[i])(1+exp⁡(−x[i])))loss(x, y) = - \\frac{1}{C} \\sum_i y[i] \\log((1 + \\exp(-x[i]))^{-1}) + (1-y[i]) * \\log\\left(\\frac{\\exp(-x[i])}{(1 + \\exp(-x[i]))}\\right) loss(x,y)=−C1​∗i∑​y[i]∗log((1+exp(−x[i]))−1)+(1−y[i])∗log((1+exp(−x[i]))exp(−x[i])​) 其中 i的 ∈ { 0 ， ⋯ ， x.nElement （ ） - 1 } i的\\ \\左\\ {0 \\ [] \\ cdots，\\ [] \\ {文本} x.nElement（） - 1 \\右\\} i的 ∈ { 0 ， ⋯ ， x.nElement （ ）​​ - 1 } ， Y [ i的 ∈ { 0 ， 1 } 值Y [i] \\在\\左\\ {0，\\ [] 1 \\右\\} Y [ i的 ∈ { 0 ， 1 } 。 Parameters weight ( Tensor , optional ) – a manual rescaling weight given to each class. If given, it has to be a Tensor of size C. Otherwise, it is treated as if having all ones. size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: 输入： （ N ， C ） （N，C） （ N ， C ） 其中 N 是批量大小和 C 是类的数量。 目标： （ N ， C ） （N，C） （ N ， C ） ，标记目标填充由-1确保相同的形状的输入。 Output: scalar. If reductionis 'none', then (N)(N)(N) . CosineEmbeddingLoss classtorch.nn.``CosineEmbeddingLoss( margin=0.0 , size_average=None , reduce=None , reduction='mean' )[source] 创建一种测量标准的损失给定的输入张量 × 1 X_1 × 1 ， × 2 X_2 × 2 [HT G102] 和a 张量标签 Y Y Y 与值1或-1。此被用于测量两个输入是否是相似或不相似，使用余弦距离，并且通常用于学习的嵌入的非线性或半监督学习。 每个样品的损失函数是： loss(x,y)={1−cos⁡(x1,x2),if y=1max⁡(0,cos⁡(x1,x2)−margin),if y=−1\\text{loss}(x, y) = \\begin{cases} 1 - \\cos(x_1, x_2), & \\text{if } y = 1 \\\\ \\max(0, \\cos(x_1, x_2) - \\text{margin}), & \\text{if } y = -1 \\end{cases} loss(x,y)={1−cos(x1​,x2​),max(0,cos(x1​,x2​)−margin),​if y=1if y=−1​ Parameters 余量 （ 浮动 ， 可选 ） - 应该是从 [HTG12的数] - 1 -1- - 1 至 1 1 1 ， 0 0 0 至 0.5 0.5 [H TG102] 0 。 5 建议。如果余量缺失，则默认值为 0 0 0 。 size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' MultiMarginLoss classtorch.nn.``MultiMarginLoss( p=1 , margin=1.0 , weight=None , size_average=None , reduce=None , reduction='mean' )[source] 创建优化输入 × 之间的多类分类铰链损失（基于容限的损失）[HTG9的标准]× × （二维微型批次张量）和输出 Y Y Y （它是目标类索引的1D张量， 0 ≤ Y ≤ x.size （ 1 ） - 1 0 \\当量Y \\当量\\文本{x.size}（1）-1 0 ≤ Y ≤ x.size （ 1 ） - 1 ）： 对于每个小批量样品，在一维输入方面损失 × × × 和标量输出 Y Y Y 是： loss(x,y)=∑imax⁡(0,margin−x[y]+x[i]))px.size(0)\\text{loss}(x, y) = \\frac{\\sum_i \\max(0, \\text{margin} - x[y] + x[i]))^p}{\\text{x.size}(0)} loss(x,y)=x.size(0)∑i​max(0,margin−x[y]+x[i]))p​ 其中 × ∈ { 0 ， ⋯ ， x.size （ 0 ） - 1 } × \\在\\左\\ {0，\\ [] \\ cdots，\\ [] \\ {文本} x.size（0） - 1 \\右\\} × ∈ { 0 ， ⋯ ， x.size （ 0 ） - 1 } 和 i的 ≠ Y I \\ NEQ Y i的  = Y 。 可选地，可以通过使1D 重量张量到构造给出的类不相等的权重。 那么损失函数变为： loss(x,y)=∑imax⁡(0,w[y]∗(margin−x[y]+x[i]))p)x.size(0)\\text{loss}(x, y) = \\frac{\\sum_i \\max(0, w[y] * (\\text{margin} - x[y] + x[i]))^p)}{\\text{x.size}(0)} loss(x,y)=x.size(0)∑i​max(0,w[y]∗(margin−x[y]+x[i]))p)​ Parameters P （ INT ， 可选 ） - 具有的 默认值 1 1 1 。 1 1 1 和 2 2 2 是唯一支持的值。 余量 （ 浮动 ， 可选 ） - 具有的 默认值 1 1 1 。 weight ( Tensor , optional ) – a manual rescaling weight given to each class. If given, it has to be a Tensor of size C. Otherwise, it is treated as if having all ones. size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' TripletMarginLoss classtorch.nn.``TripletMarginLoss( margin=1.0 , p=2.0 , eps=1e-06 , swap=False , size_average=None , reduce=None , reduction='mean' )[source] 创建测量三重损失的标准给定的输入张量 × 1 X1 × 1 ， × 2 X2 × 2 ， × 3 ×3 × 3 并以更大的值的裕度比 0 0 0 。此被用于测量样本之间的相对相似性。三元组是由一， P 和 n的（即锚，正例和[HTG118组成]反例分别地）。所有输入张量的形状应是 （ N ， d ） （N，d） （ N ， d ） 。 距离交换中详细纸张学习与三重态损耗由V. Balntas，E.里巴等人浅卷积特征描述符描述。 The loss function for each sample in the mini-batch is: L(a,p,n)=max⁡{d(ai,pi)−d(ai,ni)+margin,0}L(a, p, n) = \\max \\{d(a_i, p_i) - d(a_i, n_i) + {\\rm margin}, 0\\} L(a,p,n)=max{d(ai​,pi​)−d(ai​,ni​)+margin,0} 哪里 d(xi,yi)=∥xi−yi∥pd(x_i, y_i) = \\left\\lVert {\\bf x}_i - {\\bf y}_i \\right\\rVert_p d(xi​,yi​)=∥xi​−yi​∥p​ Parameters 余量 （ 浮动 ， 可选 ） - 默认值： 1 1 1 。 P （ INT ， 可选 ） - 范数度成对距离。默认值： 2 2 2 。 交换 （ 布尔 ， 可选 ） - 的距离交换被详细描述在本文中描述HTG10]学习浅卷积特征描述符与三重态损耗由V. Balntas，E.里巴等。默认值：假 [HTG15。 size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Shape: 输入： （ N ， d ） （N，d） （ N ， d ） 其中 d d d 是矢量维数。 Output: scalar. If reductionis 'none', then (N)(N)(N) . >>> triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2) >>> anchor = torch.randn(100, 128, requires_grad=True) >>> positive = torch.randn(100, 128, requires_grad=True) >>> negative = torch.randn(100, 128, requires_grad=True) >>> output = triplet_loss(anchor, positive, negative) >>> output.backward() 视力层 PixelShuffle classtorch.nn.``PixelShuffle( upscale_factor )[source] 重新排列的元件在形状 （ ， ℃的张量 × R 2 ， H ， W ） （，C \\倍R ^ 2，H，W） （ ， C × R 2 ， H ， W ） 到的张量定型 （ ， C H × R ， W × R ） （，C，H \\倍R，W \\次数R） （ ， C ， H × R W × R ） 。 这是用于实现高效的子像素卷积用的 1 / R A步幅有用 1 / R 1 / R 。 见文章：实时单幅图像和视频超分辨率采用高效的子像素卷积神经网络由Shi等。人，（2016）的更多细节。 Parameters upscale_factor （ INT ） 因子以增加由空间分辨率 Shape: 输入： （ N ， L ， H i的 n的 ， W i的 n的 ） （N，L，H {IN} ，W {在}） （ N ， L ， H i的 n的 ， W i的 n的 ） 其中 L = C × upscale_factor 2 L = c ^ \\倍\\文本{高档\\ _factor} ^ 2 L = C × upscale_factor [HTG19 6] 2 输出： （ N ， C ， H O U T ， W O U T ） （N，C，H {出}，W {出}） （ N ， C ， H O U T ， W O U T ） 其中 H O U T = H i的 n的 × upscalefactor H {出} = H {在} \\倍\\文本{高档\\ _factor} H [H TG196] O U T = H i的 n的 × ​​ upscale_factor 和 W¯¯ [HTG29 2] O U T = W i的 n的 × upscale_factor W {出} = W_ {在} \\倍\\文本{高档\\ _factor} W O U T = W I n的 × upscale_factor Examples: >>> pixel_shuffle = nn.PixelShuffle(3) >>> input = torch.randn(1, 9, 4, 4) >>> output = pixel_shuffle(input) >>> print(output.size()) torch.Size([1, 1, 12, 12]) 上采样 classtorch.nn.``Upsample( size=None , scale_factor=None , mode='nearest' , align_corners=None )[source] 上采样一个给定的多通道1D（时间），二维（空间）或3D（体积）的数据。 所述输入数据被假定为形式 minibatch X通道×[可选深度]×[可选高度]×宽度的。因此，对于空间的投入，我们预计四维张量和体积的投入，我们预计5D张量。 可用于上采样的算法分别是3D，4D和5D输入张量最近邻和线性，双线性，双三次和三线性。 一个可以得到scale_factor或目标输出大小来计算输出大小。 （你不能给双方，因为它是不明确） Parameters 大小 （ INT 或 元组 [ INT ]或 元组 [ INT ， INT ]或 元组 [ INT ， INT ， INT _ ， 可选的_ ） - 输出空间尺寸 scale_factor （ 浮动 或 元组 [ 浮动 ]或 元组 [ 浮动 ， 浮动 ]或 元组 [ 浮动 ， 浮动 ， 浮动 _ ， 可选的_ ） - 乘法器，用于空间尺寸。有，如果它是一个元组匹配输入的内容。 模式 （ STR ， 可选 ） - 上采样算法：的一个'最近”，'线性'，'双线性'，'双三次'和'三线性'。默认值：'最近' align_corners （ 布尔 ， 可选 ） - 如果真，输入和输出张量的拐角像素被对齐，从而保持在那些像素的值。这仅具有效力时模式是'线性'，'双线性'或'三线性'。默认值：假 Shape: 输入： （ N ， C ， W i的 n的 ） （N，C，W {在}） （ N ， C ， W i的 n的 ） ， （ N ， C ， H i的 n的 ， W i的 n的 ） （N，C，H {IN}，W {IN} ） （ N ， C ， H i的 n的 ， W [HTG20 1] i的 n的 ） 或 （ N ， C ， d i的 n的 ， H i的 n的 ， W ​​ i的 n的 ） （N，C，D {IN}，H {IN}，W {在}） （ N ，[HTG2 95] C ， d i的 n的 ， H i的 n的 ， W i的 n的 [HTG39 3] ） 输出： （ N ， C ， W O U T ） （N，C，W {出}） （ N ， C ， W O U T ） ， （ N ， C ， H O U T ， W O U T ） （N，C，H {出}，W {出}） （ N ， C ， H O U T ， W O U T ） 或 （ N ， C ， d O U T ， ​​ H O U T ， W O U T ）[HTG2 97] （N，C，D {出}，H {出}，W {出}） （ N ， C ， d O U T ， H O U T [H TG392] ， W O U T ） ，其中 Dout=⌊Din×scalefactor⌋D{out} = \\left\\lfloor D_{in} \\times \\text{scale\\_factor} \\right\\rfloor Dout​=⌊Din​×scale_factor⌋ Hout=⌊Hin×scalefactor⌋H{out} = \\left\\lfloor H_{in} \\times \\text{scale\\_factor} \\right\\rfloor Hout​=⌊Hin​×scale_factor⌋ Wout=⌊Win×scalefactor⌋W{out} = \\left\\lfloor W_{in} \\times \\text{scale\\_factor} \\right\\rfloor Wout​=⌊Win​×scale_factor⌋ Warning 与align_corners = 真时，线性地内插模式（线性，双线性 双三次和三线性）不按比例对齐的输出和输入的像素，和因此输出值可以依赖于输入的大小。这是这些模式可支持高达0.3.1版本的默认行为。此后，缺省行为是align_corners = 假。见下面关于这将如何影响输出的具体例子。 Note 如果您想采样/一般大小调整，你应该使用插值（） [HTG3。 Examples: >>> input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2) >>> input tensor([[[[ 1., 2.], [ 3., 4.]]]]) >>> m = nn.Upsample(scale_factor=2, mode='nearest') >>> m(input) tensor([[[[ 1., 1., 2., 2.], [ 1., 1., 2., 2.], [ 3., 3., 4., 4.], [ 3., 3., 4., 4.]]]]) >>> m = nn.Upsample(scale_factor=2, mode='bilinear') # align_corners=False >>> m(input) tensor([[[[ 1.0000, 1.2500, 1.7500, 2.0000], [ 1.5000, 1.7500, 2.2500, 2.5000], [ 2.5000, 2.7500, 3.2500, 3.5000], [ 3.0000, 3.2500, 3.7500, 4.0000]]]]) >>> m = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) >>> m(input) tensor([[[[ 1.0000, 1.3333, 1.6667, 2.0000], [ 1.6667, 2.0000, 2.3333, 2.6667], [ 2.3333, 2.6667, 3.0000, 3.3333], [ 3.0000, 3.3333, 3.6667, 4.0000]]]]) >>> # Try scaling the same data in a larger tensor >>> >>> input_3x3 = torch.zeros(3, 3).view(1, 1, 3, 3) >>> input_3x3[:, :, :2, :2].copy_(input) tensor([[[[ 1., 2.], [ 3., 4.]]]]) >>> input_3x3 tensor([[[[ 1., 2., 0.], [ 3., 4., 0.], [ 0., 0., 0.]]]]) >>> m = nn.Upsample(scale_factor=2, mode='bilinear') # align_corners=False >>> # Notice that values in top left corner are the same with the small input (except at boundary) >>> m(input_3x3) tensor([[[[ 1.0000, 1.2500, 1.7500, 1.5000, 0.5000, 0.0000], [ 1.5000, 1.7500, 2.2500, 1.8750, 0.6250, 0.0000], [ 2.5000, 2.7500, 3.2500, 2.6250, 0.8750, 0.0000], [ 2.2500, 2.4375, 2.8125, 2.2500, 0.7500, 0.0000], [ 0.7500, 0.8125, 0.9375, 0.7500, 0.2500, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]]) >>> m = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) >>> # Notice that values in top left corner are now changed >>> m(input_3x3) tensor([[[[ 1.0000, 1.4000, 1.8000, 1.6000, 0.8000, 0.0000], [ 1.8000, 2.2000, 2.6000, 2.2400, 1.1200, 0.0000], [ 2.6000, 3.0000, 3.4000, 2.8800, 1.4400, 0.0000], [ 2.4000, 2.7200, 3.0400, 2.5600, 1.2800, 0.0000], [ 1.2000, 1.3600, 1.5200, 1.2800, 0.6400, 0.0000], [ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]]) UpsamplingNearest2d classtorch.nn.``UpsamplingNearest2d( size=None , scale_factor=None )[source] 施加2D最近邻上采样到几个输入信道组成的输入信号。 要指定规模，它需要要么大小或scale_factor，因为它的构造函数的参数。 当大小中给出，它是图像的输出尺寸（H，W）。 Parameters 大小 （ INT 或 元组 [ INT ， INT _ ， 可选_ ） - 输出空间大小 scale_factor （ 浮动 或 元组 [ 浮动 ， 浮动 _ ， 可选_ ） - 乘法器，用于空间的大小。 Warning 这个类是有利于插值（）弃用。 Shape: Input: (N,C,Hin,Win)(N, C, H{in}, W{in})(N,C,Hin​,Win​) Output: (N,C,Hout,Wout)(N, C, H{out}, W{out})(N,C,Hout​,Wout​) where Hout=⌊Hin×scalefactor⌋H{out} = \\left\\lfloor H_{in} \\times \\text{scale\\_factor} \\right\\rfloor Hout​=⌊Hin​×scale_factor⌋ Wout=⌊Win×scalefactor⌋W{out} = \\left\\lfloor W_{in} \\times \\text{scale\\_factor} \\right\\rfloor Wout​=⌊Win​×scale_factor⌋ Examples: >>> input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2) >>> input tensor([[[[ 1., 2.], [ 3., 4.]]]]) >>> m = nn.UpsamplingNearest2d(scale_factor=2) >>> m(input) tensor([[[[ 1., 1., 2., 2.], [ 1., 1., 2., 2.], [ 3., 3., 4., 4.], [ 3., 3., 4., 4.]]]]) UpsamplingBilinear2d classtorch.nn.``UpsamplingBilinear2d( size=None , scale_factor=None )[source] 施加2D双线性上采样到几个输入信道组成的输入信号。 To specify the scale, it takes either the sizeor the scale_factoras it’s constructor argument. When sizeis given, it is the output size of the image (h, w). Parameters size ( int or Tuple [ int , int ] , optional ) – output spatial sizes scale_factor ( float or Tuple [ float , float ] , optional ) – multiplier for spatial size. Warning 这个类是有利于插值（）弃用。它等同于nn.functional.interpolate（...， 模式= '双线性'， align_corners =真）。 Shape: Input: (N,C,Hin,Win)(N, C, H{in}, W{in})(N,C,Hin​,Win​) Output: (N,C,Hout,Wout)(N, C, H{out}, W{out})(N,C,Hout​,Wout​) where Hout=⌊Hin×scalefactor⌋H{out} = \\left\\lfloor H_{in} \\times \\text{scale\\_factor} \\right\\rfloor Hout​=⌊Hin​×scale_factor⌋ Wout=⌊Win×scalefactor⌋W{out} = \\left\\lfloor W_{in} \\times \\text{scale\\_factor} \\right\\rfloor Wout​=⌊Win​×scale_factor⌋ Examples: >>> input = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2) >>> input tensor([[[[ 1., 2.], [ 3., 4.]]]]) >>> m = nn.UpsamplingBilinear2d(scale_factor=2) >>> m(input) tensor([[[[ 1.0000, 1.3333, 1.6667, 2.0000], [ 1.6667, 2.0000, 2.3333, 2.6667], [ 2.3333, 2.6667, 3.0000, 3.3333], [ 3.0000, 3.3333, 3.6667, 4.0000]]]]) 数据并行层（多GPU，分布式） 数据并行 classtorch.nn.``DataParallel( module , device_ids=None , output_device=None , dim=0 )[source] 实现了在模块级数据并行。 这个容器通过在批尺寸分块分割在整个指定的设备上的输入并行化给定的模块的应用（其他目的将每一次设备中复制）。在正向通，该模块被复制在每个设备上，和每个复制品处理输入的一部分。在向后传递，从每个副本梯度求和成原来的模块。 将批料尺寸应比使用GPU的数量大。 另请参见： 使用nn.DataParallel而不是多处理 任意位置和关键字输入被允许被传递到数据并行但某些类型是特殊处理的。张量将 散 上暗淡指定（默认为0）。元组，列表和字典类型将是浅复制。其他类型将不同的线程之间共享，并且可以如果模型中的直传写入被破坏。 并行化模块必须对它的参数和缓冲剂device_ids [0]运行前此 数据并行模块。 Warning 在每一个前向，模块是 复制 在每台设备上，因此任何更新在向前运行模块会迷路。例如，如果模块具有在每个递增计数器属性向前，它会一直停留在初始值，因为更新其上后转发破坏了副本完成。然而， 数据并行保证设备上的副本[0]将具有其参数和缓冲器共享存储与基部并行模块。所以 就地 [0] 将被记录设备上更新的参数或缓冲剂。例如，BatchNorm2d 和spectral_norm（） 依靠这种行为来更新缓冲区。 Warning 上向前和向后的钩子定义的模块及其子模块将被调用LEN（device_ids）次，每次用定位于特定的输入设备。特别地，钩只保证以正确的顺序相对于操作上的相应装置来执行。例如，它不能保证通过 被所有 ` len个之前执行register_forward_pre_hook（）设置挂钩（ device_ids）向前（） 电话，但每一个这样的钩之前执行相应的该设备的前向（） `呼叫。 Warning 当模块在向前返回一个标（即，0维张量）（），此包装将返回长度的矢量等于在数据并行使用的设备，包含来自每个设备的结果的数量。 Note 有在使用收拾 序列的微妙 - & GT ; 复发 网络 - & GT ; 解压 序列在 模块图案包裹在 数据并行。参见 我经常性的网络不与数据并行 部分中常见问题的细节工作。 Parameters 模块 （ 模块 ） - 模块可以并行 device_ids （ 蟒的列表：INT 或 torch.device ） - CUDA设备（默认值：所有设备） output_device （ INT 或 torch.device ） - 输出的设备位置（默认值：device_ids [0]） Variables 〜DataParallel.module （ 模块 ） - 该模块可以并行 Example: >>> net = torch.nn.DataParallel(model, device_ids=[0, 1, 2]) >>> output = net(input_var) # input_var can be on any device, including CPU DistributedDataParallel classtorch.nn.parallel.``DistributedDataParallel( module , device_ids=None , output_device=None , dim=0 , broadcast_buffers=True , process_group=None , bucket_cap_mb=25 , find_unused_parameters=False , check_reduction=False )[source] 分布式数据并行实现了基于torch.distributed封装在模块级。 这个容器通过在批尺寸分块分割在整个指定的设备上的输入并行化给定的模块的应用。该模块被复制每台机器和每个设备上，并且每个这样的副本处理输入的一部分。在向后传递，从每个节点的梯度进行平均。 将批料尺寸应比本地使用GPU的数量大。 参见： 基础 和[ 使用nn.DataParallel而不是多处理 HTG7。如 上输入相同的约束torch.nn.DataParallel适用。 这个类的创作要求torch.distributed被已经初始化，通过调用 torch.distributed.init_process_group（） 。 DistributedDataParallel可在以下两种方式使用： 单进程多GPU 在这种情况下，一个单一的过程将每个主机/节点上催生了每个进程将在它的运行节点的所有GPU的操作。要使用DistributedDataParallel [HTG3以这种方式，你可以简单的构建模型，如下： >>> torch.distributed.init_process_group(backend=\"nccl\") >>> model = DistributedDataParallel(model) # device_ids will include all GPU devices by default 多进程单GPU 这是使用高度推荐的方法DistributedDataParallel，其中多个进程，其中的每一个在单个GPU工作。这是目前使用PyTorch做数据并行训练最快的方法和适用于单节点（多GPU）和多节点数据并行训练。它被证明比 torch.nn.DataParallel为单节点多GPU数据并行训练显著更快。 这里是如何使用它：用N GPU的每台主机上，你应该产卵N个流程，同时确保每道工序上的单个GPU单独工作从0到N-1。因此，它是你的工作，以确保您的培训脚本通过调用一个给定的GPU工作： >>> torch.cuda.set_device(i) 其中i是从0到N-1。在每一个过程中，你应该参考以下构造此模块： >>> torch.distributed.init_process_group(backend='nccl', world_size=4, init_method='...') >>> model = DistributedDataParallel(model, device_ids=[i], output_device=i) 为了产卵了每个节点的多个进程，则可以使用torch.distributed.launch或torch.multiprocessing.spawn Note NCCL后端是目前与多进程单GPU分布式训练中使用最快和高度推荐的后端，这既适用于单节点和多节点分布式训练 Note 该模块还支持混合精度分布式训练。这意味着，你的模型可以有不同类型的参数，如混合类型FP16和FP32的，对这些混合类型的参数梯度减少将只是正常工作。还要注意的是NCCL后端是目前FP16 / FP32混合精度训练最快，强烈推荐后端。 Note 如果您使用torch.save在一个进程设置检查点模块，以及torch.load一些其他进程来恢复它，确保map_location正确每个进程配置。无map_location，torch.load将恢复模块，其中所述模块是从保存器件。 Warning 此模块只能与GLOO和NCCL后端。 Warning 构造，向前方法，以及输出（或该模块的输出的函数）的分化是一个分布式同步点。考虑到这一点的情况下，不同的过程可能会执行不同的代码。 Warning 该模块假定所有的参数都在被它创建的时候模型上注册。没有参数应增加，也没有晚删除。同样适用于缓冲区。 Warning 该模块假定在每个分布式过程的模型被注册的所有参数都以相同的顺序。模块本身将以下模型的登记参数的相反顺序进行梯度所有还原。换句话说，它是用户的责任，以确保每个分布式过程具有完全相同的模型，因此完全相同的参数登记顺序。 Warning 该模块假定所有的缓冲区和梯度密集。 Warning 此模块不一起工作 torch.autograd.grad（）（即，它将仅当梯度在[HTG7要累积的工作] .grad的参数属性）。 Warning 如果打算使用该模块带有NCCL后端或GLOO后端（即使用的Infiniband），具有的DataLoader在一起使用多个工人，请改变多处理开始方法forkserver（Python 3中只）或菌种。不幸的是GLOO（使用的Infiniband）和NCCL2不是叉安全，你可能会经历死锁，如果你不更改此设置。 Warning 上模块及其子模块将不再被调用，除非钩在向前初始化（） [HTG7向前和向后的钩子限定] 方法。 Warning 你不应该尝试DistributedDataParallel结束了你的模型后，改变你的模型参数。换句话说，结束了与DistributedDataParallel你的模型时，DistributedDataParallel的构造函数将登记于模型本身的所有参数在施工时的附加梯度降低功能。如果您在DistributedDataParallel施工后改变模型的参数，这是不支持的和意想不到的行为可能发生，因为有些参数的梯度减少功能可能不会被调用。 Note 参数从不进程之间播出。该模块对梯度全减少步骤，并且假设它们将被优化器中以相同的方式的所有过程被修改。缓冲液（例如BatchNorm数据）是从列0的过程中的模块广播，给系统中的在每一个迭代中的所有其它复制品。 Parameters module ( Module) – module to be parallelized device_ids （ 蟒的列表：INT 或 torch.device ） - CUDA设备。当输入模块驻留在单个CUDA设备上这应该只被提供。对于单器件模块时，i``th ：ATTR：module副本 是 放置 在 ``device_ids [I]。对于多设备模块和CPU模块，device_ids必须是无或一个空列表，并且输入数据为直传必须放置在正确的设备上。 （默认值：单器件模块的所有设备） output_device （ INT 或 torch.device ） - 用于输出的装置位置单设备CUDA模块。对于多设备模块和CPU模块，它必须是无，模块本身决定了输出位置。 （默认值：device_ids [0]为单器件模块） broadcast_buffers （ 布尔 ） - 标志，使在前进功能的开始同步的模块的（广播）的缓冲器。 （默认值：真） process_group - 用于分布式数据所有还原处理组。如果无，默认处理组，它是由建立torch.distributed.init_process_group`，将被使用。 （默认值：无 `） bucket_cap_mb - DistributedDataParallel将桶的参数分成多个存储桶，使得每个桶的梯度减小可以潜在地与向后计算重叠。 bucket_cap_mb控制以兆字节为桶大小（MB）（默认值：25） find_unused_pa​​rameters （ 布尔 ） - 遍历包含在返回值的所有张量的autograd曲线图中的包装的模块的向前功能。不接收梯度，因为这图的一部分参数被抢先标记为准备减少。请注意，所有向前从模块参数导出的输出必须参与计算损失和更高的梯度计算。如果他们不这样做，这个包装将挂起等待autograd产生这些参数的梯度。其他未使用的从模块的参数导出的任何输出可从autograd图表使用torch.Tensor.detach脱离。 （默认值：假） check_reduction - 设置为真，它使DistributedDataParallel如果前一次迭代落后的减少是在每次迭代的正向功能年初成功发行自动检查时。你通常不需要启用这个选项，除非你正在观察怪异行为，如不同等级越来越不同梯度，如果DistributedDataParallel正确使用应该不会发生。 （默认值：假） Variables 〜DistributedDataParallel.module （ 模块 ） - 该模块可以并行 Example: >>> torch.distributed.init_process_group(backend='nccl', world_size=4, init_method='...') >>> net = torch.nn.DistributedDataParallel(model, pg) no_sync()[source] 上下文管理器跨DDP过程禁用梯度同步。在这方面，将梯度上模块的变量，这将在后面的第一个前后通离开上下文同步进行累积。 Example: >>> ddp = torch.nn.DistributedDataParallel(model, pg) >>> with ddp.no_sync(): ... for input in inputs: ... ddp(input).backward() # no synchronization, accumulate grads ... ddp(another_input).backward() # synchronize grads 公用事业 clipgrad_norm torch.nn.utils.``clip_grad_norm_( parameters , max_norm , norm_type=2 )[source] 的参数可迭代的视频梯度范数。 范数上计算所有梯度在一起，如同它们连接成一个单一的载体中。梯度就地修改。 Parameters 参数 （ 可迭代 [ 张量 ]或 张量 ） - 张量的一个可迭代或单个张量，将有梯度归一化 max_norm （ 浮动 或 INT ） - 最大梯度的范数 norm_type （ 浮动 或 INT ） - 所使用的p-范数的类型。可以用'INF'为无穷规范。 Returns 的参数的总范数（视为单个矢量）。 clipgrad_value torch.nn.utils.``clip_grad_value_( parameters , clip_value )[source] 在指定的值的参数可迭代的视频梯度。 梯度就地修改。 Parameters parameters ( Iterable [ Tensor ] or Tensor) – an iterable of Tensors or a single Tensor that will have gradients normalized clip_value （ 浮动 或 INT ） - 最大允许梯度的值。的梯度的范围限幅 [ -clip_value ， clip_value \\左[\\ {文本-clip \\ _value}，\\ {文本夹\\ _value} \\右] [ -clip_value ， clip_value parameters_to_vector torch.nn.utils.``parameters_to_vector( parameters )[source] 转换参数，以一个矢量 Parameters 参数 （ 可迭代 [ 张量 __ ） - 张量的迭代器，是模型的参数。 Returns 由单个向量表示的参数 vector_to_parameters torch.nn.utils.``vector_to_parameters( vec , parameters )[source] 将一个向量的参数 Parameters VEC （ 张量 ） - 一个单一的矢量表示的模型的参数。 parameters ( Iterable [ Tensor ] ) – an iterator of Tensors that are the parameters of a model. weight_norm torch.nn.utils.``weight_norm( module , name='weight' , dim=0 )[source] 适用重量归一化到给定模块中的参数。 w=gv∥v∥\\mathbf{w} = g \\dfrac{\\mathbf{v}}{|\\mathbf{v}|} w=g∥v∥v​ 重量归一化是解耦其方向的张量重量的大小的重新参数化。这取代由name指定的参数（例如'重量'）使用两个参数：一个指定的幅度（例如，'weight_g'）和一个指定方向（例如，'weight_v'）。重量归一化是通过每一个向前（）呼叫之前重新计算从所述幅度和方向的重量张量的钩实现。 默认情况下，与暗淡= 0，规范独立地，每个输出通道/平面来计算。为了计算在整个重量张量范数，用暗淡=无。 参见 https://arxiv.org/abs/1602.07868 Parameters 模块 （ 模块 ） - 包含模块 名称 （ STR ， 可选 ） - 权重参数的名称 暗淡 （ INT ， 可选 ） - 维在其上计算标准 Returns 原始模块与重量规范钩 Example: >>> m = weight_norm(nn.Linear(20, 40), name='weight') >>> m Linear(in_features=20, out_features=40, bias=True) >>> m.weight_g.size() torch.Size([40, 1]) >>> m.weight_v.size() torch.Size([40, 20]) remove_weight_norm torch.nn.utils.``remove_weight_norm( module , name='weight' )[source] 删除从一个模块的重量归一化重新参数化。 Parameters module ( Module) – containing module name ( str , optional ) – name of weight parameter 例 >>> m = weight_norm(nn.Linear(20, 40)) >>> remove_weight_norm(m) spectral_norm torch.nn.utils.``spectral_norm( module , name='weight' , n_power_iterations=1 , eps=1e-12 , dim=None )[source] 适用谱归一化到给定模块中的参数。 WSN=Wσ(W),σ(W)=max⁡h:h≠0∥Wh∥2∥h∥2\\mathbf{W}{SN} = \\dfrac{\\mathbf{W}}{\\sigma(\\mathbf{W})}, \\sigma(\\mathbf{W}) = \\max{\\mathbf{h}: \\mathbf{h} \\ne 0} \\dfrac{|\\mathbf{W} \\mathbf{h}|_2}{|\\mathbf{h}|_2} WSN​=σ(W)W​,σ(W)=h:h​=0max​∥h∥2​∥Wh∥2​​ 谱归一化通过重新缩放重量张量与谱范数 σ稳定在剖成对抗性网络（甘斯）鉴别器（影评）的训练 \\西格玛 σ 使用幂迭代方法计算的权重矩阵的。如果重量张量的维数大于2，它被整形以幂迭代法在二维获得谱范数。这是通过计算光谱范数和再缩放重量之前每向前（）调用的钩实现。 见剖成对抗性网络 谱归。 Parameters module ( nn.Module) – containing module name ( str , optional ) – name of weight parameter n_power_iterations （ INT ， 可选 ） - 功率的迭代次数来计算谱范 EPS （ 浮动 ， 可选 ） - 小量在计算准则的数值稳定性 暗淡 （ INT ， 可选 ） - 维对应的输出数，默认是0，除了模块，其ConvTranspose {1,2,3} d的情况下，当它是1 Returns 原始模块与所述谱范数钩 Example: >>> m = spectral_norm(nn.Linear(20, 40)) >>> m Linear(in_features=20, out_features=40, bias=True) >>> m.weight_u.size() torch.Size([40]) remove_spectral_norm torch.nn.utils.``remove_spectral_norm( module , name='weight' )[source] 删除从一个模块的光​​谱归一化重新参数化。 Parameters module ( Module) – containing module name ( str , optional ) – name of weight parameter Example >>> m = spectral_norm(nn.Linear(40, 10)) >>> remove_spectral_norm(m) PackedSequence torch.nn.utils.rnn.``PackedSequence( data , batch_sizes=None , sorted_indices=None , unsorted_indices=None )[source] 保持数据和填充序列的batch_sizes 的列表。 所有RNN模块接受打包序列作为输入。 Note 这个类的实例绝不应手动创建。这意味着它们是用相同的功能被实例化pack_padded_sequence（）。 批量大小表示在批次中的每个序列步骤的数量的元件，而不是不同的序列长度传递到 pack_padded_sequence（）。例如，给定的数据ABC和×中的 PackedSequence将包含与batch_sizes = [数据axbc2,1,1]。 Variables 〜PackedSequence.data （ 张量 ） - 张量含有包装序列 〜PackedSequence.batch_sizes （ 张量 ） - 在每个序列步骤保持约批量大小信息的整数的张量 〜PackedSequence.sorted_indices （ 张量 ， 可选 ） - 整数张量保持如何 PackedSequence是从序列构建。 〜PackedSequence.unsorted_indices （ 张量 ， 可选 ） - 整数张量保持如何以恢复原始与正确的顺序的序列。 Note 数据可以在任意设备和任意的D型。 sorted_indices和unsorted_indices必须torch.int64相同装置上张量数据。 然而，batch_sizes应当总是一个CPU torch.int64张量。 这个不变的保持在整个 PackedSequence类，并且该构建体的所有功能的：类：PackedSequence 在PyTorch（即，它们只通过在张量符合此约束）。 pack_padded_sequence torch.nn.utils.rnn.``pack_padded_sequence( input , lengths , batch_first=False , enforce_sorted=True )[source] 包含可变长度的填充序列的张量。 输入可以是大小T × B × *其中 T 是最长的序列的长度（等于长度[0]），B是批量大小，和*是任何数目的维度（包括0）的。如果batch_first是真，B × T ... × *``输入预计。 对于未排序的序列，用 enforce_sorted =假。如果enforce_sorted是真，所述序列应通过长度以递减的顺序排序的，即输入[ ：0]应该是最长的序列，和输入[：，B-1]最短的一个。 enforce_sorted =真仅用于ONNX出口必要的。 Note 该函数接受具有至少两个维度的任何输入。你可以运用它来包装标签，并使用RNN的输出与他们直接计算的损失。张量可以从 PackedSequence 对象通过访问其。数据属性进行检索。 Parameters 输入 （ 张量 ） - 填充料的可变长度的序列。 长度 （ 张量 ） - 每批元件的序列长度的列表。 batch_first （ 布尔 ， 可选 ） - 如果真，输入预计B × T × *格式。 enforce_sorted （ 布尔 ， 可选 ） - 如果真，输入被预期含有由长度以递减的顺序排序的序列。如果假，这种情况不检查。默认值：真 [HTG21。 Returns 一个 PackedSequence对象 pad_packed_sequence torch.nn.utils.rnn.``pad_packed_sequence( sequence , batch_first=False , padding_value=0.0 , total_length=None )[source] 垫的填充料的可变长度的序列。 这是一个逆运算为 pack_padded_sequence（）。 返回的张量的数据将是大小T × B × *的，其中 T 是最长的序列的长度和 B 是批量大小。如果batch_first是True，则数据将被移位到B × T X *格式。 批处理元素将通过逐渐降低它们的长度进行排序。 Note total_length是有用的实施收拾 序列 - & GT ; 复发 网络 - & GT ; 解压 序列在图案一个 模块 包裹在 数据并行。参见 这个常见问题解答部分 了解详情。 Parameters 序列 （ PackedSequence ） - 批次到垫 batch_first （ 布尔 ， 可选 ） - 如果真，输出将在B × T × *格式。 padding_value （ 浮动 ， 可选 ） - 用于填充元素的值。 total_length （ INT ， 可选 ） - 如果不是无，输出将被填充到具有长度total_length。此方法将抛出 ValueError异常如果total_length小于最大序列长度序列。 Returns 张量的含元组中的填充序列，和包含在所述批次中的每个序列的长度的列表中的张量。 pad_sequence torch.nn.utils.rnn.``pad_sequence( sequences , batch_first=False , padding_value=0 )[source] 垫可变长度张量与padding_value列表 pad_sequence堆叠张量的沿一个新的维度的列表，并把它们垫相等的长度。例如，如果输入是序列的大小为列表L × *并且如果batch_first是False，并且T × B × *否则。 B 是批量大小。它等于在序列的元素数。 T 是最长的序列的长度。 L 是序列的长度。 * 是任意数量的尾随尺寸，包括没有的。 Example >>> from torch.nn.utils.rnn import pad_sequence >>> a = torch.ones(25, 300) >>> b = torch.ones(22, 300) >>> c = torch.ones(15, 300) >>> pad_sequence([a, b, c]).size() torch.Size([25, 3, 300]) Note 此函数返回的大小T × B × *或张量B × T × *其中 T 是最长的序列的长度。此函数假定尾随尺寸和序列的所有的张量的类型相同。 Parameters 序列 （ 列表 [ 张量 __ ） - 可变长度的序列的列表。 batch_first （ 布尔 ， 可选 ） - 输出将处于B × T × *如果为True，或在T X B × *否则 padding_value （ 浮动 ， 可选 ） - 用于填充元件值。默认值：0。 Returns 的大小T × B × *如果张量 batch_first是假。的张量大小B × T × *否则 pack_sequence torch.nn.utils.rnn.``pack_sequence( sequences , enforce_sorted=True )[source] 包长度可变张量的列表 序列应该是大小L × *，其中的张量的列表 L 是一个序列的长度和 * 是任意数量的尾随尺寸，包括零的。 对于未排序的序列，用 enforce_sorted =假。如果enforce_sorted是真，所述序列应在降低长度的顺序进行排序。 enforce_sorted = 真仅用于ONNX出口必要的。 Example >>> from torch.nn.utils.rnn import pack_sequence >>> a = torch.tensor([1,2,3]) >>> b = torch.tensor([4,5]) >>> c = torch.tensor([6]) >>> pack_sequence([a, b, c]) PackedSequence(data=tensor([ 1, 4, 6, 2, 5, 3]), batch_sizes=tensor([ 3, 2, 1])) Parameters 序列 （ 列表 [ 张量 __ ） - 减小长度的序列的列表。 enforce_sorted （ 布尔 ， 可选 ） - 如果真，检查该输入包含由长度以递减的顺序排序的序列。如果假，这种情况不检查。默认值：真 [HTG21。 Returns a PackedSequenceobject 拼合 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"nn.functional.html":{"url":"nn.functional.html","title":"torch.nn.functional","keywords":"","body":"torch.nn.functional 卷积函数 conv1d torch.nn.functional.``conv1d( input , weight , bias=None , stride=1 , padding=0 , dilation=1 , groups=1 ) → Tensor 施加1D卷积在几个输入平面组成的输入信号。 参见 Conv1d的详细信息和输出形状。 注意 在使用CUDA后端与CuDNN当某些情况下，这种操作者可以选择不确定性的算法来提高性能。如果这是不可取的，你可以尝试通过设置torch.backends.cudnn.deterministic = 真[使操作确定性（可能以性能为代价） HTG6]。请参阅 重复性 为背景的音符。 Parameters 输入 - 的输入张量形状 （ minibatch ， in_channels ， i的 W ） （\\文本{minibatch}，\\文本{在\\ _channels}，IW） （ minibatch ， in_channels ， i的 W ） 重量 - 的过滤器形状 （ out_channels ， in_channels 基团 ， K W ） （\\文本{出\\ _channels}，\\压裂{\\文本{在\\ _channels}} {\\文本{基}}，千瓦） （ out_channels ， 基团 in_channels [HTG9 3] ， K W ） 偏压 - 形状 （ out_channels ）[的可选偏置HTG13 ] （\\文本{出\\ _channels}） （ out_channels ） 。默认值：无 步幅 - 在卷积内核的步幅。可以是单一的数或一个元素的元组（SW）。默认值：1 填充 - 对输入的两侧隐填补处理。可以是单一的数或一个元素的元组（padW，）。默认值：0 扩张 - 内核元件之间的间隔。可以是单一的数或一个元素的元组（DW）。默认值：1 基团 - 分裂输入成组， in_channels \\文本{在\\ _channels } in_channels 应该是组数整除。默认值：1 例子： >>> filters = torch.randn(33, 16, 3) >>> inputs = torch.randn(20, 16, 50) >>> F.conv1d(inputs, filters) conv2d torch.nn.functional.``conv2d( input , weight , bias=None , stride=1 , padding=0 , dilation=1 , groups=1 ) → Tensor 施加二维卷积在几个输入平面构成的输入图像。 参见 Conv2d的详细信息和输出形状。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters 输入 - 的输入张量形状 （ minibatch ， in_channels ， i的 H ， i的 W ） （\\文本{minibatch}，\\文本{在\\ _channels}，1H，IW） （ minibatch ， in_channels ， i的 H ， i的 W ） 重量 - 的过滤器形状 （ out_channels ， in_channels 基团 ， K H ， K W ） （\\文本{出\\ _channels}，\\压裂{\\文本{在\\ _channels}} {\\文本{基}}，KH，千瓦） （ out_channels ， 基团 in_channels ， K H ， K W ） 偏压 - 形状 （ out_channels ）[的可选偏置张量HTG13] （\\文本{出\\ _channels}） （ out_channels ） 。默认值：无 步幅 - 在卷积内核的步幅。可以是单一的数或一个元组（SH，SW）。默认值：1 填充 - 对输入的两侧隐填补处理。可以是单一的数或一个元组（PADH，padW）。默认值：0 扩张 - 内核元件之间的间隔。可以是单一的数或一个元组（DH，一页）。默认值：1 基团 - 分裂输入成组， in_channels \\文本{在\\ _channels } in_channels 应该是组数整除。默认值：1 Examples: >>> # With square kernels and equal stride >>> filters = torch.randn(8,4,3,3) >>> inputs = torch.randn(1,4,5,5) >>> F.conv2d(inputs, filters, padding=1) conv3d torch.nn.functional.``conv3d( input , weight , bias=None , stride=1 , padding=0 , dilation=1 , groups=1 ) → Tensor 应用了3D卷积在数输入面构成的输入图像。 参见 Conv3d的详细信息和输出形状。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters 输入 - 的输入张量形状 （ minibatch ， in_channels ， i的 T ， i的 H ， i的 W ） （\\文本{minibatch}，\\文本{在\\ _channels}，这，1H，IW） （ minibatch ， in_channels ， i的 T ， i的 H ， i的 W ） 重量 - 的过滤器形状 （ out_channels ， in_channels 基团 ， K T ， K H ， K W ） （\\文本{出\\ _channels}，\\压裂{\\文本{在\\ _channels}} {\\文本{基}}，KT，KH，千瓦） （ out_channels ， 基团 in_channels ， K T ， K H ， K W ） 偏压 - 形状 （ out_channels ）[的可选偏置张量HTG13] （\\文本{出\\ _channels}） （ out_channels ） 。默认值：无 步幅 - 在卷积内核的步幅。可以是单一的数或一个元组（ST，SH，SW）。默认值：1 填充 - 对输入的两侧隐填补处理。可以是单一的数或一个元组（PADT，PADH，padW）。默认值：0 扩张 - 内核元件之间的间隔。可以是单一的数或一个元组（DT，DH，一页）。默认值：1 groups – split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by the number of groups. Default: 1 Examples: >>> filters = torch.randn(33, 16, 3, 3, 3) >>> inputs = torch.randn(20, 16, 50, 10, 20) >>> F.conv3d(inputs, filters) conv_transpose1d torch.nn.functional.``conv_transpose1d( input , weight , bias=None , stride=1 , padding=0 , output_padding=0 , groups=1 , dilation=1 ) → Tensor 适用过的几个输入飞机组成的输入信号，有时也称为“反卷积”一维的转置卷积运算。 参见 ConvTranspose1d的详细信息和输出形状。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters input – input tensor of shape (minibatch,in_channels,iW)(\\text{minibatch} , \\text{in\\_channels} , iW)(minibatch,in_channels,iW) 重量 - 的过滤器形状 （ in_channels ， out_channels 基团 ， K W ） （\\文本{在\\ _channels}，\\压裂{\\文本{出\\ _channels}} {\\文本{基}}，千瓦） （ in_channels ， 基团 out_channels [HTG9 3] ， K W ） 偏压 - 形状 （ out_channels ）[的可选偏置HTG13 ] （\\文本{出\\ _channels}） （ out_channels ） 。默认值：无 步幅 - 在卷积内核的步幅。可以是单一的数或一个元组（SW）。默认值：1 填充 - 扩张 * （kernel_size - 1） - 填充零填充将被添加到输入中的每个维度的两侧。可以是单一的数或一个元组（padW，）。默认值：0 output_padding - 附加大小添加到在输出形状的每个维度的一侧。可以是单一的数或一个元组（out_padW）。默认值：0 groups – split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by the number of groups. Default: 1 扩张 - 内核元件之间的间隔。可以是单一的数或一个元组（DW）。默认值：1 Examples: >>> inputs = torch.randn(20, 16, 50) >>> weights = torch.randn(16, 33, 5) >>> F.conv_transpose1d(inputs, weights) conv_transpose2d torch.nn.functional.``conv_transpose2d( input , weight , bias=None , stride=1 , padding=0 , output_padding=0 , groups=1 , dilation=1 ) → Tensor 应用在多个输入平面构成的输入图像的2D转卷积运算，有时也被称为“反卷积”。 参见 ConvTranspose2d的详细信息和输出形状。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters input – input tensor of shape (minibatch,in_channels,iH,iW)(\\text{minibatch} , \\text{in\\_channels} , iH , iW)(minibatch,in_channels,iH,iW) 重量 - 的过滤器形状 （ in_channels ， out_channels 基团 ， K H ， K W ） （\\文本{在\\ _channels}，\\压裂{\\文本{出\\ _channels}} {\\文本{基}}，KH，千瓦） （ in_channels ， 基团 out_channels ， K H ， K W ） bias – optional bias of shape (out_channels)(\\text{out\\_channels})(out_channels) . Default: None 步幅 - 在卷积内核的步幅。可以是 单数或一个元组（SH， SW）。默认值：1 填充 - 扩张 * （kernel_size - 1） - 填充零填充将被添加到输入中的每个维度的两侧。可以是单一的数或一个元组（PADH， padW）。默认值：0 output_padding - 附加大小添加到在输出形状的每个维度的一侧。可以是单一的数或一个元组（out_padH， out_padW）。默认值：0 groups – split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by the number of groups. Default: 1 扩张 - 内核元件之间的间隔。可以是单一的数或一个元组（DH， 一页）。默认值：1 Examples: >>> # With square kernels and equal stride >>> inputs = torch.randn(1, 4, 5, 5) >>> weights = torch.randn(4, 8, 3, 3) >>> F.conv_transpose2d(inputs, weights, padding=1) conv_transpose3d torch.nn.functional.``conv_transpose3d( input , weight , bias=None , stride=1 , padding=0 , output_padding=0 , groups=1 , dilation=1 ) → Tensor 应用在多个输入平面构成的输入图像的3D换位卷积运算，有时也被称为“解卷积” 参见 ConvTranspose3d的详细信息和输出形状。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Parameters input – input tensor of shape (minibatch,in_channels,iT,iH,iW)(\\text{minibatch} , \\text{in\\_channels} , iT , iH , iW)(minibatch,in_channels,iT,iH,iW) 重量 - 的过滤器形状 （ in_channels ， out_channels 基团 ， K T ， K H ， K W ） （\\文本{在\\ _channels}，\\压裂{\\文本{出\\ _channels}} {\\文本{基}}，KT，KH，千瓦） （ in_channels ， 基团 out_channels ， K T ， K H ， K W ） bias – optional bias of shape (out_channels)(\\text{out\\_channels})(out_channels) . Default: None 步幅 - 在卷积内核的步幅。可以是（ SH ST， SW） 单数或一个元组。默认值：1 填充 - 扩张 * （kernel_size - 1） - 填充零填充将被添加到输入中的每个维度的两侧。可以是 单数或一个元组（PADT， PADH， padW）。默认值：0 output_padding - 附加大小添加到在输出形状的每个维度的一侧。可以是（ out_padH out_padT， out_padW）单个数字或一个元组``。默认值：0 groups – split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by the number of groups. Default: 1 dilation – the spacing between kernel elements. Can be a single number or a tuple (dT, dH, dW). Default: 1 Examples: >>> inputs = torch.randn(20, 16, 50, 10, 20) >>> weights = torch.randn(16, 33, 3, 3, 3) >>> F.conv_transpose3d(inputs, weights) 展开 torch.nn.functional.``unfold( input , kernel_size , dilation=1 , padding=0 , stride=1 )[source] 从提取的批量输入张量滑动局部块。 警告 目前，只有4-d的输入张量（成批图像样张量）的支持。 Warning 展开的张量的多于一个的元件可指代单个存储器位置。其结果是，就地操作（特别是那些有量化的）可能会导致不正确的行为。如果你需要写张，请先克隆。 参见 torch.nn.Unfold详细内容 倍 torch.nn.functional.``fold( input , output_size , kernel_size , dilation=1 , padding=0 , stride=1 )[source] 结合滑动局部块到大量含有张量的阵列。 Warning 目前，只有4-d输出张量（成批图像样张量）的支持。 参见 torch.nn.Fold详细内容 汇集功能 avg_pool1d torch.nn.functional.``avg_pool1d( input , kernel_size , stride=None , padding=0 , ceil_mode=False , count_include_pad=True ) → Tensor 适用在几个输入平面组成的输入信号的平均1D池。 参见 AvgPool 1D的细节和输出形状。 Parameters input – input tensor of shape (minibatch,in_channels,iW)(\\text{minibatch} , \\text{in\\_channels} , iW)(minibatch,in_channels,iW) kernel_size - 窗口的大小。可以是单一的数或一个元组（千瓦） 步幅 - 窗口的步幅。可以是单一的数或一个元组（SW）。默认值：kernel_size 填充 - 对输入的两侧隐含零个填补处理。可以是单一的数或一个元组（padW，）。默认值：0 ceil_mode - 真时，将使用小区而非地板来计算输出形状。默认值：假 count_include_pad - 真时，将包括在平均计算的零填充。默认值：真 Examples: >>> # pool of square window of size=3, stride=2 >>> input = torch.tensor([[[1, 2, 3, 4, 5, 6, 7]]], dtype=torch.float32) >>> F.avg_pool1d(input, kernel_size=3, stride=2) tensor([[[ 2., 4., 6.]]]) avg_pool2d torch.nn.functional.``avg_pool2d( input , kernel_size , stride=None , padding=0 , ceil_mode=False , count_include_pad=True , divisor_override=None ) → Tensor 适用于 K H × ķ2D平均池操作 W 的kH \\倍千瓦 K H × K W¯¯ 由步长HTG48] S H [HTG57区域] × S W SH \\倍SW S H × S W 步骤。的输出特征的数量等于输入平面的数量。 参见 AvgPool2d的详细信息和输出形状。 Parameters 输入 - 输入张量 （ minibatch ， in_channels ， i的 H ， i的 W ） （\\文本{minibatch}，\\文本{在\\ _channels}，1H，IW） （ minibatch ， in_channels ， i的 H ， i的 W ） kernel_size - 汇集区域的大小。可以是单一的数或一个元组（KH，千瓦） 步幅 - 汇集操作步幅。可以是单一的数或一个元组（SH，SW）。默认值：kernel_size 填充 - 对输入的两侧隐含零个填补处理。可以是单一的数或一个元组（PADH，padW）。默认值：0 ceil_mode - 真时，将使用小区而非地板式中来计算输出形状。默认值：假 count_include_pad – when True, will include the zero-padding in the averaging calculation. Default: True divisor_override - 如果指定的话，它将被用作除数时，池区的尺寸，否则将被使用。默认值：无 avg_pool3d torch.nn.functional.``avg_pool3d( input , kernel_size , stride=None , padding=0 , ceil_mode=False , count_include_pad=True , divisor_override=None ) → Tensor 适用于 K T × ķ3D平均池操作 H × K W KT \\倍的kH \\倍千瓦 K T × K H × K W 通过步骤大小的区域 S T × S H × S W ST \\倍SH \\倍SW S T × S H × S W 步骤。的输出特征的数量等于 ⌊ 输入平面 S T ⌋ \\ lfloor \\压裂{\\文本{输入平面}} {ST} \\ rfloor ⌊ S T 输入平面 ⌋ 。 参见 AvgPool3d的详细信息和输出形状。 Parameters 输入 - 输入张量 （ minibatch ， in_channels ， i的 T × i的 H ， i的 W ） （\\文本{minibatch}，\\文本{在\\ _channels}，这\\倍IH，IW） （ minibatch ， in_channels ， i的 T × i的 H i的 W ） [HTG9 5] kernel_size - 汇集区域的大小。可以是单一的数或一个元组（KT，KH，千瓦） 步幅 - 汇集操作步幅。可以是单一的数或一个元组（ST，SH，SW）。默认值：kernel_size 填充 - 对输入的两侧隐含零个填补处理。可以是单一的数或一个元组（PADT，PADH，padW），默认值：0 ceil_mode - 真时，将使用小区而非地板式中来计算输出形状 count_include_pad - 真时，将包括在平均计算补零 divisor_override – if specified, it will be used as divisor, otherwise size of the pooling region will be used. Default: None max_pool1d torch.nn.functional.``max_pool1d( *args , **kwargs ) 应用于一维的最大汇集了多个输入飞机组成的输入信号。 参见 MaxPool1d了解详情。 max_pool2d torch.nn.functional.``max_pool2d( *args , **kwargs ) 施加最大的2D汇集在几个输入平面组成的输入信号。 参见 MaxPool2d了解详情。 max_pool3d torch.nn.functional.``max_pool3d( *args , **kwargs ) 应用了3D最大汇集了多个输入飞机组成的输入信号。 参见 MaxPool3d了解详情。 max_unpool1d torch.nn.functional.``max_unpool1d( input , indices , kernel_size , stride=None , padding=0 , output_size=None )[source] 计算的MaxPool1d的局部逆。 参见 MaxUnpool1d了解详情。 max_unpool2d torch.nn.functional.``max_unpool2d( input , indices , kernel_size , stride=None , padding=0 , output_size=None )[source] 计算的MaxPool2d的局部逆。 参见 MaxUnpool2d了解详情。 max_unpool3d torch.nn.functional.``max_unpool3d( input , indices , kernel_size , stride=None , padding=0 , output_size=None )[source] 计算的MaxPool3d的局部逆。 参见 MaxUnpool3d了解详情。 lp_pool1d torch.nn.functional.``lp_pool1d( input , norm_type , kernel_size , stride=None , ceil_mode=False )[source] 适用在几个输入平面组成的输入信号的功率1D平均池。如果所有输入至p的的功率之和为零时，梯度被设置为零。 参见 LPPool1d了解详情。 lp_pool2d torch.nn.functional.``lp_pool2d( input , norm_type , kernel_size , stride=None , ceil_mode=False )[source] 适用在几个输入平面组成的输入信号的2D功率平均池。如果所有输入至p的的功率之和为零时，梯度被设置为零。 参见 LPPool2d了解详情。 adaptive_max_pool1d torch.nn.functional.``adaptive_max_pool1d( *args , **kwargs ) 适用在几个输入平面组成的输入信号的1D自适应最大池。 参见 AdaptiveMaxPool1d的详细信息和输出形状。 Parameters output_size - 目标输出大小（单整数） return_indices - 是否返回池指数。默认值：假 adaptive_max_pool2d torch.nn.functional.``adaptive_max_pool2d( *args , **kwargs ) 适用在几个输入平面组成的输入信号的2D自适应最大池。 参见 AdaptiveMaxPool2d的详细信息和输出形状。 Parameters output_size - 目标输出大小（单整数或双整数元组） return_indices – whether to return pooling indices. Default: False adaptive_max_pool3d torch.nn.functional.``adaptive_max_pool3d( *args , **kwargs ) 适用在几个输入平面组成的输入信号的3D自适应最大池。 参见[ [HTG2自适应MaxPool3d](nn.html#torch.nn.AdaptiveMaxPool3d \"torch.nn.AdaptiveMaxPool3d\")的细节和输出形状。 Parameters output_size - 目标输出大小（单整数或三元组整数） return_indices – whether to return pooling indices. Default: False adaptive_avg_pool1d torch.nn.functional.``adaptive_avg_pool1d( input , output_size ) → Tensor 适用在几个输入平面组成的输入信号的1D自适应平均池。 参见[ [HTG2自适应AvgPool 1D](nn.html#torch.nn.AdaptiveAvgPool1d \"torch.nn.AdaptiveAvgPool1d\")的详细信息和输出形状。 Parameters output_size – the target output size (single integer) adaptive_avg_pool2d torch.nn.functional.``adaptive_avg_pool2d( input , output_size )[source] 适用在几个输入平面组成的输入信号的2D自适应平均池。 参见 AdaptiveAvgPool2d的详细信息和输出形状。 Parameters output_size – the target output size (single integer or double-integer tuple) adaptive_avg_pool3d torch.nn.functional.``adaptive_avg_pool3d( input , output_size )[source] 适用在几个输入平面组成的输入信号的3D自适应平均池。 参见 AdaptiveAvgPool3d的详细信息和输出形状。 Parameters output_size – the target output size (single integer or triple-integer tuple) 非线性激活函数 阈 torch.nn.functional.``threshold( input , threshold , value , inplace=False )[source] 阈值输入张量的每个元素。 参见 阈值了解更多详情。 torch.nn.functional.``threshold_( input , threshold , value ) → Tensor 就地版本的 阈值（）。 RELU torch.nn.functional.``relu( input , inplace=False ) → Tensor[source] 施加整流的线性单元函数逐元素。参见 RELU了解更多详情。 torch.nn.functional.``relu_( input ) → Tensor 就地版本的 RELU（）。 hardtanh torch.nn.functional.``hardtanh( input , min_val=-1. , max_val=1. , inplace=False ) → Tensor[source] 应用HardTanh功能件明智的。参见 Hardtanh了解更多详情。 torch.nn.functional.``hardtanh_( input , min_val=-1. , max_val=1. ) → Tensor 就地版本的 hardtanh（）。 relu6 torch.nn.functional.``relu6( input , inplace=False ) → Tensor[source] 适用逐元素函数 ReLU6 （ × ） = 分钟HTG17] ⁡ （ MAX ⁡ （ 0 ， × ） ， 6 ） \\文本{ReLU6}（X）= \\分钟（\\ MAX（0，x）时，6） ReLU6 （ × ） = 分钟HTG73] （ MAX （ 0 ， × ） ， 6 ） [HT G98] 。 参见 ReLU6了解更多详情。 ELU torch.nn.functional.``elu( input , alpha=1.0 , inplace=False )[source] 适用逐元素， ELU （ × ） = MAX ⁡ （ 0 ， × ） + 分钟HTG33] ⁡ （ 0 ， α （ EXP ⁡ （ × ） - 1 ） ） \\文本{ELU}（X）= \\最大（0，x）的+ \\分钟（0，\\阿尔法（\\ EXP（X） - 1）） ELU （ × ） = MAX （ 0 ， × ） + 分钟HTG121] （ 0 α * （ 实验值 （ × ） - 1 ） ） 。 参见 ELU了解更多详情。 torch.nn.functional.``elu_( input , alpha=1. ) → Tensor 就地版本的 ELU（）。 九色鹿 torch.nn.functional.``selu( input , inplace=False ) → Tensor[source] 适用逐元素， 九色鹿 （ × ） = S C 一 L E （ MAX ⁡ （ 0 ， × ） + 分钟HTG47] ⁡ （ 0 ， α （ EXP ⁡ （ × ） - 1 ） ） ） \\文本{九色鹿} （X）=比例（\\ MAX（0，x）的+ \\分钟（0，\\阿尔法（\\ EXP（X） - 1））） 九色鹿 （ × ） = S C 一 L E （ MAX （ 0 ， × ） + 分钟HTG159] （ 0 ， α （ EXP （ × ） [HT G191] - 1 ） ） ） ，其中 α = 1.6732632423543772848170429916717 \\阿尔法= 1.6732632423543772848170429916717 α = 1 。 6 7 3 2 6 3 2 4 2 3 ​​ 5 4 3 7 7 2 8 4 8 1 7 0 4 2 9 9 1 6 7 1 7 和 S C 一 L E = 1.0507009873554804934193349852946 规模= 1.050700987355480493419334985 2946 S C 一 升 E = 1 。 0 5 0 7 0 0 9 8 7 3 5 5 4 8 0 4 9 3 4 1 9 3 3 4 9 8 5 2 9 4 6 。 参见 九色鹿了解更多详情。 celu torch.nn.functional.``celu( input , alpha=1. , inplace=False ) → Tensor[source] 适用逐元素， CELU （ × ） = MAX ⁡ （ 0 ， × ） + 分钟HTG33] ⁡ （ 0 ， α （ EXP ⁡ （ × / α ） - 1 ） ） \\文本{CELU}（X）= \\ MAX（0，x）的+ \\分钟（0，\\阿尔法（\\ EXP（X / \\阿尔法） - 1）） CELU （ × ） = MAX （ 0 ， × ） + 分钟HTG125] （ 0 ， α * （ EXP （ × / α ） - 1 ） ） 。 参见 CELU了解更多详情。 leaky_relu torch.nn.functional.``leaky_relu( input , negative_slope=0.01 , inplace=False ) → Tensor[source] 适用逐元素， LeakyReLU （ × ） = MAX ⁡ （ 0 ， × ） + negative_slope 分钟HTG37] ⁡ （ 0 ， × ） \\文本{LeakyReLU}（X）= \\ MAX（0，X）+ \\文本{负\\ _slope} \\分钟（0，x）的 LeakyReLU （ × ） = MAX （ 0 ， × ） + negative_slope * 分钟HTG119] （ 0 × ） 参见 LeakyReLU了解更多详情。 torch.nn.functional.``leaky_relu_( input , negative_slope=0.01 ) → Tensor 就地版本的 leaky_relu（）。 prelu torch.nn.functional.``prelu( input , weight ) → Tensor[source] 适用逐元素的函数 PReLU （ × ） = MAX ⁡ （ 0 ， × ） + 重量 分钟HTG37] ⁡ （ 0 ， × ） \\文本{PReLU}（X）= \\ MAX（0，x）的+ \\文本{重量} \\分钟（0，x）的 PReLU （ × ） = MAX （ 0 ， × ） + 重量 * 分钟HTG119] （ 0 ， × ） 其中权重是可学习参数。 参见 PReLU了解更多详情。 rrelu torch.nn.functional.``rrelu( input , lower=1./8 , upper=1./3 , training=False , inplace=False ) → Tensor[source] 随机漏RELU。 参见 RReLU了解更多详情。 torch.nn.functional.``rrelu_( input , lower=1./8 , upper=1./3 , training=False ) → Tensor 就地版本的 rrelu（）。 glu的 torch.nn.functional.``glu( input , dim=-1 ) → Tensor[source] 门控线性单元。计算： GLU(a,b)=a⊗σ(b)\\text{GLU}(a, b) = a \\otimes \\sigma(b) GLU(a,b)=a⊗σ(b) 其中，输入被分成两半沿暗淡，以形成一和 B ， σ \\西格玛 σ 为S形函数和 ⊗ \\ otimes ⊗ 为逐元素矩阵之间的产物。 参见带门卷积网络语言模型。 Parameters 输入 （ 张量 ） - 输入张量 暗淡 （ INT ） - 在其上分割输入维数。默认值：-1 格鲁 torch.nn.functional.``gelu( input ) → Tensor[source] 适用逐元素的函数 格鲁 （ × ） = × Φ （ × ） \\文本{格鲁}（X）= X \\披（X） 格鲁 （ × ） = × * Φ （ × ） 其中 Φ （ × ） \\披（X） Φ （ × ） 为高斯分布的累积分布函数。 参见高斯误差线性单位（GELUs）。 logsigmoid torch.nn.functional.``logsigmoid( input ) → Tensor 适用逐元素 LogSigmoid （ × i的 ） = 日志 ⁡ （ 1 1 + EXP ⁡ （ - × i的 ） ） \\文本{LogSigmoid}（X_I）= \\ LOG \\左（\\压裂{1} {1 + \\ EXP（-x_i）} \\右） LogSigmoid （ × i的 [ H TG96] ） = LO G （ 1 + EXP （ - × i的 ） 1 ） 参见 LogSigmoid了解更多详情。 hardshrink torch.nn.functional.``hardshrink( input , lambd=0.5 ) → Tensor[source] 适用的硬收缩函数逐元素 参见 Hardshrink了解更多详情。 tanhshrink torch.nn.functional.``tanhshrink( input ) → Tensor[source] 适用逐元素， Tanhshrink （ × ） = × - 双曲正切 （ × ） \\文本{Tanhshrink}（X）= X - \\文本{双曲正切}（X） Tanhshrink （ × ） = × - 双曲正切 （ × ） 参见 Tanhshrink了解更多详情。 softsign torch.nn.functional.``softsign( input ) → Tensor[source] 适用逐元素，函数 SoftSign （ × ） = × 1 + | × | \\文本{SoftSign}（X）= \\压裂{X} {1 + | X |} SoftSign （ × ） = 1 + | × | × 参见 Softsign了解更多详情。 softplus torch.nn.functional.``softplus( input , beta=1 , threshold=20 ) → Tensor softmin torch.nn.functional.``softmin( input , dim=None , _stacklevel=3 , dtype=None )[source] 应用一个softmin功能。 注意， Softmin （ × ） = 使用SoftMax （ - × ） \\文本{Softmin }（X）= \\文本{使用SoftMax}（ - x）的 Softmin （ × ） = 使用SoftMax （ - × ） 。见数学公式定义添加Softmax。 参见 Softmin了解更多详情。 Parameters 输入 （ 张量 ） - 输入 暗淡 （ INT ） - 沿其softmin将被计算的尺寸（因此沿暗淡每片将总结为1）。 DTYPE （torch.dtype，可选） - 所需的数据返回张量的类型。如果指定，输入张量浇铸到在执行操作之前D型细胞。这是为了防止数据溢出型有用。默认值：无。 SOFTMAX torch.nn.functional.``softmax( input , dim=None , _stacklevel=3 , dtype=None )[source] 应用一个SOFTMAX功能。 使用SoftMax定义为： 使用SoftMax （ × i的 ） = E × p （ × i的 ） Σ [HTG43：J E × p （ × [HTG57：J ） \\文本{使用SoftMax}（X_ {I}）= \\压裂{EXP（X_I）} {\\ sum_j EXP（x_j）} 使用SoftMax （ × i的 ） = Σ [HTG145：J E × p （ × [HTG183：J [HT G199] ） E × p （ × i的 ） ​​ 它适用于沿暗淡所有切片，并且将重新缩放它们使得元件位于在范围 [0,1] 和总和为1。 参见 SOFTMAX了解更多详情。 Parameters input ( Tensor) – input 暗淡 （ INT ） - 沿其SOFTMAX将被计算的尺寸。 dtype (torch.dtype, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to dtypebefore the operation is performed. This is useful for preventing data type overflows. Default: None. Note 此功能不与NLLLoss，其预计使用SoftMax和自身之间要计算日志直接工作。使用log_softmax代替（它的速度更快，具有更好的数值属性）。 softshrink torch.nn.functional.``softshrink( input , lambd=0.5 ) → Tensor 应用软收缩功能的elementwise 参见 Softshrink了解更多详情。 gumbel_softmax torch.nn.functional.``gumbel_softmax( logits , tau=1 , hard=False , eps=1e-10 , dim=-1 )[source] 从冈贝尔-使用SoftMax分布（链接1 链路2 ）和任选的离散化的样品。 Parameters logits - [...，NUM_FEATURES] 非标准化数概率 tau蛋白 - 非负标量温度 硬 - 如果真，返回的样品将被离散化作为一热载体，但将被区分为如果是在autograd软样品 暗淡 （ INT ） - 沿其SOFTMAX将被计算的尺寸。缺省值：-1。 Returns 相同的形状，从冈贝尔-使用SoftMax分布logits 的采样张量。如果硬=真，返回的样品将一热的，否则会概率分布其总和为1所有暗淡。 Note 此功能是在这里遗留原因，可以从nn.Functional在将来被移除。 Note 对于主特技硬是做 y_hard - y_soft.detach（）+ y_soft 它实现了两件事情： - 使输出值完全独热（因为我们添加然后减去y_soft值） - 使梯度等于y_soft梯度（因为我们去除所有其他梯度） Examples:: >>> logits = torch.randn(20, 32) >>> # Sample soft categorical using reparametrization trick: >>> F.gumbel_softmax(logits, tau=1, hard=False) >>> # Sample hard categorical using \"Straight-through\" trick: >>> F.gumbel_softmax(logits, tau=1, hard=True) log_softmax torch.nn.functional.``log_softmax( input , dim=None , _stacklevel=3 , dtype=None )[source] 应用一个SOFTMAX接着是对数。 虽然数学上等同于登录（SOFTMAX（X）），分别在做这两个操作是比较慢，并且数值上是不稳定的。该函数使用一个替代的制剂来计算输出和正确梯度。 参见 LogSoftmax了解更多详情。 Parameters input ( Tensor) – input 暗淡 （ INT ） - 甲沿log_softmax将被计算尺寸。 dtype (torch.dtype, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to dtypebefore the operation is performed. This is useful for preventing data type overflows. Default: None. 的tanh torch.nn.functional.``tanh( input ) → Tensor[source] 适用逐元素， 双曲正切 （ × ） = 的tanh ⁡ （ × ） = 实验值 ⁡ （ × ） - EXP ⁡ （ - × ） EXP ⁡ （ × ） + EXP ⁡ （ - × ） \\文本{双曲正切}（x）的= \\的tanh（x）= \\压裂{\\ EXP（X） - \\ EXP（-x）} {\\ EXP（X）+ \\ EXP（-x）} 双曲正切 （ × ） = 的tanh （ × ） = 实验值 （ × ） + EXP （ - × ） EXP （ × ） - EXP （ - × ） 参见 双曲正切了解更多详情。 乙状结肠 torch.nn.functional.``sigmoid( input ) → Tensor[source] 适用逐元素函数 乙状结肠 （ × ） = 1 1 + 实验值 ⁡ （ - × ） \\文本{乙状结肠}（X）= \\压裂{1} {1个+ \\ EXP（-x）} 乙状结肠 （ × ） = 1 + 实验值 （ - × ） [H T G98] 1 参见 乙状结肠了解更多详情。 归一化函数 batch_norm torch.nn.functional.``batch_norm( input , running_mean , running_var , weight=None , bias=None , training=False , momentum=0.1 , eps=1e-05 )[source] 适用批标准化用于在批量数据的每个信道。 参见 BatchNorm1d， BatchNorm2d， BatchNorm3d了解详情。 instance_norm torch.nn.functional.``instance_norm( input , running_mean=None , running_var=None , weight=None , bias=None , use_input_stats=True , momentum=0.1 , eps=1e-05 )[source] 适用实例标准化为在间歇的每个数据样本中的每一个通道。 参见 InstanceNorm1d， InstanceNorm2d ， InstanceNorm3d了解详情。 layer_norm torch.nn.functional.``layer_norm( input , normalized_shape , weight=None , bias=None , eps=1e-05 )[source] 适用于过去的某些维数层正常化。 参见 LayerNorm了解详情。 local_response_norm torch.nn.functional.``local_response_norm( input , size , alpha=0.0001 , beta=0.75 , k=1.0 )[source] 适用在几个输入平面，其中信道占用所述第二维组成的输入信号响应的本地归一化。适用跨渠道正常化。 参见 LocalResponseNorm了解详情。 正常化 torch.nn.functional.``normalize( input , p=2 , dim=1 , eps=1e-12 , out=None )[source] 执行 L P L_P L p 超过规定尺寸的输入归一化。 对于张量输入大小的 （ n的 0 ， 。 。 。 ， n的 d i的 M ， 。 。 。 ， n的 K ） （N0，...，N {暗淡}，...，nk） （ n的 0 ， [HTG1 02]。 。 。 ， n的 d i的 M ， 。 。 。 ， n的 K ） ，各 n的 d i的 M N {暗淡} n的 d i的 M - 元素向量 [HTG266】V [HTG269】v ​​ [HTG278】v 沿着维度暗淡被变换为 v=vmax⁡(∥v∥p,ϵ).v = \\frac{v}{\\max(\\lVert v \\rVert_p, \\epsilon)}. v=max(∥v∥p​,ϵ)v​. 用默认的参数，它使用欧几里得范数超过矢量沿着维度 1 1 1 [HTG23用于归一化。 Parameters 输入 - 任何形状的输入张量 P （ 浮动 ） - 在常态制剂中的指数值。默认值：2 暗淡 （ INT ） - 的尺寸，以减少。默认值：1 EPS （ 浮动 ） - 小的值，以避免被零除。默认值：1E-12 OUT （ 张量 ， 可选 ） - 输出张量。如果OUT时，此操作将不会被微分的。 线性函数 线性 torch.nn.functional.``linear( input , weight , bias=None )[source] 适用的线性变换，以将输入数据： Y = × A T + b Y = XA ^ T + b Y = × A T + b 。 形状： 输入： （ N ， ， i的 n的 _ F E 一 T U R E S ） （N，，在\\ features） （ N ， * ， i的 n的 [HTG70 F的 E 一 T U R E S ） 其中 * 是指任何数量的附加维度的 > 重量： （ O U T F E 一 T U R E S ， i的 n的 F ë 一 T U R E S ） （下\\ features，在\\ _features） （ O U T F E 一 T U R E S ， i的 n的 _ F E 一 T U R E S ） > 偏压： （ O U T F E 一 T U R E S ） （下\\ _features） （ O U T F E 一 T U R E S ） > 输出： （ N ， ， O U T _ F E 一个 T U R E S ） （N，，出\\ features） （ N ， * ， O U 吨 F E 一 T U R E S ） > > 双线性 torch.nn.functional.``bilinear( input1 , input2 , weight , bias=None )[source] 差函数 差 torch.nn.functional.``dropout( input , p=0.5 , training=True , inplace=False )[source] 在训练期间，随机归零一些输入张量与概率P使用样品从贝努利分布元件。 参见 降了解详情。 Parameters P - 元素的概率将被归零。默认值：0.5 训练 - 如果是真申请退学。默认值：真 就地 - 如果设置为真，会做此操作就地。默认值：假 alpha_dropout torch.nn.functional.``alpha_dropout( input , p=0.5 , training=False , inplace=False )[source] 适用的α-差向输入。 参见 AlphaDropout了解详情。 dropout2d torch.nn.functional.``dropout2d( input , p=0.5 , training=True , inplace=False )[source] 随机零出整个信道（信道是2D特征映射，例如， [HTG6：J [HTG9：J [HTG18：J 的第信道 i的 i的 i的 在成批输入第样品是二维张量 输入 [ i的 ， [HTG62：J \\文本{输入} [I，J] 输入 [ i的 ， [HTG88：J [H输入张量的TG91] ））。每个信道将与使用的样品从一个伯努利分布概率P独立地置零在每一个前向呼叫。 参见 Dropout2d了解详情。 Parameters P - 一个信道的概率将被归零。默认值：0.5 training – apply dropout if is True. Default: True inplace – If set to True, will do this operation in-place. Default: False dropout3d torch.nn.functional.``dropout3d( input , p=0.5 , training=True , inplace=False )[source] 随机零出整个信道（信道是3D特征地图，例如， [HTG6：J [HTG9：J [HTG18：J 的第信道 i的 i的 i的 在成批输入第样品是三维张量 输入 [ i的 ， [HTG62：J \\文本{输入} [I，J] 输入 [ i的 ， [HTG88：J [H输入张量的TG91] ））。每个信道将与使用的样品从一个伯努利分布概率P独立地置零在每一个前向呼叫。 参见 Dropout3d了解详情。 Parameters p – probability of a channel to be zeroed. Default: 0.5 training – apply dropout if is True. Default: True inplace – If set to True, will do this operation in-place. Default: False 稀疏功能 嵌入 torch.nn.functional.``embedding( input , weight , padding_idx=None , max_norm=None , norm_type=2.0 , scale_grad_by_freq=False , sparse=False )[source] 简单的查找表中查找在一个固定字典和大小的嵌入。 该模块经常被用来获取字的嵌入使用索引。输入到模块是指数列表，和嵌入基质，并且输出是对应的字的嵌入。 参见 torch.nn.Embedding了解更多详情。 Parameters 输入 （ LongTensor ） - 张量包含索引到嵌入基质 重量 （ 张量 ） - 与行数等于最大可能的索引+ 1，并等于嵌入尺寸的列数的包埋基质 padding_idx （ INT ， 可选 ） - 如果给定的，垫在与嵌入矢量输出padding_idx（初始化为零）每当遇到的索引。 max_norm （ 浮动 ， 可选 ） - 如果给定的，具有范数大于各嵌入矢量max_norm被重新归一化，以具有规范max_norm。注意：这将修改重量原地。 norm_type （ 浮动 ， 可选 ） - 的p范数的p来计算用于max_norm选项。默认2。 scale_grad_by_freq （ 布尔 ， 可选 ） - 如果给出，这将通过的话频率在微型逆扩展梯度批量。默认的假 [HTG11。 稀疏 （ 布尔 ， 可选 ） - 如果真，梯度WRT 重量将是一个稀疏张量。参见下[ 笔记torch.nn.EmbeddingHTG23对于有关稀疏梯度的更多细节。 Shape: 输入：包含索引来提取任意形状的LongTensor Weight: Embedding matrix of floating point type with shape (V, embedding_dim), 其中V =最大索引+ 1和embedding_dim =嵌入尺寸 输出：（，embedding_dim），其中 是输入形状 Examples: >>> # a batch of 2 samples of 4 indices each >>> input = torch.tensor([[1,2,4,5],[4,3,2,9]]) >>> # an embedding matrix containing 10 tensors of size 3 >>> embedding_matrix = torch.rand(10, 3) >>> F.embedding(input, embedding_matrix) tensor([[[ 0.8490, 0.9625, 0.6753], [ 0.9666, 0.7761, 0.6108], [ 0.6246, 0.9751, 0.3618], [ 0.4161, 0.2419, 0.7383]], [[ 0.6246, 0.9751, 0.3618], [ 0.0237, 0.7794, 0.0528], [ 0.9666, 0.7761, 0.6108], [ 0.3385, 0.8612, 0.1867]]]) >>> # example with padding_idx >>> weights = torch.rand(10, 3) >>> weights[0, :].zero_() >>> embedding_matrix = weights >>> input = torch.tensor([[0,2,0,5]]) >>> F.embedding(input, embedding_matrix, padding_idx=0) tensor([[[ 0.0000, 0.0000, 0.0000], [ 0.5609, 0.5384, 0.8720], [ 0.0000, 0.0000, 0.0000], [ 0.6262, 0.2438, 0.7471]]]) embedding_bag torch.nn.functional.``embedding_bag( input , weight , offsets=None , max_norm=None , norm_type=2 , scale_grad_by_freq=False , mode='mean' , sparse=False , per_sample_weights=None )[source] 计算总和，装置或马克塞斯袋【HTG1]的嵌入的的，没有实例化的嵌入中间。 参见 torch.nn.EmbeddingBag了解更多详情。 Note 当使用CUDA后端，该操作可以诱导向后非确定性的行为是不容易断开。请参阅 重复性 为背景的音符。 Parameters 输入 （ LongTensor ） - 张量含有指数的袋装入嵌入基质 weight ( Tensor) – The embedding matrix with number of rows equal to the maximum possible index + 1, and number of columns equal to the embedding size 偏移 （ LongTensor ， 可选 ） - 仅当输入是1D使用。 偏移确定输入的每个袋（序列）的起始索引位置。 max_norm ( float , optional ) – If given, each embedding vector with norm larger than max_normis renormalized to have norm max_norm. Note: this will modify weightin-place. norm_type （ 浮动 ， 可选 ） - 在P在p范数来计算的max_norm选项。默认2。 scale_grad_by_freq （ 布尔 ， 可选 ） - 如果给定的，这将通过的话频率在微型逆扩展梯度批量。默认的假 [HTG11。注意：不支持此选项时模式= “MAX” [HTG15。`` 模式 （ 串 ， 可选 ） - “总和”，“的意思是”或“最大”。指定要降低袋的方式。默认值：“的意思是” 稀疏 （ 布尔 ， 可选 ） - 如果真，梯度WRT 重量将是一个稀疏张量。参见下[ 笔记torch.nn.Embedding[HTG23对于有关稀疏梯度的更多细节。注意：不支持此选项时模式= “MAX” [HTG27。](nn.html#torch.nn.Embedding \"torch.nn.Embedding\") per_sample_weights （ 张量 ， 可选 ） - 浮动/双权重的张量，或无来表示所有权重应取为1，如果指定，per_sample_weights必须具有完全相同的形状作为输入，被视为具有相同的偏移，如果这些都不是无。 Shape: 输入（LongTensor）和偏移（LongTensor，可选） > * 如果`输入 `是形状的2D （B，N） > 它会被视为B袋（序列）各固定长度的N，这将返回B值在某种程度上取决于模式聚合。 偏移被忽略，并且需要为无在这种情况下。 > * 如果`输入 `是形状的1D （N） > 它会被视为多个袋（序列）的级联。 偏移需要为含有输入每个袋子的起始索引位置的1D张量。因此，对于偏移形状的（B），输入将被视为具有B袋。空袋通过零填充（即，具有长度为0的）将已经返回向量。 > 重量（张量）：形状（num_embeddings，embedding_dim）的模块的可学习权重 > per_sample_weights（张量，可选）。具有相同的形状为输入。 > 输出：聚集嵌入形状的值（B，embedding_dim） > > Examples: >>> # an Embedding module containing 10 tensors of size 3 >>> embedding_matrix = torch.rand(10, 3) >>> # a batch of 2 samples of 4 indices each >>> input = torch.tensor([1,2,4,5,4,3,2,9]) >>> offsets = torch.tensor([0,4]) >>> F.embedding_bag(embedding_matrix, input, offsets) tensor([[ 0.3397, 0.3552, 0.5545], [ 0.5893, 0.4386, 0.5882]]) one_hot torch.nn.functional.``one_hot( tensor , num_classes=-1 ) → LongTensor 注意到LongTensor具有形状的指标值（*）和返回的形状（*， num_classes）的张量具有零到处除非最后一维的索引输入张量，在这种情况下这将是1的相应值相匹配。 参见维基百科一热。 Parameters 张量 （ LongTensor ） - 的任何形状的类值。 num_classes （ INT ） - 类的总数。如果设置为-1，班数将被推断为一个比输入张量最大的一类值。 Returns LongTensor具有与最后一维的由输入指定的指数值1和0其他地方多了一个维度。 例子 >>> F.one_hot(torch.arange(0, 5) % 3) tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0]]) >>> F.one_hot(torch.arange(0, 5) % 3, num_classes=5) tensor([[1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [1, 0, 0, 0, 0], [0, 1, 0, 0, 0]]) >>> F.one_hot(torch.arange(0, 6).view(3,2) % 3) tensor([[[1, 0, 0], [0, 1, 0]], [[0, 0, 1], [1, 0, 0]], [[0, 1, 0], [0, 0, 1]]]) 距离函数 pairwise_distance torch.nn.functional.``pairwise_distance( x1 , x2 , p=2.0 , eps=1e-06 , keepdim=False )[source] 参见 torch.nn.PairwiseDistance详细内容 cosine_similarity torch.nn.functional.``cosine_similarity( x1 , x2 , dim=1 , eps=1e-8 ) → Tensor 返回x1和x2之间的余弦相似，沿着昏暗的计算。 similarity=x1⋅x2max⁡(∥x1∥2⋅∥x2∥2,ϵ)\\text{similarity} = \\dfrac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2 \\cdot \\Vert x_2 \\Vert _2, \\epsilon)} similarity=max(∥x1​∥2​⋅∥x2​∥2​,ϵ)x1​⋅x2​​ Parameters X1 （ 张量 ） - 第一输入端。 X2 （ 张量 ） - 第二输入（的大小匹配X1）。 暗淡 （ INT ， 可选 ） - 矢量的维数。默认值：1 EPS （ 浮动 ， 可选 ） - 小值由零避免分裂。默认值：1E-8 Shape: 输入： （ 1 d ， 2 ） （\\ ast_1，d，\\ ast_2） （ 1 ， d ， 2 [H TG105] ） 其中d是在位置暗淡。 输出： （ 1 2 ） （\\ ast_1，\\ ast_2） （ 1 ， 2 ） 其中，1是在位置暗淡。 例： >>> input1 = torch.randn(100, 128) >>> input2 = torch.randn(100, 128) >>> output = F.cosine_similarity(input1, input2) >>> print(output) pdist torch.nn.functional.``pdist( input , p=2 ) → Tensor 计算在输入每对行向量之间的p-范数的距离。这是相同的上三角部分，不包括对角线，的 torch.norm（输入[:,无] - 输入，暗淡= 2，P = p）的。如果行是连续的，此功能会更快。 如果输入具有形状 N × M n的\\倍M N × M 然后输出将具有形状 1 2 N （ N - 1 ） \\压裂{1} {2} N（N - 1） 2 [HTG10 0] 1 N （ N - 1 ） 。 该函数等于 scipy.spatial.distance.pdist（输入， '明可夫斯基'，p值= P）如果 p ∈ （ 0 ， ∞ ） 在（0，\\ infty） p [ p \\ HTG36]∈ （ 0 ， ∞ ） 。当 P = 0 p = 0时 p = 0 它相当于 scipy.spatial.distance.pdist（输入， '汉明' ）* M 。当 P = ∞ P = \\ infty p = ∞ ，最接近SciPy的函数为 scipy.spatial.distance.pdist（XN，拉姆达X，Y：np.abs（X - Y）的.max（））。 Parameters 输入 - 形状的输入张量 N × M n的\\倍M N × M 。 P - 为对p范数距离p值，以各矢量对之间计算 ∈ [ 0 ， ∞ \\ [0，\\ infty] ∈ [ 0 ， ∞ 。 损失函数 binary_cross_entropy torch.nn.functional.``binary_cross_entropy( input , target , weight=None , size_average=None , reduce=None , reduction='mean' )[source] 该功能可以测量目标与输出之间的二进制交叉熵。 参见 BCELoss了解详情。 Parameters 输入 - 任意形状的张量 目标 - 相同的形状作为输入的张量 重量 （ 张量 ， 可选 ） - 如果提供手动重新缩放重量它重复输入张量形状匹配 size_average （ 布尔 ， 可选 ） - 已过时（见还原）。默认情况下，损失平均超过批中每个元素的损失。注意：每个样本，对于一些损失，有多个元素。如果该字段size_average被设定为假时，损失代替求和每个minibatch。当减少是假忽略。默认值：真 减少 （ 布尔 ， 可选 ） - 已过时（见还原）。默认情况下，损耗进行平均或求和观测为视size_average每个minibatch。当减少是假，返回每批元件的损耗，而不是并忽略size_average。默认值：真 还原 （ 串 ， 可选 ） - 指定还原应用到输出：'无'| '的意思是'| '和'。 '无'：不降低将被应用，'意味'：将输出的总和将通过的数量来划分在输出中，'和'元素：输出将被累加。注意：size_average和减少处于被淘汰，并且在此同时，指定是这两个参数的个数将覆盖还原。默认值：'平均' Examples: >>> input = torch.randn((3, 2), requires_grad=True) >>> target = torch.rand((3, 2), requires_grad=False) >>> loss = F.binary_cross_entropy(F.sigmoid(input), target) >>> loss.backward() binary_cross_entropy_with_logits torch.nn.functional.``binary_cross_entropy_with_logits( input , target , weight=None , size_average=None , reduce=None , reduction='mean' , pos_weight=None )[source] 功能测量目标和输出logits之间的二进制交叉熵。 参见 BCEWithLogitsLoss了解详情。 Parameters input – Tensor of arbitrary shape target – Tensor of the same shape as input weight ( Tensor , optional ) – a manual rescaling weight if provided it’s repeated to match input tensor shape size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' pos_weight （ 张量 ， 可选 ） - 正例的权重。必须与长度等于类的数量的矢量。 Examples: >>> input = torch.randn(3, requires_grad=True) >>> target = torch.empty(3).random_(2) >>> loss = F.binary_cross_entropy_with_logits(input, target) >>> loss.backward() poisson_nll_loss torch.nn.functional.``poisson_nll_loss( input , target , log_input=True , full=False , size_average=None , eps=1e-08 , reduce=None , reduction='mean' )[source] 泊松负对数似然的损失。 参见 PoissonNLLLoss了解详情。 Parameters 输入 - 底层泊松分布的期望。 目标 - 随机样品 T 一 R G E T 〜 泊松 （ i的 n的 p U T ） 目标\\ SIM \\文本{泊松}（输入） T 一 R 克 E T 〜 泊松 （ i的 n的 p U T ） 。 log_input - 如果真损耗被计算为 EXP ⁡ （ 输入 ） - 目标 输入 \\ EXP（\\文本{输入}） - \\文本{目标} \\文本{输入} 实验值 （ 输入 ） - 目标 输入 时，如果假然后损失是 [HTG9 2]输入 - 目标 日志 ⁡ （ 输入 + EPS ） \\文本{输入} - \\文本{目标} \\日志（\\文本{输入} + \\文本{EPS}） 输入 - 目标 LO G （ 输入 + EPS ） 。默认值：真 全 - 是否计算全部损失，我。即添加的斯特林近似术语。默认值：假目标 登录 ⁡ （ 目标 ） - 目标 + 0.5 日志 ⁡ （ 2 π 目标 ） \\文本{目标} \\日志（\\文本{目标} ） - \\文本{目标} + 0.5 \\日志（2 \\ PI \\文本{靶}） 目标 LO 克 （ 目标 ） - 目标 + 0 。 5 LO G （ 2 π 目标 ） 。 size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True EPS （ 浮动 ， 可选 ） - 小值，以避免的 [评价HTG12] 日志 ⁡ （ 0 ） \\日志（0） LO G （ 0 ） 时log_input=FALSE。默认值：1E-8 reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' cosine_embedding_loss torch.nn.functional.``cosine_embedding_loss( input1 , input2 , target , margin=0 , size_average=None , reduce=None , reduction='mean' ) → Tensor[source] 参见 CosineEmbeddingLoss了解详情。 cross_entropy torch.nn.functional.``cross_entropy( input , target , weight=None , size_average=None , ignore_index=-100 , reduce=None , reduction='mean' )[source] 该标准结合 log_softmax 和 nll_loss 在一个单一的功能。 参见 CrossEntropyLoss了解详情。 Parameters 输入 （ 张量 ） - （ N ， C ） （N，C） （ N ， C ） 其中 C =类或 数（ N ， C ， H ， W ） （N，C，H，W） （ N ， C ， H ， W ） 在2D损失的情况下，或 （ N ， C ， d 1 ， d 2 ， 。 。 。 ， d K ） （N，C，D_1， D_2，...，d_K） （ N C ， d 1 ， d 2 ， 。 。 。 ， d K ​​ ） 其中 K ≥ 1 ķ\\ GEQ 1 ķ ≥ 1 在K维损失的情况下。 目标 （ 张量 ） - （ N ） （N） （ N ） 其中每个值是 0 ≤ 目标 [ i的 ≤ C - 1 0 \\当量\\文本{目标} [I] \\当量C-1 0 ≤ 目标 [ i的 ≤ C - 1 或 （ N ， d 1 ， d 2 ， 。 。 。 ， d K ） （N，D_1，D_2， ...，d_K） （ N ， d 1 ， d 2 ， 。 [HTG252 。 ， d K ） 其中 K ≥ 1 ķ\\ GEQ 1 ķ ≥ 1 为K维损失。 重量 （ 张量 ， 可选 ） - 给每个类的手动重新缩放权重。如果给定的，必须是尺寸℃的张量 size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True ignore_index （ INT ， 可选 ） - 指定将被忽略，并且不向目标值输入梯度。当size_average是真，损失平均超过非忽略的目标。默认值：-100 reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Examples: >>> input = torch.randn(3, 5, requires_grad=True) >>> target = torch.randint(5, (3,), dtype=torch.int64) >>> loss = F.cross_entropy(input, target) >>> loss.backward() ctc_loss torch.nn.functional.``ctc_loss( log_probs , targets , input_lengths , target_lengths , blank=0 , reduction='mean' , zero_infinity=False )[source] 该联结颞分类损失。 参见 CTCLoss了解详情。 Note In some circumstances when using the CUDA backend with CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting torch.backends.cudnn.deterministic = True. Please see the notes on Reproducibility for background. Note When using the CUDA backend, this operation may induce nondeterministic behaviour in be backward that is not easily switched off. Please see the notes on Reproducibility for background. Parameters log_probs - （ T ， N ， C ） （T，N，C） （ T ， N C ） 其中 C =字符的字母数，包括空白， T =输入长度和 N =批量大小。的输出的取对数概率（例如，用 获得torch.nn.functional.log_softmax（））。 目标 - （ N ， S ） （N，S） （ N ， S ） 或（总和（target_lengths））。目标不能为空。在第二种形式中，目标被认为是连接在一起。 input_lengths - （ N ） （N） （ N ） 。的输入端（长度每一个都必须 ≤ T \\当量T ≤ T ） target_lengths - （ N ） （N） （ N ） 。目标的长度 空白 （ INT ， 可选 ） - 空白标签。默认 0 0 0 。 还原 （ 串 ， 可选 ） - 指定还原应用到输出：'无'| '的意思是'| '和'。 '无'：不降低将被应用，'意味'：输出损耗将由目标长度，然后被划分平均过的批料采取，'和'：输出将被累加。默认值：'平均' zero_infinity （ 布尔 ， 可选 ） - 是否为零无限损失和相关联的梯度。默认值：假主要是当输入太短，无法对准目标出现无限损失。 Example: >>> log_probs = torch.randn(50, 16, 20).log_softmax(2).detach().requires_grad_() >>> targets = torch.randint(1, 20, (16, 30), dtype=torch.long) >>> input_lengths = torch.full((16,), 50, dtype=torch.long) >>> target_lengths = torch.randint(10,30,(16,), dtype=torch.long) >>> loss = F.ctc_loss(log_probs, targets, input_lengths, target_lengths) >>> loss.backward() hinge_embedding_loss torch.nn.functional.``hinge_embedding_loss( input , target , margin=1.0 , size_average=None , reduce=None , reduction='mean' ) → Tensor[source] 参见 HingeEmbeddingLoss了解详情。 kl_div torch.nn.functional.``kl_div( input , target , size_average=None , reduce=None , reduction='mean' )[source] 的 的Kullback-Leibler距离divergence_ 损失。 参见 KLDivLoss了解详情。 Parameters input – Tensor of arbitrary shape target – Tensor of the same shape as input size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True 还原 （ 串 ， 可选 ） - 指定还原应用到输出：'无'| 'batchmean'| '和'| '意味'。 '无'：不降低将被应用'batchmean'：将输出的总和将由BATCHSIZE [HTG32划分] '和' ：输出将被累加'平均'：输出将通过在输出的默认元素的数目可分为： '意味' Note size_average和减少处于被淘汰，并且在此同时，指定是这两个参数的个数将覆盖还原。 Note ：ATTR：还原= '平均'不回真正的KL散度值，请使用：ATTR：还原= 'batchmean'与KL数学定义对齐。在接下来的主要版本，'的意思是'将变更为是相同的“batchmean”。 l1_loss torch.nn.functional.``l1_loss( input , target , size_average=None , reduce=None , reduction='mean' ) → Tensor[source] 函数，它的平均元素方面的绝对差值。 参见 L1Loss了解详情。 mse_loss torch.nn.functional.``mse_loss( input , target , size_average=None , reduce=None , reduction='mean' ) → Tensor[source] 措施逐元素均方误差。 参见 MSELoss了解详情。 margin_ranking_loss torch.nn.functional.``margin_ranking_loss( input1 , input2 , target , margin=0 , size_average=None , reduce=None , reduction='mean' ) → Tensor[source] 参见 MarginRankingLoss了解详情。 multilabel_margin_loss torch.nn.functional.``multilabel_margin_loss( input , target , size_average=None , reduce=None , reduction='mean' ) → Tensor[source] 参见 MultiLabelMarginLoss了解详情。 multilabel_soft_margin_loss torch.nn.functional.``multilabel_soft_margin_loss( input , target , weight=None , size_average=None ) → Tensor[source] 参见 MultiLabelSoftMarginLoss了解详情。 multi_margin_loss torch.nn.functional.``multi_margin_loss( input , target , p=1 , margin=1.0 , weight=None , size_average=None , reduce=None , reduction='mean' )[source] multi_margin_loss(input, target, p=1, margin=1, weight=None, size_average=None, 减少=无，减少=”平均”） - & GT ;张量 参见 MultiMarginLoss了解详情。 nll_loss torch.nn.functional.``nll_loss( input , target , weight=None , size_average=None , ignore_index=-100 , reduce=None , reduction='mean' )[source] 负对数似然的损失。 参见 NLLLoss了解详情。 Parameters 输入 - （ N ， C ） （N，C） （ N ， C ） 其中 C =班数或 （ N ， C ， H ， W ） （ N，C，H，W） （ N C ， H ， W [H TG102]） 在2D损失的情况下，或 （ N ， C ， d 1 ， d 2 ， 。 。 。 ， d K ） （N，C，D_1， D_2，...，d_K） （ N C ， d 1 ， d 2 ， 。 。 。 ， d K ​​ ） 其中 K ≥ 1 ķ\\ GEQ 1 ķ ≥ 1 在K维损失的情况下。 目标 - （ N ） （N） （ N ） 其中每个值是 0 ≤ 目标 [ i的 ≤ C - 1 0 \\当量\\文本{目标} [I] \\当量C-1 0 ≤ 目标 [ i的 ≤ [HTG9 9] C - 1 或 （ N ， d 1 ， d 2 ， 。 。 。 ， d K ） （N，D_1，D_2， ...，d_K） （ N ， d 1 ， d 2 ， 。 [HTG248 。 ， d K ​​ ） 其中 K ≥ 1 ķ\\ GEQ 1 ķ ≥ 1 为K维损失。 weight ( Tensor , optional ) – a manual rescaling weight given to each class. If given, has to be a Tensor of size C size_average ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there multiple elements per sample. If the field size_averageis set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True ignore_index ( int , optional ) – Specifies a target value that is ignored and does not contribute to the input gradient. When size_averageis True, the loss is averaged over non-ignored targets. Default: -100 reduce ( bool , optional ) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduceis False, returns a loss per batch element instead and ignores size_average. Default: True reduction ( string , optional ) – Specifies the reduction to apply to the output: 'none'| 'mean'| 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_averageand reduceare in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean' Example: >>> # input is of size N x C = 3 x 5 >>> input = torch.randn(3, 5, requires_grad=True) >>> # each element in target has to have 0 >> target = torch.tensor([1, 0, 4]) >>> output = F.nll_loss(F.log_softmax(input), target) >>> output.backward() smooth_l1_loss torch.nn.functional.``smooth_l1_loss( input , target , size_average=None , reduce=None , reduction='mean' )[source] 使用的平方项，如果绝对逐元素误差低于1和L1术语否则功能。 参见 SmoothL1Loss了解详情。 soft_margin_loss torch.nn.functional.``soft_margin_loss( input , target , size_average=None , reduce=None , reduction='mean' ) → Tensor[source] 参见 SoftMarginLoss了解详情。 triplet_margin_loss torch.nn.functional.``triplet_margin_loss( anchor , positive , negative , margin=1.0 , p=2 , eps=1e-06 , swap=False , size_average=None , reduce=None , reduction='mean' )[source] 参见 TripletMarginLoss详细内容 视觉功能 pixel_shuffle torch.nn.functional.``pixel_shuffle() 重新排列的元件在形状 （ ， ℃的张量 × R 2 ， H ， W ） （，C \\倍R ^ 2，H，W） （ ， C × R 2 ， H ， W ） 到的张量定型 （ ， C H × R ， W × R ） （，C，H \\倍R，W \\次数R） （ ， C ， H × R W × R ） 。 参见 PixelShuffle了解详情。 Parameters 输入 （ 张量 ） - 输入张量 upscale_factor （ INT ） - 因子以增加由空间分辨率 Examples: >>> input = torch.randn(1, 9, 4, 4) >>> output = torch.nn.functional.pixel_shuffle(input, 3) >>> print(output.size()) torch.Size([1, 1, 12, 12]) 垫 torch.nn.functional.``pad( input , pad , mode='constant' , value=0 )[source] 垫张量。 Padding size: 填充大小，通过该垫输入的一些尺寸从最后一维起始和向前移动进行说明。 ⌊ LEN（垫） 2 ⌋ \\左\\ lfloor \\压裂{\\文本{LEN（垫）}} {2} \\右\\ rfloor ⌊ 2 LEN（垫） ⌋ 输入的尺寸将被填充。例如，为了垫只有输入张量的最后一维，然后 垫的形式为 （ padding_left ， padding_right ） （\\文本{填充\\ _Left}，\\文本{填充\\ _right}） （ padding_left ， padding_right ） ;到垫输入张量的最后2米的尺寸，然后用 （ padding_left ， padding_right ， （\\ {文本填充\\ _Left}， \\文本{填充\\ _right}， （ padding_left ， padding_right ， padding_top ， padding_bottom ） \\文本{填充\\ _top}，\\文本{填充\\ _bottom}） padding_top ， padding_bottom ） ;到垫的最后3个维度，用 （ padding_left [HTG24 7] ， padding_right ， （\\文本{填充\\ _Left}，\\文本{填充\\ _right}， （ padding_left ​​， padding_right ， padding_top ， padding_bottom \\文本{填充\\ _top}，\\文本{填充\\ _bottom} padding_top ， padding_bottom padding_front ， padding_back ） \\文本{填充\\ _front}，\\文本{填充\\ _back}） padding_front ， padding_back ） 。 Padding mode: 参见 torch.nn.ConstantPad2d， torch.nn.ReflectionPad2d ，和 torch.nn.ReplicationPad2d关于如何每个填充模式中的工作原理的具体例子。恒定填充为了任意尺寸来实现。复制填充被用于填充5D输入张量的最后3个维度，或最后2个维度4D输入张量的，或3D输入张量的最后一维实现。反映填充仅用于填充的最后2个维度4D输入张量，或3D输入张量的最后一维的实现。 Note When using the CUDA backend, this operation may induce nondeterministic behaviour in be backward that is not easily switched off. Please see the notes on Reproducibility for background. Parameters 输入 （ 张量 ） - N维张量 垫 （ 元组 ） - 间 - 元素的元组，其中 M 2 ≤ \\压裂{米} {2} \\当量 2 M ≤ 输入的尺寸和 M M [HTG10 1] M 是偶数。 模式 - '恒定'，'反映'，'复制'或'循环'。默认值：'恒定' 值 - 填补'恒定'填充值。默认值：0 Examples: >>> t4d = torch.empty(3, 3, 4, 2) >>> p1d = (1, 1) # pad last dim by 1 on each side >>> out = F.pad(t4d, p1d, \"constant\", 0) # effectively zero padding >>> print(out.data.size()) torch.Size([3, 3, 4, 4]) >>> p2d = (1, 1, 2, 2) # pad last dim by (1, 1) and 2nd to last by (2, 2) >>> out = F.pad(t4d, p2d, \"constant\", 0) >>> print(out.data.size()) torch.Size([3, 3, 8, 4]) >>> t4d = torch.empty(3, 3, 4, 2) >>> p3d = (0, 1, 2, 1, 3, 3) # pad by (0, 1), (2, 1), and (3, 3) >>> out = F.pad(t4d, p3d, \"constant\", 0) >>> print(out.data.size()) torch.Size([3, 9, 7, 3]) 内插 torch.nn.functional.``interpolate( input , size=None , scale_factor=None , mode='nearest' , align_corners=None )[source] 向下/向上采样输入要么给定大小或给定的scale_factor 用于内插的算法由模式确定。 目前的时间，空间和体积采样都被支持，即预期输入是3-d，4-d或在形状5- d。 输入尺寸解释的形式：迷你批次X通道×[可选深度]×[可选高度]×宽度。 可用于调整大小的模式是：最近，线性（3D-只），双线性，双三次（4D-只），三线性（5D-只），面积 Parameters input ( Tensor) – the input tensor 大小 （ INT 或 元组 [ INT ]或 元组 [ INT ， INT ]或 元组 [ INT ， INT ， INT __ ） - 输出空间大小。 scale_factor （ 浮动 或 元组 [ 浮动 __ ） - 乘法器，用于空间尺寸。有，如果它是一个元组匹配输入的内容。 模式 （ STR ） - 用于上采样算法：'最近'| '线性'| '双线性'| '双三次'| '三线性'| '区域'。默认值：'最近' align_corners （ 布尔 ， 可选 ） - 几何上，我们考虑的输入和输出作为平方的像素而不是点。如果设置为真，输入和输出张量由它们的拐角像素的中心点对齐，在拐角处的像素保持的值。如果设置为假，输入和输出张量由它们的拐角像素的角点对准，并且内插使用边缘值填充为外的边界值，使这操作 独立 输入尺寸的时scale_factor保持相同。这仅具有效果时模式是'线性'，'双线性'，'双三次'或'三线性'。默认值：假 Note 与模式=“双三次”，有可能引起过冲，换句话说，它可以产生负的值或值大于255的图像。显式调用result.clamp（分钟= 0， [HTG7最大= 255）如果要显示图像时减小过冲。 Warning 与align_corners = 真时，线性地内插模式（线性，双线性和三线性）不按比例对齐的输出和输入的像素，和因此输出值可以依赖于输入的大小。这是这些模式可支持高达0.3.1版本的默认行为。此后，缺省行为是align_corners = 假。参见 上采样关于这如何影响输出的具体例子。 Note When using the CUDA backend, this operation may induce nondeterministic behaviour in be backward that is not easily switched off. Please see the notes on Reproducibility for background. 上采样 torch.nn.functional.``upsample( input , size=None , scale_factor=None , mode='nearest' , align_corners=None )[source] 上采样输入要么给定大小或给定的scale_factor Warning 此功能有利于弃用torch.nn.functional.interpolate（）。这相当于与nn.functional.interpolate（......）。 Note When using the CUDA backend, this operation may induce nondeterministic behaviour in be backward that is not easily switched off. Please see the notes on Reproducibility for background. 用于上采样的算法由模式确定。 目前的时间，空间和体积上采样都被支持，即预期输入是3-d，4-d或在形状5- d。 The input dimensions are interpreted in the form: mini-batch x channels x [optional depth] x [optional height] x width. 可用于上采样的模式是：最近，线性（3D-只），双线性，双三次（4D-只），三线性（5D-只） Parameters input ( Tensor) – the input tensor size ( int or Tuple [ int ] or Tuple [ int , int ] or Tuple [ int , int , int ] ) – output spatial size. scale_factor （ 浮动 或 元组 [ 浮动 __ ） - 乘法器，用于空间尺寸。必须是一个整数。 模式 （ 串 ） - 算法用于上采样：'最近'| '线性'| '双线性'| '双三次'| '三线性'。默认值：'最近' align_corners ( bool , optional ) – Geometrically, we consider the pixels of the input and output as squares rather than points. If set to True, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels. If set to False, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when scale_factoris kept the same. This only has an effect when modeis 'linear', 'bilinear', 'bicubic'or 'trilinear'. Default: False Note With mode='bicubic', it’s possible to cause overshoot, in other words it can produce negative values or values greater than 255 for images. Explicitly call result.clamp(min=0, max=255)if you want to reduce the overshoot when displaying the image. Warning With align_corners = True, the linearly interpolating modes (linear, bilinear, and trilinear) don’t proportionally align the output and input pixels, and thus the output values can depend on the input size. This was the default behavior for these modes up to version 0.3.1. Since then, the default behavior is align_corners = False. See Upsample for concrete examples on how this affects the outputs. upsample_nearest torch.nn.functional.``upsample_nearest( input , size=None , scale_factor=None )[source] 上采样的输入，使用最近邻居的像素值。 Warning 此功能有利于弃用torch.nn.functional.interpolate（）。这相当于与nn.functional.interpolate（...， 模式= '最近'）。 目前空间和体积上采样的支持（即预期输入是4或5维）。 Parameters input ( Tensor) – input 大小 （ INT 或 元组 [ INT ， INT ]或 元组 [ INT ， INT ， INT __ ） - 输出spatia大小。 scale_factor （ INT ） - 用于空间大小乘数。必须是一个整数。 Note When using the CUDA backend, this operation may induce nondeterministic behaviour in be backward that is not easily switched off. Please see the notes on Reproducibility for background. upsample_bilinear torch.nn.functional.``upsample_bilinear( input , size=None , scale_factor=None )[source] 上采样输入，使用双线性采样。 Warning 此功能有利于弃用torch.nn.functional.interpolate（）。这相当于与nn.functional.interpolate（...， 模式= '双线性'， align_corners =真）。 预期输入是空间（4维）。使用 upsample_trilinear FO体积（5维）输入。 Parameters input ( Tensor) – input 大小 （ INT 或 元组 [ INT ， INT __ ） - 输出空间大小。 scale_factor （ INT 或 元组 [ INT ， INT __ ） - 乘法器，用于空间尺寸 Note When using the CUDA backend, this operation may induce nondeterministic behaviour in be backward that is not easily switched off. Please see the notes on Reproducibility for background. grid_sample torch.nn.functional.``grid_sample( input , grid , mode='bilinear' , padding_mode='zeros' )[source] 给定一个输入和流场格时，输出使用计算从格输入 值和像素位置。 目前，只有空间（4- d）和体积（5-d）输入的支持。 在空间（4- d）情况下，对于输入具有形状 （ N ， C ， H 在 ， W 在 ） （N，C，H \\文本{IN} ，W \\文本{在}） （ N C ， H 在 ， W [HT G100] 在 ） 和格具有形状 （ N ， H OUT ， W OUT ， 2 ） （N，H \\文本{出}，W \\文本{出}，2） （ N ， H [H TG192] OUT ， W OUT ， 2 ） ，输出将具有形状 （ N ​​， C ， H OUT ， W OUT ） （N，C，H \\文本{出}，W \\文本{出}） （ N ， C ， H OUT ， W OUT [HTG38 0]） 。 对于每个输出位置输出[N， ： H， W]，尺寸-2载体格[N， H， W]指定输入的像素位置×和Y，其被用于内插的输出值输出[N， ： H， W]。在图5D的输入的情况下，格[N， d H， W]指定×，Y，Z用于内插的像素位置输出[N， ： d H， W]。 模式参数指定最近或双线性的内插方法来采样输入像素。 格指定由输入空间尺寸归一化的采样像素位置。因此，应该具有在的范围内最值[-1， 1]。例如，值× = -1， Y = -1-被输入的的左上端的像素和值× = 1， Y = 1是输入右下角的像素。 如果格具有的范围之外的值[-1， 1]，相应的输出处理如由padding_mode中定义。选项 padding_mode = “0”：使用0 [HTG7用于结合外的网格位置， > padding_mode = “边界”：使用边界值外的结合网格位置， > padding_mode =“反射”：在由边界为外的结合网格位置反射的地点使用的值。用于位置远离边界，它会保持被反射直到成为结合的，例如，（归一化）的像素位置× = -3.5由边界-1-反射并变成×” = 1.5，然后通过边界1反射并变成× '' = -0.5。 > > Note 该功能通常在建设空间变压器网络部使用。 Note When using the CUDA backend, this operation may induce nondeterministic behaviour in be backward that is not easily switched off. Please see the notes on Reproducibility for background. Parameters 输入 （ 张量 ） - 形状 的输入（ N ， C ， H 在 ， W 在 ） （N，C，H \\文本{IN} ，W \\文本{在}） （ N C ， H 在 ， W 在 ） （4- d情况下）或 （ N ， C d 在 ， H 在 ， W 在 ） （N，C，D \\文本{在}，H \\文本{IN}，W_ \\文本{在}） （ N ， C d 在 ， H 在 ， W ​​ 在 ） （5- d情况下） 格 （ 张量 ） - 的形状 流场（ N ， H OUT ， W OUT ， 2 ） （N，H \\文本{出} ，W \\文本{出}，2） （ N ， H OUT ， W OUT ， 2 ） （4- d情况下）或 （ N ， d OUT ， H OUT ， W OUT ， 3 ） （N，D \\文本{出}，H \\文本{出}，W_ \\文本{出}，3） （ N ， [HTG1 91] d OUT ， H OUT ， W ​​ OUT ， 3 ） （5- d情况下） 模式 （ STR ） - 内插模式来计算输出值'双线性'| '最近'。默认值：'双线性' padding_mode （ STR ） - 填充模式用于外部电网的值'零'| '边界'| '反射'。默认值：'零' Returns 输出张量 Return type 输出（张量） affine_grid torch.nn.functional.``affine_grid( theta , size )[source] 产生二维流场，在给定批次的仿射矩阵THETA的。与 结合通常使用grid_sample（）实施空间变换器网络。 Parameters THETA （ 张量 ） - 仿射矩阵的输入批次（ N × 2 × 3 n的\\倍2 \\倍3 N × 2 × 3 ） 大小 （ torch.Size ） - 目标输出图像尺寸（ N × C × H × W n的\\ C时代\\倍ħ\\倍W N × C × H × W¯¯ ）。例如：torch.Size（（32，3，24，24）） Returns 大小的输出张量（ N × H × W × 2 n的\\倍ħ\\倍数W \\倍2 N × H × W × 2 ） Return type output (Tensor) 数据并行功能（多GPU，分布式） data_parallel torch.nn.parallel.``data_parallel( module , inputs , device_ids=None , output_device=None , dim=0 , module_kwargs=None )[source] 评估跨在给定device_ids所述GPU并行模块（输入）。 这是该数据并行模块的功能版本。 Parameters 模块 （ 模块 ） - 模块并行评估 输入 （ 张量 ） - 输入到模块 device_ids （ 蟒的列表：INT 或 torch.device ） - 在其上GPU IDS复制模块 output_device （ 蟒的列表：INT 或 torch.device ） - 输出使用GPU位置 - 1，以指示CPU。 （默认值：device_ids [0]） Returns 含模块（输入）的结果的张量位于output_device Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"nn.init.html":{"url":"nn.init.html","title":"torch.nn.init","keywords":"","body":"torch.nn.init torch.nn.init.``calculate_gain( nonlinearity , param=None )[source] 返回推荐增益值对于给定的非线性函数。该值如下： 非线性 | 获得 ---|--- 线性/身份 | 1 1 1 CONV {1,2,3} d | 111 乙状结肠 | 111 正切 | 5 3 \\压裂{5} { 3} 3 5 RELU | 2 \\ SQRT {2} 2 漏RELU | 2 1 + negative_slope 2 \\ SQRT {\\压裂{2} {1个+ \\文本{负\\ _slope } ^ 2}} 1 + negative_slope 2 2 [HTG10 2] Parameters 非线性 - 非线性函数（ nn.functional 名称） PARAM - 为对非线性函数可选参数 例子 >>> gain = nn.init.calculate_gain('leaky_relu', 0.2) # leaky_relu with negative_slope=0.2 torch.nn.init.``uniform_( tensor , a=0.0 , b=1.0 )[source] 填充输入张量与值从均匀分布 绘制U （ 一 ， b ） \\ mathcal {U】（A，b） U （ 一 ， b ） 。 Parameters 张量 - n维 torch.Tensor 一 - 下界的均匀分布的 B - 上界的均匀分布的 Examples >>> w = torch.empty(3, 5) >>> nn.init.uniform_(w) torch.nn.init.``normal_( tensor , mean=0.0 , std=1.0 )[source] 填充与值的输入张量从正常的分布中抽取〔HTG0] N （ 意味着 ， STD 2 ） \\ mathcal {N}（\\文本{意味着}，\\文本{STD} ^ 2） N （ 意味着 ， STD 2 ） 。 Parameters tensor – an n-dimensional torch.Tensor 意味着 - 正常分布的平均值 STD - 正态分布的标准偏差 Examples >>> w = torch.empty(3, 5) >>> nn.init.normal_(w) torch.nn.init.``constant_( tensor , val )[source] 填充输入张量与值 VAL \\文本{VAL} VAL 。 Parameters tensor – an n-dimensional torch.Tensor VAL - 的值来填充与张力 Examples >>> w = torch.empty(3, 5) >>> nn.init.constant_(w, 0.3) torch.nn.init.``ones_( tensor )[source] 填充与标量值 1 输入张量。 Parameters tensor – an n-dimensional torch.Tensor Examples >>> w = torch.empty(3, 5) >>> nn.init.ones_(w) torch.nn.init.``zeros_( tensor )[source] 填充与标量值 0 输入张量。 Parameters tensor – an n-dimensional torch.Tensor Examples >>> w = torch.empty(3, 5) >>> nn.init.zeros_(w) torch.nn.init.``eye_( tensor )[source] 填充与单位矩阵的2维输入张量。保留的输入在线性层，其中一样多的输入被保留尽可能的身份。 Parameters 张量 - 2维 torch.Tensor Examples >>> w = torch.empty(3, 5) >>> nn.init.eye_(w) torch.nn.init.``dirac_( tensor )[source] 填充{3，4，5}维输入张量与狄拉克δ函数。保留的输入在卷积层，其中尽可能多的输入通道被保留尽可能的身份。 Parameters 张量 - 一个{3,4，5}维 torch.Tensor Examples >>> w = torch.empty(3, 16, 5, 5) >>> nn.init.dirac_(w) torch.nn.init.``xavier_uniform_( tensor , gain=1.0 )[source] 填充输入张量与根据在理解训练深前馈神经网络的难度所描述的方法的值 - Glorot，X. &安培; Bengio，Y 。（2010），使用的均匀分布。将得到的张量将已经从采样值 U （ - 一个 ， 一 ） \\ mathcal【U}（ - A，A） U （ - 一 ， 一 ） 其中 a=gain×6fan_in+fan_outa = \\text{gain} \\times \\sqrt{\\frac{6}{\\text{fan\\_in} + \\text{fan\\_out}}} a=gain×fan_in+fan_out6​​ 又称Glorot初始化。 Parameters tensor – an n-dimensional torch.Tensor 获得 - 任选的比例因子 Examples >>> w = torch.empty(3, 5) >>> nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain('relu')) torch.nn.init.``xavier_normal_( tensor , gain=1.0 )[source] 填充输入张量与根据在理解训练深前馈神经网络的难度所描述的方法的值 - Glorot，X. &安培; Bengio，Y 。（2010），使用正态分布。将得到的张量将已经从采样值 N （ 0 STD 2 ） \\ mathcal {N}（0，\\文本{性病} ^ 2） N （ 0 ， STD 2 ） 其中 std=gain×2fan_in+fan_out\\text{std} = \\text{gain} \\times \\sqrt{\\frac{2}{\\text{fan\\_in} + \\text{fan\\_out}}} std=gain×fan_in+fan_out2​​ Also known as Glorot initialization. Parameters tensor – an n-dimensional torch.Tensor gain – an optional scaling factor Examples >>> w = torch.empty(3, 5) >>> nn.init.xavier_normal_(w) torch.nn.init.``kaiming_uniform_( tensor , a=0 , mode='fan_in' , nonlinearity='leaky_relu' )[source] 填充输入张量与根据在深钻研整流器所描述的方法的值：对ImageNet分类超越人类水平的性能 - 赫，K。等人。 （2015），使用的均匀分布。将得到的张量将已经从采样值 U （ - 结合 ， 结合 ） \\ mathcal【U}（ - \\文本{结合}，\\文本{结合}） U （ - 结合 ， 结合 ） 其中 bound=6(1+a2)×fan_in\\text{bound} = \\sqrt{\\frac{6}{(1 + a^2) \\times \\text{fan\\_in}}} bound=(1+a2)×fan_in6​​ 也被称为他的初始化。 Parameters tensor – an n-dimensional torch.Tensor 一 - （默认为0 RELU）该层之后使用的整流器的负斜率 模式 - 为'fan_in'（默认）或'fan_out'。选择“fan_in”保留在直传的权重的方差的大小。选择'fan_out'保留在向后传量值。 非线性 - 非线性函数（ nn.functional 名称），建议只使用与'RELU'或'leaky_relu'（默认）。 Examples >>> w = torch.empty(3, 5) >>> nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu') torch.nn.init.``kaiming_normal_( tensor , a=0 , mode='fan_in' , nonlinearity='leaky_relu' )[source] 填充输入张量与根据在深钻研整流器所描述的方法的值：对ImageNet分类超越人类水平的性能 - 赫，K。等人。 （2015），使用正态分布。将得到的张量将已经从采样值 N （ 0 STD 2 ） \\ mathcal {N}（0，\\文本{性病} ^ 2） N （ 0 ， STD 2 ） 其中 std=2(1+a2)×fan_in\\text{std} = \\sqrt{\\frac{2}{(1 + a^2) \\times \\text{fan\\_in}}} std=(1+a2)×fan_in2​​ Also known as He initialization. Parameters tensor – an n-dimensional torch.Tensor a – the negative slope of the rectifier used after this layer (0 for ReLU by default) mode – either 'fan_in'(default) or 'fan_out'. Choosing 'fan_in'preserves the magnitude of the variance of the weights in the forward pass. Choosing 'fan_out'preserves the magnitudes in the backwards pass. nonlinearity – the non-linear function (nn.functional name), recommended to use only with 'relu'or 'leaky_relu'(default). Examples >>> w = torch.empty(3, 5) >>> nn.init.kaiming_normal_(w, mode='fan_out', nonlinearity='relu') torch.nn.init.``orthogonal_( tensor , gain=1 )[source] 填充输入张量具有（半）正交矩阵，如在的精确解说明在深的线性神经网络学习的非线性动力学 - 萨克斯，A。等。 （2013年）。输入张量必须至少有2个维度，以及用于具有多于2个维度张量后尺寸变平。 Parameters 张量 - n维 torch.Tensor ，其中 n的 ≥ 2 n的\\ GEQ 2 n的 ≥ 2 获得 - 任选的比例因子 Examples >>> w = torch.empty(3, 5) >>> nn.init.orthogonal_(w) torch.nn.init.``sparse_( tensor , sparsity , std=0.01 )[source] 填充2D输入张量作为稀疏矩阵，其中的非零元素将从正态分布 被吸入N （ 0 ， 0.01 ） \\ mathcal {N} （0，0.01） N （ 0 ， 0 。 0 1 ） ，经由自由Hessian矩阵的优化在深学习描述 - 马丁，J。（2010）。 Parameters tensor – an n-dimensional torch.Tensor 稀疏 - 元素中的每一列的级分被设置为零 STD - 所使用的正态分布的标准偏差，以产生非零值 Examples >>> w = torch.empty(3, 5) >>> nn.init.sparse_(w, sparsity=0.1) Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"optim.html":{"url":"optim.html","title":"torch.optim","keywords":"","body":"torch.optim torch.optim是实施各种优化算法的软件包。最常用的方法已经被支持，并且接口足够一般情况下，让更尖端的也可以很容易地集成到未来。 如何使用一个优化 要使用 torch.optim你必须构造一个优化的对象，这将保持当前状态，并且会更新基于计算梯度的参数。 其构建 为了构建一个 优化你必须给它包含的参数可迭代（都应该可变S ）优化。然后，您可以指定特定的优化选项，如学习率，权衰减等。 注意 如果你需要移动的模型通过到GPU .cuda（），请构建优化的前这样做。之后的模型的参数.cuda（）将与那些呼叫之前不同的对象。 在一般情况下，你应该确保优化的参数生活在一致的位置时，优化器的建造和使用。 例： optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) optimizer = optim.Adam([var1, var2], lr=0.0001) 每参数选项 优化S还支持指定每个参数的选项。要做到这一点，而不是传递可变S的迭代，通过在 可迭代DICT S 。它们中的每将定义一个单独的参数组，并应包含一个PARAMS键，包含属于它的参数列表。其他键应该匹配优化器接受关键字参数，并且将作为该组优化选项。 Note 您还可以通过选项作为关键字参数。他们将作为默认设置，在不重写它们的组。如果你只是想改变一个选项，同时保持参数组之间是一致的所有其他人，这非常有用。 例如，这是非常有用的，当一个人想指定每层的学习率： optim.SGD([ {'params': model.base.parameters()}, {'params': model.classifier.parameters(), 'lr': 1e-3} ], lr=1e-2, momentum=0.9) 这意味着model.base 的参数将使用的缺省学习速率 1E-2，model.classifier的参数将使用的1E-3，和0.9 [动量HTG19学习速率]将用于所有参数。 以优化步骤 所有优化实现 步骤（）的方法，即更新的参数。它可以以两种方式使用： optimizer.step（） 这是最优化支持的一个简化版本。一旦梯度使用例如计算的功能可以被称为向后（）。 Example: for input, target in dataset: optimizer.zero_grad() output = model(input) loss = loss_fn(output, target) loss.backward() optimizer.step() optimizer.step（闭合） 一些优化算法，如共轭梯度和LBFGS需要的功能，多次重新评估，所以你必须在一个封闭，使他们能够重新计算模型通过。封闭应清除的梯度，计算损失，并将其返回。 Example: for input, target in dataset: def closure(): optimizer.zero_grad() output = model(input) loss = loss_fn(output, target) loss.backward() return loss optimizer.step(closure) 算法 classtorch.optim.``Optimizer( params , defaults )[source] 基类的所有优化。 警告 参数需要被指定为具有确定性的排序是运行之间的一致的集合。不满足这些属性的对象的例子是组和迭代过的字典值。 Parameters PARAMS （ 可迭代 ） - torch.Tensor S的迭代或 字典秒。指定了张量应该优化。 默认 - （字典）：含有的优化选项的默认值的字典（当使用时的参数组不指定它们）。 add_param_group( param_group )[source] 一组PARAM添加到 优化S param_groups 。 当微调预训练的网络作为冷冻层可以由可训练并添加到 优化作为训练的进行这可以是有用的。 Parameters param_group （ DICT ） - 指定哪张量应与组一起被优化 优化选项。 （ 具体 ） - load_state_dict( state_dict )[source] 加载优化状态。 Parameters state_dict （ DICT ） 优化状态。应该从一个调用返回一个目的是 state_dict（）。 state_dict()[source] 返回作为 字典优化的状态。 它包含两个条目： state - a dict holding current optimization state. Its content 优化类之间是不同的。 param_groups - 包含所有参数组的字典 step( closure )[source] 执行单一优化步骤（参数更新）。 Parameters 闭合 （ 可调用 ） - 即重新评估该模型，并返回损失的闭合件。可选的最优化。 zero_grad()[source] 清除所有优化 torch.Tensor S的梯度。 classtorch.optim.``Adadelta( params , lr=1.0 , rho=0.9 , eps=1e-06 , weight_decay=0 )[source] 实现Adadelta算法。 它已在[ ADADELTA被提出：一种自适应学习速率法HTG1。 Parameters PARAMS （ 可迭代 ） - 的参数可迭代优化或类型的字典定义的参数组 RHO （ 浮动 ， 可选 ） - 系数用于计算平方梯度（缺省的运行平均值： 0.9） EPS （ 浮动 ， 可选 ） - 术语添加到分母以提高数值稳定性（默认值：1E -6） LR （ 浮动 ， 可选 ） - 系数尺度增量之前它被施加到参数（缺省：1.0） weight_decay （ 浮动 ， 可选 ） - 重量衰变（L2罚分）（默认值：0） step( closure=None )[source] 执行单一优化步骤。 Parameters 闭合 （ 可调用 ， 可选 ） - 即重新评估该模型，并返回损失的闭合件。 classtorch.optim.``Adagrad( params , lr=0.01 , lr_decay=0 , weight_decay=0 , initial_accumulator_value=0 )[source] 实现Adagrad算法。 它已在[HTG0自适应次梯度法在线学习和随机优化被提出。 Parameters params ( iterable ) – iterable of parameters to optimize or dicts defining parameter groups LR （ 浮动 ， 可选 ） - 学习率（默认值：1E-2） lr_decay （ 浮动 ， 可选 ） - 学习速率衰变（默认值：0） weight_decay ( float , optional ) – weight decay (L2 penalty) (default: 0) step( closure=None )[source] Performs a single optimization step. Parameters closure ( callable , optional ) – A closure that reevaluates the model and returns the loss. classtorch.optim.``Adam( params , lr=0.001 , betas=(0.9 , 0.999) , eps=1e-08 , weight_decay=0 , amsgrad=False )[source] 亚当实现算法。 它已经提出了亚当：一种随机优化方法。 Parameters params ( iterable ) – iterable of parameters to optimize or dicts defining parameter groups LR （ 浮动 ， 可选 ） - 学习率（默认值：1E-3） 贝塔 （ 元组 [ 浮动 ， 浮动 _ ， 可选_ ） - 用于计算梯度的运行平均值和其平方的系数（默认值：0.9（，0.999）） EPS （ 浮动 ， 可选 ） - 术语添加到分母以提高数值稳定性（默认值：1E -8） weight_decay ( float , optional ) – weight decay (L2 penalty) (default: 0) amsgrad （ 布尔 ， 可选 ） - 是否使用该算法的AMSGrad变体从纸在收敛亚当和超越（默认值：false） step( closure=None )[source] Performs a single optimization step. Parameters closure ( callable , optional ) – A closure that reevaluates the model and returns the loss. classtorch.optim.``AdamW( params , lr=0.001 , betas=(0.9 , 0.999) , eps=1e-08 , weight_decay=0.01 , amsgrad=False )[source] 实现AdamW算法。 原来亚当算法提出亚当：一种随机优化方法。该AdamW变种在[解耦权衰减正则建议HTG3。 Parameters params ( iterable ) – iterable of parameters to optimize or dicts defining parameter groups lr ( float , optional ) – learning rate (default: 1e-3) betas ( Tuple [ float , float ] , optional ) – coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999)) eps ( float , optional ) – term added to the denominator to improve numerical stability (default: 1e-8) weight_decay （ 浮动 ， 可选 ） - 重量衰减系数（默认值：1E-2） amsgrad ( boolean , optional ) – whether to use the AMSGrad variant of this algorithm from the paper On the Convergence of Adam and Beyond (default: False) step( closure=None )[source] Performs a single optimization step. Parameters closure ( callable , optional ) – A closure that reevaluates the model and returns the loss. classtorch.optim.``SparseAdam( params , lr=0.001 , betas=(0.9 , 0.999) , eps=1e-08 )[source] 实现适用于稀疏张量亚当算法的懒惰版本。 在该变型中，只有在梯度显示时刻得到更新，并且只有所述梯度的那些部分会应用于参数。 Parameters params ( iterable ) – iterable of parameters to optimize or dicts defining parameter groups lr ( float , optional ) – learning rate (default: 1e-3) betas ( Tuple [ float , float ] , optional ) – coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999)) eps ( float , optional ) – term added to the denominator to improve numerical stability (default: 1e-8) step( closure=None )[source] Performs a single optimization step. Parameters closure ( callable , optional ) – A closure that reevaluates the model and returns the loss. classtorch.optim.``Adamax( params , lr=0.002 , betas=(0.9 , 0.999) , eps=1e-08 , weight_decay=0 )[source] 实现Adamax算法（亚当基于无穷范数变体）。 It has been proposed in Adam: A Method for Stochastic Optimization. Parameters params ( iterable ) – iterable of parameters to optimize or dicts defining parameter groups LR （ 浮动 ， 可选 ） - 学习率（默认值：2E-3） 贝塔 （ 元组 [ 浮动 ， 浮动 _ ， 可选_ ） - 用于计算梯度及正方形的运行平均值的系数 eps ( float , optional ) – term added to the denominator to improve numerical stability (default: 1e-8) weight_decay ( float , optional ) – weight decay (L2 penalty) (default: 0) step( closure=None )[source] Performs a single optimization step. Parameters closure ( callable , optional ) – A closure that reevaluates the model and returns the loss. classtorch.optim.``ASGD( params , lr=0.01 , lambd=0.0001 , alpha=0.75 , t0=1000000.0 , weight_decay=0 )[source] 器具场均随机梯度下降。 它已在随机逼近的加速度的平均值被提出。 Parameters params ( iterable ) – iterable of parameters to optimize or dicts defining parameter groups lr ( float , optional ) – learning rate (default: 1e-2) lambd （ 浮动 ， 可选 ） - 衰减项（默认值：1E-4） 阿尔法 （ 浮动 ， 可选 ） - 功率ETA更新（默认值：0.75） T0 （ 浮动 ， 可选 ） - 点处开始平均（默认值：1E6） weight_decay ( float , optional ) – weight decay (L2 penalty) (default: 0) step( closure=None )[source] Performs a single optimization step. Parameters closure ( callable , optional ) – A closure that reevaluates the model and returns the loss. classtorch.optim.``LBFGS( params , lr=1 , max_iter=20 , max_eval=None , tolerance_grad=1e-05 , tolerance_change=1e-09 , history_size=100 , line_search_fn=None )[source] 实现L-BFGS算法，很大程度上受到启发minFunc & LT ; https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html & GT [; ] 。 Warning 这种优化不支持每个参数的选项和参数组（只能有一个）。 Warning 现在所有的参数都必须在单个设备上。这将在未来得到改善。 Note 这是一个非常内存密集型优化器（它需要额外的param_bytes * （history_size + 1）字节）。如果不装入内存尝试降低历史记录的大小，或者使用不同的算法。 Parameters LR （ 浮动 ） - 学习率（默认值：1） max_iter （ INT ） - 每优化步骤迭代的最大数量（默认值：20） max_eval （ INT ） - 每优化步骤功能评价的最大数量（默认值：max_iter * 1.25）。 （：1E-5默认）上一阶最优终止公差 - tolerance_grad （ 浮动 ）。 （：1E-9默认）上函数值/参数改变终止公差 - tolerance_change （ 浮动 ）。 history_size （ INT ） - 更新历史尺寸（默认值：100）。 line_search_fn （ STR ） - 要么“strong_wolfe”或无（默认：无）。 step( closure )[source] Performs a single optimization step. Parameters 闭合 （ 可调用 ） - 即重新评估该模型，并返回损失的闭合件。 classtorch.optim.``RMSprop( params , lr=0.01 , alpha=0.99 , eps=1e-08 , weight_decay=0 , momentum=0 , centered=False )[source] 实现RMSprop算法。 由G.韩丁在他的[HTG0当然提出。 居中版本首先出现在生成的序列的递归神经网络。 Parameters params ( iterable ) – iterable of parameters to optimize or dicts defining parameter groups lr ( float , optional ) – learning rate (default: 1e-2) 动量 （ 浮动 ， 可选 ） - 动量因子（默认值：0） 阿尔法 （ 浮动 ， 可选 ） - 平滑常数（默认值：0.99） eps ( float , optional ) – term added to the denominator to improve numerical stability (default: 1e-8) 居中 （ 布尔 ， 可选 ） - 如果真，计算居中RMSProp，梯度是由它的方差的估计归一化 weight_decay ( float , optional ) – weight decay (L2 penalty) (default: 0) step( closure=None )[source] Performs a single optimization step. Parameters closure ( callable , optional ) – A closure that reevaluates the model and returns the loss. classtorch.optim.``Rprop( params , lr=0.01 , etas=(0.5 , 1.2) , step_sizes=(1e-06 , 50) )[source] 实现了弹性BP算法。 Parameters params ( iterable ) – iterable of parameters to optimize or dicts defining parameter groups lr ( float , optional ) – learning rate (default: 1e-2) ETAS （ 元组 [ 浮动 ， 浮动 _ ， 可选_ ） - 双（etaminus，etaplis），即是乘法增加和减少的因素（默认值：（0.5，1.2 ）） step_sizes （ 元组 [ 浮动 ， 浮动 _ ， 可选_ ） - 一对最小和最大允许的步长大小（默认值：（1E-6，50）） step( closure=None )[source] Performs a single optimization step. Parameters closure ( callable , optional ) – A closure that reevaluates the model and returns the loss. classtorch.optim.``SGD( params , lr= , momentum=0 , dampening=0 , weight_decay=0 , nesterov=False )[source] 实现随机梯度下降（任选地与动量）。 涅斯捷罗夫势头是基于公式在初始化和动量的深度学习的重要性。 Parameters params ( iterable ) – iterable of parameters to optimize or dicts defining parameter groups LR （ 浮动 ） - 学习率 momentum ( float , optional ) – momentum factor (default: 0) weight_decay ( float , optional ) – weight decay (L2 penalty) (default: 0) 阻尼 （ 浮动 ， 可选 ） - 润湿动量（默认值：0） 涅斯捷罗夫 （ 布尔 ， 可选 ） - 使涅斯捷罗夫势头（默认值：false） 例 >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) >>> optimizer.zero_grad() >>> loss_fn(model(input), target).backward() >>> optimizer.step() Note SGD与动量执行/涅斯捷罗夫巧妙地不同于Sutskever等。人。而在一些其他框架的实现。 考虑动量的特定情况下，更新可以写成 v=ρ∗v+gp=p−lr∗vv = \\rho v + g \\\\ p = p - lr v v=ρ∗v+gp=p−lr∗v 其中p，G，V和 ρ \\哌 [分别HTG13] ρ 表示的参数，梯度，速度和动量。 这是相对于Sutskever等。人。和其采用的形式的更新其他框架 v=ρ∗v+lr∗gp=p−vv = \\rho v + lr g \\\\ p = p - v v=ρ∗v+lr∗gp=p−v 该版本涅斯捷罗夫，类似修改。 step( closure=None )[source] Performs a single optimization step. Parameters closure ( callable , optional ) – A closure that reevaluates the model and returns the loss. 如何调整学习率 torch.optim.lr_scheduler提供了几种方法来调整基于历元的数目的学习速率。torch.optim.lr_scheduler.ReduceLROnPlateau允许动态学习速率还原性基于一些验证测量。 学习速率调度后，应优化器的更新应用;例如，你应该写你的代码是这样的： >>> scheduler = ... >>> for epoch in range(100): >>> train(...) >>> validate(...) >>> scheduler.step() Warning 到PyTorch 1.1.0之前，学习率调度，预计优化的更新之前被称为; 1.1.0在BC破的方式改变了这种行为。如果您使用的学习速率调度（调用scheduler.step（））优化的更新前（调用optimizer.step（） ），这将跳过学习税率表的第一价值。如果您无法升级到1.1.0 PyTorch后重现的结果，请检查您是否调用scheduler.step（）在错误的时间。 classtorch.optim.lr_scheduler.``LambdaLR( optimizer , lr_lambda , last_epoch=-1 )[source] 设置每个参数组的学习速率的初始LR倍的给定功能。当last_epoch = -1，设置初始LR作为LR。 Parameters 优化 （ 优化 ） - 包裹优化器。 lr_lambda （ 函数 或 列表 ） - 其计算给定的整数参数划时代一个乘法因子的函数，或这样的功能的列表，每一个组中optimizer.param_groups。 last_epoch （ INT ） - 最后历元的索引。缺省值：-1。 Example >>> # Assuming optimizer has two groups. >>> lambda1 = lambda epoch: epoch // 30 >>> lambda2 = lambda epoch: 0.95 ** epoch >>> scheduler = LambdaLR(optimizer, lr_lambda=[lambda1, lambda2]) >>> for epoch in range(100): >>> train(...) >>> validate(...) >>> scheduler.step() load_state_dict( state_dict )[source] 加载调度状态。 Parameters state_dict （ DICT ） 调度器状态。应该从一个调用返回一个目的是 state_dict（）。 state_dict()[source] 返回作为 字典调度器的状态。 它包含了每一个变量自. dict的项，这并不是优化。如果他们是可调用的对象，而不是他们是否是函数或lambda表达式学习率lambda函数只会被保存。 classtorch.optim.lr_scheduler.``StepLR( optimizer , step_size , gamma=0.1 , last_epoch=-1 )[source] 设置每个参数组，以通过γ每STEP_SIZE历元衰减初始LR学习率。当last_epoch = -1，设置初始LR作为LR。 Parameters optimizer ( Optimizer) – Wrapped optimizer. STEP_SIZE （ INT ） - 学习速率衰变的时期。 伽马 （ 浮动 ） - 学习速率衰变的乘法因子。默认值：0.1。 last_epoch ( int) – The index of last epoch. Default: -1. Example >>> # Assuming optimizer uses lr = 0.05 for all groups >>> # lr = 0.05 if epoch >> # lr = 0.005 if 30 >> # lr = 0.0005 if 60 >> # ... >>> scheduler = StepLR(optimizer, step_size=30, gamma=0.1) >>> for epoch in range(100): >>> train(...) >>> validate(...) >>> scheduler.step() classtorch.optim.lr_scheduler.``MultiStepLR( optimizer , milestones , gamma=0.1 , last_epoch=-1 )[source] 每个参数组的学习率一旦历元的数目达到里程碑之一设置为通过γ衰减初始LR。当last_epoch = -1，设置初始LR作为LR。 Parameters optimizer ( Optimizer) – Wrapped optimizer. 里程碑 （ 列表 ） - 历元索引列表。必须增加。 gamma ( float) – Multiplicative factor of learning rate decay. Default: 0.1. last_epoch ( int) – The index of last epoch. Default: -1. Example >>> # Assuming optimizer uses lr = 0.05 for all groups >>> # lr = 0.05 if epoch >> # lr = 0.005 if 30 >> # lr = 0.0005 if epoch >= 80 >>> scheduler = MultiStepLR(optimizer, milestones=[30,80], gamma=0.1) >>> for epoch in range(100): >>> train(...) >>> validate(...) >>> scheduler.step() classtorch.optim.lr_scheduler.``ExponentialLR( optimizer , gamma , last_epoch=-1 )[source] 每个参数组的学习率设置为通过γ每历元衰减初始LR。当last_epoch = -1，设置初始LR作为LR。 Parameters optimizer ( Optimizer) – Wrapped optimizer. 伽马 （ 浮动 ） - 学习速率衰变的乘法因子。 last_epoch ( int) – The index of last epoch. Default: -1. classtorch.optim.lr_scheduler.``CosineAnnealingLR( optimizer , T_max , eta_min=0 , last_epoch=-1 )[source] 使用余弦退火时间表，其中 η 米设定各参数组的学习率 一 × \\ eta {MAX} η M 一 × 被设定为初始LR和 T C U R T { CUR} [H TG95] T C U [R 是因为在SGDR上次重启历元数： ηt=ηmin+12(ηmax−ηmin)(1+cos⁡(TcurTmaxπ))\\etat = \\eta{min} + \\frac{1}{2}(\\eta{max} - \\eta{min})(1 + \\cos(\\frac{T{cur}}{T{max}}\\pi)) ηt​=ηmin​+21​(ηmax​−ηmin​)(1+cos(Tmax​Tcur​​π)) 当last_epoch = -1，设置初始LR作为LR。 它已经提出了[ SGDR：随机梯度下降以热烈的重新启动HTG1。请注意，这仅实现SGDR的余弦退火的一部分，而不是重新启动。 Parameters optimizer ( Optimizer) – Wrapped optimizer. T_MAX （ INT ） - 迭代的最大数量。 eta_min （ 浮动 ） - 最小学习速率。默认值：0。 last_epoch ( int) – The index of last epoch. Default: -1. classtorch.optim.lr_scheduler.``ReduceLROnPlateau( optimizer , mode='min' , factor=0.1 , patience=10 , verbose=False , threshold=0.0001 , threshold_mode='rel' , cooldown=0 , min_lr=0 , eps=1e-08 )[source] 当指标已停止提高降低学习速率。模型通常受益于2-10一次学习停滞的一个因素减少学习率。该调度器读取指标量，并且如果没有改善被视作历元的一个“忍耐”号，学习率降低。 Parameters optimizer ( Optimizer) – Wrapped optimizer. 模式 （ STR [HTG5） - 酮的分钟HTG7]， MAX 。 ;在分钟HTG11]模式中，当监视的量已经停止下降LR将减少在 MAX 模式将监视时的数量已停止增加被减小。默认：“分钟”。 因子 （ 浮动 ） - 因子，通过该学习率将降低。 new_lr = LR *因子。默认值：0.1。 没有改善之后，学习率将降低历元数 - 耐性 （ INT ）。例如，如果耐性= 2 ，然后我们将忽略所述第一2个时期没有改善，并且第三时期后只会降低LR如果损失仍然没有再提高。默认值：10。 冗长 （ 布尔 ） - 如果真，打印一条消息到标准输出每个更新。默认值：假 [HTG13。 用于测量新的最佳，仅着眼于显著变化阈值 - 阈 （ 浮动 ）。默认值：1E-4。 threshold_mode （ STR [HTG5） - 酮的 REL ， ABS 。在 REL 模式，dynamic_threshold =最好（1个+阈值）在“最大”模式或最佳 - 在分钟HTG13]模式（1个阈值）。在 ABS 模式，dynamic_threshold =在最大最佳+阈模式或最佳 - 阈值分钟HTG19]模式。默认：“相对”。 冷却时间 （ INT ） - 历元LR之后恢复正常操作之前要等待的数量已经减少。默认值：0。 min_lr （ 浮动 或 列表 ） - 标量或标量的列表。的下界所有PARAM群体的学习速率或每个组分别。默认值：0。 EPS （ 浮动 ） - 最小衰变应用于LR。如果新旧LR的差比EPS小，更新被忽略。默认值：1E-8。 Example >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) >>> scheduler = ReduceLROnPlateau(optimizer, 'min') >>> for epoch in range(10): >>> train(...) >>> val_loss = validate(...) >>> # Note that step should be called after validate() >>> scheduler.step(val_loss) classtorch.optim.lr_scheduler.``CyclicLR( optimizer , base_lr , max_lr , step_size_up=2000 , step_size_down=None , mode='triangular' , gamma=1.0 , scale_fn=None , scale_mode='cycle' , cycle_momentum=True , base_momentum=0.8 , max_momentum=0.9 , last_epoch=-1 )[source] 设置根据周期性学习率政策（CLR）的各参数组的学习率。策略周期两个边界之间的学习率具有恒定频率，如在文献周期性学习价格的训练神经网络详述。两个边界之间的距离可以在每个迭代或每个周期的基础上进行缩放。 周期性学习率的政策变化，每批次后的学习率。 步骤应该被称为一个批次已被用于训练。 这个类有三个内置的政策，如纸提出：“三角”： 基本三角形的周期与/没有幅度缩放。 “triangular2”: 通过半每个周期扩展初始幅度A基本三角形的周期。 “exp_range”: 在每个循环迭代通过γ**（循环迭代）缩放初始幅度A循环。 此实现改编自GitHub库： bckenstler / CLR Parameters optimizer ( Optimizer) – Wrapped optimizer. base_lr （ 浮动 或 列表 ） - 初始学习速率是低边界在循环的每个参数组。 max_lr （ 浮动 或 列表 ） - 在循环上学习率边界每个参数组。在功能上，它定义了周期振幅（max_lr - base_lr）。在任何周期的LR是base_lr和振幅的某些缩放的总和;因此max_lr实际上可能没有达到根据缩放功能。 step_size_up （ INT ） - 在增加周期的一半训练迭代次数。默认值：2000 step_size_down （ INT ） - 在一个周期的减小一半训练迭代次数。如果step_size_down是无，它被设置为step_size_up。默认值：无 模式 （[ STR HTG5） - 酮{三角形，triangular2，exp_range}的。值对应于上述详细的政策。如果scale_fn不是无，则忽略此参数。默认：“三角” 伽马 （ 浮动 ） - 常量在“exp_range”缩放功能：伽马**（循环迭代）缺省值：1.0 scale_fn （ 函数 ） - 定义的缩放比例由单个参数lambda函数，定义的策略，其中0 & LT ; = scale_fn（X）& LT ; = 1对于所有的x & GT ; = 0。如果指定，则 '模式' 被忽略。默认值：无 scale_mode （ STR ） - {“循环”，“次迭代”}。定义是否scale_fn是（因为循环的开始训练迭代）上循环数或周期的迭代评估。默认：“周期” cycle_momentum （ 布尔 ） - 如果真，动量进行逆循环到 'base_momentum' 和之间学习率'max_momentum'。默认值：true base_momentum （ 浮动 或 列表 ） - 在循环下动量边界每个参数组。需要注意的是势头是负循环到学习速率;在一个周期的高峰期，气势“base_momentum”和学习率“max_lr”。默认值：0.8 max_momentum （ 浮动 或 列表 ） - 在周期上动量边界每个参数组。在功能上，它定义了周期振幅（max_momentum - base_momentum）。在任何周期的动量是max_momentum和振幅的一些结垢差;因此base_momentum实际上可能没有达到根据缩放功能。需要注意的是势头是负循环到学习速率;在一个周期的开始，气势“max_momentum”和学习率“base_lr”默认值：0.9 last_epoch （ INT ） - 最后一批的索引。恢复训练作业时使用此参数。由于步骤（）应当每批之后，而不是每个时期之后被调用，此数字表示计算，而不是计算总历元的数目的 批次的总数。当last_epoch = -1，计划从一开始启动。默认值：-1 Example >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) >>> scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1) >>> data_loader = torch.utils.data.DataLoader(...) >>> for epoch in range(10): >>> for batch in data_loader: >>> train_batch(...) >>> scheduler.step() get_lr()[source] 在计算指数批学习率。该函数将 self.last_epoch 作为最后一批指标。 如果 self.cycle_momentum 是真时，此功能有更新优化的势头的副作用。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"autograd.html":{"url":"autograd.html","title":"torch.autograd","keywords":"","body":"自动分化包 - torch.autograd torch.autograd提供的类和函数执行的任意的标量值的函数的自动分化。它需要最少的改变现有的代码 - 你只需要声明张量 S代表其梯度应与requires_grad =真 [HTG11计算]关键字。 torch.autograd.``backward( tensors , grad_tensors=None , retain_graph=None , create_graph=False , grad_variables=None )[source] 计算给出张量的梯度之w.r.t.图叶。 该图是使用链式法则区分。如果有任何的张量是非标量（即，它们的数据具有一个以上的元素），并且需要的梯度，然后雅可比矢量乘积将被计算，在这种情况下，函数附加地需要指定grad_tensors。它应该是匹配长度的序列中，包含在雅可比矢量乘积的“载体”，通常是有区别的功能w.r.t.的梯度相应的张量（无为不需要梯度张量的所有张量的可接受的值）。 此功能聚集在叶梯度 - 你可能需要调用它之前为零它们。 Parameters 张量 （ 的张量 序列） - 张量，其的衍生物将被计算出来。 grad_tensors （ 的 （ 张量 或 无序列 ） ） - 在雅可比矢量乘积的“载体”，通常梯度WRT对应张量的每个元素。无值可以用于标量张量或那些不要求毕业生指定。如果没有值将所有grad_tensors是可以接受的，那么这种说法是可选的。 retain_graph （ 布尔 ， 可选 ） - 如果假，用于计算所述市图表将被释放。请注意，在几乎所有情况下将此选项设置为真不需要，经常可以围绕以更有效的方式来工作。默认为create_graph的值。 create_graph （ 布尔 ， 可选 ） - 如果真，所述衍生物的图形将被构建，从而允许计算高阶衍生产品。默认为假 [HTG17。 torch.autograd.``grad( outputs , inputs , grad_outputs=None , retain_graph=None , create_graph=False , only_inputs=True , allow_unused=False )[source] 计算并返回的输出梯度之和w.r.t.输入。 grad_outputs应该是长度匹配[HTG7含有在雅可比矢量乘积的“载体”，输出通常是预先计算的梯度的序列WRT每一个输出。如果输出不require_grad，则梯度可以是无 ）。 如果only_inputs是真，则该函数将只返回梯度w.r.t指定输入的列表。如果是假，然后梯度w.r.t.其余所有的叶子仍然会被计算，并且将累积到他们.grad属性。 Parameters 输出 （ 的张量 序列） - 微分函数的输出。 输入 （ 张量的序列 ） - 输入w.r.t.该梯度将被返回（并且不累积到.grad）。 grad_outputs （ 张量 的序列） - 在雅可比矢量乘积的“载体”。通常梯度w.r.t.每个输出。无值可以用于标量张量或那些不要求毕业生指定。如果没有值将所有grad_tensors是可以接受的，那么这种说法是可选的。默认值：无。 retain_graph ( bool , optional ) – If False, the graph used to compute the grad will be freed. Note that in nearly all cases setting this option to Trueis not needed and often can be worked around in a much more efficient way. Defaults to the value of create_graph. create_graph （ 布尔 ， 可选 ） - 如果真，所述衍生物的图形将被构建，从而允许计算高阶衍生产品。默认值：假 [HTG17。 allow_unused （ 布尔 ， 可选 ） - 如果假，指定计算输出时不使用的输入（和因此它们的毕业生总是零）是错误的。默认为假 [HTG17。 本地禁用梯度计算 classtorch.autograd.``no_grad[source] 上下文管理器禁用梯度计算。 禁用梯度计算是推论有用，当你确信你不会叫Tensor.backward（） [HTG3。这将减少用于计算，否则将具有 requires_grad =真内存消耗。 在这种模式下，每一个计算结果将具有 requires_grad =假，即使当输入具有 requires_grad =真。 使用 enable_grad上下文管理器时，此模式没有影响。 这个上下文管理器是线程本地;它不会在其他线程影响计算。 也可作为装饰。 例： >>> x = torch.tensor([1], requires_grad=True) >>> with torch.no_grad(): ... y = x * 2 >>> y.requires_grad False >>> @torch.no_grad() ... def doubler(x): ... return x * 2 >>> z = doubler(x) >>> z.requires_grad False classtorch.autograd.``enable_grad[source] 上下文管理器，它使梯度计算。 使梯度计算，如果它已被通过 禁用no_grad或 set_grad_enabled ``。 This context manager is thread local; it will not affect computation in other threads. Also functions as a decorator. Example: >>> x = torch.tensor([1], requires_grad=True) >>> with torch.no_grad(): ... with torch.enable_grad(): ... y = x * 2 >>> y.requires_grad True >>> y.backward() >>> x.grad >>> @torch.enable_grad() ... def doubler(x): ... return x * 2 >>> with torch.no_grad(): ... z = doubler(x) >>> z.requires_grad True classtorch.autograd.``set_grad_enabled( mode )[source] 上下文管理器，其设定梯度计算为开或关。 set_grad_enabled将启用或禁用根据它的自变量模式梯度。它可以作为一个上下文经理或作为一个功能。 当使用 enable_grad上下文管理器，set_grad_enabled（假）没有影响。 This context manager is thread local; it will not affect computation in other threads. Parameters 模式 （ 布尔 ） - 标志是否启用研究所（真），或禁用（假）。这可以用来有条件地允许梯度。 Example: >>> x = torch.tensor([1], requires_grad=True) >>> is_train = False >>> with torch.set_grad_enabled(is_train): ... y = x * 2 >>> y.requires_grad False >>> torch.set_grad_enabled(True) >>> y = x * 2 >>> y.requires_grad True >>> torch.set_grad_enabled(False) >>> y = x * 2 >>> y.requires_grad False 就地对运营张量 在autograd支持就地操作是很难的事，我们不鼓励在大多数情况下，它们的使用。 Autograd咄咄逼人的缓冲释放和再利用使得它非常有效，也有极少数场合就地操作任何显著量实际上更低的内存使用率。除非你在重内存压力工作，你可能永远需要使用它们。 就地正确性检查 所有张量S跟踪就地操作适用于他们，如果实现检测到张在的功能之一保存落后，但它被修改IN- 事后到位，错误将引发一次向通行已启动。这确保了如果你使用就地功能，没有看到任何错误，你可以肯定的是，计算的梯度是正确的。 变量（不建议使用） 警告 变量API已被弃用：变量不再需要用张量使用autograd。 Autograd自动支持与requires_grad设置为真 张量。请在下面找到发生了什么变化的快速指南： 变量（张量）和变量（张量， requires_grad）HTG8]仍按预期方式工作，但他们回到张量而不是变量。 var.data是同样的事情tensor.data。 的方法，如var.backward（）， var.detach（）， var.register_hook（）现在在与张量的工作同样的方法名称。 此外，一个现在可以创建与requires_grad =真使用工厂方法，如 torch.randn（） [张量HTG9]， torch.zeros（） ， torch.ones（） 和其他类似如下： autograd_tensor = torch.randn（（2， 3， 4）， requires_grad = TRUE） 张量autograd功能 classtorch.``Tensor backward( gradient=None , retain_graph=None , create_graph=False )[source] 计算当前张量w.r.t.的梯度图叶。 该图是使用链式法则区分。如果张量是非标量（即，其数据具有一个以上的元素），并且需要的梯度，所述函数另外需要指定梯度。它应该是匹配的类型和位置的张量，包含有区别的功能w.r.t.的梯度自。 此功能聚集在叶梯度 - 你可能需要调用它之前为零它们。 Parameters 梯度 （ 张量 或 无 ） - 梯度w.r.t.张量。如果它是一个张量，它将被自动转换为不需要研究所除非create_graph为True张量。无值可以用于标量张量或那些不要求毕业生指定。如果没有值是可以接受的，然后这种说法是可选的。 retain_graph （ 布尔 ， 可选 ） - 如果假，用于计算梯度的图表将被释放。请注意，在几乎所有情况下的设置则不需要此选项设置为True，往往可以以更有效的方式围绕工作。默认为create_graph的值。 create_graph （ 布尔 ， 可选 ） - 如果真，所述衍生物的图形将被构建，从而允许计算高阶衍生产品。默认为假 [HTG17。 detach() 返回一个新的张量，从当前图形分离。 其结果将永远不需要梯度。 注意 回到张量股与原来相同的存储。就地对它们中的修改可以看出，并可能引发正确性检查错误。重要提示：以前，就地尺寸/步幅/存储的变化（如 resize / resize_as / SET / transpose ）来返回的张量也更新原有的张量。现在，这些就地变化将不再更新原有的张量，而会触发一个错误。对于稀疏张量：就地索引/值的变化（如 zero / copy / add_ ）发送到返回张量将不再更新原始张量，而会触发一个错误。 detach_() 分离从创建它，使其成为一个叶子图表中的张量。意见不能就地分离。 grad 该属性是无缺省和成为张量在第一时间 呼叫向后（）计算梯度为自。然后，属性将包含计算出的梯度，并 向后（） 将积累（添加）梯度到它将来的呼叫。 is_leaf 有所有的张量 requires_grad是假将叶按约定张量。 对于张量具有 requires_grad，它是真，他们将叶张量如果他们被创建用户。这意味着它们不是一个操作的结果等grad_fn是无。 仅叶张量人员在 GRAD至 向后（在呼叫期间填充）。为了得到 毕业填充的无叶张量，你可以使用[ retain_grad（） HTG23。 Example: >>> a = torch.rand(10, requires_grad=True) >>> a.is_leaf True >>> b = torch.rand(10, requires_grad=True).cuda() >>> b.is_leaf False # b was created by the operation that cast a cpu Tensor into a cuda Tensor >>> c = torch.rand(10, requires_grad=True) + 2 >>> c.is_leaf False # c was created by the addition operation >>> d = torch.rand(10).cuda() >>> d.is_leaf True # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine) >>> e = torch.rand(10).cuda().requires_grad_() >>> e.is_leaf True # e requires gradients and has no operations creating it >>> f = torch.rand(10, requires_grad=True, device=\"cuda\") >>> f.is_leaf True # f requires grad, has no operation creating it register_hook( hook )[source] 寄存器向后钩。 钩将被称为每相对于该张量的梯度被计算的时间。钩子应该具有以下特征： hook(grad) -> Tensor or None 钩不应该修改它的参数，但它可以任选地返回一个新的梯度，这将代替 GRAD一起使用。 该函数返回与方法handle.remove手柄（），其去除从所述模块的钩。 Example: >>> v = torch.tensor([0., 0., 0.], requires_grad=True) >>> h = v.register_hook(lambda grad: grad * 2) # double the gradient >>> v.backward(torch.tensor([1., 2., 3.])) >>> v.grad 2 4 6 [torch.FloatTensor of size (3,)] >>> h.remove() # removes the hook requires_grad 是真 [HTG3如果梯度需要计算该张量，假 [HTG7否则。`` Note 该梯度需要计算的张量，这一事实并不意味着 毕业属性将被填充，请参阅 is_leaf 的更多细节。 retain_grad()[source] 启用了非叶张量.grad属性。 函数 classtorch.autograd.``Function[source] 记录操作历史，并定义区分OPS公式。 在张量S创建一个新的函数对象，执行计算，执行的每一个操作，并记录它的发生。历史被保持在的功能的DAG的形式，与表示边缘数据依赖性（输入 & LT ; - 输出）。然后，当向后被调用时，曲线图中的拓扑排序处理时，通过调用 向后（）的每个 [方法HTG20 ]函数 对象，并通过返回梯度到下一个 函数秒。 通常情况下，用户使用的功能交互的唯一方法是通过创建子类和定义新的操作。这是延长torch.autograd的推荐方式。 每个功能对象是指仅使用一次（在正向通）。 例子： >>> class Exp(Function): >>> >>> @staticmethod >>> def forward(ctx, i): >>> result = i.exp() >>> ctx.save_for_backward(result) >>> return result >>> >>> @staticmethod >>> def backward(ctx, grad_output): >>> result, = ctx.saved_tensors >>> return grad_output * result staticbackward( ctx , *grad_outputs )[source] 定义用于区分该操作的公式。 此功能是通过所有子类覆盖。 它必须接受上下文CTX作为第一个参数，其次是因为许多输出做 向前（）返回，并且它应该返回尽可能多的张量，因为有输入 向前（） 。每个参数是w.r.t给定输出的梯度，并且每个返回的值应该是梯度w.r.t.相应的输入。 上下文可以用来检索直传期间保存张量。它也有一个属性ctx.needs_input_grad作为表示每个输入是否需要梯度的布尔值的元组。例如， 向后（）将ctx.needs_input_grad [0] = 真如果第一输入为 向前（）需要梯度computated WRT输出。 staticforward( ctx , *args , **kwargs )[source] 执行该操作。 This function is to be overridden by all subclasses. 它必须接受CTX作为第一个参数的上下文，后跟任意数量的参数（张量或其它类型的）。 上下文可以用来存储可反向通期间则检索张量。 数值梯度检查 torch.autograd.``gradcheck( func , inputs , eps=1e-06 , atol=1e-05 , rtol=0.001 , raise_exception=True , check_sparse_nnz=False , nondet_tol=0.0 )[source] 检查梯度经由针对分析梯度小有限差分计算w.r.t.在张量能与浮点型的和输入 requires_grad =真。 数字分析梯度之间的检查使用 allclose（）。 Note 的默认值被设计用于的双精度输入。如果输入是精度要求不高，例如，FloatTensor该检查很可能会失败。 Warning 如果在任何选中的张量输入具有重叠的存储，即，指向相同的存储器地址（例如，不同的指数，从torch.expand（）），该检查可能会失败，因为在这些指数由点扰动计算的数值梯度将在共享同一存储器地址上的所有其他指数变化的值。 Parameters FUNC （ 函数 ） - 一个Python函数，它接受张量的输入，并返回一个或张量的张量的元组 输入 （ 的张量 或 张量 元组） - 函数的输入 EPS （ 浮动 ， 可选 ） - 摄动有限差 蒂 （ 浮动 ， 可选 ） - 绝对公差 RTOL （ 浮动 ， 可选 ） - 相对公差 raise_exception （ 布尔 ， 可选 ） - 指示是否如果检查失败引发异常。异常提供了有关故障的确切性质的更多信息。调试gradchecks时，这是有帮助的。 check_sparse_nnz （ 布尔 ， 可选 ） - 如果为True，gradcheck允许SparseTensor输入，并且对于任何SparseTensor在输入，gradcheck将执行仅NNZ位置检查。 nondet_tol （ 浮动 ， 可选 ） - 用于非确定性的耐受性。当通过分化运行相同的输入，结果必须或者完全匹配（默认值，0.0）或者是此公差范围内。 Returns 真如果所有的差值满足allclose条件 torch.autograd.``gradgradcheck( func , inputs , grad_outputs=None , eps=1e-06 , atol=1e-05 , rtol=0.001 , gen_non_contig_grad_outputs=False , raise_exception=True , nondet_tol=0.0 )[source] 梯度的检查梯度经由针对分析梯度小有限差分计算w.r.t.在张量输入和grad_outputs认为是浮点型的，并通过requires_grad =真 [ HTG11。 此，通过计算给定的grad_outputs梯度backpropagating函数检查是正确的。 The check between numerical and analytical gradients uses allclose(). Note 的默认值被设计用于输入和的双精度grad_outputs。如果它们的精度要求不高，例如该检查很可能会失败，FloatTensor。 Warning 如果在输入和任何检查张量grad_outputs具有重叠的存储，即，指向相同的存储器地址（例如，不同的指数，从torch.expand（）），该检查可能会失败，因为在这些指数由点扰动计算的数值梯度将在共享同一存储器地址上的所有其他指数变化的值。 Parameters func ( function ) – a Python function that takes Tensor inputs and returns a Tensor or a tuple of Tensors inputs ( tuple of Tensor or Tensor) – inputs to the function grad_outputs （ 张量 或 张量 ， 可选的元组 ） - 相对于所述功能的输出的梯度。 eps ( float , optional ) – perturbation for finite differences atol ( float , optional ) – absolute tolerance rtol ( float , optional ) – relative tolerance gen_non_contig_grad_outputs （ 布尔 ， 可选 ） - 如果grad_outputs是无和gen_non_contig_grad_outputs是真中，随机产生的梯度输出做成非连续 raise_exception ( bool , optional ) – indicating whether to raise an exception if the check fails. The exception gives more information about the exact nature of the failure. This is helpful when debugging gradchecks. nondet_tol （ 浮动 ， 可选 ） - 用于非确定性的耐受性。当通过分化运行相同的输入，结果必须或者完全匹配（默认值，0.0）或者是此公差范围内。注意，非确定性的梯度少量会导致在二阶导数更大的误差。 Returns True if all differences satisfy allclose condition 探查 Autograd包括一个分析器，它可让您检查不同运营商的成本模型中 - 无论是CPU和GPU上。有目前实施的两种模式 - 仅CPU使用 个人资料 [HTG5。并使用 emit_nvtxnvprof基于（寄存器CPU和GPU两者的活性）。 classtorch.autograd.profiler.``profile( enabled=True , use_cuda=False , record_shapes=False )[source] 管理autograd探查状态并保持结果的摘要上下文管理。引擎盖下它只是记录在C ++中执行的功能的事件和暴露这些事件到Python。你可以用任何代码到它，它只会报告的PyTorch功能运行。 Parameters 启用 （ 布尔 ， 可选 ） - 此设置为false使此背景下经理无操作。默认值：真 [HTG13。 use_cuda （ 布尔 ， 可选 ） - 允许使用cudaEvent API以及CUDA事件的定时。添加约4us的开销每个张量操作。默认值：假 record_shapes （ 布尔 ， 可选 ） - 如果形状将录制设定，关于输入尺寸信息将被收集。这允许人们看到哪些尺寸已经罩，并进一步按他们下使用利用prof.key_averages（group_by_input_shape =真）。请注意，形状记录可能会扭曲你的分析数据。它建议使用单独的运行具有和不具有形状记录来验证定时。最有可能的倾斜将是微不足道的最底层的事件（在嵌套函数调用的情况下）。但对于更高层次的功能，总的自我CPU时间可能会因为人为的形状收集的增加。 例 >>> x = torch.randn((1, 1), requires_grad=True) >>> with torch.autograd.profiler.profile() as prof: >>> for _ in range(100): # any normal python code, really! >>> y = x ** 2 >> y.backward() >>> # NOTE: some columns were removed for brevity >>> print(prof.key_averages().table(sort_by=\"self_cpu_time_total\")) ----------------------------------- --------------- --------------- --------------- Name Self CPU total CPU time avg Number of Calls ----------------------------------- --------------- --------------- --------------- mul 32.048ms 32.048ms 200 pow 27.041ms 27.041ms 200 PowBackward0 9.727ms 55.483ms 100 torch::autograd::AccumulateGrad 9.148ms 9.148ms 100 torch::autograd::GraphRoot 691.816us 691.816us 100 ----------------------------------- --------------- --------------- --------------- export_chrome_trace( path )[source] 出口的一个EVENTLIST以及Chrome的跟踪工具文件。 检查点可以在以后加载并铬下检查：//追踪URL。 Parameters 路径 （ STR ） - ，其中所述迹线将被写入路径。 key_averages( group_by_input_shape=False )[source] 平均在他们的密钥对所有功能的事件。 @参数group_by_input_shapes的关键将成为（事件名称，输入尺寸），而不仅仅是事件名称。这是有用的，看看哪些维度有助于运行最并可与维特定的优化或选择最佳候选量化帮助（又名拟合的车顶线条） Returns 含有FunctionEventAvg对象的EVENTLIST。 propertyself_cpu_time_total 返回花费在所有的自我时代的所有事件的总和获得的CPU总时间。 table( sort_by=None , row_limit=100 , header=None )[source] 打印的EVENTLIST作为一个很好的格式化的表格。 Parameters sort_by （ STR ， 可选 ） - 属性用于条目进行排序。默认情况下，它们被印在为它们注册的顺序相同。有效键包括：CPU_TIME，cuda_time，cpu_time_total，cuda_time_total，计数。 Returns 将含有表字符串。 total_average()[source] 平均值的所有事件。 Returns 一个FunctionEventAvg对象。 classtorch.autograd.profiler.``emit_nvtx( enabled=True , record_shapes=False )[source] 情境管理，使每一个autograd操作发出NVTX范围。 下nvprof运行程序时是非常有用的： nvprof --profile-from-start off -o trace_name.prof -- 不幸的是，有没有办法强迫nvprof刷新它收集到磁盘上的数据，所以对于CUDA剖析一个具有使用此背景下经理注释nvprof跟踪和等待的过程中检查他们之前退出。然后，无论是NVIDIA的视觉分析器（nvvp）可以被用于可视化的时间线，或 torch.autograd.profiler.load_nvprof（）可以加载对结果检查如在Python REPL。 Parameters 启用 （ 布尔 ， 可选 ， 默认=真 ） - 设置启用=假将此情况管理器无操作。默认值：真 [HTG21。 record_shapes （ 布尔 ， 可选 ， 默认=假 ） - 如果record_shapes =真时，nvtx范围包裹每个autograd运算将追加关于由该运算所接收的张量参数的大小的信息，在下面的格式：[[arg0.size（0）， arg0.size（1）， ...]， [arg1.size（0）， arg1.size（1）， ...]， ...]非张量参数将被表示为[]。参数将在它们由后端运算收到的顺序列出。请注意，这个顺序可能不匹配，使这些参数传递的Python端的顺序。还要注意的是形状记录可能会增加nvtx范围内创建的开销。 Example >>> with torch.cuda.profiler.profile(): ... model(x) # Warmup CUDA memory allocator and profiler ... with torch.autograd.profiler.emit_nvtx(): ... model(x) 前后的相关性 当观看使用 中创建的简档emit_nvtx在NVIDIA的视觉分析器，各后向通运算与相应的前向通运算关联可能是困难的。为了缓解此任务， emit_nvtx附加序列数信息向它生成的范围。 在直传，每个功能范围装饰有SEQ = & LT ; N & GT ;。 SEQ是一个运行计数器，递增每一个新的后向功能对象被创建并藏匿用于向后时间。因此，SEQ = & LT ; N & GT ;与每个进功能范围相关联的注释告诉你，如果一个向后作用目的是通过此正向函数创建，后向对象将接收序号N.在向后通，顶层范围包裹每个C ++向后功能的申请（）呼叫装饰与藏匿 SEQ = & LT ; M & GT ;。 M是向后对象与所创建的序列号。通过向后比较藏匿 序列​​ 数字序列正向号码，你可以跟踪哪些向前运创建的每个向后作用。 向后传递期间执行的任何功能也装饰有SEQ = & LT ; N & GT ;。默认向后期间（与create_graph =假）这个信息是无关的，而事实上，N可以简单地是0对于所有此类职能。只有具有向后功能对象相关联的顶层范围申请（）方法是有用的，作为方式关联与较早直传这些功能对象。 双向后 如果，在另一方面，后向通用create_graph =真正在进行（换句话说，如果要设置为双向后）期间落后，每个功能的执行给出非零的，有用的SEQ = & LT ; N & GT ;。这些功能可以自己创建要在以后执行的函数对象双重落后，就像直传原有功能一样。向后和双向后之间的关系是概念性一样向前和向后之间的关系：该功能仍然发射电流序列号标记的范围内，功能对象他们创建仍然藏匿那些序列号，和最终双期间落后，函数对象申请（）范围仍具有标记藏匿 SEQ的数字，其可以进行比较，以 SEQ 号码从反向通。 torch.autograd.profiler.``load_nvprof( path )[source] 打开一个nvprof跟踪文件，并解析autograd注解。 Parameters 路径 （ STR ） - 路径nvprof跟踪 异常检测 classtorch.autograd.``detect_anomaly[source] 上下文管理器启用的autograd发动机异常检测。 这做了两两件事： - 运行直传启用检测将允许向通行打印创建失败后退功能正向操作的回溯。 - 产生任何向后计算“男”值将产生一个错误。 Example >>> import torch >>> from torch import autograd >>> class MyFunc(autograd.Function): ... @staticmethod ... def forward(ctx, inp): ... return inp.clone() ... @staticmethod ... def backward(ctx, gO): ... # Error during the backward pass ... raise RuntimeError(\"Some error in backward\") ... return gO.clone() >>> def run_fn(a): ... out = MyFunc.apply(a) ... return out.sum() >>> inp = torch.rand(10, 10, requires_grad=True) >>> out = run_fn(inp) >>> out.backward() Traceback (most recent call last): File \"\", line 1, in File \"/your/pytorch/install/torch/tensor.py\", line 93, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph) File \"/your/pytorch/install/torch/autograd/__init__.py\", line 90, in backward allow_unreachable=True) # allow_unreachable flag File \"/your/pytorch/install/torch/autograd/function.py\", line 76, in apply return self._forward_cls.backward(self, *args) File \"\", line 8, in backward RuntimeError: Some error in backward >>> with autograd.detect_anomaly(): ... inp = torch.rand(10, 10, requires_grad=True) ... out = run_fn(inp) ... out.backward() Traceback of forward call that caused the error: File \"tmp.py\", line 53, in out = run_fn(inp) File \"tmp.py\", line 44, in run_fn out = MyFunc.apply(a) Traceback (most recent call last): File \"\", line 4, in File \"/your/pytorch/install/torch/tensor.py\", line 93, in backward torch.autograd.backward(self, gradient, retain_graph, create_graph) File \"/your/pytorch/install/torch/autograd/__init__.py\", line 90, in backward allow_unreachable=True) # allow_unreachable flag File \"/your/pytorch/install/torch/autograd/function.py\", line 76, in apply return self._forward_cls.backward(self, *args) File \"\", line 8, in backward RuntimeError: Some error in backward classtorch.autograd.``set_detect_anomaly( mode )[source] 上下文管理器设置或关闭的autograd发动机异常检测。 set_detect_anomaly 根据它的自变量模式 ``将启用或禁用所述autograd异常检测。它可以作为一个上下文经理或作为一个功能。 参见detect_anomaly上述用于异常检测的行为的细节。 Parameters 模式 （ 布尔 ） - 标志是否启用异常检测（真），或禁止（假）。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed.html":{"url":"distributed.html","title":"torch.distributed","keywords":"","body":"分布式通信包 - torch.distributed 后端 torch.distributed支持三种后端，每个具有不同的能力。下表显示了哪些功能可用于与CPU / CUDA张量使用。 MPI支持CUDA只有在执行用于构建PyTorch支持它。 后端 | GLOO | MPI | NCCL ---|---|---|--- 设备 | 中央处理器 | GPU | CPU | GPU | CPU | GPU 发送 | ✓ | ✘ | ✓ | ？ | ✘ | ✘ 的recv | ✓ | ✘ | ✓ | ? | ✘ | ✘ 广播 | ✓ | ✓ | ✓ | ? | ✘ | ✓ all_reduce | ✓ | ✓ | ✓ | ? | ✘ | ✓ 降低 | ✓ | ✘ | ✓ | ? | ✘ | ✓ all_gather | ✓ | ✘ | ✓ | ? | ✘ | ✓ 收集 | ✓ | ✘ | ✓ | ? | ✘ | ✘ 分散 | ✓ | ✘ | ✓ | ? | ✘ | ✘ 屏障 | ✓ | ✘ | ✓ | ? | ✘ | ✓ 来与后端PyTorch PyTorch目前仅分布支持Linux。默认情况下，GLOO和NCCL后端构建和包含在分布式PyTorch（NCCL只有CUDA建设时）。 MPI是一个可选的后端，如果你从源代码编译PyTorch只能被包括在内。 （例如构建PyTorch已安装MPI的主机上）。 其后端使用？ 在过去，我们经常被问道：“我应该用哪个后端？”。 经验法则 使用NCCL后端分布式 GPU 培训 使用GLOO后端分布式 CPU 培训。 与InfiniBand互联GPU主机 使用NCCL，因为它是目前支持InfiniBand和GPUDirect唯一的后端。 与以太网互连GPU主机 使用NCCL，因为它目前提供最好的分布式GPU训练的性能，特别是对于多进程单节点或多节点分布式训练。如果您遇到任何NCCL问题，使用GLOO作为后备选项。 （请注意，目前GLOO运行速度比NCCL慢于GPU的。） CPU主机与InfiniBand互联 如果您的InfiniBand已经启用IP超过IB，使用GLOO，否则，使用MPI来代替。我们计划在即将到来的版本中添加了对GLOO支持InfiniBand。 CPU主机与以太网互连 使用GLOO，除非你有使用MPI具体原因。 常见的环境变量 选择网络接口来使用 默认情况下，NCCL和GLOO后端都将尝试找到正确的网络接口使用。如果自动检测到的接口是不正确的，你可以使用下面的环境变量（适用于各自的后端）覆盖它： NCCL_SOCKET_IFNAME ，例如出口 NCCL_SOCKET_IFNAME = eth0的 GLOO_SOCKET_IFNAME ，例如出口 GLOO_SOCKET_IFNAME = eth0的 如果您使用的GLOO后台，你​​可以通过用逗号隔开他们，像这样指定多个接口：出口 GLOO_SOCKET_IFNAME =为eth0，eth1的，ETH2，ETH3 [ HTG5。后端会通过这些接口一个循环方式调度操作。至关重要的是，所有的进程指定在此变量相同数量的接口。 其他NCCL环境变量 NCCL还提供了一些环境变量进行微调的目的。 常用的包括用于调试的目的如下： 出口 NCCL_DEBUG = INFO 出口 NCCL_DEBUG_SUBSYS = ALL 对于NCCL环境变量的完整列表，请参阅 NVIDIA NCCL的官方文档 基础 的 torch.distributed 包提供了跨在一个或多个计算机上运行的几个计算节点对多进程并行PyTorch支持与通信原语。类 torch.nn.parallel.DistributedDataParallel（） 基于这样一种功能，以提供同步分布式训练为围绕任何PyTorch模型的包装。这不同于由 多处理包中提供的种并行 - torch.multiprocessing 和 torch.nn.DataParallel（），它支持多个网络连接的机器和在用户必须明确地启动主训练脚本的单独副本为每个进程。 在单机同步的情况下， torch.distributed 或 torch.nn.parallel.DistributedDataParallel（）包装纸可能仍然有在其他的方法来数据并行的优点，包括 torch.nn.DataParallel（）： 每个进程维护自己的优化，并执行与每个迭代一个完整的优化步骤。虽然这可能会出现多余的，因为梯度已经聚集和跨进程平均，并且因此对于每个过程是相同的，这意味着没有参数广播步骤是需要的，减少花费的节点之间传送张量的时间。 每个进程都包含一个独立的Python解释器，消除了多余的解释开销以及来自来自一个Python程序驱动多执行绪，模型复制品，或GPU“GIL-颠簸”。这是一个模型，大量使用Python运行时，包括复发层或很多小的组件模型尤为重要。 初始化 程序包需要调用任何其他方法之前使用 torch.distributed.init_process_group （）函数被初始化。这将阻止，直到所有进程都加入。 torch.distributed.``init_process_group( backend , init_method=None , timeout=datetime.timedelta(0 , 1800) , world_size=-1 , rank=-1 , store=None , group_name='' )[source] 初始化默认的分布式进程组，而这也将初始化分发包。 There are 2 main ways to initialize a process group: 指定店，位次和world_size明确。 指定init_method（URL字符串），其指示其中/如何发现对等体。有选择地指定秩和world_size，或编码在URL所有必需的参数，并省略它们。 如果不指定，init_method假设为“ENV：//”。 Parameters 后端 （ STR 或 后端 ） - 后端使用。取决于构建时配置中，有效的值包括MPI，GLOO和NCCL [ HTG23。该字段应该被给定为小写字符串（例如，“GLOO” ），其也可以通过后端 [HTG32访问] 属性（例如，Backend.GLOO）。如果使用每个机器的多个进程使用NCCL后端，每个进程必须具有它使用每个GPU独占访问，如进程之间共享的GPU可以导致死锁。 init_method （ STR ， 可选 ） - URL指定如何初始化进程组。默认值是“ENV：//”如果没有指定init_method或店。互斥与店。 world_size （ INT ， 可选 ） - 的参与工作进程数。如果存储指定是必需的。 秩 （ INT ， 可选 ） - 当前进程的秩。如果存储指定是必需的。 店 （ 存储 ， 可选 ） - 键/值存储的所有员工都可以访问，用于交换连接/地址信息。互斥与init_method。 超时 （ timedelta ， 可选 ） - 超时针对进程组执行的操作。默认值等于30分钟。这是仅适用于GLOO后端。 GROUP_NAME （ STR ， 可选 ， 弃用 ） - 组名。 为了使后端 == Backend.MPI，PyTorch需要从源内置支持MPI的系统上。这同样适用于NCCL为好。 classtorch.distributed.``Backend[source] 枚举类类可用后端的：GLOO，NCCL和MPI。 这个类的值是字符串小写，例如，“GLOO”。它们可以作为属性，例如被访问，Backend.NCCL。 这个类可以直接调用来解析字符串，如后端（backend_str）HTG2]将检查backend_str是有效的，而回报解析小写的字符串，如果是的话。它还接受大写字符串，例如，后端（ “GLOO”）返回“GLOO”。 注意 入口Backend.UNDEFINED存在，但仅作为一些字段的初始值。用户应不直接使用它，也没有承担起它的存在。 torch.distributed.``get_backend( group= )[source] 返回给定工艺组的后端。 Parameters 组 （ ProcessGroup ， 可选 ） - 进程组上下工夫。默认值是一般主进程组。如果指定了另一个特定的组，调用进程必须是组部分。 Returns 给定的处理组作为小写字符串的后端。 torch.distributed.``get_rank( group= )[source] 返回当前进程组的秩 秩是分布式处理组内的分配给每个进程的唯一标识符。他们总是连续整数范围从0到world_size [HTG3。 Parameters 组 （ ProcessGroup ， 可选 ） - 进程组上下工夫 Returns 进程组-1的秩，如果不是组的一部分 torch.distributed.``get_world_size( group= )[source] 返回当前处理组中的进程数 Parameters group ( ProcessGroup , optional ) – The process group to work on Returns 进程组-1的世界大小，如果不是组的一部分 torch.distributed.``is_initialized()[source] 检查是否默认进程组已初始化 torch.distributed.``is_mpi_available()[source] 检查该MPI后端是可用的。 torch.distributed.``is_nccl_available()[source] 检查该NCCL后端是可用的。 目前有三个初始化方法的支持： TCP的初始化 有两种方式使用TCP来初始化，既需要网络地址从所有进程到达和期望world_size。第一种方法要求指定属于等级0进程的地址。这种初始化方法要求所有的过程都有手动指定的行列。 请注意，多播地址未在最新的分布式包支持了。 组名已被弃用，以及。 import torch.distributed as dist # Use address of one of the machines dist.init_process_group(backend, init_method='tcp://10.1.1.20:23456', rank=args.rank, world_size=4) 共享文件系统初始化 另一个初始化方法利用被共享的文件系统，并从可见的所有机器的基团中，与期望的world_size沿。 URL应以文件开始：//和含有一个共享文件系统到一个不存在的文件的路径（在现有的目录中）。文件系统初始化将自动创建文件，如果它不存在，但不会删除该文件。因此，它是你的责任，以确保该文件之前清理下。 init_process_group（）调用同一文件路径/文件名。 需要注意的是自动排名分配没有在最新的分布式包装不再支持和GROUP_NAME已废弃好。 警告 此方法假定文件系统支持使用的fcntl锁定 - 大多数本地系统和NFS支持。 Warning 此方法将总是创建该文件，尽力清理，并在程序结束时删除该文件。换句话说，与文件init方法每次初始化需要一个全新的空文件，以便初始化成功。如果先前的初始化（恰好没有得到清理）使用相同的文件再次使用，这是意外的行为，常可引起死锁和失败。因此，即使这种方法会尽力清理文件，如果自动删除恰好是不成功的，这是你的责任，以确保该文件是在训练结束删除，以防止同一个文件是接下来的时间期间再次重复使用。如果您打算调用 init_process_group（）在同一个文件名多次，这一点尤为重要。换句话说，如果该文件不会被删除/清理和调用 init_process_group（）[HTG11再次在该文件中，失败是期望。这里的经验法则是，请确保该文件不存在或为空，每次 init_process_group（）被调用。 import torch.distributed as dist # rank should always be specified dist.init_process_group(backend, init_method='file:///mnt/nfs/sharedfile', world_size=4, rank=args.rank) 环境变量初始化 这种方法将读取的环境变量的配置，允许一个完全自定义如何获得的信息。要设置的变量是： MASTER_PORT- 所需;必须是机器上的空闲端口与秩0 MASTER_ADDR- 需要（除了秩0）;秩0节点的地址 WORLD_SIZE- 所需;既可以在此设置，或者在一个呼叫到INIT功能 RANK- 所需;既可以在此设置，或者在一个呼叫到INIT功能 秩0的机器将被用来建立的所有连接。 这是默认的方法，这意味着init_method没有被指定的（或可以是ENV：//）。 组 默认情况下，集体的默认组（也称为世界）工作，并要求所有进程进入分布函数调用。然而，一些工作负载可以受益于更细粒度的通信。这是分布式的群体发挥作用。new_group（）函数可用于创建新的组，所有进程的任意子集。它返回可以作为一个组参数向所有集体的不透明基手柄（集体分布函数的某些公知的编程模式交换信息）。 torch.distributed.``new_group( ranks=None , timeout=datetime.timedelta(0 , 1800) , backend=None )[source] 创建一个新的分布式组。 此功能要求的主要组中的所有进程（即是分布式工作的一部分的进程）进入该功能，即使他们不打算成为组的成员。此外，集团应该在所有进程以相同的顺序创建。 Parameters 行列 （ 列表 [ INT __ ） - 小组成员的队伍名单。 timeout ( timedelta , optional ) – Timeout for operations executed against the process group. Default value equals 30 minutes. This is only applicable for the gloobackend. 后端 （ STR 或 后端 ， 可选的 ） - 后端使用。取决于构建时的配置，有效值为GLOO和NCCL。默认情况下，使用相同的后端为全局组。该字段应该被给定为小写字符串（例如，“GLOO”），其也可以通过 后端 [HTG32访问]属性（例如，Backend.GLOO）。 Returns 分布式组的句柄，可以给集体呼吁。 点对点通信 torch.distributed.``send( tensor , dst , group= , tag=0 )[source] 同步发送一个张量。 Parameters 张量 （ 张量 ） - 张量来发送。 DST （ INT ） - 目的地等级。 group ( ProcessGroup , optional ) – The process group to work on 标记 （ INT ， 可选 ） - 标签，以匹配与远程的recv发送 torch.distributed.``recv( tensor , src=None , group= , tag=0 )[source] 同步接收一个张量。 Parameters 张量 （ 张量 ） - 张量来填充接收的数据。 SRC （ INT ， 可选 ） - 来源秩。将收到如果未指定任何进程。 group ( ProcessGroup , optional ) – The process group to work on 标记 （ INT ， 可选 ） - 标签以匹配RECV与远程发送 Returns 发件人等级-1，如果不是组的一部分 isend（）和 irecv（） 当用于返回分布式请求对象。在一般情况下，该对象的类型是未指定的，因为它们不应该被手动创建，但它们保证支持两种方法： is_completed（）- 返回真，如果操作已完成 等待（）- 将直至操作完成块的过程。 is_completed（）保证返回真一旦它返回。 torch.distributed.``isend( tensor , dst , group= , tag=0 )[source] 异步发送一个张量。 Parameters tensor ( Tensor) – Tensor to send. dst ( int) – Destination rank. group ( ProcessGroup , optional ) – The process group to work on tag ( int , optional ) – Tag to match send with remote recv Returns 分布式请求对象。无，如果不是组的一部分 torch.distributed.``irecv( tensor , src , group= , tag=0 )[source] 异步接收一个张量。 Parameters tensor ( Tensor) – Tensor to fill with received data. SRC （ INT ） - 来源秩。 group ( ProcessGroup , optional ) – The process group to work on tag ( int , optional ) – Tag to match recv with remote send Returns A distributed request object. None, if not part of the group 同步和异步共同操作 每个集体操作功能支持以下两种操作： 同步操作 - 默认模式中，当async_op设定为False。当函数返回时，可以保证执行集体操作的任何进一步的函数调用取决于集体操作的数据可以被称为（不一定完成，如果它是一个CUDA运算，因为所有的CUDA OPS是异步），和。在同步模式，集体功能不会返回任何东西 异步操作 - 当async_op设置为True。集体操作函数返回一个分布式请求对象。一般情况下，你不需要手动创建它，它是保证支持两种方法： is_completed()- returns True if the operation has finished 等待（）- 将直至操作完成块的过程。 集体函数 torch.distributed.``broadcast( tensor , src , group= , async_op=False )[source] 广播张全群。 张量必须具有相同数目的参与该集体的所有进程的元素。 Parameters 张量 （ 张量 ） - 如果SRC是当前进程的秩要发送的数据，和张量以用来保存否则所接收的数据。 src ( int) – Source rank. group ( ProcessGroup , optional ) – The process group to work on async_op （ 布尔 ， 可选 ） - 这是否OP应该是一个异步运 Returns 异步工作手柄，如果async_op设置为True。无，如果没有async_op或者如果不是组的一部分 torch.distributed.``all_reduce( tensor , op=ReduceOp.SUM , _group= , _async_op=False )[source] 减少以这样的方式，所有得到最终结果在所有机器上的数据张。 呼叫张量之后将被逐位在所有过程是相同的。 Parameters 张量 （ 张量 ） - 输入和集体的输出。该函数就地操作。 OP （ 可选[HTG3） - 酮从的值 torch.distributed.ReduceOp枚举的。指定用于元素方面减少的操作。 group ( ProcessGroup , optional ) – The process group to work on async_op ( bool , optional ) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group torch.distributed.``reduce( tensor , dst , op=ReduceOp.SUM , _group= , _async_op=False )[source] 减少在所有机器上的数据张。 只有等级的过程DST将要接收的最终结果。 Parameters tensor ( Tensor) – Input and output of the collective. The function operates in-place. DST （ INT ） - 目的地等级 op ( optional ) – One of the values from torch.distributed.ReduceOpenum. Specifies an operation used for element-wise reductions. group ( ProcessGroup , optional ) – The process group to work on async_op ( bool , optional ) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group torch.distributed.``all_gather( tensor_list , tensor , group= , async_op=False )[source] 汇集了来自全团张量在列表中。 Parameters tensor_list （ 列表 [ 张量 __ ） - 输出列表。它应该包含用于集体的正确输出大小的张量。 张量 （ 张量 ） - 张量从当前进程广播。 group ( ProcessGroup , optional ) – The process group to work on async_op ( bool , optional ) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group torch.distributed.``gather( tensor , gather_list , dst , _group= , _async_op=False )[source] 集张量在单个进程的列表。 Parameters 张量 （ 张量 ） - 输入张量。 gather_list （ 列表 [ 张量 __ ） - 适当大小的张量清单用于接收数据。仅在接收过程中必需。 DST （ INT ） - 目的地等级。需要不同之处在于receiveing数据的一个所有进程。 group ( ProcessGroup , optional ) – The process group to work on async_op ( bool , optional ) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group torch.distributed.``scatter( tensor , scatter_list , src , _group= , _async_op=False )[source] 散射张量的一组中的所有进程的列表。 每个进程将收到恰好一个张量并存储在张量参数其数据。 Parameters 张量 （ 张量 ） - 输出张量。 scatter_list （ 列表 [ 张量 __ ） - 张量清单散落一地。仅在正在发送数据的过程必需。 SRC （ INT ） - 来源秩。需要不同之处在于发送数据的一个所有进程。 group ( ProcessGroup , optional ) – The process group to work on async_op ( bool , optional ) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group torch.distributed.``barrier( group= , async_op=False )[source] 同步所有进程。 这种集体块处理，直到全团进入该功能，如果async_op是假，或者如果异步工作手柄上调用wait（）的。 Parameters group ( ProcessGroup , optional ) – The process group to work on async_op ( bool , optional ) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group classtorch.distributed.``ReduceOp 枚举状类的可用的减少的操作：SUM，产物，MIN和MAX。 这个类的值可以作为属性，例如被访问，ReduceOp.SUM。它们在指定为降低集体，例如策略中使用的， 减少（）， all_reduce_multigpu（）等 成员： 和 > 产品 > MIN > MAX classtorch.distributed.``reduce_op[source] 减少操作弃用枚举状类：SUM，产物，MIN和MAX。 ReduceOp建议改用。 多GPU集体函数 如果你有每个节点在一个以上的GPU，使用NCCL和GLOO后端时， broadcast_multigpu（） `` all_reduce_multigpu （） ``reduce_multigpu（）和 all_gather_multigpu（） 支持分布式每个节点内多个GPU之间的集体操作。这些功能可以潜在地提高整体的分布式训练的性能和很容易被路过张量的列表中。在通过张量列表中的每个张量必须在函数被调用主机的独立GPU设备上。需要注意的是，张量清单的长度需要所有的分布式进程之间是相同的。还要注意的是目前的多GPU集体功能仅由NCCL后端支持。 例如，如果我们使用用于分布式训练的系统具有2个节点，其中的每一个具有8个GPU。在每个16个GPU的，还有的是，我们希望所有减少的张量。下面的代码可以作为参考： 守则节点0运行 import torch import torch.distributed as dist dist.init_process_group(backend=\"nccl\", init_method=\"file:///distributed_test\", world_size=2, rank=0) tensor_list = [] for dev_idx in range(torch.cuda.device_count()): tensor_list.append(torch.FloatTensor([1]).cuda(dev_idx)) dist.all_reduce_multigpu(tensor_list) 代码节点上运行1 import torch import torch.distributed as dist dist.init_process_group(backend=\"nccl\", init_method=\"file:///distributed_test\", world_size=2, rank=1) tensor_list = [] for dev_idx in range(torch.cuda.device_count()): tensor_list.append(torch.FloatTensor([1]).cuda(dev_idx)) dist.all_reduce_multigpu(tensor_list) 通话结束后，两个节点上的所有16张量将有16的全价值降低 torch.distributed.``broadcast_multigpu( tensor_list , src , _group= , _async_op=False , src_tensor=0 )[source] 广播张量与每节点的多个GPU张量全组。 张量必须具有相同数目的在从参与集体的所有进程的所有的GPU元件。列表中的每个张量必须在不同的GPU 只有NCCL和GLOO后端目前支持张量应该只是GPU张量 Parameters tensor_list （ 列表 [ 张量 __ ） - 参与集体张量操作。如果SRC是秩，则tensor_list指定src_tensor元素（ tensor_list [src_tensor]）将被广播到在src过程的所有其他张量（在不同的GPU）和所有张量在tensor_list的其它非SRC过程。您还需要确保LEN（tensor_list）HTG34]是所有分布式进程调用此函数相同。 src ( int) – Source rank. group ( ProcessGroup , optional ) – The process group to work on async_op ( bool , optional ) – Whether this op should be an async op src_tensor （ INT ， 可选 ） - tensor_list内源张量秩 Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group torch.distributed.``all_reduce_multigpu( tensor_list , op=ReduceOp.SUM , group= , async_op=False )[source] 减少以这样的方式，所有得到最终结果在所有机器上的数据张。此功能可降低一个数量的每个节点上的张量，而每个张量驻留在不同的GPU。因此，在张量列表中输入张量需要为GPU张量。此外，在张量列表中的每个张量需要驻留在不同的GPU。 通话结束后，所有张量在tensor_list将被逐位在所有过程是相同的。 只有NCCL和GLOO后端目前支持张量应该只是GPU张量 Parameters 列表 （ 张量 ） - 集体的输入和输出张量的列表。功能就地操作，并且要求每个张量，以在不同的GPU一个GPU张量。您还需要确保LEN（tensor_list）HTG6]是所有分布式进程调用此函数相同。 op ( optional ) – One of the values from torch.distributed.ReduceOpenum. Specifies an operation used for element-wise reductions. group ( ProcessGroup , optional ) – The process group to work on async_op ( bool , optional ) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group torch.distributed.``reduce_multigpu( tensor_list , dst , op=ReduceOp.SUM , group= , async_op=False , dst_tensor=0 )[source] 减少了对所有机器多个GPU张量数据。在[HTG1每一张量tensor_list应该驻留在单独的GPU 的只有GPU tensor_list [dst_tensor]与位次DST将要接收的最终结果的过程。 目前仅支持NCCL后端张量应该只是GPU张量 Parameters tensor_list （ 列表 [ 张量 __ ） - 的输入和输出GPU张量集体。该函数就地操作。您还需要确保LEN（tensor_list）HTG14]是所有分布式进程调用此函数相同。 dst ( int) – Destination rank op ( optional ) – One of the values from torch.distributed.ReduceOpenum. Specifies an operation used for element-wise reductions. group ( ProcessGroup , optional ) – The process group to work on async_op ( bool , optional ) – Whether this op should be an async op dst_tensor （ INT ， 可选 ） - tensor_list内目的地张量秩 Returns 异步工作手柄，如果async_op设置为True。无，否则 torch.distributed.``all_gather_multigpu( output_tensor_lists , input_tensor_list , group= , async_op=False )[source] 汇集了来自全团张量在列表中。在[HTG1每一张量tensor_list应该驻留在单独的GPU Only nccl backend is currently supported tensors should only be GPU tensors Parameters output_tensor_lists （ 列表 [ 列表 [ 张量 ） - 输出列表。它应包含在每个GPU正确大小的张量要用于集体，例如输出output_tensor_lists [I]包含驻留在的input_tensor_list [I]GPU上的all_gather结果。 需要注意的是output_tensor_lists 的每个元件具有的world_size LEN（input_tensor_list）的大小 ，因为该函数的所有收集来自该组中的每一个GPU的结果。为了解释的每个元素output_tensor_lists [I]，请注意， input_tensor_list [j]的 秩k将是出现在output_tensor_lists [I] [K world_size + j]的 `` 还要注意的是LEN（output_tensor_lists）和in 的每个元件的尺寸output_tensor_lists（每个元素是一个列表，因此LEN（output_tensor_lists [I]））必须对所有的分布式进程调用此函数是相同的。 input_tensor_list （ 列表 [ 张量 __ ） - 张量的列表（在不同的图形处理器），以从当前进程广播。需要注意的是LEN（input_tensor_list）HTG14]需要为所有的分布式进程调用此函数相同。 group ( ProcessGroup , optional ) – The process group to work on async_op ( bool , optional ) – Whether this op should be an async op Returns Async work handle, if async_op is set to True. None, if not async_op or if not part of the group 启动程序 的 torch.distributed 包还提供了在 torch.distributed.launch 发射工具。这个辅助工具可以用来启动每个节点的多个进程的分布式训练。此实用程序还支持python2和python3。 衍生实用程序 的 torch.multiprocessing 包还提供了菌种函数在 torch.multiprocessing.spawn（） 。这个辅助函数可以用来产卵多个进程。其工作原理是通过在要运行，并产生数处理运行它的功能。这可以用于多进程分布式训练为好。 有关如何使用它的引用，请参考 PyTorch例子 - ImageNet实现 请注意，此功能需要Python 3.4或更高版本。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributions.html":{"url":"distributions.html","title":"torch.distributions","keywords":"","body":"概率分布 - torch.distributions 的分布包中包含参数化概率分布和采样函数。这使得随机计算图形和优化随机梯度估计的建设。这个软件包通常遵循 TensorFlow分布包裹的设计。 这是不可能直接通过随机样本backpropagate。不过，也有用于创建可通过被backpropagated替代的功能主要有两种方法。这些是得分函数估计器/似然比估计器/加固和pathwise衍生物估计。加固这通常被视为在强化学习政策梯度法的基础上，与pathwise衍生估计是在变的自动编码重新参数伎俩常见。虽然得分函数仅需要的值样本 F （ × ） F（X） F （ × ） 时，pathwise衍生物需要衍生物 F ' （ × ） F'（x）的 F ' （ × ） 。接下来的章节中增强学习的榜样讨论这两个。欲了解更多详情，请参阅[梯度估计使用随机计算图形HTG97。 得分函数 当概率密度函数是可微分的相对于它的参数，我们只需要样品（）和log_prob（）实施加固： Δθ=αr∂log⁡p(a∣πθ(s))∂θ\\Delta\\theta = \\alpha r \\frac{\\partial\\log p(a|\\pi^\\theta(s))}{\\partial\\theta}Δθ=αr∂θ∂logp(a∣πθ(s))​ 其中 θ \\ THETA θ 为参数， α \\阿尔法 α 是学习速率， R R R 是奖励和 p （ 一 | π θ （ S ） ） P（A | \\ PI ^ \\ THETA（S）） P （ 一 | π θ （ S ） ） 是服用概率操作 一个 一 一 在状态 S S S 给定的策略 π θ \\ PI ^ \\ THETA π θ 。 在实践中，我们将采样来自一个网络的输出的动作，在一个环境中应用该动作，然后用log_prob构造的等效损失函数。注意，我们使用一个负的，因为优化使用梯度下降，而上面的规则假定梯度上升。有了明确的政策，实施加固将如下代码： probs = policy_network(state) # Note that this is equivalent to what used to be called multinomial m = Categorical(probs) action = m.sample() next_state, reward = env.step(action) loss = -m.log_prob(action) * reward loss.backward() Pathwise衍生物 实现这些随机/策略梯度的另一种方法是使用从R样品的重新参数化特技（）的方法，其中所述参数化的随机变量可以通过的一个参数确定的函数构造一个无参数的随机变量。因此，重新参数化样本变为微的。用于实现pathwise衍生物将如下所示的代码： params = policy_network(state) m = Normal(*params) # Any distribution with .has_rsample == True could work based on the application action = m.rsample() next_state, reward = env.step(action) # Assuming that reward is differentiable loss = -reward loss.backward() 发行 classtorch.distributions.distribution.``Distribution( batch_shape=torch.Size([]) , event_shape=torch.Size([]) , validate_args=None )[source] 碱： 对象 分布是概率分布的抽象基类。 propertyarg_constraints 返回从参数名字典来 应该由这种分配的每个参数满足约束对象。参数数量不属于张量不必出现在这个字典。 propertybatch_shape 返回在其参数是成批的形状。 cdf( value )[source] 返回在值评价的累积密度/质量函数。 Parameters 值 （ 张量 ） - entropy()[source] 返回分布的熵，批处理过batch_shape。 Returns 形状batch_shape的张量。 enumerate_support( expand=True )[source] 包含由离散分布支持的所有值返回张量。其结果将枚举尺寸0，所以结果的形状将是（基数）+ batch_shape + event_shape （其中 event_shape =（）[HTG3用于单变量分布）。 请注意，此枚举在所有分批张量在锁步 [0,0]，[1,1]，...] [HTG1。与扩大=假，枚举沿着昏暗0发生，但与剩余批次尺寸是单尺寸， [[0]，[1]，.. 。 来遍历充分笛卡尔乘积使用 itertools.product（m.enumerate_support（））。 Parameters 展开 （ 布尔 ） - 是否在批量变暗以匹配分配的 batch_shape 扩展支持。 Returns 张量循环访问尺寸0。 propertyevent_shape 返回单个样品（无配料）的形状。 expand( batch_shape , _instance=None )[source] 返回一个新的分配实例（或填充由派生类提供的现有实例）具有扩展为 batchshape 批次的尺寸。此方法调用 展开 上分布的参数。因此，这不适用于扩大分销实例分配新的内存。此外，此不赘述任何ARGS检查或 _init.py 参数广播中，首先创建一个实例时。 Parameters batch_shape （ torch.Size ） - 所需的扩展的大小。 _instance - 由需要重写 .expand 子提供了新的实例。 Returns 有一批新的尺寸分布例如扩大到的batch_size [HTG1。 icdf( value )[source] 返回在值评估了逆累积密度/质量函数。 Parameters value ( Tensor) – log_prob( value )[source] 返回在值评估的概率密度/质量函数的对数。 Parameters value ( Tensor) – propertymean 返回分布的均值。 perplexity()[source] 返回分布的困惑，分批在batch_shape。 Returns Tensor of shape batch_shape. rsample( sample_shape=torch.Size([]) )[source] 生成sample_shape形重新参数化样本或sample_shape形批量重新参数化的样本，如果分布参数是成批的。 sample( sample_shape=torch.Size([]) )[source] 生成样本的sample_shape形样品或sample_shape形批次如果分布参数是成批的。 sample_n( n )[source] 生成n个样本或样品的n个批次如果分布参数是成批的。 propertystddev 返回分布的标准偏差。 propertysupport 返回表示此发行版的支持 约束对象。 propertyvariance 返回分布的方差。 ExponentialFamily classtorch.distributions.exp_family.``ExponentialFamily( batch_shape=torch.Size([]) , event_shape=torch.Size([]) , validate_args=None )[source] 碱： torch.distributions.distribution.Distribution ExponentialFamily为属于一个指数族，其概率质量的概率分布的抽象基类/密度函数具有下面定义的形式 pF(x;θ)=exp⁡(⟨t(x),θ⟩−F(θ)+k(x))p_{F}(x; \\theta) = \\exp(\\langle t(x), \\theta\\rangle - F(\\theta) + k(x))pF​(x;θ)=exp(⟨t(x),θ⟩−F(θ)+k(x)) 其中 θ \\ THETA θ 表示自然的参数， T （ × ） T（X） T （ × ） 表示充分统计量， F （ θ ） F（\\ THETA） F （ θ ） 是日志归一化本功能离子对于给定的家庭和 K （ × ） K（x）的 K （ × ） 是载波度量。 注意 这个类是分布之间的媒介类和属于一个指数家庭主要是检查 .entropy（）和分析KL散方法的正确性分布。我们使用这个类来计算熵和使用AD框架KL信息量和布雷格曼分歧（礼貌：弗兰克·尼尔森和理查德·诺克，熵和指数家庭交叉熵）。 entropy()[source] 方法来计算使用日志归一化的布雷格曼发散熵。 伯努利 classtorch.distributions.bernoulli.``Bernoulli( probs=None , logits=None , validate_args=None )[source] 碱： torch.distributions.exp_family.ExponentialFamily 创建一个伯努利分布由 probs参数或 logits（但不是两者） 。 样品是二进制（0或1）。他们采取值 1 的概率 P 和 0 的概率 1 - P 。 例： >>> m = Bernoulli(torch.tensor([0.3])) >>> m.sample() # 30% chance 1; 70% chance 0 tensor([ 0.]) Parameters probs （ 号码 ， 张量 ） - 抽样的概率 1 logits （ 号码 ， 张量 ） - 采样的对数比值 1 arg_constraints= {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0)} entropy()[source] enumerate_support( expand=True )[source] expand( batch_shape , _instance=None )[source] has_enumerate_support= True log_prob( value )[source] logits[source] propertymean propertyparam_shape probs[source] sample( sample_shape=torch.Size([]) )[source] support= Boolean() propertyvariance 贝塔 classtorch.distributions.beta.``Beta( concentration1 , concentration0 , validate_args=None )[source] Bases: torch.distributions.exp_family.ExponentialFamily β分布由 参数concentration1和 concentration0。 Example: >>> m = Beta(torch.tensor([0.5]), torch.tensor([0.5])) >>> m.sample() # Beta distributed with concentration concentration1 and concentration0 tensor([ 0.1046]) Parameters concentration1 （ 浮动 或 张量 ） - 的分布的第一浓度参数（常称为α） concentration0 （ 浮动 或 张量 ） - 分配的第二浓度参数（通常被称为测试版） arg_constraints= {'concentration0': GreaterThan(lower_bound=0.0), 'concentration1': GreaterThan(lower_bound=0.0)} propertyconcentration0 propertyconcentration1 entropy()[source] expand( batch_shape , _instance=None )[source] has_rsample= True log_prob( value )[source] propertymean rsample( sample_shape=() )[source] support= Interval(lower_bound=0.0, upper_bound=1.0) propertyvariance 二项式 classtorch.distributions.binomial.``Binomial( total_count=1 , probs=None , logits=None , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 创建一个二项分布由TOTAL_COUNT和参数为 probs或 logits（但不是两者）。 TOTAL_COUNT必须broadcastable与 probs/logits。 Example: >>> m = Binomial(100, torch.tensor([0 , .2, .8, 1])) >>> x = m.sample() tensor([ 0., 22., 71., 100.]) >>> m = Binomial(torch.tensor([[5.], [10.]]), torch.tensor([0.5, 0.8])) >>> x = m.sample() tensor([[ 4., 5.], [ 7., 6.]]) Parameters TOTAL_COUNT （ INT 或 张量 ） - 数目的伯努利试验的 probs （ 张量 ） - 事件概率 logits （ 张量 ） - 事件日志赔率 arg_constraints= {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0), 'total_count': IntegerGreaterThan(lower_bound=0)} enumerate_support( expand=True )[source] expand( batch_shape , _instance=None )[source] has_enumerate_support= True log_prob( value )[source] logits[source] propertymean propertyparam_shape probs[source] sample( sample_shape=torch.Size([]) )[source] propertysupport propertyvariance 范畴 classtorch.distributions.categorical.``Categorical( probs=None , logits=None , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 创建由任一 probs或 logits（但不是两者参数化的分类分配）。 Note 它相当于分布 torch.multinomial（）样本。 样品是整数，从 { 0 ， ... ， K - 1 } \\ {0，\\ ldots，K- 1 \\} { 0 ， ... ， K - 1 } 其中 K 是probs.size（-1）。 如果 probs是1D与长度 - K ，每一个元素是该索引处采样的类的相对概率。 如果 probs是2D，它被处理为批量相对概率向量。 Note probs必须是非负的，有限的，并且有一个非零和，并且将被归一化总和为1。 参见： torch.multinomial（） Example: >>> m = Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ])) >>> m.sample() # equal probability of 0, 1, 2, 3 tensor(3) Parameters probs （ 张量 ） - 事件概率 logits （ 张量 ） - 事件日志赔率 arg_constraints= {'logits': Real(), 'probs': Simplex()} entropy()[source] enumerate_support( expand=True )[source] expand( batch_shape , _instance=None )[source] has_enumerate_support= True log_prob( value )[source] logits[source] propertymean propertyparam_shape probs[source] sample( sample_shape=torch.Size([]) )[source] propertysupport propertyvariance 柯西 classtorch.distributions.cauchy.``Cauchy( loc , scale , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 从柯西（洛仑兹）分布的样品。独立正态分布的随机变量的装置的比的分布0 如下柯西分布。 Example: >>> m = Cauchy(torch.tensor([0.0]), torch.tensor([1.0])) >>> m.sample() # sample from a Cauchy distribution with loc=0 and scale=1 tensor([ 2.3214]) Parameters LOC （ 浮动 或 张量 ） - 模式或分布的中值。 规模 （ 浮动 或 张量 ） - 半峰半宽。 arg_constraints= {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)} cdf( value )[source] entropy()[source] expand( batch_shape , _instance=None )[source] has_rsample= True icdf( value )[source] log_prob( value )[source] propertymean rsample( sample_shape=torch.Size([]) )[source] support= Real() propertyvariance χ2 classtorch.distributions.chi2.``Chi2( df , validate_args=None )[source] 碱： torch.distributions.gamma.Gamma 创建由形状参数 DF参数化的χ2分布。这是完全等同于伽玛（阿尔法= 0.5 * df，则 的β= 0.5） Example: >>> m = Chi2(torch.tensor([1.0])) >>> m.sample() # Chi2 distributed with shape df=1 tensor([ 0.1046]) Parameters DF （ 浮动 或 张量 ） - 分布的形状参数 arg_constraints= {'df': GreaterThan(lower_bound=0.0)} propertydf expand( batch_shape , _instance=None )[source] 狄利克雷 classtorch.distributions.dirichlet.``Dirichlet( concentration , validate_args=None )[source] Bases: torch.distributions.exp_family.ExponentialFamily 创建由浓度浓度参数化的狄利克雷分布。 Example: >>> m = Dirichlet(torch.tensor([0.5, 0.5])) >>> m.sample() # Dirichlet distributed with concentrarion concentration tensor([ 0.1046, 0.8954]) Parameters 浓度 （ 张量 ） - 分布的浓度参数（通常称为α） arg_constraints= {'concentration': GreaterThan(lower_bound=0.0)} entropy()[source] expand( batch_shape , _instance=None )[source] has_rsample= True log_prob( value )[source] propertymean rsample( sample_shape=() )[source] support= Simplex() propertyvariance 指数 classtorch.distributions.exponential.``Exponential( rate , validate_args=None )[source] Bases: torch.distributions.exp_family.ExponentialFamily 创建由速率参数化的指数分布。 Example: >>> m = Exponential(torch.tensor([1.0])) >>> m.sample() # Exponential distributed with rate=1 tensor([ 0.1046]) Parameters 速率 （ 浮动 或 张量 ） - 率= 1 /刻度分配 arg_constraints= {'rate': GreaterThan(lower_bound=0.0)} cdf( value )[source] entropy()[source] expand( batch_shape , _instance=None )[source] has_rsample= True icdf( value )[source] log_prob( value )[source] propertymean rsample( sample_shape=torch.Size([]) )[source] propertystddev support= GreaterThan(lower_bound=0.0) propertyvariance FisherSnedecor classtorch.distributions.fishersnedecor.``FisherSnedecor( df1 , df2 , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 创建由DF1和DF2参数化的费雪分布。 Example: >>> m = FisherSnedecor(torch.tensor([1.0]), torch.tensor([2.0])) >>> m.sample() # Fisher-Snedecor-distributed with df1=1 and df2=2 tensor([ 0.2453]) Parameters DF1 （ 浮动 或 张量 ） - 自由度参数1的 DF2 （ 浮动 或 张量 ） - 自由度参数2的 arg_constraints= {'df1': GreaterThan(lower_bound=0.0), 'df2': GreaterThan(lower_bound=0.0)} expand( batch_shape , _instance=None )[source] has_rsample= True log_prob( value )[source] propertymean rsample( sample_shape=torch.Size([]) )[source] support= GreaterThan(lower_bound=0.0) propertyvariance 伽玛 classtorch.distributions.gamma.``Gamma( concentration , rate , validate_args=None )[source] Bases: torch.distributions.exp_family.ExponentialFamily 创建由形状浓度参数和速率一个Gamma分布。 Example: >>> m = Gamma(torch.tensor([1.0]), torch.tensor([1.0])) >>> m.sample() # Gamma distributed with concentration=1 and rate=1 tensor([ 0.1046]) Parameters 浓度 （ 浮动 或 张量 ） - 分布的形状参数（通常称为α） 速率 （ 浮动 或 张量 ） - 率= 1 /刻度分布（通常被称为测试版） arg_constraints= {'concentration': GreaterThan(lower_bound=0.0), 'rate': GreaterThan(lower_bound=0.0)} entropy()[source] expand( batch_shape , _instance=None )[source] has_rsample= True log_prob( value )[source] propertymean rsample( sample_shape=torch.Size([]) )[source] support= GreaterThan(lower_bound=0.0) propertyvariance 几何 classtorch.distributions.geometric.``Geometric( probs=None , logits=None , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 创建一个几何分布由参数 probs，其中 probs是的概率伯努利试验的成功。它代表在 K + 1 的概率 K + 1 K + 1 伯努利试验，第一个 K K ķ 试验看到一个成功之前失败。 样品是一个非负整数[0， INF ⁡ \\ INF 在 F ） 。 Example: >>> m = Geometric(torch.tensor([0.3])) >>> m.sample() # underlying Bernoulli has 30% chance 1; 70% chance 0 tensor([ 2.]) Parameters probs （ 号码 ， 张量 ） - 取样 1 的概率。必须在范围（0，1] logits （ 号码 ， 张量 ） - 采样的对数比值 1 。 arg_constraints= {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0)} entropy()[source] expand( batch_shape , _instance=None )[source] log_prob( value )[source] logits[source] propertymean probs[source] sample( sample_shape=torch.Size([]) )[source] support= IntegerGreaterThan(lower_bound=0) propertyvariance 冈贝尔 classtorch.distributions.gumbel.``Gumbel( loc , scale , validate_args=None )[source] 碱： torch.distributions.transformed_distribution.TransformedDistribution 从Gumbel分布样本。 例子： >>> m = Gumbel(torch.tensor([1.0]), torch.tensor([2.0])) >>> m.sample() # sample from Gumbel distribution with loc=1, scale=2 tensor([ 1.0124]) Parameters LOC （ 浮动 或 张量 ） - 分布的位置参数 规模 （ 浮动 或 张量 ） - 分布的尺度参数 arg_constraints= {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)} entropy()[source] expand( batch_shape , _instance=None )[source] log_prob( value )[source] propertymean propertystddev support= Real() propertyvariance HalfCauchy classtorch.distributions.half_cauchy.``HalfCauchy( scale , validate_args=None )[source] Bases: torch.distributions.transformed_distribution.TransformedDistribution 创建由规模其中参数化的半正态分布： X ~ Cauchy(0, scale) Y = |X| ~ HalfCauchy(scale) Example: >>> m = HalfCauchy(torch.tensor([1.0])) >>> m.sample() # half-cauchy distributed with scale=1 tensor([ 2.3214]) Parameters 规模 （ 浮动 或 张量 ） - 全柯西分布的尺度 arg_constraints= {'scale': GreaterThan(lower_bound=0.0)} cdf( value )[source] entropy()[source] expand( batch_shape , _instance=None )[source] has_rsample= True icdf( prob )[source] log_prob( value )[source] propertymean propertyscale support= GreaterThan(lower_bound=0.0) propertyvariance HalfNormal classtorch.distributions.half_normal.``HalfNormal( scale , validate_args=None )[source] Bases: torch.distributions.transformed_distribution.TransformedDistribution Creates a half-normal distribution parameterized by scale where: X ~ Normal(0, scale) Y = |X| ~ HalfNormal(scale) Example: >>> m = HalfNormal(torch.tensor([1.0])) >>> m.sample() # half-normal distributed with scale=1 tensor([ 0.1046]) Parameters 规模 （ 浮动 或 张量 ） - 全正态分布的规模 arg_constraints= {'scale': GreaterThan(lower_bound=0.0)} cdf( value )[source] entropy()[source] expand( batch_shape , _instance=None )[source] has_rsample= True icdf( prob )[source] log_prob( value )[source] propertymean propertyscale support= GreaterThan(lower_bound=0.0) propertyvariance 独立 classtorch.distributions.independent.``Independent( base_distribution , reinterpreted_batch_ndims , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 重新诠释一些分布作为事件DIMS的一批DIMS的。 这是用于改变 log_prob（）结果的形状主要是有用的。例如，要创建一个具有相同形状的对角线正态分布为多元正态分布（这样它们可以互换），您可以： >>> loc = torch.zeros(3) >>> scale = torch.ones(3) >>> mvn = MultivariateNormal(loc, scale_tril=torch.diag(scale)) >>> [mvn.batch_shape, mvn.event_shape] [torch.Size(()), torch.Size((3,))] >>> normal = Normal(loc, scale) >>> [normal.batch_shape, normal.event_shape] [torch.Size((3,)), torch.Size(())] >>> diagn = Independent(normal, 1) >>> [diagn.batch_shape, diagn.event_shape] [torch.Size(()), torch.Size((3,))] Parameters base_distribution （ torch.distributions.distribution.Distribution ） - 碱分布 reinterpreted_batch_ndims （ INT ） - 批次的数量变暗以重新解释作为事件变暗 arg_constraints= {} entropy()[source] enumerate_support( expand=True )[source] expand( batch_shape , _instance=None )[source] propertyhas_enumerate_support propertyhas_rsample log_prob( value )[source] propertymean rsample( sample_shape=torch.Size([]) )[source] sample( sample_shape=torch.Size([]) )[source] propertysupport propertyvariance 拉普拉斯 classtorch.distributions.laplace.``Laplace( loc , scale , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 创建由LOC和参数化的拉普拉斯分布：ATTR：”缩放”。 Example: >>> m = Laplace(torch.tensor([0.0]), torch.tensor([1.0])) >>> m.sample() # Laplace distributed with loc=0, scale=1 tensor([ 0.1046]) Parameters LOC （ 浮动 或 张量 ） - 分布的平均 规模 （ 浮动 或 张量 ） - 分布的尺度 arg_constraints= {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)} cdf( value )[source] entropy()[source] expand( batch_shape , _instance=None )[source] has_rsample= True icdf( value )[source] log_prob( value )[source] propertymean rsample( sample_shape=torch.Size([]) )[source] propertystddev support= Real() propertyvariance 对数正态分布 classtorch.distributions.log_normal.``LogNormal( loc , scale , validate_args=None )[source] Bases: torch.distributions.transformed_distribution.TransformedDistribution 创建一个日志正态分布由参数 LOC和 规模其中： X ~ Normal(loc, scale) Y = exp(X) ~ LogNormal(loc, scale) Example: >>> m = LogNormal(torch.tensor([0.0]), torch.tensor([1.0])) >>> m.sample() # log-normal distributed with mean=0 and stddev=1 tensor([ 0.1046]) Parameters LOC （ 浮动 或 张量 ） - 平均log分布的 规模 （ 浮动 或 张量 ） - 日志中的分布的标准偏差 arg_constraints= {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)} entropy()[source] expand( batch_shape , _instance=None )[source] has_rsample= True propertyloc propertymean propertyscale support= GreaterThan(lower_bound=0.0) propertyvariance LowRankMultivariateNormal classtorch.distributions.lowrank_multivariate_normal.``LowRankMultivariateNormal( loc , cov_factor , cov_diag , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 创建具有由cov_factor和参数化的低秩形式协方差矩阵多元正态分布cov_diag： covariance_matrix = cov_factor @ cov_factor.T + cov_diag 例 >>> m = LowRankMultivariateNormal(torch.zeros(2), torch.tensor([1, 0]), torch.tensor([1, 1])) >>> m.sample() # normally distributed with mean=`[0,0]`, cov_factor=`[1,0]`, cov_diag=`[1,1]` tensor([-0.2102, -0.5429]) Parameters LOC （ 张量 ） - 与形状分布的平均值 batch_shape + event_shape cov_factor （ 张量 ） - 具有形状 batch_shape + event_shape +（秩）协方差矩阵的低秩形式因子部分 cov_diag （ 张量 ） - 具有形状协方差矩阵的低秩的形式对角部分 batch_shape + event_shape Note 用于行列式和协方差矩阵的逆的计算，避免当 cov_factor.shape [1] & LT ; & LT ; cov_factor.shape [0] 由于 Woodbury的矩阵身份和矩阵行列式引理。由于这些公式，我们只需要计算小尺寸“电容”矩阵的行列式和逆： capacitance = I + cov_factor.T @ inv(cov_diag) @ cov_factor arg_constraints= {'cov_diag': GreaterThan(lower_bound=0.0), 'cov_factor': Real(), 'loc': Real()} covariance_matrix[source] entropy()[source] expand( batch_shape , _instance=None )[source] has_rsample= True log_prob( value )[source] propertymean precision_matrix[source] rsample( sample_shape=torch.Size([]) )[source] scale_tril[source] support= Real() variance[source] 多项式 classtorch.distributions.multinomial.``Multinomial( total_count=1 , probs=None , logits=None , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 创建一个多项分布由TOTAL_COUNT和参数为 probs或 logits（但不是两者）。 probs 索引超过类别 最内尺寸。所有其他尺寸价格指数比批次。 注意，TOTAL_COUNT不必如果只 log_prob（）被称为指定（见下面例子） Note probs必须是非负的，有限的，并且有一个非零和，并且将被归一化总和为1。 样品（）需要一个单一的共享 TOTAL_COUNT 所有参数和样品。 log_prob（）允许为每个参数和样品不同 TOTAL_COUNT 。 Example: >>> m = Multinomial(100, torch.tensor([ 1., 1., 1., 1.])) >>> x = m.sample() # equal probability of 0, 1, 2, 3 tensor([ 21., 24., 30., 25.]) >>> Multinomial(probs=torch.tensor([1., 1., 1., 1.])).log_prob(x) tensor([-4.1338]) Parameters TOTAL_COUNT （ INT ） - 的实验中 probs ( Tensor) – event probabilities logits （ 张量 ） - 事件数概率 arg_constraints= {'logits': Real(), 'probs': Simplex()} expand( batch_shape , _instance=None )[source] log_prob( value )[source] propertylogits propertymean propertyparam_shape propertyprobs sample( sample_shape=torch.Size([]) )[source] propertysupport propertyvariance MultivariateNormal classtorch.distributions.multivariate_normal.``MultivariateNormal( loc , covariance_matrix=None , precision_matrix=None , scale_tril=None , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 创建一个多变量正态分布（也称为高斯分布）由一个平均向量和协方差矩阵参数分布。 多元正态分布可以在正定协方差矩阵 Σ \\ mathbf {方面来参数化\\西格玛} Σ 或正定精度矩阵 Σ - 1 \\ mathbf {\\西格玛} ^ { - 1} Σ - 1 或下三角矩阵 [HTG8 5] L \\ mathbf {L} L 具有正值对角项，使得 Σ = L L ⊤ \\ mathbf {\\西格玛} = \\ mathbf {L} \\ mathbf {L} ^ \\顶 Σ = L L ⊤ 。这个三角矩阵可以通过例如获得协方差的Cholesky分解。 Example >>> m = MultivariateNormal(torch.zeros(2), torch.eye(2)) >>> m.sample() # normally distributed with mean=`[0,0]`and covariance_matrix=`I` tensor([-0.2102, -0.5429]) Parameters LOC （ 张量 ） - 分布的平均 covariance_matrix （ 张量 ） - 正定协方差矩阵 precision_matrix （ 张量 ） - 正定矩阵精度 scale_tril （ 张量 ） - 协方差的下三角因子，具有正值的对角 Note 只有 covariance_matrix或 precision_matrix或 酮 scale_tril可以被指定。 使用 scale_tril将更有效率：所有计算内部是基于 scale_tril。如果 covariance_matrix 或 precision_matrix被传递，相反，它只是用来计算相应的使用Cholesky分解下三角矩阵。 arg_constraints= {'covariance_matrix': PositiveDefinite(), 'loc': RealVector(), 'precision_matrix': PositiveDefinite(), 'scale_tril': LowerCholesky()} covariance_matrix[source] entropy()[source] expand( batch_shape , _instance=None )[source] has_rsample= True log_prob( value )[source] propertymean precision_matrix[source] rsample( sample_shape=torch.Size([]) )[source] scale_tril[source] support= Real() propertyvariance NegativeBinomial classtorch.distributions.negative_binomial.``NegativeBinomial( total_count , probs=None , logits=None , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 创建一个负二项分布，即TOTAL_COUNT得以实现故障之前需要独立同伯努利试验数目的分布。每个伯努利试验的成功的概率是 probs。 Parameters TOTAL_COUNT （ 浮动 或 张量 ） - 负伯努利的非负数试验停止，虽然分布仍然是成立的实值计 probs （ 张量 ） - 在半开区间[0成功的事件概率，1） logits （ 张量 ） - 事件日志把握成功的概率 arg_constraints= {'logits': Real(), 'probs': HalfOpenInterval(lower_bound=0.0, upper_bound=1.0), 'total_count': GreaterThanEq(lower_bound=0)} expand( batch_shape , _instance=None )[source] log_prob( value )[source] logits[source] propertymean propertyparam_shape probs[source] sample( sample_shape=torch.Size([]) )[source] support= IntegerGreaterThan(lower_bound=0) propertyvariance 正常 classtorch.distributions.normal.``Normal( loc , scale , validate_args=None )[source] Bases: torch.distributions.exp_family.ExponentialFamily 创建普通的（也称为高斯分布）由LOC和规模参数化分布。 Example: >>> m = Normal(torch.tensor([0.0]), torch.tensor([1.0])) >>> m.sample() # normally distributed with loc=0 and scale=1 tensor([ 0.1046]) Parameters LOC （ 浮动 或 张量 ） - 的分布的平均值（通常称为作为亩） 规模 （ 浮动 或 张量 ） - 的分布的标准偏差（通常称为西格马） arg_constraints= {'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)} cdf( value )[source] entropy()[source] expand( batch_shape , _instance=None )[source] has_rsample= True icdf( value )[source] log_prob( value )[source] propertymean rsample( sample_shape=torch.Size([]) )[source] sample( sample_shape=torch.Size([]) )[source] propertystddev support= Real() propertyvariance OneHotCategorical classtorch.distributions.one_hot_categorical.``OneHotCategorical( probs=None , logits=None , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 创建由 参数化的独热分类分布probs或 logits。 样品独热编码大小的矢量probs.size（-1）。 Note probs必须是非负的，有限的，并且有一个非零和，并且将被归一化总和为1。 参见：torch.distributions.Categorical（） [HTG3用于probs的规范 和logits。 Example: >>> m = OneHotCategorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ])) >>> m.sample() # equal probability of 0, 1, 2, 3 tensor([ 0., 0., 0., 1.]) Parameters probs ( Tensor) – event probabilities logits ( Tensor) – event log probabilities arg_constraints= {'logits': Real(), 'probs': Simplex()} entropy()[source] enumerate_support( expand=True )[source] expand( batch_shape , _instance=None )[source] has_enumerate_support= True log_prob( value )[source] propertylogits propertymean propertyparam_shape propertyprobs sample( sample_shape=torch.Size([]) )[source] support= Simplex() propertyvariance 帕累托 classtorch.distributions.pareto.``Pareto( scale , alpha , validate_args=None )[source] Bases: torch.distributions.transformed_distribution.TransformedDistribution 从帕累托1型分布的样品。 Example: >>> m = Pareto(torch.tensor([1.0]), torch.tensor([1.0])) >>> m.sample() # sample from a Pareto distribution with scale=1 and alpha=1 tensor([ 1.5623]) Parameters scale ( float or Tensor) – Scale parameter of the distribution 阿尔法 （ 浮动 或 张量 ） - 分布的形状参数 arg_constraints= {'alpha': GreaterThan(lower_bound=0.0), 'scale': GreaterThan(lower_bound=0.0)} entropy()[source] expand( batch_shape , _instance=None )[source] propertymean propertysupport propertyvariance 泊松 classtorch.distributions.poisson.``Poisson( rate , validate_args=None )[source] Bases: torch.distributions.exp_family.ExponentialFamily 创建由速率，速率参数参数化的泊松分布。 样品为非负整数，由给定PMF rateke−ratek!\\mathrm{rate}^k \\frac{e^{-\\mathrm{rate}}}{k!} ratekk!e−rate​ Example: >>> m = Poisson(torch.tensor([4])) >>> m.sample() tensor([ 3.]) Parameters 速率 （ 号码 ， 张量 ） - 速率参数 arg_constraints= {'rate': GreaterThan(lower_bound=0.0)} expand( batch_shape , _instance=None )[source] log_prob( value )[source] propertymean sample( sample_shape=torch.Size([]) )[source] support= IntegerGreaterThan(lower_bound=0) propertyvariance RelaxedBernoulli classtorch.distributions.relaxed_bernoulli.``RelaxedBernoulli( temperature , probs=None , logits=None , validate_args=None )[source] Bases: torch.distributions.transformed_distribution.TransformedDistribution 创建RelaxedBernoulli分布，由 温度参数化的，并且或者 probs或 logits （但不是两者）。这是伯努利分布的松弛版本，所以这些值是（0，1），并且具有reparametrizable样品。 Example: >>> m = RelaxedBernoulli(torch.tensor([2.2]), torch.tensor([0.1, 0.2, 0.3, 0.99])) >>> m.sample() tensor([ 0.2951, 0.3442, 0.8918, 0.9021]) Parameters 温度 （ 张量 ） - 松弛温度 probs ( Number , Tensor) – the probability of sampling 1 logits ( Number , Tensor) – the log-odds of sampling 1 arg_constraints= {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0)} expand( batch_shape , _instance=None )[source] has_rsample= True propertylogits propertyprobs support= Interval(lower_bound=0.0, upper_bound=1.0) propertytemperature LogitRelaxedBernoulli classtorch.distributions.relaxed_bernoulli.``LogitRelaxedBernoulli( temperature , probs=None , logits=None , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 创建LogitRelaxedBernoulli分布由参数 probs或 logits（但不是两者） ，这是一个RelaxedBernoulli分布的分对数。 样品是在（0，1）的值的logits。见[1]的更多细节。 Parameters temperature ( Tensor) – relaxation temperature probs ( Number , Tensor) – the probability of sampling 1 logits ( Number , Tensor) – the log-odds of sampling 1 [1]的具体分布：离散随机变量的连续松弛（麦迪逊等人，2017） [2]范畴重新参数化与冈贝尔-使用SoftMax（Jang等，2017） arg_constraints= {'logits': Real(), 'probs': Interval(lower_bound=0.0, upper_bound=1.0)} expand( batch_shape , _instance=None )[source] log_prob( value )[source] logits[source] propertyparam_shape probs[source] rsample( sample_shape=torch.Size([]) )[source] support= Real() RelaxedOneHotCategorical classtorch.distributions.relaxed_categorical.``RelaxedOneHotCategorical( temperature , probs=None , logits=None , validate_args=None )[source] Bases: torch.distributions.transformed_distribution.TransformedDistribution 创建RelaxedOneHotCategorical分布通过参数化 温度，并且或者 probs或 logits。这是OneHotCategorical分布宽松的版，所以它的样品都在单一，且reparametrizable。 Example: >>> m = RelaxedOneHotCategorical(torch.tensor([2.2]), torch.tensor([0.1, 0.2, 0.3, 0.4])) >>> m.sample() tensor([ 0.1294, 0.2324, 0.3859, 0.2523]) Parameters temperature ( Tensor) – relaxation temperature probs ( Tensor) – event probabilities logits （ 张量 ） - 每个事件的对数概率。 arg_constraints= {'logits': Real(), 'probs': Simplex()} expand( batch_shape , _instance=None )[source] has_rsample= True propertylogits propertyprobs support= Simplex() propertytemperature 学生 classtorch.distributions.studentT.``StudentT( df , loc=0.0 , scale=1.0 , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 创建一个学生T分布的自由度参数DF，意思是LOC和规模量表。 Example: >>> m = StudentT(torch.tensor([2.0])) >>> m.sample() # Student's t-distributed with degrees of freedom=2 tensor([ 0.1046]) Parameters DF （ 浮动 或 张量 ） - 自由度 loc ( float or Tensor) – mean of the distribution scale ( float or Tensor) – scale of the distribution arg_constraints= {'df': GreaterThan(lower_bound=0.0), 'loc': Real(), 'scale': GreaterThan(lower_bound=0.0)} entropy()[source] expand( batch_shape , _instance=None )[source] has_rsample= True log_prob( value )[source] propertymean rsample( sample_shape=torch.Size([]) )[source] support= Real() propertyvariance TransformedDistribution classtorch.distributions.transformed_distribution.``TransformedDistribution( base_distribution , transforms , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 分发类，它适用变换的序列的碱分布的扩展。令f是施加变换的组合物： X ~ BaseDistribution Y = f(X) ~ TransformedDistribution(BaseDistribution, f) log p(Y) = log p(X) + log |det (dX/dY)| 请注意，.event_shape的 TransformedDistribution 是其碱分布及其变换的最大形状，因为变换可以介绍事件之间的相关性。 为 的使用的示例TransformedDistribution将是： # Building a Logistic Distribution # X ~ Uniform(0, 1) # f = a + b * logit(X) # Y ~ f(X) ~ Logistic(a, b) base_distribution = Uniform(0, 1) transforms = [SigmoidTransform().inv, AffineTransform(loc=a, scale=b)] logistic = TransformedDistribution(base_distribution, transforms) 对于更多的例子，请看的 冈贝尔所述实施方式中， HalfCauchy``HalfNormal， 对数正态分布， 帕累托， 威布尔， RelaxedBernoulli和 RelaxedOneHotCategorical arg_constraints= {} cdf( value )[source] 通过反转变换（S）和计算基础分布的分数计算的累积分布函数。 expand( batch_shape , _instance=None )[source] propertyhas_rsample icdf( value )[source] 计算使用变换（S）的倒数累积分布函数以及计算基分布的分数。 log_prob( value )[source] 分数通过反转变换（S）和使用所述碱分布的得分得分和日志腹肌DET雅可比样品。 rsample( sample_shape=torch.Size([]) )[source] 生成sample_shape形重新参数化样本或sample_shape形批量重新参数化的样本，如果分布参数是成批的。从基地分配样品的第一和适用变换（）为列表中的每个变换。 sample( sample_shape=torch.Size([]) )[source] 生成样本的sample_shape形样品或sample_shape形批次如果分布参数是成批的。从基地分配样品的第一和适用变换（）为列表中的每个变换。 propertysupport 统一 classtorch.distributions.uniform.``Uniform( low , high , validate_args=None )[source] Bases: torch.distributions.distribution.Distribution 生成均匀地从半开区间分布的随机样品[低， 高）。 Example: >>> m = Uniform(torch.tensor([0.0]), torch.tensor([5.0])) >>> m.sample() # uniformly distributed in the range [0.0, 5.0) tensor([ 2.3418]) Parameters 低 （ 浮动 或 张量 ） - 较低范围（含）。 高 （ 浮动 或 张量 ） - 上限范围（不包括）。 arg_constraints= {'high': Dependent(), 'low': Dependent()} cdf( value )[source] entropy()[source] expand( batch_shape , _instance=None )[source] has_rsample= True icdf( value )[source] log_prob( value )[source] propertymean rsample( sample_shape=torch.Size([]) )[source] propertystddev propertysupport propertyvariance 威布尔 classtorch.distributions.weibull.``Weibull( scale , concentration , validate_args=None )[source] Bases: torch.distributions.transformed_distribution.TransformedDistribution 从两参数Weibull分布样本。 Example >>> m = Weibull(torch.tensor([1.0]), torch.tensor([1.0])) >>> m.sample() # sample from a Weibull distribution with scale=1, concentration=1 tensor([ 0.4784]) Parameters 规模 （ 浮动 或 张量 ） - 分布（拉姆达）的尺度参数。 浓度 （ 浮动 或 张量 ） - 分配的浓度参数（k /形状）。 arg_constraints= {'concentration': GreaterThan(lower_bound=0.0), 'scale': GreaterThan(lower_bound=0.0)} entropy()[source] expand( batch_shape , _instance=None )[source] propertymean support= GreaterThan(lower_bound=0.0) propertyvariance KL散度 torch.distributions.kl.``kl_divergence( p , q )[source] 计算相对熵 K L （ P ∥ q ） KL（p \\ | q）的 K L （ p ∥ q ） [HTG47两个分布之间。 KL(p∥q)=∫p(x)log⁡p(x)q(x) dxKL(p | q) = \\int p(x) \\log\\frac {p(x)} {q(x)} \\,dxKL(p∥q)=∫p(x)logq(x)p(x)​dx Parameters P （ 发行 ） - A 发行对象。 Q （ 发行 ） - A 发行对象。 Returns 一批形状 batch_shape 的KL分歧的。 Return type 张量 Raises NotImplementedError - 如果分布类型还没有被通过 注册 register_kl（）。 torch.distributions.kl.``register_kl( type_p , type_q )[source] 装饰器注册到成对函数kl_divergence（）。用法： @register_kl(Normal, Normal) def kl_normal_normal(p, q): # insert implementation here 查找返回由子类下令最具体的（类型，类型）相匹配。如果匹配是不明确的，一个 RuntimeWarning 升高。例如为了解决模棱两可的情况： @register_kl(BaseP, DerivedQ) def kl_version1(p, q): ... @register_kl(DerivedP, BaseQ) def kl_version2(p, q): ... 要注册第三最特定的实现，例如： register_kl(DerivedP, DerivedQ)(kl_version1) # Break the tie. Parameters type_p （ 输入 ） - 的发行的子类。 type_q （ 输入 ） - 的发行的子类。 变换 classtorch.distributions.transforms.``Transform( cache_size=0 )[source] 抽象类与可计算日志DET雅可比可翻转变换。它们主要在torch.distributions.TransformedDistribution使用。 缓存是tranforms其逆要么是昂贵或数值不稳定有用。请注意，你必须要好好memoized值占用，因为autograd图可被逆转。例如，虽然有或无缓存了以下工作： y = t(x) t.log_abs_det_jacobian(x, y).backward() # x will receive gradients. 然而，由于依赖逆转缓存时，以下将错误： y = t(x) z = t.inv(y) grad(z.sum(), [y]) # error because z is x 派生类应该实现的一个或两个的_call（）或_inverse（）。该设定派生类双射=真还应当执行 log_abs_det_jacobian（）。 Parameters CACHE_SIZE （ INT ） - 高速缓存的大小。如果是零，没有缓存完成。如果为一，最新的单值缓存。只有0和1的支持。 Variables 〜Transform.domain （ 约束） - 表示有效输入此变换的约束。 〜Transform.codomain （ 约束） - 表示有效输出给此变换哪些约束被输入到逆变换。 〜Transform.bijective （ 布尔 ） - 是否此变换是双射。变换T是双射当且仅当T.INV（T（X）） == ×和T（T.INV（Y）） == Y为每一个×在陪域的域和Y。未双射变换应至少保持较弱伪逆特性T（T.INV（T（X）） == T（X）和T.INV（吨（T.INV（Y））） == T.INV（Y）。 〜Transform.sign （ INT 或 张量 ） - 对于双射变换单变量，这应该是+1或-1取决于是否变换是单调递增或递减。 〜Transform.event_dim （ INT ） - 这是在变换event_shape相关一起维数。这应该是0为逐点变换，1为共同作用于载体，2变换的变换，关于矩阵联合行动，等等。 propertyinv 返回逆 变换的此变换。这应该满足t.inv.inv 是 T。 propertysign 返回雅可比的行列式的符号，如果适用。一般而言，这不仅使为双射变换感。 log_abs_det_jacobian( x , y )[source] 计算日志DET雅可比登录| DY / DX | 给定的输入和输出。 classtorch.distributions.transforms.``ComposeTransform( parts )[source] 构成在一个链中的多个变换。所组成的变换是负责缓存。 Parameters 份 （变换的 列表） - 变换的列表组成。 classtorch.distributions.transforms.``ExpTransform( cache_size=0 )[source] 通过变换映射 Y = EXP ⁡ （ × ） Y = \\ EXP（X） Y = EXP （ × ） 。 classtorch.distributions.transforms.``PowerTransform( exponent , cache_size=0 )[source] 通过映射 Y = × 指数变换 Y = X ^ {\\文本{指数}} Y = × 指数 。 classtorch.distributions.transforms.``SigmoidTransform( cache_size=0 )[source] 通过变换映射 Y = 1 1 + 实验值 ⁡ （ - × ） Y = \\压裂{1} {1 + \\ EXP（-x）} Y = 1 + EXP （ - × ） 1 [ H T G102] 和 × = 分对数 （ Y ） ×= \\文本{分对数}（Y） × = 分对数 （ Y ） 。 classtorch.distributions.transforms.``AbsTransform( cache_size=0 )[source] 通过变换映射 Y = | × | Y = | X | Y = | × | 。 classtorch.distributions.transforms.``AffineTransform( loc , scale , event_dim=0 , cache_size=0 )[source] 通过逐点仿射映射 变换Y = LOC + 规模 × × Y = \\文本{LOC} + \\文本{规模} \\乘以x Y = LOC + 规模 × × 。 Parameters LOC （ 张量 或 浮动 ） - 位置的参数。 规模 （ 张量 或 浮动 ） - 缩放参数。 event_dim （ INT ） - 的 event_shape 可选大小。这应该是零为单变量随机变量，1用于在矢量分布，2超过矩阵等分布 classtorch.distributions.transforms.``SoftmaxTransform( cache_size=0 )[source] 通过从不受约束的空间变换至单面 Y = EXP ⁡ （ × ） Y = \\ EXP（X） Y = EXP （ × ） 然后正火。 这不是双射的，不能用于HMC。然而，这种作用主要是坐标明智（除了最后标准化），并且因此适合于坐标明智的优化算法。 classtorch.distributions.transforms.``StickBreakingTransform( cache_size=0 )[source] 通过棒折断处理从不受约束的空间转换到一个额外维的单纯。 此变换产生作为迭代乙状结肠在狄利克雷分布的棒破结构变换：第一分对数是通过乙状结肠变换到第一概率和其他一切的概率，然后处理递归。 这是双射和适合于HMC使用;但是它混合在一起的坐标，是优化不太合适。 classtorch.distributions.transforms.``LowerCholeskyTransform( cache_size=0 )[source] 从约束矩阵以下三角矩阵非负对角线项变换。 这是在他们的Cholesky分解方面参数化正定矩阵有用。 classtorch.distributions.transforms.``CatTransform( tseq , dim=0 , lengths=None )[source] 变换应用于变换的序列函子 TSEQ 逐个分量的每个子矩阵在暗淡，长度的长度[暗淡] ，与[HTG6兼容的方式] torch.cat（）。 Example:: X0 = torch.cat（[torch.range（1，10），torch.range（1，10）]，暗淡= 0）X = torch.cat（[X0，X0]，暗淡= 0）T0 = CatTransform（ [ExpTransform（），identity_transform]，暗淡= 0，长度= [10,10]）T = CatTransform（[T0，T0]，暗淡= 0，长度= [20,20]）Y = T（X） classtorch.distributions.transforms.``StackTransform( tseq , dim=0 )[source] 变换应用于变换的序列函子 TSEQ 逐个分量的每个子矩阵在暗淡的方式与 torch.stack（兼容） 。 Example:: X = torch.stack（[torch.range（1，10），torch.range（1，10）]，暗淡= 1）T = StackTransform（[ExpTransform（），identity_transform]，暗淡= 1）Y = T（ X） 约束 下面的约束来实现： constraints.boolean constraints.cat constraints.dependent constraints.greater_than（LOWER_BOUND） constraints.integer_interval（LOWER_BOUND， UPPER_BOUND） constraints.interval（LOWER_BOUND， UPPER_BOUND） constraints.lower_cholesky constraints.lower_triangular constraints.nonnegative_integer constraints.positive constraints.positive_definite constraints.positive_integer constraints.real constraints.real_vector constraints.simplex constraints.stack constraints.unit_interval classtorch.distributions.constraints.``Constraint[source] 抽象基类的约束。 约束对象表示在其上可变是有效的，例如一个区域在其内的变量可以被优化。 check( value )[source] 返回的字节张量sample_shape + batch_shape 指示是否在值满足每一个事件此约束。 torch.distributions.constraints.``dependent_property 的别名torch.distributions.constraints._DependentProperty torch.distributions.constraints.``integer_interval 的别名torch.distributions.constraints._IntegerInterval torch.distributions.constraints.``greater_than 的别名torch.distributions.constraints._GreaterThan torch.distributions.constraints.``greater_than_eq 的别名torch.distributions.constraints._GreaterThanEq torch.distributions.constraints.``less_than 的别名torch.distributions.constraints._LessThan torch.distributions.constraints.``interval 的别名torch.distributions.constraints._Interval torch.distributions.constraints.``half_open_interval 的别名torch.distributions.constraints._HalfOpenInterval torch.distributions.constraints.``cat 的别名torch.distributions.constraints._Cat torch.distributions.constraints.``stack 的别名torch.distributions.constraints._Stack 约束注册表 PyTorch提供了两个全球 ConstraintRegistry对象链接 约束对象 变换 对象。这些对象都输入约束和返回变换，但它们对双射不同的担保。 biject_to（约束）查找一个双射 变换从constraints.real为给定的约束。返回变换保证具有.bijective = 真，并执行.log_abs_det_jacobian（）。 transform_to（约束）查找未一定双射 变换从约束。真正的为给定的约束。返回的变换不能保证实现.log_abs_det_jacobian（）。 的transform_to（）注册表是上的概率分布的约束条件下参数，这是由每个分布的.arg_constraints指示执行无约束优化有用字典。这些变换通常，为了避免旋转overparameterize的空间;因此，它们更适合于坐标明智优化算法像亚当： loc = torch.zeros(100, requires_grad=True) unconstrained = torch.zeros(100, requires_grad=True) scale = transform_to(Normal.arg_constraints['scale'])(unconstrained) loss = -Normal(loc, scale).log_prob(data).sum() 的biject_to（）注册表是哈密顿蒙特卡洛，有用的，其中从具有约束。支持在一个传播的概率分布的样本不受约束的空间，和算法通常是旋转不变： dist = Exponential(rate) unconstrained = torch.zeros(100, requires_grad=True) sample = biject_to(dist.support)(unconstrained) potential_energy = -dist.log_prob(sample).sum() Note 一个例子，其中transform_to和biject_to不同的是constraints.simplex：transform_to（constraints.simplex）返回 SoftmaxTransform ，简单地exponentiates和归一化其输入;这是一个价格便宜，主要是协调明智的操作适合于像SVI算法。相比之下，biject_to（constraints.simplex）返回 StickBreakingTransform 为bijects其输入降低到一个-fewer维空间;这样更昂贵更少数值稳定变换，但需要用于像HMC算法。 的biject_to和transform_to目的可以通过用户定义的约束扩展和变换使用他们.register（ ）方法既可以作为单上的约束的函数： transform_to.register(my_constraint, my_transform) 或作为参数约束的装饰： @transform_to.register(MyConstraintClass) def my_factory(constraint): assert isinstance(constraint, MyConstraintClass) return MyTransform(constraint.param1, constraint.param2) 您可以通过创建一个新的 ConstraintRegistry对象创建自己的注册表。 classtorch.distributions.constraint_registry.``ConstraintRegistry[source] 注册表来约束链接转换。 register( constraint , factory=None )[source] 注册在此注册表一个 约束子类。用法： @my_registry.register(MyConstraintClass) def construct_transform(constraint): assert isinstance(constraint, MyConstraint) return MyTransform(constraint.arg_constraints) Parameters 约束 （ 约束的子类） - 的 甲亚类约束，或所需的类的单一对象。 工厂 （ 可调用 ） - ，其输入约束对象，并返回可调用一个 变换对象。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"hub.html":{"url":"hub.html","title":"torch.hub","keywords":"","body":"torch.hub Pytorch中心是一个旨在促进研究再现性的预训练模型库。 出版模式 Pytorch中心通过添加一个简单的hubconf.py文件支持发布预先训练模型（模型定义和预训练的权重）到GitHub的库; hubconf.py可以有多个入口点。每个入口点被定义为一个Python函数（例如：您要发布一个预先训练模型）。 def entrypoint_name(*args, **kwargs): # args & kwargs are optional, for models which take positional/keyword arguments. ... 如何实现一个入口点？ 下面的代码片段指定resnet18如果我们扩大在pytorch /视觉/ hubconf.py实现模型的入口点。在大多数情况下，在导入hubconf.py右边的功能就足够了。在这里，我们只是想用扩展版本作为一个例子来说明它是如何工作的。你可以看到在 pytorch /视觉回购的完整剧本 dependencies = ['torch'] from torchvision.models.resnet import resnet18 as _resnet18 # resnet18 is the name of entrypoint def resnet18(pretrained=False, **kwargs): \"\"\" # This docstring shows up in hub.help() Resnet18 model pretrained (bool): kwargs, load pretrained weights into the model \"\"\" # Call the model, load pretrained weights model = _resnet18(pretrained=pretrained, **kwargs) return model 依赖性变量是需要 负载 该模型包名的 列表。请注意，这可能是从训练模型需要的依赖略有不同。 ARGS和kwargs沿着到真正的可调用的函数传递。 该函数的文档字符串可以作为一个帮助信息。它说明了什么呢模型做什么都允许的位置/关键字参数。我们强烈建议在这里补充几个例子。 入口函数可以返回一个模型（nn.module），或辅助工具，使所述用户的工作流平滑，例如断词。 以下划线前缀可调用被认为是辅助功能，这将不能在torch.hub.list（）显示。 预训练的权重可以是在GitHub库存储在本地，或者通过torch.hub.load_state_dict_from_url（）装载。如果小于2GB，建议将其连接到项目发布和释放使用的URL。在上述torchvision.models.resnet.resnet18手柄预训练，或者可以把下面的逻辑在入口点定义的例子。 if pretrained: # For checkpoint saved in local github repo, e.g. =weights/save.pth dirname = os.path.dirname(__file__) checkpoint = os.path.join(dirname, ) state_dict = torch.load(checkpoint) model.load_state_dict(state_dict) # For checkpoint saved elsewhere checkpoint = 'https://download.pytorch.org/models/resnet18-5c106cde.pth' model.load_state_dict(torch.hub.load_state_dict_from_url(checkpoint, progress=False)) 重要提示 已公布的车型应该是至少的一个分支/标签。它不能是一个随机的承诺。 从轮毂承载量模型 Pytorch集线器提供了方便的API通过torch.hub.list探索毂所有可用的模型（）到torch.hub.help ，显示文档字符串和实施例（ ）和负载使用torch.hub.load（）预先训练的模型 torch.hub.``list( github , force_reload=False )[source] 列出 github上 hubconf所有可用的入口点。 Parameters 的github - 所需的，具有格式“repo_owner / repo_name [：TAG_NAME]”的字符串与任选的标记/分支。默认分支为主如果未指定。例如：“pytorch /视力[：毂]” force_reload - 可选，是否放弃现有缓存并强制新鲜下载。默认为假[HTG3。 Returns 可用的入口点名称的列表 Return type 入口点 例 >>> entrypoints = torch.hub.list('pytorch/vision', force_reload=True) torch.hub.``help( github , model , force_reload=False )[source] 显示入口点模型的文档字符串。 Parameters 的github - 所需的，与格式的字符串& LT ; repo_owner / repo_name [：TAG_NAME] & GT ;具有任选的标记/分支。默认分支为主如果未指定。例如：“pytorch /视力[：毂]” 模型 - 必须在回购的hubconf.py定义的入口点名称的字符串 force_reload – Optional, whether to discard the existing cache and force a fresh download. Default is False. Example >>> print(torch.hub.help('pytorch/vision', 'resnet18', force_reload=True)) torch.hub.``load( github , model , *args , **kwargs )[source] 从GitHub库加载模式，与预训练的权重。 Parameters github – Required, a string with format “repo_owner/repo_name[:tag_name]” with an optional tag/branch. The default branch is master if not specified. Example: ‘pytorch/vision[:hub]’ model – Required, a string of entrypoint name defined in repo’s hubconf.py * ARGS - 可选，用于可调用模型相应ARGS 。 force_reload - 可选，是否强制GitHub库的新鲜下载无条件。默认为假[HTG3。 ** kwargs - 可选，用于可调用模型相应kwargs 。 Returns 一个单一的模型与对应的预训练的权重。 Example >>> model = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True) 运行加载的模型：HTG0] 注意，*指定参数时， ** kwargs在torch.load（）用于 实例 的模型。您加载模型之后，你怎么能找出你可以与模型做什么呢？一个建议的工作流程 DIR（模型）以查看模型的所有可用的方法。 帮助（model.foo）HTG2]检查哪些参数model.foo需要运行 为了帮助用户浏览，而不指的文档来回，我们强烈建议回购业主进行函数帮助信息清晰而简洁。这也有利于包括最小工作示例。 我下载的模型保存？ 的位置是在的顺序使用 主叫hub.set_dir（& LT ; PATH_TO_HUB_DIR & GT ;） $ TORCH_HOME /集线器时，如果环境变量TORCH_HOME被设置。 $ XDG_CACHE_HOME /torch/集线器时，如果环境变量XDG_CACHE_HOME被设置。 〜/ .cache /torch/集线器 torch.hub.``set_dir( d )[source] （可选）设置hub_dir到本地目录保存下载的模型&放;权重。 如果set_dir不叫，缺省路径为$ TORCH_HOME /集线器其中环境变量$ TORCH_HOME默认为$ XDG_CACHE_HOME /torch。 $ XDG_CACHE_HOME遵循了Linux filesytem布局的X设计集团说明书中，具有缺省值〜/ .cache如果环境变量未设置。 Parameters d - 路径到本地文件夹来保存下载的模型&放;权重。 高速缓存逻辑 默认情况下，我们不会加载它清理干净后的文件。集线器默认使用的缓存，如果它已经在hub_dir存在。 用户可以通过调用hub.load强迫重载（...， force_reload =真）。这将删除现有GitHub的文件夹和下载的权重，重新初始化一个新的下载。当更新发布到同一分支，这非常有用，用户可以使用最新版本跟上。 已知的限制： Torch 中心的工作原理是，如果它是安装包导入。还有就是通过导入Python中引入了一些副作用。例如，你可以看到新的项目在Python缓存sys.modules中和sys.path_importer_cache这是正常的Python行为。 已知的限制，即这里值得一提是用户 不能 负载在 相同蟒过程 相同回购两个不同的分支。这就像在Python中相同的名称，这是不好的安装两个包。缓存可能入党，给你惊喜，如果你真的尝试。当然，这是完全正常加载它们在单独的进程。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"jit.html":{"url":"jit.html","title":"torch.jit","keywords":"","body":"TorchScript 创建TorchScript代码 混合跟踪和脚本 TorchScript语言参考 类型 默认类型 可选类型细化 用户定义类型 表达式 字面 列表构造 元组建筑 字典建筑 变量 算术运算符 比较运算符 逻辑运算符 下标 函数调用 方法调用 三元表达式 粪中 访问模块参数 下列 分辨率可变 Python中值的使用 功能 属性查找有关python模块 Python的定义的常量 模块属性 调试 [HTG0用于调试禁用JIT 检查代码 解释图表 跟踪边缘情况 自动跟踪检查 示踪剂警告 常见问题 内建函数 TorchScript是创建PyTorch代码序列化和优化的模型的方式。任何TorchScript程序可以从一个Python程序被保存，并在过程中不存在的Python依赖加载。 我们提供工具来递增地转变从一个纯Python程序模型，以能够独立地从Python中运行，诸如在一个独立的C ++程序的程序TorchScript。这使得训练使用Python中熟悉的工具在PyTorch模型，然后通过TorchScript导出模型的生产环境下的Python程序可能是不利的。性能和多线程的原因。 创建TorchScript代码 torch.jit.``script( obj , optimize=None , framesup=0 , rcb=None_ )[source] 脚本编写的函数或nn.Module将检查源代码，使用编译器TorchScript编译为TorchScript代码，并返回一个ScriptModule或torch._C.Function。 Scripting a function 的@ torch.jit.script装饰将构造一个torch._C.Function。 实施例（脚本的函数）： import torch @torch.jit.script def foo(x, y): if x.max() > y.max(): r = x else: r = y return r Scripting an nn.Module 编写脚本的nn.Module缺省将编译向前方法和递归编译任何方法，子模块，并且功能由[HTG8称为] 向前 。如果nn.Module只使用在TorchScript支持的功能，以原模块代码没有改变应该是必要的。 实施例（脚本用参数a单模）： import torch class MyModule(torch.nn.Module): def __init__(self, N, M): super(MyModule, self).__init__() # This parameter will be copied to the new ScriptModule self.weight = torch.nn.Parameter(torch.rand(N, M)) # When this submodule is used, it will be compiled self.linear = torch.nn.Linear(N, M) def forward(self, input): output = self.weight.mv(input) # This calls the `forward`method of the `nn.Linear`module, which will # cause the `self.linear`submodule to be compiled to a `ScriptModule`here output = self.linear(output) return output scripted_module = torch.jit.script(MyModule()) 实施例（与脚本跟踪子模块的模块）： import torch import torch.nn as nn import torch.nn.functional as F class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() # torch.jit.trace produces a ScriptModule's conv1 and conv2 self.conv1 = torch.jit.trace(nn.Conv2d(1, 20, 5), torch.rand(1, 1, 16, 16)) self.conv2 = torch.jit.trace(nn.Conv2d(20, 20, 5), torch.rand(1, 20, 16, 16)) def forward(self, input): input = F.relu(self.conv1(input)) input = F.relu(self.conv2(input)) return input scripted_module = torch.jit.script(MyModule()) 要编译比转发（和递归编译任何东西它调用）以外的方法，添加@ torch.jit.export装饰器方法。 torch.jit.``trace( func , example_inputs , optimize=None , check_trace=True , check_inputs=None , check_tolerance=1e-05 , forceoutplace=False , moduleclass=None , __compilation_unit= _)[source] 跟踪的功能，并返回一个可执行ScriptModule或torch.jit._C.Function将使用刚刚在时间进行优化汇编。 警告 只有正确地跟踪记录功能，并且不依赖数据（例如，不具有在张量数据条件语句），并且没有任何未跟踪外部依赖（例如，执行输入/输出或访问全局变量）模块。如果您跟踪这些模型，你可以静静地坐上模型的后续调用不正确的结果。示踪将尝试发出做某事时警告，可能会导致产生不正确的轨迹。 Parameters FUNC （ 可调用 或 torch.nn.Module ） - Python函数或torch.nn.Module将与example_inputs运行。参数，并返回至FUNC必须张量或包含张量（可能是嵌套）元组。 example_inputs （ 元组 ） - 的同时跟踪将被传递给函数示例输入的元组。将得到的迹线可以与不同类型和形状假设跟踪操作的输入来运行支持这些类型和形状。 example_inputs也可以是单一的张量在这种情况下，它是自动包装在元组 Keyword Arguments check_trace （ 布尔 ， 可选 ） - 检查是否相同的输入通过跟踪代码运行产生相同的输出。默认值：真 [HTG13。你可能想禁用此，如果，例如，您的网络中包含非确定性OPS，或者如果你是确保网络尽管检查故障是否正确。 check_inputs （ 元组的列表 ， 可选[HTG7） - 应使用要检查的跟踪的输入参数的元组的名单是什么是期待。每个元组相当于一组输入参数，将在example_inputs来指定。为了达到最佳效果，通过一组检查输入代表性的形状和类型的你期望在网络上看到输入的空间的。如果未指定，则原始example_inputs 用于检查 check_tolerance （ 浮动 ， 可选 ） - 浮点比较耐受性检查过程中使用。这可以被用来放松中的结果发散数值为一个已知的原因，如操作者的融合事件的检查严格。 Returns 如果可调用是nn.Module或向前（的）nn.Module，痕量返回与ScriptModule对象的单个向前（） [HTG27含有被跟踪代码方法。返回的ScriptModule将具有相同的组的子模块和参数作为原始nn.Module 。如果可调用 是一个独立的函数，痕量 返回torch.jit._C.Function`` 例： class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv = nn.Conv2d(1, 1, 3) def forward(self, x): return self.conv(x) def weighted_kernel_sum(self, weight): return weight * self.conv.weight example_weight = torch.rand(1, 1, 3, 3) example_forward_input = torch.rand(1, 1, 3, 3) n = Net() # the following two calls are equivalent module = torch.jit.trace_module(n, example_forward_input) module = torch.jit.trace_module(n.forward, example_forward_input) classtorch.jit.``ScriptModule( optimize=None , qualifiedname=None , compilationunit=None , _cpp_module=None )[source] 在TorchScript核心数据结构是ScriptModule。它是Torch 的nn.Module类似物和表示整个模型作为子模块的一棵树。像正常模块，在ScriptModule可以有子模块，参数和方法每个单独模块。在nn.ModuleS的方法被实现为Python函数，但在ScriptModuleS的方法被实现为TorchScript功能，一个statically- Python中的类型子集，它包含了所有PyTorch内置的张量操作。这种差异使您ScriptModules代码，而不需要一个Python解释器运行。 ScriptModuleS以两种方式产生： 跟踪： 使用torch.jit.trace和torch.jit.trace_module，可以把现有的模块或Python函数成TorchScript torch._C.Function或ScriptModule。你必须提供例如输入，我们运行的功能，记录所有的张量所执行的操作。 将所得的独立功能的记录产生torch._C.Function。 将所得的向前的nn.Module或nn.Module 函数记录生产ScriptModule。该模块还包含了原来的模块有以及任何参数。 > 实施例（跟踪函数）： import torch def foo(x, y): return 2 * x + y traced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3))) 注意 > 跟踪一个独立的功能将构造一个torch._C.Function追踪nn.Module``s``向前将构造一个ScriptModule > 实施例（跟踪现有模块）： import torch class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv = nn.Conv2d(1, 1, 3) def forward(self, x): return self.conv(x) def weighted_kernel_sum(self, weight): return weight * self.conv.weight n = Net() example_weight = torch.rand(1, 1, 3, 3) example_forward_input = torch.rand(1, 1, 3, 3) # all three trace calls below are equivalent # and construct `ScriptModule`with a single `forward`method module = torch.jit.trace(n.forward, example_forward_input) # produces ScriptModule with forward module = torch.jit.trace(n, example_forward_input) # produces ScriptModule with forward module = torch.jit.trace_module(n, inputs) # produces ScriptModule with forward inputs = {'forward' : example_forward_input, 'weighted_kernel_sum' : example_weight} # trace_module produces `ScriptModule`with two methods: # `forward`and `weighted_kernel_sum` module = torch.jit.trace_module(n, inputs, True, True) Note > 前三跟踪/ trace_module调用是等效的，并返回ScriptModule > > > 与单一向前方法。 *最后trace_module呼叫产生一个ScriptModule用两种方法。当给定函数在给定的张量运行跟踪完成只记录操作。因此，返回的ScriptModule将始终运行于任何输入相同的跟踪图。这有一些重要的启示，当你的模块预计将运行不同操作的集合，根据输入和/或模块的状态。例如， > * 跟踪不会记录任何控制流一样，如果语句或循环。当这个控制流程是在您的模块不变，这是好的，它往往内联的控制流决策。但有时控制流实际上是模型本身的一部分。例如，一个经常性的网络是一个环上的输入序列的（可能是动态的）长度。 > 在返回ScriptModule，操作是在训练和不同的行为EVAL模式将总是执行如它是在它在跟踪期间在模式，无论ScriptModule是其中模式。 > > > 在这样的情况下，跟踪是不恰当的和脚本是一个更好的选择。 脚本： 您可以直接使用Python语法编写TorchScript代码。你这样做使用@ torch.jit.script装饰的功能和模块。您也可以直接与要编译功能或模块调用torch.jit.script [HTG7。在功能方面，函数体被编译成TorchScript。如果施加到nn.Module，默认情况下向前 方法，它调用被编译的任何方法，并且所有缓冲器和参数原始模块的被复制到一个新的ScriptModule。你不应该需要手动构建 ScriptModule [HTG23。 TorchScript本身是Python语言的一个子集，因此不会在Python工作的所有功能，但我们提供足够的功能来计算的张量和做相关的控制操作。`` torch.jit.``save( m , f , _extra_files=ExtraFilesMap{} )[source] 在一个单独的进程保存此模块中使用的离线版本。保存的模块序列化的所有方法，子模块，参数和该模块的属性。它可以使用torch:: JIT ::负载（文件名）或与 负载Python API中被加载到C ++ API。 为了能够保存模块，它必须不使本机Python功能的任何电话。这意味着，所有的子模块必须的torch.jit.ScriptModule亚类。 危险 所有模块，不管他们的设备，总是被载入到CPU加载过程中。这是从 不同加载的语义和在未来可能改变。 Parameters M - 一个ScriptModule保存 F - 一个类文件对象（必须实现写和flush）或包含文件名的字符串 _extra_files - 从文件名映射到内容将被存储为“F”的一部分 Warning 如果您在使用Python 2，torch.save不支持StringIO.StringIO为有效的类文件对象。这是因为写方法应该返回写入的字节数; StringIO.write（）不执行此操作。 请使用类似io.BytesIO代替。 Example: import torch import io class MyModule(torch.nn.Module): def forward(self, x): return x + 10 m = torch.jit.script(MyModule()) # Save to file torch.jit.save(m, 'scriptmodule.pt') # Save to io.BytesIO buffer buffer = io.BytesIO() torch.jit.save(m, buffer) # Save with extra files extra_files = torch._C.ExtraFilesMap() extra_files['foo.txt'] = 'bar' torch.jit.save(m, 'scriptmodule.pt', _extra_files=extra_files) torch.jit.``load( f , map_location=None , _extra_files=ExtraFilesMap{} )[source] 负载的ScriptModule以前保存的与 保存 之前保存的所有模块，不管他们的设备，首先被加载到CPU，然后移动到他们从已保存的设备。如果失败（例如，由于运行时系统不具有一定的设备），将引发一个例外。然而，存储器可以被动态地重新映射到一组替代使用 map_location 参数的设备。比较 torch.load（），在此功能map_location 被简化，只接受一个字符串（例如， 'CPU' 'CUDA：0'），或torch.device（例如，torch.device（ 'CPU'）） Parameters F - 一个类文件对象（必须实现读，readline的，告诉，求），或包含文件名的字符串 map_location - 可以一个字符串（例如，“CPU”，“CUDA：0”），设备（例如，torch.device（“CPU”）） _extra_files - 从文件名映射到的内容。在图中给出的额外的文件名会被加载和内容将被存储在所提供的地图。 Returns A ScriptModule对象。 Example: torch.jit.load('scriptmodule.pt') # Load ScriptModule from io.BytesIO object with open('scriptmodule.pt', 'rb') as f: buffer = io.BytesIO(f.read()) # Load all tensors to the original device torch.jit.load(buffer) # Load all tensors onto CPU, using a device torch.jit.load(buffer, map_location=torch.device('cpu')) # Load all tensors onto CPU, using a string torch.jit.load(buffer, map_location='cpu') # Load with extra files. files = {'metadata.json' : ''} torch.jit.load('scriptmodule.pt', _extra_files = files) print (files['metadata.json']) 混合跟踪和脚本 在许多情况下，不是跟踪或脚本为模型转换到TorchScript一个更简单的方法。跟踪和脚本可以组成以适应模型的一部分的特殊要求。 脚本函数可以调用追踪功能。当你需要使用围绕一个简单的前馈模型对照流这是特别有用。例如，所述波束搜索的序列序列模型通常将写在脚本但可以调用使用跟踪产生的编码器模块。 Example: import torch def foo(x, y): return 2 * x + y traced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3))) @torch.jit.script def bar(x): return traced_foo(x, x) 究其根源，函数可以调用脚本函数。当一个模型的一小部分需要一些控制流尽管大多数模型仅仅是一个前馈网络，这非常有用。通过跟踪函数调用的脚本功能的内部控制流程正确保存： Example: import torch @torch.jit.script def foo(x, y): if x.max() > y.max(): r = x else: r = y return r def bar(x, y, z): return foo(x, y) + z traced_bar = torch.jit.trace(bar, (torch.rand(3), torch.rand(3), torch.rand(3))) 该组合物也适用于nn.ModuleS以及，在那里它可被用于产生使用跟踪，可以从脚本模块的方法中被称为子模块： Example: import torch import torchvision class MyScriptModule(torch.nn.Module): def __init__(self): super(MyScriptModule, self).__init__() self.means = torch.nn.Parameter(torch.tensor([103.939, 116.779, 123.68]) .resize_(1, 3, 1, 1)) self.resnet = torch.jit.trace(torchvision.models.resnet18(), torch.rand(1, 3, 224, 224)) def forward(self, input): return self.resnet(input - self.means) my_script_module = torch.jit.script(MyScriptModule()) TorchScript语言参考 TorchScript是Python一个静态类型子集，它可以直接（使用@ torch.jit.script装饰）从Python代码经由跟踪书面或自动生成。当使用追踪，代码自动被上张量仅记录实际运营商和简单地执行并丢弃其它周围Python代码转换成Python的该子集。 当写TorchScript直接使用@ torch.jit.script装饰，程序员必须只使用Python的子集，支持TorchScript。本节介绍什么是TorchScript支持就​​好像它是一个独立的语言的语言参考。在此引用未提及的Python的任何功能都不会TorchScript的一部分。 对于Python的一个子集的任何有效TorchScript功能也是一个有效的Python功能。这使得它能够去除@ torch.jit.script装饰，并使用标准的Python工具，如PDB调试功能。相反的是不正确的：有无效的TorchScript程序许多有效的Python程序。相反，TorchScript特别侧重于那些需要代表Torch 神经网络模型的Python的特点。 PYTORCH_JIT=1 设置环境变量PYTORCH_JIT = 0将禁用所有脚本和追踪注解。如果有难以调试错误在你ScriptModules之一，您可以使用此标志强制所有使用本地Python来运行。这使得像调试代码PDB工具的使用。 类型 TorchScript和完整Python语言之间最大的区别是，TorchScript只支持一小部分的所需要表达的神经网络模型的类型。特别是，TorchScript支持： 类型 | 描述 ---|--- 张量 | 任何D型，尺寸，或后端的PyTorch张量 元组[T0， T1， ...] | 将含有元组亚型T0，T1等（例如，元组[张量， 张量]） 布尔 | 一个布尔值 INT | 标量整型 浮动 | 标量浮点数 列出[T] | 其列表中的所有成员都是类型T 可选[T] | 其是无或键入T的值 字典[K， V] | 与密钥类型K和值的类型[HTG5】V一个字典。只有STR，INT和浮动被允许作为密钥类型。 不像Python中，在TorchScript函数每个变量必须有一个单一的静态类型。这使得更容易优化TorchScript功能。 实施例（类型不匹配）： @torch.jit.script def an_error(x): if x: r = torch.rand(1) else: r = 4 return r # Type mismatch: r is set to type Tensor in the true branch # and type int in the false branch 默认类型 默认情况下，在TorchScript函数的所有参数都假定为张量。要指定的参数时TorchScript功能是另一种类型，也可以使用利用上述列出的类型MyPy风格类型注释： Example: @torch.jit.script def foo(x, tup): # type: (int, Tuple[Tensor, Tensor]) -> Tensor t0, t1 = tup return t0 + t1 + x print(foo(3, (torch.rand(3), torch.rand(3)))) Note 也可以来注释类型与Python 3类型的注释。在我们的例子中，我们使用基于注释的注释，以确保Python的2兼容性为好。 假定一个空列表是列表[张量]和空类型的字典字典[STR， 张量]。实例化的其他类型的空列表或字典中，用torch.jit.annotate。 Example: import torch from torch.jit import Tensor from typing import List, Tuple class EmptyDataStructures(torch.jit.ScriptModule): def __init__(self): super(EmptyDataStructures, self).__init__() @torch.jit.script_method def forward(self, x): # type: (Tensor) -> Tuple[List[Tuple[int, float]], Dict[str, int]] # This annotates the list to be a `List[Tuple[int, float]]` my_list = torch.jit.annotate(List[Tuple[int, float]], []) for i in range(10): my_list.append((x, x)) my_dict = torch.jit.annotate(Dict[str, int], {}) return my_list, my_dict 可选类型细化 TorchScript熬炼类型可选[T]的变量的类型时为比较无的条件的内部由if语句。编译器可以推理多个无将检查相结合，与和，或和不。细化也将发生未明确书面if语句的else块。 表达式必须在有条件的射出;分配无检查一个变量，并使用它在条件不会缩小的类型。像的属性self.x 将不会完善，但在分配 self.x 一个局部变量第一会工作。 Example: @torch.jit.script_method def optional_unwrap(self, x, y): # type: (Optional[int], Optional[int]) -> int if x is None: x = 1 x = x + 1 z = self.z if y is not None and z is not None: x = y + z return x 用户定义类型 Python类可以TorchScript使用，如果它们与注释@ torch.jit.script，类似于你会怎么声明TorchScript功能： @torch.jit.script class Foo: def __init__(self, x, y): self.x = x def aug_add_x(self, inc): self.x += inc 这个子集的限制： 所有的功能必须是有效TorchScript功能（包括init `（） `） 类必须是新样式类，我们用__new __（）与pybind11构建它们 TorchScript类是静态类型的。部件由在__init __（）方法分配给自声明 例如，分配__init __（）方法之外： > @torch.jit.script class Foo: def assign_x(self): self.x = torch.rand(2, 3) 将导致： > RuntimeError: Tried to set nonexistent attribute: x. Did you forget to initialize it in init()?: def assign_x(self): self.x = torch.rand(2, 3) ~~~~~~~~~~~~~~~~~~~~~~~~ 除了方法定义没有表情被允许在类的主体 继承或任何其他多态性战略，除了从对象继承不支持指定一个新式类 一类被定义之后，它可以在两个TorchScript和Python可互换使用像任何其他TorchScript类型： @torch.jit.script class Pair: def __init__(self, first, second): self.first = first self.second = second @torch.jit.script def sum_pair(p): # type: (Pair) -> Tensor return p.first + p.second p = Pair(torch.rand(2, 3), torch.rand(2, 3)) print(sum_pair(p)) 表达式 下面的Python表达式支持 字面 真，假，无，“串 文字，“串 文字”，数字面值3（解释为INT）3.4（解释为float） 列表构造 [3， 4]，[]，[torch.rand（ 3）中， torch.rand（4）] > Note > 空列表假设有型列表[张量] [HTG3。类型其他列表文字的从构件的类型的。表示另一种类型的空列表，用torch.jit.annotate 。 元组建筑 （3， 4），（3） 字典建筑 { '你好'： 3}，{}，{'一“： torch.rand（3）， 'b'： torch.rand（4）} > Note > 一个空的字典假设有式字典[STR， 张量]。类型的dict其他文字的从构件的类型的。表示另一种类型的空字典，用torch.jit.annotate。 变量 my_variable_name > Note > 请参阅变量是如何解决可变分辨率[HTG1。 算术运算符 一 + B > 一 - B > 一 * B > 一 / B > 一 ^ B > 一 @ B 比较运算符 一 == B > 一 ！= B > 一 & LT ; B > 一 & GT ; B > 一 & LT ; = B > 一 & GT ; = B 逻辑运算符 一 和 B > 一 或 B > 不 B 下标 T [0] > T [-1] > T [0：2] > T [1：] > T [1] > T [：] > T [0， 1] > T [0， 1：2] > T [0， ：1] > T [-1， 1 :, 0] > T [1 :, -1， 0] > T [1：J-， I] 函数调用 调用内置函数：torch.rand（3， D型= torch.int） > 调用其它脚本函数： import torch @torch.jit.script def foo(x): return x + 1 @torch.jit.script def bar(x): return foo(x) 方法调用 调用等张量内建类型的方法：x.mm（Y） > 当定义一个ScriptModule内部的脚本的方法，所述@script_method 注释用于。里面的这些方法可能调用的子模块这一类或访问方法的其他方法。 > 直接调用的子模块（例如，self.resnet（输入））等效于调用其向前方法（例如self.resnet.forward（输入）） import torch class MyScriptModule(torch.jit.ScriptModule): def __init__(self): super(MyScriptModule, self).__init__() self.means = torch.nn.Parameter(torch.tensor([103.939, 116.779, 123.68]) .resize_(1, 3, 1, 1)) self.resnet = torch.jit.trace(torchvision.models.resnet18(), torch.rand(1, 3, 224, 224)) @torch.jit.script_method def helper(self, input): return self.resnet(input - self.means) @torch.jit.script_method def forward(self, input): return self.helper(input) 三元表达式 × 如果 × & GT ; Y 别的 Y 施放 浮子（10） > INT（3.5） > 布尔（10） 访问模块参数 self.my_parameter > self.my_submodule.my_parameter 下列 TorchScript支持下列类型的语句： Simple Assignments a = b a += b # short-hand for a = a + b, does not operate in-place on a a -= b Pattern Matching Assignments a, b = tuple_or_list a, b, *c = a_tuple 打印报表 打印（以下简称 “ 导致 的 的 添加：”， 一 + [HTG15 b） 如果语句 > 如果 一 & LT ; 4 ： R = - 一 的elif 一 & LT ; 3 ： R = 一 一 别的 ： R = 3 * 一 除了布尔变量，浮点数，整型，和张量可以在有条件的使用，将被隐式浇铸为布尔值。 While循环 > 一 = 0 ，而 一 & LT ; 4 ： 打印 （ 一 ） 一 + = 1 对于范围环 > × = 0 为 i的 在 范围 （ 10 ）： × * = i的 在过去的元组循环： > tup = (3, torch.rand(4)) for x in tup: print(x) Note > 用于通过元组循环将展开循环，从而产生体为元组的每个成员。身体必须正确键入检查每个成员。 对于超过环路常数torch.nn.ModuleList > class SubModule(torch.jit.ScriptModule): def __init__(self): super(Sub, self).__init__() self.weight = nn.Parameter(torch.randn(2)) @torch.jit.script_method def forward(self, input): return self.weight + input class MyModule(torch.jit.ScriptModule): __constants__ = ['mods'] def __init__(self): super(MyModule, self).__init__() self.mods = torch.nn.ModuleList([SubModule() for i in range(10)]) @torch.jit.script_method def forward(self, v): for module in self.mods: v = m(v) return v Note > 使用nn.ModuleList内的@script_method必须通过添加属性的名称到[标示恒定HTG8 ] constants 列表的类型。用于在环的nn.ModuleList将展开循环的主体在编译时，与恒定模块列表的每个成员。 break和continue > 为 i的 在 范围 （ 5 ）： 如果 i的 == 1 ： 继续 如果 i的 == 3 ： 打破 打印 （ i的 ） Return 返回 A， B Note TorchScript allows returns in the following circumstances: 在一个函数的结尾 在if语句，其中& LT ;真& GT ;和& LT ;假& GT ;都返回 在if语句，其中& LT ;真& GT ;回报和& LT ;假& GT ;是空的（一个提前返回） 分辨率可变 TorchScript支持Python的可变分辨率（即作用域）规则的子集。局部变量行为相同，在Python中，除了一个变量必须一起通过函数的所有路径相同类型的限制。如果一个变量对if语句的不同侧面不同的类型，它是if语句结束后，使用它的一个错误。 类似地，变量是不允许被使用，如果它仅仅是 沿着通过函数一些路径定义 。 Example: @torch.jit.script def foo(x): if x 定义函数时非本地变量有决心在编译时的Python值。然后，将这些值转换为使用的Python值的用途中描述的规则TorchScript值。 Python中值的使用 为了使编写TorchScript更方便，我们允许脚本代码来引用的Python值在周边范围。例如，任何时候有至torch参考，TorchScript编译器实际上是它解决到torch Python模块当函数声明。这些Python的值不TorchScript的第一类部分。相反，他们去糖在编译时成TorchScript支持原始类型。这依赖于动态类型值当编译时引用了Python的。本节介绍了TorchScript访问Python的值时使用的规则。 功能 > TorchScript可以调用Python函数。这个功能是非常有用的，当一种模式逐步转化为TorchScript。该模型可以移动的功能按功能TorchScript，留在地方调用Python函数。这样，您就可以逐步检查模型的正确性，当您去。 > Example: def foo(x): print(\"I am called with {}\".format(x)) import pdb; pdb.set_trace() return x @torch.jit.script def bar(x) return foo(x + 1) 试图调用保存在包含到Python函数的调用将失败ScriptModule。目的是使这一途径用于调试和调用删除或保存之前变成脚本功能。如果你想导出模块Python的功能，添加@ torch.jit.ignore装饰的功能，这将替换异常这些函数调用时保存的模型： class M(torch.jit.ScriptModule): def __init__(self): super(M, self).__init__() @torch.jit.script_method def forward(self, x): self.ignored_code(x) return x + 2 @torch.jit.ignore def ignored_code(self, x): # non-TorchScript code import pdb; pdb.set_trace() m = M() # Runs, makes upcall to Python to run `ignored_code` m(torch.ones(2, 2)) # Replaces all calls to `ignored_code`with a `raise` m.save(\"m.pt\") loaded = torch.jit.load(\"m.pt\") # This runs `ignored_code`after saving which will raise an Exception! loaded(torch.ones(2, 2)) 属性查找有关python模块 TorchScript可以查找在模块属性。像内建函数torch.add被访问这种方式。这允许TorchScript调用其他模块中定义的功能。 Python的定义的常量 > TorchScript还提供了一种使用在Python中定义的常量。这些可用于硬编码超参数到函数，或定义通用常数。有指定一个Python值应为一个常数进行治疗的方法有两种。 > 价值观抬头作为一个模块的属性被认为是恒定的。例如：math.pi > 一个ScriptModule的属性可以被标记通过列出它们作为类的__constants__属性的成员常数： > Example: > class Foo(torch.jit.ScriptModule): __constants__ = ['a'] def __init__(self): super(Foo, self).__init__(False) self.a = 1 + 4 @torch.jit.script_method def forward(self, input): return self.a + input > > 支持不断Python的价值观是 > int > float > bool > torch.device > torch.layout > torch.dtype > 包含支持的类型的元组 > torch.nn.ModuleList，它被在TorchScript用于循环 > > 模块属性 的torch.nn.Parameter包装和register_buffer可用于指定张量的ScriptModule。与此类似，任何类型的属性可以在ScriptModule通过用它们包裹torch.jit.Attribute并指定分配方式。所有可用的类型TorchScript的支持。这些属性是可变的，并在序列化模型二进制保存在单独的存档。张量的属性在语义上是一样的缓冲区。 Example: class Foo(torch.jit.ScriptModule): def __init__(self, a_dict): super(Foo, self).__init__(False) self.words = torch.jit.Attribute([], List[str]) self.some_dict = torch.jit.Attribute(a_dict, Dict[str, int]) @torch.jit.script_method def forward(self, input): # type: (str) -> int self.words.append(input) return self.some_dict[input] 调试 停用JIT用于调试 如果你想禁用所有的JIT模式（跟踪和脚本），所以您可以用原始的Python调试程序，你可以使用PYTORCH_JIT环境变量。 PYTORCH_JIT可用于全局禁用通过将其值设置为0的JIT。给定一个示例脚本： @torch.jit.script def scripted_fn(x : torch.Tensor): for i in range(12): x = x + x return x def fn(x): x = torch.neg(x) import pdb; pdb.set_trace() return scripted_fn(x) traced_fn = torch.jit.trace(fn, (torch.rand(4, 5),)) traced_fn(torch.rand(3, 4)) 除了当我们调用@ torch.jit.script功能调试这个脚本PDB工作。我们可以在全球范围禁用JIT，这样我们就可以称之为@ torch.jit.script功能作为一个正常的Python函数，而不是编译它。如果上面的脚本被称为disable_jit_example.py，我们可以调用它像这样： $ PYTORCH_JIT=0 python disable_jit_example.py 和我们将能够torch.jit.script 功能步入@作为一个正常的Python函数。 检查代码 TorchScript为所有ScriptModule实例代码漂亮打印机。这个漂亮的打印机给人的脚本方法的是有效的Python语法代码的解释。例如： @torch.jit.script def foo(len): # type: (int) -> torch.Tensor rv = torch.zeros(3, 4) for i in range(len): if i A ScriptModule与单一向前方法将具有属性代码，它你可以用它来检查ScriptModule的代码。如果ScriptModule有一个以上的方法，你将需要访问.CODE的方法本身，而不是该模块。我们可以检查名为方法的代码通过访问 .bar.code酒吧上的ScriptModule。 > 上面的示例脚本生成的代码： def forward(self, len: int) -> Tensor: rv = torch.zeros([3, 4], dtype=None, layout=None, device=None) rv0 = rv for i in range(len): if torch.lt(i, 10): rv1 = torch.sub(rv0, 1., 1) else: rv1 = torch.add(rv0, 1., 1) rv0 = rv1 return rv0 这是转发方法的代码的TorchScript的编译。你可以用它来确保TorchScript（跟踪或脚本）已正确捕获你的模型代码。 解释图表 TorchScript还具有在比码pretty-打印机较低水平的表示，在IR图的形式。 > TorchScript使用静态单赋值（SSA）的中间表示（IR）来表示的计算。在此格式的指令包括阿坦（PyTorch的C ++后端）运营商和其他原始运营商，包括控制流运营商循环和条件的。举个例子： @torch.jit.script def foo(len): # type: (int) -> torch.Tensor rv = torch.zeros(3, 4) for i in range(len): if i .graph如下在检查代码部分关于向前方法查找所描述的相同的规则。 > 上面的例子中的脚本产生的曲线图： graph(%len : int) { %15 : int = prim::Constant[value=1]() %9 : bool = prim::Constant[value=1]() %7 : Device = prim::Constant[value=\"cpu\"]() %6 : int = prim::Constant[value=0]() %5 : int = prim::Constant[value=6]() %1 : int = prim::Constant[value=3]() %2 : int = prim::Constant[value=4]() %11 : int = prim::Constant[value=10]() %14 : float = prim::Constant[value=1]() %4 : int[] = prim::ListConstruct(%1, %2) %rv.1 : Tensor = aten::zeros(%4, %5, %6, %7) %rv : Tensor = prim::Loop(%len, %9, %rv.1) block0(%i : int, %13 : Tensor) { %12 : bool = aten::lt(%i, %11) %rv.4 : Tensor = prim::If(%12) block0() { %rv.2 : Tensor = aten::sub(%13, %14, %15) -> (%rv.2) } block1() { %rv.3 : Tensor = aten::add(%13, %14, %15) -> (%rv.3) } -> (%9, %rv.4) } return (%rv); } 取指令％rv.1 ： 动态 = ATEN ::零（％3， ％4， ％5， ％6）例如。 ％rv.1 ： 动态意味着我们分配输出到名为RV一个（唯一的）值。 1，并且该值是动态类型，即，我们还不知道其具体形状。 ATEN ::零是操作者（相当于torch.zeros）和输入列表（％ 3， ％4， ％5， ％6）指定哪个范围值应该作为输入传递。该架构内建的功能，如ATEN ::零可以在内置函数研究发现。 > 注意，运营商也可以具有相关联嵌段，即呆板::环和呆板::如果运算符。在该图中打印出的，这些运营商被格式化，以反映它们的等效源代码形式，以便于容易调试。 > 如下所述图形可以检查如图以确认由ScriptModule所述的计算是正确的，在自动和手动方式。 跟踪边缘情况 有迹象表明，存在其中给定Python函数/模块的轨迹不会代表底层代码的一些边缘情况。这些情况可能包括： > 控制流程的跟踪是依赖于输入（例如张量形状） > 就地的张量的观点操作的跟踪（在赋值的左侧例如索引） > > > 请注意，这些情况可能实际上是在未来的可追溯。 自动跟踪检查 自动赶上痕迹许多错误的一种方法是通过使用check_inputs关于torch.jit.trace（）API。 check_inputs需要的将被用于重新跟踪计算和验证结果输入元组的列表。例如： def loop_in_traced_fn(x): result = x[0] for i in range(x.size(0)): result = result * x[i] return result inputs = (torch.rand(3, 4, 5),) check_inputs = [(torch.rand(4, 5, 6),), (torch.rand(2, 3, 4),)] traced = torch.jit.trace(loop_in_traced_fn, inputs, check_inputs=check_inputs) Gives us the following diagnostic information:: 错误：图形跨越调用不同！图DIFF： graph(%x : Tensor) { %1 : int = prim::Constant[value=0]() %2 : int = prim::Constant[value=0]() %result.1 : Tensor = aten::select(%x, %1, %2) %4 : int = prim::Constant[value=0]() %5 : int = prim::Constant[value=0]() %6 : Tensor = aten::select(%x, %4, %5) %result.2 : Tensor = aten::mul(%result.1, %6) %8 : int = prim::Constant[value=0]() %9 : int = prim::Constant[value=1]() %10 : Tensor = aten::select(%x, %8, %9) - %result : Tensor = aten::mul(%result.2, %10) + %result.3 : Tensor = aten::mul(%result.2, %10) ? ++ %12 : int = prim::Constant[value=0]() %13 : int = prim::Constant[value=2]() %14 : Tensor = aten::select(%x, %12, %13) + %result : Tensor = aten::mul(%result.3, %14) + %16 : int = prim::Constant[value=0]() + %17 : int = prim::Constant[value=3]() + %18 : Tensor = aten::select(%x, %16, %17) - %15 : Tensor = aten::mul(%result, %14) ? ^ ^ + %19 : Tensor = aten::mul(%result, %18) ? ^ ^ - return (%15); ? ^ + return (%19); ? ^ } 此消息表明我们的计算，当我们第一次追查之间，当我们与check_inputs追查不同。的确，在身体内循环loop_in_traced_fn取决于输入×，并因此，当我们试图另一[HTG12的形状] × 具有不同形状，跟踪不同。 > 在这种情况下，像这样的数据有关的控制流可以使用脚本，而不是被捕获： def fn(x): result = x[0] for i in range(x.size(0)): result = result * x[i] return result inputs = (torch.rand(3, 4, 5),) check_inputs = [(torch.rand(4, 5, 6),), (torch.rand(2, 3, 4),)] scripted_fn = torch.jit.script(fn) print(scripted_fn.graph) for input_tuple in [inputs] + check_inputs: torch.testing.assert_allclose(fn(*input_tuple), scripted_fn(*input_tuple)) 主要生产： graph(%x : Tensor) { %5 : bool = prim::Constant[value=1]() %1 : int = prim::Constant[value=0]() %result.1 : Tensor = aten::select(%x, %1, %1) %4 : int = aten::size(%x, %1) %result : Tensor = prim::Loop(%4, %5, %result.1) block0(%i : int, %7 : Tensor) { %10 : Tensor = aten::select(%x, %1, %i) %result.2 : Tensor = aten::mul(%7, %10) -> (%5, %result.2) } return (%result); } 示踪剂警告 示踪产生警告，在追溯计算若干问题的模式。作为一个例子，取包含在张量的一个切片（视图）的就地分配的功能的跟踪： def fill_row_zero(x): x[0] = torch.rand(*x.shape[1:2]) return x traced = torch.jit.trace(fill_row_zero, (torch.rand(3, 4),)) print(traced.graph) 产生多次警告，它简单的返回输入的图形： fill_row_zero.py:4: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe. x[0] = torch.rand(*x.shape[1:2]) fill_row_zero.py:6: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error: Not within tolerance rtol=1e-05 atol=1e-05 at input[0, 1] (0.09115803241729736 vs. 0.6782537698745728) and 3 other locations (33.00%) traced = torch.jit.trace(fill_row_zero, (torch.rand(3, 4),)) graph(%0 : Float(3, 4)) { return (%0); } 我们可以通过修改代码不使用就地更新解决这个问题，而是建立结果张外的地方用 torch.cat ： def fill_row_zero(x): x = torch.cat((torch.rand(1, *x.shape[1:2]), x[1:2]), dim=0) return x traced = torch.jit.trace(fill_row_zero, (torch.rand(3, 4),)) print(traced.graph) 常见问题 问：我想在训练GPU的模型，做CPU的推论。什么是最好的做法？ 首先从GPU转换你的模型到CPU，然后保存它，就像这样： cpu_model = gpu_model.cpu() sample_input_cpu = sample_input_gpu.cpu() traced_cpu = torch.jit.trace(traced_cpu, sample_input_cpu) torch.jit.save(traced_cpu, \"cpu.pth\") traced_gpu = torch.jit.trace(traced_gpu, sample_input_gpu) torch.jit.save(traced_gpu, \"gpu.pth\") # ... later, when using the model: if use_gpu: model = torch.jit.load(\"gpu.pth\") else: model = torch.jit.load(\"cpu.pth\") model(input) 这是推荐的，因为示踪剂可以在特定设备上看到张量创建，使铸造一个已经载入的模型可能会有意想不到的效果。保存它确保示踪剂具有正确的设备信息之前，铸造模型 。 问：我如何保存在ScriptModule属性？ 假设我们有一个像模型： class Model(torch.jit.ScriptModule): def __init__(self): super(Model, self).__init__() self.x = 2 @torch.jit.script_method def forward(self): return self.x 如果型号被实例化会导致编译错误，因为编译器不知道× [HTG7。有4种方式告知属性的编译器上ScriptModule： > 1. nn.Parameter- 包裹在值nn.Parameter将作为它们的NN做工作。模块S > 2. register_buffer- 值包裹在register_buffer，因为它们在nn.Module做将工作 S > 3 HTG0] constants - 加入了一个名为列表__constants__在类定义级别将迎来包含名称为常数。常量在模型的代码直接保存。参见 Python的定义的常量。 > 4. torch.jit.Attribute- 包裹在值torch.jit.Attribute可以是任何TorchScript类型，待突变并保存了该模型的代码的外部。参见模块属性。 问：我想跟踪模块的方法，但我不断收到此错误： RuntimeError： 不能 插入 A 张量 是 需要 GRAD 如 一 常数。 考虑 制备 它 一 参数 或 输入， 或 拆卸 中的 梯度 此错误通常意味着，你正在跟踪的方法中，使用模块的参数和要传递一个模块实例的模块的方法，而不是（例如，my_module_instance.forward对my_module_instance）。 > 调用痕量与模块的方法捕获模块参数（可能需要的梯度）作为 常数 。 > 在另一方面，调用追踪与模块的实例（例如my_module）创建一个新的模块，并正确地拷贝参数到新模块，因此，如果需要，他们可以积累梯度。 > > > 鉴于痕量对待my_module_instance.forward作为一个独立的功能，这也意味着有 不 目前一方法来跟踪任意方法在模块中除了转发在使用模块的参数。版本 1.1.1 将增加一个新的API trace_module，将允许用户跟踪模块中的任何方法不止一种方法 class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv = nn.Conv2d(1, 1, 3) def forward(self, x): return self.conv(x) def weighted_kernel_sum(self, weight): return weight * self.conv.weight example_weight = torch.rand(1, 1, 3, 3) example_forward_input = torch.rand(1, 1, 3, 3) n = Net() inputs = {'forward' : example_forward_input, 'weighted_kernel_sum' : example_weight} module = torch.jit.trace_module(n, inputs) 内置函数 TorchScript支持内建张量和神经网络函数PyTorch提供的一个子集。上张量大多数方法以及在torch功能命名空间，在torch.nn.functional的所有功能，并从所有模块torch.nn在支持TorchScript，不包括在下面的表中。对于不支持的模块，建议使用 torch.jit.trace（）。 不支持torch.nn模块 torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss torch.nn.modules.normalization.CrossMapLRN2d torch.nn.modules.fold.Fold torch.nn.modules.fold.Unfold torch.nn.modules.rnn.GRU torch.nn.modules.rnn.RNN Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"multiprocessing.html":{"url":"multiprocessing.html","title":"torch.multiprocessing","keywords":"","body":"多包 - torch.multiprocessing torch.multiprocessing是天然 多处理 模块周围的包装。它注册的自定义减速器，其使用共享存储器，以提供在不同的处理相同的数据共享视图。一旦张量/存储移动到sharedmemory（见[ `share_memory（） `](tensors.html#torch.Tensor.sharememory \"torch.Tensor.sharememory\")），将有可能将其发送到其他过程，而不进行任何拷贝。 API是与原模块100％兼容 - 这是足以改变进口 多重处理至进口 Torch .multiprocessing将所有经由其他机制通过队列发送或共享的张量，移动到共享存储器。 由于原料药的相似性，我们不记录大部分这个包的内容，我们建议参考原来的内存模块的很好的文档。 警告 如果主过程退出突然（例如，由于输入信号的），Python的多处理有时不能清理其子女。这是一个已知的警告，所以如果你打断解释后，看不到任何资源泄漏，这可能意味着这只是发生在你身上。 战略管理 torch.multiprocessing.``get_all_sharing_strategies()[source] 返回一组支持的当前系统上共享战略。 torch.multiprocessing.``get_sharing_strategy()[source] 返回共享CPU张量目前的策略。 torch.multiprocessing.``set_sharing_strategy( new_strategy )[source] 设置共享CPU张量的策略。 Parameters new_strategy （ STR ） - 所选择的策略的名称。应该是由 返回的值中的一个get_all_sharing_strategies（）。 分享CUDA张量 进程之间共享CUDA张量仅在Python 3被支撑，利用产卵或forkserver开始的方法。 多处理 在Python 2可使用叉仅创建子过程，并且它不被CUDA运行时的支持。 不同于CPU张量，需要在发送过程中保持原有的张量，只要该接收处理保留了张量的副本。该引用计数是引擎盖下实现的，但要求用户按照下面的最佳实践。 Warning 如果消费者进程异常死亡的致命信号，共享的张量可能会永远只要发送进程正在运行保存在内存中。 在消费者尽快释放内存。 ## Good x = queue.get() # do somethings with x del x ## Bad x = queue.get() # do somethings with x # do everything else (producer have to keep x in memory) 2.保持生产过程中运行，直到所有的消费者退出。这将防止这种情况，当生产者进程释放内存仍处于由消费者使用。 ## producer # send tensors, do something event.wait() ## consumer # receive tensors and use them event.set() 千万不要错过收到张量。 # not going to work x = queue.get() queue_2.put(x) # you need to create a process-local copy x = queue.get() x_clone = x.clone() queue_2.put(x_clone) # putting and getting from the same queue in the same process will likely end up with segfault queue.put(tensor) x = queue.get() 共享策略 本节提供了一个简要介绍如何将不同的共享战略方面的工作。请注意，它仅适用于CPU张量 - CUDA张量将始终使用CUDA API，因为这是他们可以共享的唯一途径。 文件描述符 - 类file_descriptor 注意 这是（如果它不支持除MacOS和OS X）默认的策略。 这一战略将使用文件描述符共享内存句柄。每当一个存储被移动到共享存储器，从获得的文件描述符的shm_open被高速缓存与所述对象，并​​且当它要被发送到其他过程，文件描述符将被转移（通过UNIX插座EG）给它。接收机还将缓存文件描述符和MMAP它，以获得共享视图到存储数据。 请注意，如果将有很多共享的张量，这一战略将保留大量文件描述符打开的大部分时间。如果你的系统有打开的文件描述符的数量下限，并且你不能养宠物，你应该使用将file_system策略。 文件系统 - 将file_system 这一战略将使用给予的shm_open文件名称来标识的共享内存区域。这具有不需要缓存从中获得的文件描述符执行的一个好处，但同时又是易共享内存泄漏。该文件不能在创建后删除，因为其他进程需要访问它打开了自己的看法。如果流程致命崩溃，或者被打死，不叫存储析构函数，该文件将保留在系统中。这是非常严重的，因为他们继续使用了内存，直至系统重新启动，或者他们正在手动释放。 为了对抗共享存储器文件泄漏的问题， torch.multiprocessing将产生一个守护进程名为torch_shm_manager为将本身从当前进程组隔离，并且将跟踪所有共享存储器分配。一旦连接到它退出所有进程，它会等待片刻，以确保不会有新的连接，并会遍历由组分配的所有共享内存文件。如果发现其中的任何依然存在，他们将被释放。我们已经测试过这种方法，它被证明是稳健的各种故障。不过，如果你的系统有足够高的限制，类file_descriptor被支持的战略，我们不建议切换到这一个。 产卵子过程 Note 可用于Python & GT ; = 3.4。 这取决于在Python的多处理包菌种启动方法。 产卵一些子来执行一些功能可以通过创建过程实例，并调用加入等待其完成来完成。与单个子打交道时，这种方法工作正常，但有多个进程打交道时具有潜在的问题。 即，在加入过程依次意味着它们将按顺序终止。如果他们不这样做，和第一进程不会终止，进程终止将被忽视。另外，还有一些错误传播没有原生的设施。 下面的产卵功能解决了这些问题，并采取错误传播的护理，乱序终止，并将积极终止进程当在其中的一个检测错误。 torch.multiprocessing.``spawn( fn , args=() , nprocs=1 , join=True , daemon=False )[source] 产卵nprocs流程运行FN与ARGS。 如果其中一个进程与非零状态退出，剩下的进程被终止，并抛出一个异常与终止的原因。在一个异常被夹在子进程的情况下，被转发和回溯包含在父进程引发的异常。 Parameters FN （ 函数 ） - 功能被称为衍生进程的入口点。该功能必须在模块的顶部电平被限定以便它可以进行酸洗和衍生。这是一个由多处理施加的规定。 该函数被称为FN（I， *参数），其中i的是进程索引和ARGS在贯通的参数元组通过。 ARGS （ 元组 ） - 参数传递给FN。 nprocs （ INT ） - 过程编号产卵。 加入 （ 布尔 ） - 执行上的所有进程的阻挡加入。 守护程序 （ 布尔 ） - 衍生的进程的守护进程标记。如果设置为True一样，后台进程将被创建。 Returns 无如果加入是真， SpawnContext如果加入是假 classtorch.multiprocessing.``SpawnContext[source] 通过 产卵返回（）当使用加入=假调用。 join( timeout=None )[source] 试图在此背景下产卵加入一个或多个进程。如果其中一人非零退出状态退出，此功能杀死剩余的所有进程，并提出与离开第一工艺的原因的异常。 返回真如果所有的过程已经成功加入，假如果有需要连接多个进程。 Parameters 超时 （ 浮动 ） - 上等待放弃之前长时间等待此。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"random.html":{"url":"random.html","title":"torch.random","keywords":"","body":"torch.random torch.random.``fork_rng( devices=None , enabled=True , caller='forkrng' , deviceskw='devices' )[source] 福克斯的RNG，所以，当你返回时，RNG复位的状态，这是以前英寸 Parameters 设备 （ 可迭代CUDA编号 的） - CUDA设备针对其叉的RNG。 CPU RNG状态始终分叉。默认情况下， fork_rng（）运行在所有设备上，但会发出警告，如果你的机器有很多的设备，因为该功能将运行非常缓慢在这种情况下。如果您明确指定的设备，这个警告将被抑制 启用 （ 布尔 ） - 如果假时，RNG没有分叉。这是很容易禁用上下文管理，而不必删除它，并在它之下取消缩进Python代码便利的说法。 torch.random.``get_rng_state()[source] 返回随机数发生器状态作为 torch.ByteTensor 。 torch.random.``initial_seed()[source] 返回初始种子用于产生随机数作为一个Python 长。 torch.random.``manual_seed( seed )[source] 设置生成随机数种子。返回 torch.Generator 对象。 Parameters 种子 （ INT ） - 所需的种子。 torch.random.``seed()[source] 设置用于产生随机数，以非确定性的随机数种子。返回用于播种RNG一个64位的数。 torch.random.``set_rng_state( new_state )[source] 设置随机数生成器的状态。 Parameters NEW_STATE （ torch.ByteTensor ） - 期望状态 随机数发生器 torch.random.``get_rng_state()[source] Returns the random number generator state as a torch.ByteTensor. torch.random.``set_rng_state( new_state )[source] Sets the random number generator state. Parameters new_state ( torch.ByteTensor ) – The desired state torch.random.``manual_seed( seed )[source] Sets the seed for generating random numbers. Returns a torch.Generator object. Parameters seed ( int) – The desired seed. torch.random.``seed()[source] Sets the seed for generating random numbers to a non-deterministic random number. Returns a 64 bit number used to seed the RNG. torch.random.``initial_seed()[source] Returns the initial seed for generating random numbers as a Python long. torch.random.``fork_rng( devices=None , enabled=True , caller='forkrng' , deviceskw='devices' )[source] Forks the RNG, so that when you return, the RNG is reset to the state that it was previously in. Parameters devices ( iterable of CUDA IDs ) – CUDA devices for which to fork the RNG. CPU RNG state is always forked. By default, fork_rng()operates on all devices, but will emit a warning if your machine has a lot of devices, since this function will run very slowly in that case. If you explicitly specify devices, this warning will be suppressed enabled ( bool) – if False, the RNG is not forked. This is a convenience argument for easily disabling the context manager without having to delete it and unindent your Python code under it. Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"bottleneck.html":{"url":"bottleneck.html","title":"torch.utils.bottleneck","keywords":"","body":"torch.utils.bottleneck torch.utils.bottleneck 是可以用作用于在程序调试的瓶颈中的初始步骤的工具。它总结了Python的探查和PyTorch的autograd探查脚本的运行。 它运行在命令行上 python -m torch.utils.bottleneck /path/to/source/script.py [args] 其中，[参数]是任意数量的参数script.py ，或运行蟒 -m torch.utils.bottleneck -h [HTG11为更多的使用的指令。 警告 因为你的脚本将被异形，请确保它在退出的时间有限。 Warning 由于CUDA内核的异步特性，对CUDA代码运行时，CPROFILE输出和CPU模式autograd廓线仪可能无法显示正确的时序：报告的CPU时间报告的时间用于启动的内核数量，但不包括时间除非操作做了同步内核花在GPU执行。那些同步出现行动是在常规CPU模式廓线仪非常昂贵。在这些情况下的定时不正确，则CUDA模式autograd分析器可以是有帮助的。 注意 要决定哪些（仅CPU模式或CUDA模式）autograd探查器输出看，应先检查，如果你的脚本是CPU绑定（“CPU总时间比CUDA总时间要大得多”）。如果是CPU密集型的，看着CPU模式autograd分析器可以帮助的结果。如果在另一方面你的脚本花费大量的时间在GPU上执行的，则是有意义的开始寻找负责CUDA运营商在CUDA模式autograd探查器的输出。 当然，现实情况要复杂得多，你的脚本可能不是取决于你正在评估模型的一部分这两个极端中的一个。如果探查器输出不帮忙，你可以尝试寻找 torch.autograd.profiler.emit_nvtx的结果（） 与nvprof。但是，请考虑到该NVTX开销是非常高的，往往给人一种严重扭曲的时间表。 Warning 如果您正在配置CUDA代码，第一个分析器，瓶颈运行（CPROFILE）将在其报告时间在CUDA启动时间（CUDA缓冲区分配费用）。如果您的系统瓶颈导致代码比CUDA启动时间慢得多这不应该的问题。 对于（在多GPU情况下等）的廓线的更复杂的应用，请参见 https://docs.python.org/3/library/profile.html 或 torch.autograd.profiler.profile（） 获得更多信息。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"checkpoint.html":{"url":"checkpoint.html","title":"torch.utils.checkpoint","keywords":"","body":"torch.utils.checkpoint 注意 检查点是通过在向后重新运行对每个检查点段向前通段实现。这可能会导致持续的状态就像是先进的RNG状态，他们会比没有检查点。默认情况下，检查点包括逻辑来玩弄的RNG状态，使得检查点的通过利用RNG的（通过差例如）如相对于非检查点通行证具有确定性输出。逻辑藏匿和恢复RNG状态可以承担因设置检查点操作的运行时性能适中命中。如果确定的输出相比，非检查点通行证不是必需的，供应preserve_rng_state =假至检查点或checkpoint_sequential省略积攒和每个检查点期间恢复所述RNG状态。 在积攒逻辑保存并恢复为当前设备的RNG状态和所有CUDA张量参数到run_fn该设备。然而，该逻辑还没有办法预测如果用户将在run_fn本身内张量移动到新设备。因此，如果移动张量，以一个新的装置（“新”的意思不属于集合[当前设备+的张量参数的装置]的）内run_fn，确定性的输出进行比较，以非检查点通行证从不保证。 torch.utils.checkpoint.``checkpoint( function , *args , **kwargs )[source] 检查点模型的模型或部分 检查点的工作原理是交易计算内存。而不是存储整个计算图的所有中间激活用于向后计算，检查点部分不 不 保存中间激活，而是重新计算它们向后通。它可以在模型的任何部分被应用。 具体而言，在直传，函数将在torch.no_grad运行（）的方式，即不存储中间激活。相反，直传保存的输入元组和函数参数。在向后传送时，保存的输入和函数时retreived，并且直传被计算在函数再次，现在跟踪中间激活，然后梯度使用这些激活值来计算。 警告 检查点不工作 torch.autograd.grad（），但只有 torch.autograd.backward（ ） 。 Warning 如果函数在落后的调用做任何事情比一个向前时不同，例如，由于一些全局变量，设立检查点版本将不会是等价的，不幸的是它不能检测。 Parameters 函数 - 介绍如何在模型的模型或部分直传运行。还应该知道如何处理的元组传递的输入。例如，在LSTM，如果用户通过（活化， 隐藏），函数应该正确地使用第一输入为活化和第二输入为隐藏 preserve_rng_state （ 布尔 ， 可选 ， 默认=真 ） - 省略积攒和每个检查点期间恢复所述RNG状态。 ARGS - 包含元组输入到函数 Returns 运行的输出函数在* ARGS torch.utils.checkpoint.``checkpoint_sequential( functions , segments , *inputs , **kwargs )[source] 对于检查点顺序模型辅助函数。 顺序执行模型的模块/功能，以便（顺序地）的列表。因此，我们可以划分在各个分段这样的模型和检查点每个段。除了最后的所有段将在torch.no_grad（）方式运行，即不存储中间激活。每个检查点段的输入端将被保存用于重新运行段在向后通。 参见 如何检查点检查点工作（）[HTG5。 Warning Checkpointing doesn’t work with torch.autograd.grad(), but only with torch.autograd.backward(). Parameters 功能 - A torch.nn.Sequential或模块或功能（包括模型）的列表按顺序运行。 段 - 组块数量在模型中创建 输入 - 这被输入到张量的元组的功能 preserve_rng_state ( bool , optional , default=True ) – Omit stashing and restoring the RNG state during each checkpoint. Returns 运行函数的输出上依次*输入 例 >>> model = nn.Sequential(...) >>> input_var = checkpoint_sequential(model, chunks, input_var) Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"cpp_extension.html":{"url":"cpp_extension.html","title":"torch.utils.cpp_extension","keywords":"","body":"torch.utils.cpp_extension torch.utils.cpp_extension.``CppExtension( name , sources , *args , **kwargs )[source] 创建setuptools.Extension为C ++。 一个创建setuptools.Extension与最低限度（但通常​​足以）参数建立一个C ++扩展的便捷方法。 所有参数被转发到setuptools.Extension构造。 例 >>> from setuptools import setup >>> from torch.utils.cpp_extension import BuildExtension, CppExtension >>> setup( name='extension', ext_modules=[ CppExtension( name='extension', sources=['extension.cpp'], extra_compile_args=['-g']), ], cmdclass={ 'build_ext': BuildExtension }) torch.utils.cpp_extension.``CUDAExtension( name , sources , *args , **kwargs )[source] 创建setuptools.Extension [HTG3用于CUDA / C ++。 一个创建setuptools.Extension与最低限度（但通常​​足以）参数建立一个CUDA / C ++扩展的便捷方法。这包括CUDA包括路径，库路径和运行时库。 All arguments are forwarded to the setuptools.Extensionconstructor. Example >>> from setuptools import setup >>> from torch.utils.cpp_extension import BuildExtension, CUDAExtension >>> setup( name='cuda_extension', ext_modules=[ CUDAExtension( name='cuda_extension', sources=['extension.cpp', 'extension_kernel.cu'], extra_compile_args={'cxx': ['-g'], 'nvcc': ['-O2']}) ], cmdclass={ 'build_ext': BuildExtension }) torch.utils.cpp_extension.``BuildExtension( *args , **kwargs )[source] 自定义setuptools的构建扩展。 此setuptools.build_ext亚类需要经过所需要的最小编译器标志的护理（例如，-std = C ++ 11）以及作为混合的C ++ / CUDA汇编（和一般为CUDA文件的支持）。 当使用 BuildExtension，它被允许提供一个字典extra_compile_args（而不是通常的列表）从语言映射（CXX或CUDA）来的额外的编译标志来提供给编译器的列表。这使得可以为混合编译期间提供不同的标记到C ++和CUDA编译器。 torch.utils.cpp_extension.``load( name , sources , extra_cflags=None , extra_cuda_cflags=None , extra_ldflags=None , extra_include_paths=None , build_directory=None , verbose=False , with_cuda=None , is_python_module=True )[source] 加载PyTorch C ++扩展刚刚在时间（JIT）。 要加载的扩展，一个忍者构建文件被发射时，其被用来编译该给定源集成到一个动态库。该库随后被加载到当前的Python程序作为一个模块，并从该函数返回，以备使用。 默认情况下，目录到构建文件发出并编译得到的库来为& LT ; TMP & GT ; / torch_extensions / [ - - ] LT ;名称& GT ;，其中& LT ; TMP & GT ;为当前平台上的临时文件夹并& LT ;名称& GT ;扩展的名称。这个位置可以通过两种方式来覆盖。首先，如果TORCH_EXTENSIONS_DIR环境变量被设置，它取代& LT ; TMP & GT ; / torch_extensions和所有的扩展会被编译成这个目录的子文件夹。其次，如果被提供的BUILD_DIRECTORY参数给此函数，它会覆盖整个路径，即，库将被直接编译到该文件夹​​。 编译源代码，默认的系统编译器（C ++）被使用，其可以通过设置CXX环境变量被重写。传递额外的参数来编译过程，EXTRA_CFLAGS或`可以提供EXTRA_LDFLAGS。例如，为了与编译优化您的扩展，通过EXTRA_CFLAGS = [ ' - O3']。您也可以使用EXTRA_CFLAGS`进一步通过包括目录。 提供CUDA支持混合编译。简单地传递CUDA源文件（.CU或.cuh）与其他来源的沿。这些文件将被检测并与NVCC，而不是C ++编译器编译。这包括使CUDA lib64目录作为一个库的目录，和链接cudart。可以传递附加标志通过至NVCC extra_cuda_cflags，就像EXTRA_CFLAGS为C ++。为寻找CUDA安装目录各种试探被使用，通常做工精细。如果不是，设置CUDA_HOME环境变量是最安全的选择。 Parameters 名 - 扩展的名称来构建。这必须是相同pybind11模块的名称！ 来源 - 相对或绝对路径到C ++源文件的列表。 EXTRA_CFLAGS - 编译器标志的可选列表转发到构建。 extra_cuda_cflags - 编译器标志的可选列表了建设CUDA源时，NVCC。 EXTRA_LDFLAGS - 连接标志的可选列表转发到构建。 extra_include_paths - 包括目录的可选列表转发到构建。 BUILD_DIRECTORY - 可选路径为构建工作空间使用。 冗长 - 若真，接通的负载的步骤详细日志记录。 with_cuda - 确定CUDA头和库是否被添加到该生成。如果设置为无（默认），该值被自动确定基于的.CU或[HTG11存在] .cuh在来源。其设置为 TRUE`给力CUDA头文件和库包括在内。 is_python_module - 若真（默认），出口所产生的共享库的Python模块。如果假，将其加载到处理作为一个纯动态库。 Returns 如果is_python_module是真，返回加载PyTorch扩展作为一个Python模块。如果is_python_module是假返回任何（共享库加载到过程作为副作用）。 Example >>> from torch.utils.cpp_extension import load >>> module = load( name='extension', sources=['extension.cpp', 'extension_kernel.cu'], extra_cflags=['-O2'], verbose=True) torch.utils.cpp_extension.``load_inline( name , cpp_sources , cuda_sources=None , functions=None , extra_cflags=None , extra_cuda_cflags=None , extra_ldflags=None , extra_include_paths=None , build_directory=None , verbose=False , with_cuda=None , is_python_module=True )[source] 装载来自串源的PyTorch C ++扩展刚刚在时间（JIT）。 此函数的行为完全一样 负载（），但需要它的来源字符串而不是文件名。这些字符串存储到文件中生成目录，之后， load_inline的行为（） 是相同的 负载（）。 参见测试使用此功能的好例子。 源可省略典型的非直列C ++扩展的两个必需的部分：必要的头包括，以及所述（pybind11）绑定代码。更精确地，字符串传递给cpp_sources首先连接成单个的.cpp文件。该文件然后用前缀的#include & LT ;torch/ extension.h & GT ;。 此外，如果功能提供参数，绑定将被自动指定为每个功能产生。 功能可以是函数名的列表，或者从功能名称来文档字符串的字典映射。如果给出一个列表，每个函数的名称作为它的文档字符串。 cuda_sources 被连接到一个单独的.CU文件，并通过torch/ types.h中预先考虑在来源 ，cuda.h和 cuda_runtime.h包括。的的.cpp和.CU的文件被单独编译，但最终连接到单个库。注意，没有绑定在 cuda_sources本身为函数生成的。绑定到一个CUDA内核，你必须创建一个C ++函数调用它，无论是申报或cpp_sources 的一个定义这个C ++函数（且在HTG36包括它的名字] 功能）。 参见 负载（）为以下省略的参数的描述。 Parameters cpp_sources - 一个字符串或字符串的列表中，含有C ++源代码。 cuda_sources - 一个字符串或字符串的列表，包含CUDA源代码。 功能 - 要为其生成功能绑定函数名称的列表。如果字典中给出，它应该映射函数名的文档字符串（否则只是函数名）。 with_cuda - 确定CUDA头和库是否被添加到该生成。如果设置为无（默认），该值被自动确定基于是否cuda_sources提供。其设置为 TRUE`给力CUDA头文件和库包括在内。 Example >>> from torch.utils.cpp_extension import load_inline >>> source = ''' at::Tensor sin_add(at::Tensor x, at::Tensor y) { return x.sin() + y.sin(); } ''' >>> module = load_inline(name='inline_extension', cpp_sources=[source], functions=['sin_add']) torch.utils.cpp_extension.``include_paths( cuda=False )[source] 获取包括建立一个C ++或CUDA扩展所需的路径。 Parameters CUDA - CUDA专用如果真，包括包括路径。 Returns 名单包括路径字符串。 torch.utils.cpp_extension.``check_compiler_abi_compatibility( compiler )[source] 验证给定的编译器与PyTorch ABI兼容。 Parameters 编译 （ STR ） - 编译器可执行文件的名称来检查（例如，克++）。必须在shell进程可执行文件。 Returns FALSE如果编译器（可能）ABI-不符合PyTorch，否则真。 torch.utils.cpp_extension.``verify_ninja_availability()[source] 返回真如果忍者打造系统可在系统上。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"data.html":{"url":"data.html","title":"torch.utils.data","keywords":"","body":"torch.utils.data 在PyTorch数据加载工具的心脏是 torch.utils.data.DataLoader类。它代表了一个数据集的一个Python迭代，与支持 图式和可迭代式的数据集 定制数据加载顺序 自动配料 单和多处理数据加载 自动存储器钉扎。 这些选项由的构造器参数构成的 的DataLoader，其具有签名： DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None) 下面的章节详细描述了影响和这些选项的用法。 数据集类型 的 的DataLoader构造的最重要的参数是数据集，其指示数据集对象从加载数据。 PyTorch支持两种不同类型的数据集： 图式数据集 迭代式的数据集[HTG1。 地图式的数据集 一种地图风格数据集是一个用于实现__getitem __（）和__len __（）协议，以及表示从（可能是一个地图非一体）索引/键数据样本。 例如，这样的数据集，当与访问数据集[IDX]，可以读取IDX个图像和其相应的标签从磁盘上的文件夹。 参见 数据集了解更多详情。 可迭代式的数据集 可迭代式数据集的 一个子类的实例IterableDataset实现了__iter __（）协议和代表了数据样本可迭代。这种类型的数据集的特别适合于情况下随机读取是昂贵的，甚至不可能的，并且其中所述批量大小取决于所取的数据。 例如，这样的数据集，称为当ITER（数据集），可以返回数据从数据库中，远程服务器读取的流，或甚至原木实时生成。 参见 IterableDataset了解更多详情。 注意 当使用 IterableDataset与多进程数据加载。相同的数据集对象被复制在每个工作进程，因此副本必须被不同地配置，以避免重复的数据。参见 IterableDataset如何实现这个单证。 数据加载顺序和 取样 用户定义的迭代为可迭代式的数据集，数据加载顺序完全由控制。这允许数据块读取和动态批量大小的更容易实现（例如，通过产生在每个时间成批样品）。 本节的其余部分涉及与图式的数据集的情况。torch.utils.data.Sampler [HTG7类可用于指定在数据加载用于索引/键的序列。他们代表了索引到的数据集可迭代的对象。例如，与随机梯度下降（SGD）的常见情况下， 取样 可以随机置换指数列表和屈服每一次一个，或产生一个少数人的小批量SGD。 一种顺序或改组采样器将基于所述洗牌参数向 的DataLoader自动构造。可替换地，用户可以使用取样参数来指定自定义 取样对象在每个时间产生的下一个索引/键获取。 自定义 取样为在一个时间产生一批指数列表可以作为batch_sampler参数传递。自动配料，也可以通过的batch_size和drop_last参数启用。参见下一节本更多细节。 Note 既不取样也不batch_sampler是具有可迭代式的数据集兼容，因为这样的数据集没有一个键或索引的概念。 装载成批和非成批数据 的DataLoader支持单个取出的数据样本自动整理成批次经由参数的batch_size，drop_last和batch_sampler。 自动配料（默认）HTG0] 这是最常见的情况，并且对应于提取数据的minibatch并将它们整理成批处理样品，即，含有与张量一个维度是所述批料尺寸（通常是第一个）。 当的batch_size（默认1）不是无，数据加载器的产率批量样品，而不是个别样品。 的batch_size和drop_last参数用于指定数据加载器如何获得数据集密钥的批次。在地图风格数据集，用户可以另外指定batch_sampler，它在一个时间产生密钥的列表。 Note 的的batch_size和drop_last参数基本上被用于一个batch_sampler从构建取样。在地图式的数据集时，取样或者由用户提供的或根据洗牌参数构成。对于迭代式的数据集时，取样是伪无限之一。参见本节上采样的更多细节。 Note 当从迭代式的数据集与取多处理，在drop_last参数下降到最后的非整批生产的每个员工的数据集复制品。 取使用从采样器的索引的样本的列表之后，函数作为collat​​e_fn参数被用来校核样本列表成批通过。 在这种情况下，从图式集装是大致相当于： for indices in batch_sampler: yield collate_fn([dataset[i] for i in indices]) 并从迭代式集装是大致相当于： dataset_iter = iter(dataset) for indices in batch_sampler: yield collate_fn([next(dataset_iter) for _ in indices]) 自定义collat​​e_fn可以被用于定制的归类，例如，填充顺序数据至一批最大长度。查看更多关于collat​​e_fn 本节[HTG5。 禁用自动配料 在某些情况下，用户可能希望将在数据集代码手动处理配料，或简单地装载单个样品。例如，它可能更便宜直接加载成批数据（例如，批量从数据库中读取或读取的存储器大块连续）或批量大小是依赖于数据的，或者程序被设计为在单个样品工作。在这些情况下，很可能更好，不使用自动配料（其中collat​​e_fn被用来校核的样品），但让所述数据加载器直接返回的每个成员数据集对象。 当两个的batch_size和batch_sampler是无为（默认值batch_sampler已经无），自动配料被禁用。从数据集获得的每个样品与作为collat​​e_fn参数传递的功能进行处理。 [HTG0当自动配料被禁用，默认collat​​e_fn简单地NumPy的阵列转换成PyTorch张量，并保持所有其他不变。 In this case, loading from a map-style dataset is roughly equivalent with: for index in sampler: yield collate_fn(dataset[index]) and loading from an iterable-style dataset is roughly equivalent with: for data in iter(dataset): yield collate_fn(data) 查看更多关于collat​​e_fn本节[HTG1。 与collat​​e_fn工作 利用collat​​e_fn当自动配料被启用或禁用略有不同。 [HTG0当自动配料被禁用，collat​​e_fn被称为与每个单独的数据样本，并且输出从所述数据加载器的迭代得到。在这种情况下，默认collat​​e_fn简单地转换在PyTorch张量NumPy的阵列。 [HTG0当自动配料使能，collat​​e_fn调用与各时刻的数据样本的一个列表。预计到输入样本整理成批处理从数据加载器的迭代得到。本节的其余部分描述了在这种情况下，默认的collat​​e_fn的行为。 例如，如果每个数据样本包括3通道图像和积分类别标签，即，该数据集的每个元素返回一个元组（图像， class_index），默认collat​​e_fn核对这样元组的列表成批处理图像张量的一个元组和批处理类别标签张量。具体地，默认collat​​e_fn具有以下性质： 它总是预先考虑一个新的维度批次尺寸。 它自动NumPy的阵列和Python数值转换成PyTorch张量。 它保留的数据结构，例如，如果每个样本是一个字典，它输出具有相同的密钥集合，但分批张量作为值（或列表，如果值不能被转换成张量）的字典。同样为列表S，元组S，namedtupleS等 用户可以使用定制collat​​e_fn以实现自定义配料，例如，沿除各种长度，或增加对自定义数据类型支撑件的第一，填充序列以外的尺寸核对。 单和多进程数据载入 A的DataLoader缺省使用单进程数据加载。 内一个Python过程中，全局解释器锁（GIL）防止真正完全并行跨线程Python代码。为了避免与数据加载阻断计算代码，PyTorch提供了一个简单开关通过简单地将参数num_workers设置为一个正整数，以执行多处理数据加载。 单进程的数据加载（默认） 在此模式下，数据被取在相同的工艺做了 的DataLoader 被初始化。因此，数据加载可能会阻止计算。然而，这种模式可被当处理（例如，共享存储器，文件描述符）之间使用共享数据资源（多个）是有限的，或者当整个数据集是小，并且可以完全在内存加载优选的。另外，单进程加载经常显示更加可读的错误的痕迹，因此对于调试是有用的。 多进程数据加载 设置参数num_workers作为正整数将接通的多进程数据加载与装载机的工作进程指定的次数。 在这种模式下，每次迭代一个 的DataLoader，创建（例如，当调用枚举（的DataLoader）），num_workers被创建工作进程。在这一点上，数据集，collat​​e_fn和worker_init_fn被传递到每个工人，在那里它们被用来初始化，并获取数据。这意味着，数据集访问其内部IO一起，变换（包括collat​​e_fn）在工作进程中运行。 torch.utils.data.get_worker_info（） 在一个工作进程返回各种有用的信息（包括工人ID，数据集的副本，初始种子等）在主处理中，并返回无。用户可以在数据集中代码中使用此功能和/或worker_init_fn单独配置每个数据集的副本，并确定该代码是否在工作进程运行。例如，这可以是在分片数据集特别有用。 在地图风格数据集，主处理使用取样产生的索引，并将它们发送给工人。因此，任何洗牌随机化，其中通过分配指标来加载引导加载主进程完成。 对于迭代式的数据集，因为每个工作进程得到数据集对象的副本，幼稚多进程加载通常将导致复制的数据。使用 torch.utils.data.get_worker_info（）和/或worker_init_fn中，用户可以配置每个复制品独立。 （参见 IterableDataset单证如何实现这一点。）对于类似的原因，在多进程加载时，drop_last参数下降到最后的非整批生产的每个工人的迭代式的数据集副本。 工人被关闭一旦达到迭代结束时，或者当迭代器将变为垃圾收集。 警告 它一般不建议恢复在多进程加载CUDA张量，因为许多微妙之处使用CUDA和多分享CUDA张量（见多处理 CUDA）。相反，我们建议使用自动存储器钉扎（即，设置pin_memory =真），这使得能够快速数据传输到支持CUDA的GPU。 特定于平台的行为 由于工人依靠Python的 多重处理 ，工人发射行为是在Windows上的不同比的Unix。 在Unix，叉（）为默认 多处理启动方法。使用叉（），童工通常可以直接通过克隆地址空间中的数据集和Python参数的函数访问。 在Windows中，产卵（）为默认 多处理启动方法。使用重生（），另一种解释是推出是运行在主脚本，然后由接收数据集内部职工功能， collat​​e_fn和通过 泡菜序列的其它参数。 这个单独的序列化意味着你应该采取两个步骤，以确保您与Windows兼容，同时使用多进程数据加载： 包裹内你们中的大多数主要脚本代码，如果 __name__ == '__main__'：块，使确保它不会再次运行（最有可能产生误差）时，每个工作进程启动。您可以将您的数据集和 的DataLoader实例创建逻辑在这里，因为它并不需要在工人重新执行。 确保任何自定义collat​​e_fn，worker_init_fn或数据集代码声明顶层定义，__main__检查之外。这确保了他们在工作进程可用。 （这是需要，因为功能酸洗作为参考而已，不是字节码）。 随机性在多进程数据加载 默认情况下，每个工人将具有其PyTorch种子设为base_seed + worker_id，其中base_seed是一个长期的，通过使用其RNG主过程中产生的（从而，消耗了RNG状态强制）。但是，对于其他种子库可以在初始化工人（W.G.，NumPy的），使每个工人返回相同的随机数被复制。 （参见 本部分 在FAQ）。 在worker_init_fn，则可以访问PyTorch种子集对每个工人用任一 torch.utils.data.get_worker_info（）。种子或 torch.initial_seed（） ，并用它的数据加载之前种子其他库。 存储器钢钉 主机到GPU副本要快得多，当他们从固定（锁定页）内存起源。参见 使用固定的内存缓冲区 有关何时以及如何一般采用固定内存的更多细节。 为数据加载，使pin_memory =真对 的DataLoader 将自动把所获取的数据张量在钉扎存储器，并因此能够更快的数据传输到支持CUDA的GPU。 默认存储器锁定逻辑仅识别张量和地图以及包含张量iterables。默认情况下，如果锁定逻辑看到一个批次是一个自定义类型（这将如果您有发生collat​​e_fn 返回一个自定义的间歇式），或者如果每个元素的批量是一个自定义的类型，钉扎逻辑将无法识别它们，并且它会返回该批次（或那些元件）而没有钉扎的存储器。为了使存储器钉扎定制间歇或数据类型，定义上的自定义类型（多个）pin_memory（）方法。 请参见下面的例子。 例： class SimpleCustomBatch: def __init__(self, data): transposed_data = list(zip(*data)) self.inp = torch.stack(transposed_data[0], 0) self.tgt = torch.stack(transposed_data[1], 0) # custom memory pinning method on custom type def pin_memory(self): self.inp = self.inp.pin_memory() self.tgt = self.tgt.pin_memory() return self def collate_wrapper(batch): return SimpleCustomBatch(batch) inps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5) tgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5) dataset = TensorDataset(inps, tgts) loader = DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper, pin_memory=True) for batch_ndx, sample in enumerate(loader): print(sample.inp.is_pinned()) print(sample.tgt.is_pinned()) classtorch.utils.data.``DataLoader( dataset , batch_size=1 , shuffle=False , sampler=None , batch_sampler=None , num_workers=0 , collate_fn=None , pin_memory=False , drop_last=False , timeout=0 , worker_init_fn=None , multiprocessing_context=None )[source] 数据加载。结合了数据集和采样，并提供了在给定数据集的迭代。 的 的DataLoader同时支持地图风格和迭代式的数据集与单或多进程加载，定制加载顺序和可选的自动配料（对照）和内存牵制。 有关详细信息，请参见 torch.utils.data文档页面。 Parameters 数据集 （ 数据集 ） - 从该数据集到加载数据。 的batch_size （ INT ， 可选 ） - 如何每批许多样品加载（默认值：1）。 洗牌 （ 布尔 ， 可选 ） - 设置为真为具有在每个历元改组的数据（默认值：假）。 取样 （ 取样 ， 可选 ） - 定义从数据集中得出样品的策略。如果指定，洗牌必须假 [HTG17。 batch_sampler （ 取样 ， 可选 ） - 象取样，但在同一时间返回一批指标。互斥与的batch_size，洗牌，取样和drop_last。 num_workers （ INT ， 可选 ） - 多少子过程用于数据加载。 0意味着数据将在主处理加载。 （默认值：0） collat​​e_fn （ 可调用 ， 可选 ） - 合并的样本的列表，以形成小批量张量（S）的。使用从图式集装批处理时使用。 pin_memory （ 布尔 ， 可选 ） - 如果真，数据装载将在返回之前复制到张量CUDA固定内存。如果数据元素是一个自定义类型，或你的collat​​e_fn返回一批即自定义类型，见下面的例子。 drop_last （ 布尔 ， 可选 ） - 设置为真放弃最后一批不全，如果数据集大小不是由批量大小整除。如果假和数据集的大小是不是批量大小整除，则最后一批将较小。 （默认值：假） 超时 （ 数字 ， 可选 ） - 如果是阳性的，对于从工人收集一批的超时值。应始终非负。 （默认值：0） worker_init_fn （ 可调用 ， 可选 ） - 如果未无，这将是叫上与工人ID每个工人子（在一个int [0， num_workers - 1]）作为输入，在播种之后和数据加载之前。 （默认值：无） Warning 如果使用菌种启动方法，worker_init_fn不能是unpicklable对象，例如，lambda函数。参见 多处理最佳实践 在PyTorch到多处理相关的更多细节。 Note LEN（的DataLoader）启发式是基于所使用的取样器的长度。当数据集是 IterableDataset ，将使用一个无限采样器，其__len__ （）未实现，因为实际的长度取决于两个可迭代以及多进程加载构造。所以，除非他们有地图式的数据集工作，一个不应该查询该方法。参见数据集类型关于这两种类型的数据集的更多细节。 classtorch.utils.data.``Dataset[source] 表示 数据集的抽象类。 表示从键数据样本的地图所有数据集应该继承它。所有子类应该overrite __getitem __（），支持获取对于给定的密钥数据样本。子类还可以任选地覆盖__len __（），预计由返回的数据集的大小许多 取样实施方式和的 的DataLoader的默认选项。 Note 的DataLoader缺省构建一个索引采样能产生整数指数。为了使它与地图式的数据集与非整指数/键的作用，必须提供自定义采样。 classtorch.utils.data.``IterableDataset[source] 可迭代的数据集。 代表数据样本的迭代所有数据集应该继承它。当数据来自一个数据集流的这种形式是特别有用的。 所有子类应该overrite __iter __（），这将返回样本的迭代在该数据集。 当一个子类使用具有 的DataLoader，在数据集中的每个项目将被从得到的 的DataLoader迭代器。当num_workers & GT ; 0，每个工作进程将具有数据集对象的不同拷贝，因此通常希望独立地配置每个拷贝，以避免从工人返回重复数据。get_worker_info（），在一个工作进程调用时，返回关于工人的信息。它可以在任一使用的数据集的__iter __（）方法或 的DataLoader的worker_init_fn选项来修改每个副本的行为。 实施例1：在所有工人分裂工作量__iter __（）： >>> class MyIterableDataset(torch.utils.data.IterableDataset): ... def __init__(self, start, end): ... super(MyIterableDataset).__init__() ... assert end > start, \"this example code only works with end >= start\" ... self.start = start ... self.end = end ... ... def __iter__(self): ... worker_info = torch.utils.data.get_worker_info() ... if worker_info is None: # single-process data loading, return the full iterator ... iter_start = self.start ... iter_end = self.end ... else: # in a worker process ... # split workload ... per_worker = int(math.ceil((self.end - self.start) / float(worker_info.num_workers))) ... worker_id = worker_info.id ... iter_start = self.start + worker_id * per_worker ... iter_end = min(iter_start + per_worker, self.end) ... return iter(range(iter_start, iter_end)) ... >>> # should give same set of data as range(3, 7), i.e., [3, 4, 5, 6]. >>> ds = MyIterableDataset(start=3, end=7) >>> # Single-process loading >>> print(list(torch.utils.data.DataLoader(ds, num_workers=0))) [3, 4, 5, 6] >>> # Mult-process loading with two worker processes >>> # Worker 0 fetched [3, 4]. Worker 1 fetched [5, 6]. >>> print(list(torch.utils.data.DataLoader(ds, num_workers=2))) [3, 5, 4, 6] >>> # With even more workers >>> print(list(torch.utils.data.DataLoader(ds, num_workers=20))) [3, 4, 5, 6] 实施例2：使用在所有工人分裂工作量worker_init_fn： >>> class MyIterableDataset(torch.utils.data.IterableDataset): ... def __init__(self, start, end): ... super(MyIterableDataset).__init__() ... assert end > start, \"this example code only works with end >= start\" ... self.start = start ... self.end = end ... ... def __iter__(self): ... return iter(range(self.start, self.end)) ... >>> # should give same set of data as range(3, 7), i.e., [3, 4, 5, 6]. >>> ds = MyIterableDataset(start=3, end=7) >>> # Single-process loading >>> print(list(torch.utils.data.DataLoader(ds, num_workers=0))) [3, 4, 5, 6] >>> >>> # Directly doing multi-process loading yields duplicate data >>> print(list(torch.utils.data.DataLoader(ds, num_workers=2))) [3, 3, 4, 4, 5, 5, 6, 6] >>> # Define a `worker_init_fn`that configures each dataset copy differently >>> def worker_init_fn(worker_id): ... worker_info = torch.utils.data.get_worker_info() ... dataset = worker_info.dataset # the dataset copy in this worker process ... overall_start = dataset.start ... overall_end = dataset.end ... # configure the dataset to only process the split workload ... per_worker = int(math.ceil((overall_end - overall_start) / float(worker_info.num_workers))) ... worker_id = worker_info.id ... dataset.start = overall_start + worker_id * per_worker ... dataset.end = min(dataset.start + per_worker, overall_end) ... >>> # Mult-process loading with the custom `worker_init_fn` >>> # Worker 0 fetched [3, 4]. Worker 1 fetched [5, 6]. >>> print(list(torch.utils.data.DataLoader(ds, num_workers=2, worker_init_fn=worker_init_fn))) [3, 5, 4, 6] >>> # With even more workers >>> print(list(torch.utils.data.DataLoader(ds, num_workers=20, worker_init_fn=worker_init_fn))) [3, 4, 5, 6] classtorch.utils.data.``TensorDataset( *tensors )[source] 数据集包装张量。 每个样品将沿所述第一维度的索引张量进行检索。 Parameters *张量 （ 张量 ） - 具有所述第一尺寸的大小相同张量。 classtorch.utils.data.``ConcatDataset( datasets )[source] 数据集作为多个数据集的串联。 这个类是组装不同的现有数据集是有用的。 Parameters 数据集 （ 序列 ） - 数据集的列表要连接 classtorch.utils.data.``ChainDataset( datasets )[source] 数据集chainning多个 IterableDataset秒。 这个类是组装不同的现有数据集流是有用的。该chainning操作上即时完成的，因此串联与此类大型数据集将是有效的。 Parameters 数据集 （ IterableDataset 的迭代） - 数据集链接在一起 classtorch.utils.data.``Subset( dataset , indices )[source] 在指定的索引数据集的子集。 Parameters 数据集 （ 数据集 ） - 整个数据集 指数 （ 序列 ） - 在整个组索引选择的子集 torch.utils.data.``get_worker_info()[source] 返回当前 的DataLoader迭代工作进程的信息。 当一个工人叫，这将返回保证具有以下属性的对象： ID：当前作业人员ID。 num_workers：工人的总数。 种子：当前工人随机种子集。此值由主进程RNG和工人的ID来确定。参见 的DataLoader的更多细节的文档。 数据集：数据集对象在 这里 过程的副本。请注意，这将是在不同的进程比一个主处理不同的对象。 当主过程调用，这将返回无。 Note 当所使用的worker_init_fn传递到 的DataLoader，该方法可以是设置每个工人有用过程不同，例如，使用worker_id配置数据集目的是只读分片数据集的特定部分，或使用种子种子中的数据集的代码（例如，NumPy的）使用其他文库。 torch.utils.data.``random_split( dataset , lengths )[source] 随机分割数据集到给定长度的非重叠的新的数据集。 Parameters 数据集 （ 数据集 ） - 数据集要被分割 长度 （ 序列 ） - 要产生裂缝的长度 classtorch.utils.data.``Sampler( data_source )[source] 基类的所有取样。 每采样的子类必须提供一个__iter __（）的方法，提供一种方式来迭代数据集的元素的索引，和__len __（）方法，它返回所返回的迭代器的长度。 Note 的__len __（）方法并不严格 的DataLoader必需的，但在涉及任何计算预期的 的DataLoader的长度。 classtorch.utils.data.``SequentialSampler( data_source )[source] 顺序地将样品的元素，总是以相同的顺序。 Parameters DATA_SOURCE （ 数据集 ） - 数据集以从采样 classtorch.utils.data.``RandomSampler( data_source , replacement=False , num_samples=None )[source] 样品元件中随机。如果不更换，然后从一个洗牌的数据集进行采样。如果具有置换，然后用户可指定num_samples绘制。 Parameters data_source ( Dataset) – dataset to sample from 替换 （ 布尔 ） - 样品绘制替换如果真，默认=False num_samples （ INT ） - 样本的数目来绘制，默认=LEN（数据集）。该参数应该当替换是真仅被指定。 classtorch.utils.data.``SubsetRandomSampler( indices )[source] 随机样本元素从指数的定列表，无需更换。 Parameters 指数 （ 序列 ） - 索引的序列 classtorch.utils.data.``WeightedRandomSampler( weights , num_samples , replacement=True )[source] 从样品元素[0，..，LEN（权重）-1]与给定的概率（权重）。 Parameters 权重 （ 序列 ） - 权重的顺序，没有必要总结到一个 num_samples （ INT ） - 样本的数目来绘制 替换 （ 布尔 ） - 如果真，样品绘制更换。如果不是，他们绘制无需更换，这意味着当指数样本绘制为行，不能再为该行画出。 例 >>> list(WeightedRandomSampler([0.1, 0.9, 0.4, 0.7, 3.0, 0.6], 5, replacement=True)) [0, 0, 0, 1, 0] >>> list(WeightedRandomSampler([0.9, 0.4, 0.05, 0.2, 0.3, 0.1], 5, replacement=False)) [0, 1, 4, 3, 2] classtorch.utils.data.``BatchSampler( sampler , batch_size , drop_last )[source] 包装另一个采样，以产生小批量指数。 Parameters 取样 （ 取样 ） - 基采样器。 的batch_size （ INT ） - 小批量的大小。 drop_last （ 布尔 ） - 如果真，采样器将下降的最后一批，如果它的规模将是小于的batch_size Example >>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False)) [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] >>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True)) [[0, 1, 2], [3, 4, 5], [6, 7, 8]] classtorch.utils.data.distributed.``DistributedSampler( dataset , num_replicas=None , rank=None , shuffle=True )[source] 取样器，限制数据加载到数据集的一个子集。 它与 torch.nn.parallel.DistributedDataParallel 结合特别有用。在这种情况下，每个过程可以通过一个DistributedSampler实例作为的DataLoader采样器，并加载原始数据集即排它的一个子集。 Note 数据集被认为是恒定的大小。 Parameters 数据集 - 数据集用于采样。 num_replicas （ 可选 ） - 的参与分布式训练的进程数。 秩 （ 可选 ） - num_replicas内的当前过程的秩。 洗牌 （ 可选 ） - 如果为true（默认值），采样器将会洗牌指数 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"dlpack.html":{"url":"dlpack.html","title":"torch.utils.dlpack","keywords":"","body":"torch.utils.dlpack torch.utils.dlpack.``from_dlpack( dlpack ) → Tensor 解码DLPack到张量。 Parameters dlpack - 与dltensor一个PyCapsule对象 张量将与dlpack表示的对象共享存储器。请注意，每个dlpack只能使用一次消耗。 torch.utils.dlpack.``to_dlpack( tensor ) → PyCapsule 返回表示张量DLPack。 Parameters 张量 - 要导出的张量 该dlpack共享内存的张量。请注意，每个dlpack只能使用一次消耗。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"model_zoo.html":{"url":"model_zoo.html","title":"torch.utils.model_zoo","keywords":"","body":"torch.utils.model_zoo 移动到 torch.hub 。 torch.utils.model_zoo.``load_url( url , model_dir=None , map_location=None , progress=True ) 加载在给定的URLTorch 序列化对象。 如果对象已存在于 model_dir ，它的反序列化和返回。的URL的文件名部分应遵循命名惯例的文件名 - & LT。; SHA256 & GT ; EXT其中& LT ; SHA256 & GT ;是该文件的内容的散列SHA256的前八个或多个数字。哈希用于确保唯一的名称，并验证该文件的内容。 的 model_dir 默认值是$ TORCH_HOME /检查点其中环境变量$ TORCH_HOME默认为$ XDG_CACHE_HOME /Torch [HTG13。$ XDG_CACHE_HOME遵循了Linux filesytem布局的X设计组规范，带有默认值HTG18] 〜/ .cache如果没有设置。 Parameters URL （ 串 ） - 对象的URL下载 model_dir （ 串 ， 可选 ） - 目录中保存对象 map_location （ 可选 ） - 一个功能或一个字典指定如何重新映射的存储位置（参见torch.load） 进展 （ 布尔 ， 可选 ） - 是否要显​​示进度条到stderr 例 >>> state_dict = torch.hub.load_state_dict_from_url('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth') Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"tensorboard.html":{"url":"tensorboard.html","title":"torch.utils.tensorboard","keywords":"","body":"torch.utils.tensorboard 在进一步讨论之前，可以在 https://www.tensorflow.org/tensorboard/被发现TensorBoard更多详情 一旦你安装TensorBoard，这些工具让您登录PyTorch模型和指标纳入了TensorBoard UI中的可视化的目录。标量，图像，柱状图，曲线图，和嵌入可视化都支持PyTorch模型和张量以及Caffe2网和斑点。 该SummaryWriter类是TensorBoard登录消费和可视化数据的主入口。例如： import torch import torchvision from torch.utils.tensorboard import SummaryWriter from torchvision import datasets, transforms # Writer will output to ./runs/ directory by default writer = SummaryWriter() transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) trainset = datasets.MNIST('mnist_train', train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) model = torchvision.models.resnet50(False) # Have ResNet model take in grayscale rather than RGB model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False) images, labels = next(iter(trainloader)) grid = torchvision.utils.make_grid(images) writer.add_image('images', grid, 0) writer.add_graph(model, images) writer.close() 然后可以用TensorBoard可视化，这应该是安装和运行的有： pip install tb-nightly # Until 1.14 moves to the release channel tensorboard --logdir=runs 的大量信息可以记录一个实验。为了避免混乱的UI，并有更好的结果的聚类，通过分级命名它们，我们可以组地块。例如，“损失/火车”和“损耗/试验”将被分组在一起，而“准确度/火车”和“准确度/试验”将分别在TensorBoard接口分组。 from torch.utils.tensorboard import SummaryWriter import numpy as np writer = SummaryWriter() for n_iter in range(100): writer.add_scalar('Loss/train', np.random.random(), n_iter) writer.add_scalar('Loss/test', np.random.random(), n_iter) writer.add_scalar('Accuracy/train', np.random.random(), n_iter) writer.add_scalar('Accuracy/test', np.random.random(), n_iter) 预期结果： classtorch.utils.tensorboard.writer.``SummaryWriter( log_dir=None , comment='' , purge_step=None , max_queue=10 , flush_secs=120 , filename_suffix='' )[source] 直接将条目写入事件文件在LOG_DIR由TensorBoard消耗。 在 SummaryWriter 类提供了一个高层次的API来创建指定目录的事件文件，并添加摘要和事件给它。类异步更新文件内容。这使得培训计划，调用方法将数据添加到直接从训练循环的文件，而不会减慢培训。 __init__( log_dir=None , comment='' , purge_step=None , max_queue=10 , flush_secs=120 , filename_suffix='' )[source] 创建 SummaryWriter 将写出事件和摘要的事件文件。 Parameters LOG_DIR （ 串 ） - 保存目录位置。缺省值是运行/ CURRENT_DATETIME_HOSTNAME ，在每次运行后，其改变。采用分层文件夹结构容易运行之间的比较。例如通过在“运行/ EXP1”，“运行/ EXP2”等，为每一个新的实验在它们之间进行比较。 留言 （ 串 ） - 评LOG_DIR后缀附加到缺省LOG_DIR。如果LOG_DIR被分配，这种说法没有任何效果。 purge_step （ INT ） - 如果记录在步骤 T，崩溃 + X T + X T + X 和在重新开始步骤 T T T ，其global_step大于或等于 [任何事件HTG71 ] T T T 将被清除和hidde n在TensorBoard。需要注意的是死机了，重新开始实验，应该有相同的LOG_DIR [HTG97。 max_queue （ INT ） - 为的“添加”前一个未决事件和摘要的队列的大小调用迫使冲洗到磁盘。默认为十个项目。 flush_secs （ INT ） - 多久，在几秒钟内，冲洗未决事件和摘要到磁盘。默认为每两分钟。 filename_suffix （ 串 ） - 后缀添加到在LOG_DIR目录中的所有事件文件名。在文件名施工tensorboard.summary.writer.event_file_writer.EventFileWriter更多细节。 例子： from torch.utils.tensorboard import SummaryWriter # create a summary writer with automatically generated folder name. writer = SummaryWriter() # folder location: runs/May04_22-14-54_s-MacBook-Pro.local/ # create a summary writer using the specified folder name. writer = SummaryWriter(\"my_experiment\") # folder location: my_experiment # create a summary writer with comment appended. writer = SummaryWriter(comment=\"LR_0.1_BATCH_16\") # folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/ add_scalar( tag , scalar_value , global_step=None , walltime=None )[source] 标量数据添加到汇总。 Parameters 标记 （ 串 ） - 数据标识符 scalar_value （ 浮动 或 串/ blobname ） - 值保存 global_step （ INT ） - 全球步长值来记录 事件的时期后的可选覆盖默认walltime（了time.time（）），与秒 - walltime （ 浮动 ） Examples: from torch.utils.tensorboard import SummaryWriter writer = SummaryWriter() x = range(100) for i in x: writer.add_scalar('y=2x', i * 2, i) writer.close() Expected result: add_scalars( main_tag , tag_scalar_dict , global_step=None , walltime=None )[source] 增加了许多标量数据汇总。 请注意，此功能也保持记录的标量在内存中。在极端情况下，它爆炸的RAM。 Parameters main_tag （ 串 ） - 为对标签父名 tag_scalar_dict （ DICT ） - 键 - 值对存储标签和相应的值 global_step ( int) – Global step value to record walltime （ 浮动 ） - 可选覆盖默认walltime（了time.time（））秒事件的时期后 Examples: from torch.utils.tensorboard import SummaryWriter writer = SummaryWriter() r = 5 for i in range(100): writer.add_scalars('run_14h', {'xsinx':i*np.sin(i/r), 'xcosx':i*np.cos(i/r), 'tanx': np.tan(i/r)}, i) writer.close() # This call adds three values to the same scalar plot with the tag # 'run_14h' in TensorBoard's scalar section. Expected result: add_histogram( tag , values , global_step=None , bins='tensorflow' , walltime=None , max_bins=None )[source] 添加柱状图总结。 Parameters tag ( string ) – Data identifier 值 （ torch.Tensor ， numpy.array 或 串/ blobname ） - 值来构建直方图 global_step ( int) – Global step value to record 仓 （ 串[HTG3） - 酮的{“tensorflow”，”自动”，‘的fd’，...}。这决定了容器是如何制作。你可以找到其他选项： https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html walltime ( float) – Optional override default walltime (time.time()) seconds after epoch of event Examples: from torch.utils.tensorboard import SummaryWriter import numpy as np writer = SummaryWriter() for i in range(10): x = np.random.random(1000) writer.add_histogram('distribution centers', x + i, i) writer.close() Expected result: add_image( tag , img_tensor , global_step=None , walltime=None , dataformats='CHW' )[source] 图像数据添加到汇总。 注意，这需要的枕包。 Parameters tag ( string ) – Data identifier img_tensor （ torch.Tensor ， numpy.array 或 串/ blobname ） - 图像数据 global_step ( int) – Global step value to record walltime ( float) – Optional override default walltime (time.time()) seconds after epoch of event Shape: img_tensor：默认为 （ 3 ， H ， W ） （3，H，W） （ 3 ， H ， W ） 。您可以使用torchvision.utils.make_grid（）对批量张量转换成3xHxW格式或致电add_images，让我们做工作。张量 （ 1 ， H ， W ） （1，H，W） （ 1 ， H ， W ） ， （ H ， W ） （H，W） （ H ， W ） ， [H TG158] （ H ， W ， 3 ） （H，W，3） （ H ， W ， 3 ） 也只要suitible作为对应 参数传递dataformats。例如CHW，HWC，HW。 Examples: from torch.utils.tensorboard import SummaryWriter import numpy as np img = np.zeros((3, 100, 100)) img[0] = np.arange(0, 10000).reshape(100, 100) / 10000 img[1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000 img_HWC = np.zeros((100, 100, 3)) img_HWC[:, :, 0] = np.arange(0, 10000).reshape(100, 100) / 10000 img_HWC[:, :, 1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000 writer = SummaryWriter() writer.add_image('my_image', img, 0) # If you have non-default dimension setting, set the dataformats argument. writer.add_image('my_image_HWC', img_HWC, 0, dataformats='HWC') writer.close() Expected result: add_images( tag , img_tensor , global_step=None , walltime=None , dataformats='NCHW' )[source] 成批的图像数据添加到汇总。 Note that this requires the pillowpackage. Parameters tag ( string ) – Data identifier img_tensor ( torch.Tensor , numpy.array , or string/blobname ) – Image data global_step ( int) – Global step value to record walltime ( float) – Optional override default walltime (time.time()) seconds after epoch of event dataformats （ 串 ） - 形式的NCHW，NHWC，CHW，HWC，HW，WH等的图像数据格式规范 Shape: img_tensor：默认为 （ N ， 3 ， H ， W ） （N，3，H，W） （ N ， 3 ， H ， W ） 。如果dataformats被指定，其他形状将被接受。例如NCHW或NHWC。 Examples: from torch.utils.tensorboard import SummaryWriter import numpy as np img_batch = np.zeros((16, 3, 100, 100)) for i in range(16): img_batch[i, 0] = np.arange(0, 10000).reshape(100, 100) / 10000 / 16 * i img_batch[i, 1] = (1 - np.arange(0, 10000).reshape(100, 100) / 10000) / 16 * i writer = SummaryWriter() writer.add_images('my_image_batch', img_batch, 0) writer.close() Expected result: add_figure( tag , figure , global_step=None , close=True , walltime=None )[source] 渲染matplotlib图成图像并将其添加到汇总。 注意，这需要的matplotlib包。 Parameters tag ( string ) – Data identifier [HTG0图（ matplotlib.pyplot.figure ） - 图或数字的列表 global_step ( int) – Global step value to record 关闭 （ 布尔 ） - 标志自动关闭该图 walltime ( float) – Optional override default walltime (time.time()) seconds after epoch of event add_video( tag , vid_tensor , global_step=None , fps=4 , walltime=None )[source] 视频数据添加到汇总。 注意，这需要的moviepy包。 Parameters tag ( string ) – Data identifier vid_tensor （ torch.Tensor ） - 视频数据 global_step ( int) – Global step value to record FPS （ 浮动 或 INT ） - 框子每秒 walltime ( float) – Optional override default walltime (time.time()) seconds after epoch of event Shape: vid_tensor： （ N ， T ， C ， H ， W ） （N，T，C，H，W） （ N ， T ， C ， H ， W ） 。的值应该位于[0,255]为式 UINT8 或[0,1]类型浮动。 add_audio( tag , snd_tensor , global_step=None , sample_rate=44100 , walltime=None )[source] 音频数据添加到汇总。 Parameters tag ( string ) – Data identifier snd_tensor （ torch.Tensor ） - 声音数据 global_step ( int) – Global step value to record SAMPLE_RATE （ INT ） - 以Hz采样率 walltime ( float) – Optional override default walltime (time.time()) seconds after epoch of event Shape: snd_tensor： （ 1 ， L ） （1，L） （ 1 ， L ） 。值应该[-1,1]之间。 add_text( tag , text_string , global_step=None , walltime=None )[source] 文本数据添加到汇总。 Parameters tag ( string ) – Data identifier text_string的 （ 串 ） - 字符串，以节省 global_step ( int) – Global step value to record walltime ( float) – Optional override default walltime (time.time()) seconds after epoch of event Examples: writer.add_text('lstm', 'This is an lstm', 0) writer.add_text('rnn', 'This is an rnn', 10) add_graph( model , input_to_model=None , verbose=False )[source] 图数据添加到汇总。 Parameters 模型 （ torch.nn.Module ） - 模型绘制。 input_to_model （ torch.Tensor 或 torch.Tensor 的列表中） - 的变量或变量的元组被输送。 冗长 （ 布尔 ） - 是否打印图形结构在控制台。 add_embedding( mat , metadata=None , label_img=None , global_step=None , tag='default' , metadata_header=None )[source] 添加投影数据嵌入到总结。 Parameters 垫 （ torch.Tensor 或 numpy.array ） - 甲矩阵，每一行都是特征向量数据点 元数据 （ 列表 ） - 标签的列表，每个元件将转换为串 label_img （ torch.Tensor ） - 图像对应于每个数据点 global_step ( int) – Global step value to record 标记 （ 串 ） - 名称为嵌入 Shape: 垫： （ N ， d ） （N，d） （ N ， d ） ，其中N是数据的数和d是特征尺寸 label_img： （ N ， C ， H ， W ） （N，C，H，W） （ N ， C ， H ， W ） Examples: import keyword import torch meta = [] while len(meta)add_pr_curve( tag , labels , predictions , global_step=None , num_thresholds=127 , weights=None , walltime=None )[source] 增加精度召回曲线。绘制精确召回曲线，让你了解下不同的阈值设置模型的性能。有了这个功能，你所提供的地面实况标签（T / F），并为每个目标预测置信（通常是模型的输出）。该TensorBoard UI会让你选择的门槛交互。 Parameters tag ( string ) – Data identifier 标签 （ torch.Tensor ， numpy.array 或 串/ blobname ） - 地面实测数据。每个元素的二进制标签。 的预测 （ torch.Tensor ， numpy.array 或 串/ blobname ） - 该元素被分类为真概率。值应在[0，1] global_step ( int) – Global step value to record num_thresholds （ INT ） - 用于绘制曲线的阈值的数量。 walltime ( float) – Optional override default walltime (time.time()) seconds after epoch of event Examples: from torch.utils.tensorboard import SummaryWriter import numpy as np labels = np.random.randint(2, size=100) # binary label predictions = np.random.rand(100) writer = SummaryWriter() writer.add_pr_curve('pr_curve', labels, predictions, 0) writer.close() add_custom_scalars( layout )[source] 在“标量”收集图表标签创建专题图。请注意，此功能只能调用一次，每个SummaryWriter（）对象。因为它仅提供元数据tensorboard，该功能可以前或训练后循环调用。 Parameters 布局 （ DICT ） - {类别名称： 图表 }，其中 图表 也是一个字典{chartName： ListOfProperties }。在 ListOfProperties 的第一个元素是图表的类型（ 一个多行 或 保证金 ）和所述第二元件应为包含的标签列表已在add_scalar使用功能，这将被收集到新的图表。 Examples: layout = {'Taiwan':{'twse':['Multiline',['twse/0050', 'twse/2330']]}, 'USA':{ 'dow':['Margin', ['dow/aaa', 'dow/bbb', 'dow/ccc']], 'nasdaq':['Margin', ['nasdaq/aaa', 'nasdaq/bbb', 'nasdaq/ccc']]}} writer.add_custom_scalars(layout) add_mesh( tag , vertices , colors=None , faces=None , config_dict=None , global_step=None , walltime=None )[source] 添加网格或三维点云TensorBoard。可视化是基于three.js所，所以它允许用户与描绘对象进行交互。除了诸如顶点，脸上的基本定义，用户可以进一步提供摄像机参数，照明条件等，请参见 https://threejs.org/docs/index.html#manual/en/introduction/Creating-a -scene用于高级用途。需要注意的是目前这取决于TB-夜间显示。 Parameters tag ( string ) – Data identifier 顶点 （ torch.Tensor ） - 三维坐标列表的顶点。 颜色 （ torch.Tensor ） - 为每个顶点的色彩 面 （ torch.Tensor ） - 每个三角形内的顶点指数。 （可选的） config_dict - 字典与ThreeJS类的名称和结构。 global_step ( int) – Global step value to record walltime ( float) – Optional override default walltime (time.time()) seconds after epoch of event Shape: 顶点： （ B ， N ， 3 ） （B，N，3） （ B ， N ， 3 ） 。 （分批，number_of_vertices，通道） 颜色： （ B ， N ， 3 ） （B，N，3） （ B ， N ， 3 ） 。的值应该位于[0,255]为式 UINT8 或[0,1]类型浮动。 面： （ B ， N ， 3 ） （B，N，3） （ B ， N ， 3 ） 。的值应该位于[0，number_of_vertices]为式 UINT8 。 Examples: from torch.utils.tensorboard import SummaryWriter vertices_tensor = torch.as_tensor([ [1, 1, 1], [-1, -1, 1], [1, -1, -1], [-1, 1, -1], ], dtype=torch.float).unsqueeze(0) colors_tensor = torch.as_tensor([ [255, 0, 0], [0, 255, 0], [0, 0, 255], [255, 0, 255], ], dtype=torch.int).unsqueeze(0) faces_tensor = torch.as_tensor([ [0, 2, 3], [0, 3, 1], [0, 1, 2], [1, 3, 2], ], dtype=torch.int).unsqueeze(0) writer = SummaryWriter() writer.add_mesh('my_mesh', vertices=vertices_tensor, colors=colors_tensor, faces=faces_tensor) writer.close() flush()[source] 刷新事件文件到磁盘。调用此方法，以确保所有未决事件已被写入磁盘。 close()[source] Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"onnx.html":{"url":"onnx.html","title":"torch.onnx","keywords":"","body":"torch.onnx [HTG0例：端至端AlexNet从PyTorch到ONNX 跟踪VS脚本 局限性 支持的运营商 为运营商添加支持 阿坦运营 非宏正操作符 自定义操作符 常见问题 功能 [HTG0例：端至端从PyTorch AlexNet到ONNX 这里是一个出口预训练AlexNet在torchvision定义成ONNX一个简单的脚本。它运行一个单轮推理的，然后保存该所得的跟踪模型alexnet.onnx： import torch import torchvision dummy_input = torch.randn(10, 3, 224, 224, device='cuda') model = torchvision.models.alexnet(pretrained=True).cuda() # Providing input and output names sets the display names for values # within the model's graph. Setting these does not change the semantics # of the graph; it is only for readability. # # The inputs to the network consist of the flat list of inputs (i.e. # the values you would pass to the forward() method) followed by the # flat list of parameters. You can partially specify names, i.e. provide # a list here shorter than the number of inputs to the model, and we will # only set that subset of names, starting from the beginning. input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ] output_names = [ \"output1\" ] torch.onnx.export(model, dummy_input, \"alexnet.onnx\", verbose=True, input_names=input_names, output_names=output_names) 将得到的alexnet.onnx是包含两者的网络结构和导出的模型（在此情况下，AlexNet）的参数的二进制protobuf的文件。关键字参数冗长=真使出口打印出所述网络的人类可读表示： # These are the inputs and parameters to the network, which have taken on # the names we specified earlier. graph(%actual_input_1 : Float(10, 3, 224, 224) %learned_0 : Float(64, 3, 11, 11) %learned_1 : Float(64) %learned_2 : Float(192, 64, 5, 5) %learned_3 : Float(192) # ---- omitted for brevity ---- %learned_14 : Float(1000, 4096) %learned_15 : Float(1000)) { # Every statement consists of some output tensors (and their types), # the operator to be run (with its attributes, e.g., kernels, strides, # etc.), its input tensors (%actual_input_1, %learned_0, %learned_1) %17 : Float(10, 64, 55, 55) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4]](%actual_input_1, %learned_0, %learned_1), scope: AlexNet/Sequential[features]/Conv2d[0] %18 : Float(10, 64, 55, 55) = onnx::Relu(%17), scope: AlexNet/Sequential[features]/ReLU[1] %19 : Float(10, 64, 27, 27) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%18), scope: AlexNet/Sequential[features]/MaxPool2d[2] # ---- omitted for brevity ---- %29 : Float(10, 256, 6, 6) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%28), scope: AlexNet/Sequential[features]/MaxPool2d[12] # Dynamic means that the shape is not known. This may be because of a # limitation of our implementation (which we would like to fix in a # future release) or shapes which are truly dynamic. %30 : Dynamic = onnx::Shape(%29), scope: AlexNet %31 : Dynamic = onnx::Slice[axes=[0], ends=[1], starts=[0]](%30), scope: AlexNet %32 : Long() = onnx::Squeeze[axes=[0]](%31), scope: AlexNet %33 : Long() = onnx::Constant[value={9216}](), scope: AlexNet # ---- omitted for brevity ---- %output1 : Float(10, 1000) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%45, %learned_14, %learned_15), scope: AlexNet/Sequential[classifier]/Linear[6] return (%output1); } 您也可以使用 onnx 库验证的protobuf。您可以安装onnx与畅达： conda install -c conda-forge onnx 然后，你可以运行： import onnx # Load the ONNX model model = onnx.load(\"alexnet.onnx\") # Check that the IR is well formed onnx.checker.check_model(model) # Print a human readable representation of the graph onnx.helper.printable_graph(model.graph) 要运行用导出脚本caffe2 ，你需要安装 caffe2 ：如果你没有一个已经，请[按照安装说明HTG5。 一旦安装了这些，您可以使用Caffe2后端： # ...continuing from above import caffe2.python.onnx.backend as backend import numpy as np rep = backend.prepare(model, device=\"CUDA:0\") # or \"CPU\" # For the Caffe2 backend: # rep.predict_net is the Caffe2 protobuf for the network # rep.workspace is the Caffe2 workspace for the network # (see the class caffe2.python.onnx.backend.Workspace) outputs = rep.run(np.random.randn(10, 3, 224, 224).astype(np.float32)) # To run networks with more than one input, pass a tuple # rather than a single numpy ndarray. print(outputs[0]) 您也可以运行导出模型ONNXRuntime ，你需要安装 ONNXRuntime ：请[按照这些指示HTG5。 一旦安装了这些，您可以使用ONNXRuntime后端： # ...continuing from above import onnxruntime as ort ort_session = ort.InferenceSession('alexnet.onnx') outputs = ort_session.run(None, {'actual_input_1': np.random.randn(10, 3, 224, 224).astype(np.float32)}) print(outputs[0]) 这里是出口超高分辨率模型ONNX的另一个教程。 。 在未来，还会有其他框架后端为好。 跟踪VS脚本 该ONNX出口既可以是 追踪基 和 __ 基于脚本的出口国。 跟踪为主 意味着它通过执行模型一次，导出此运行期间实际运行操作人员进行操作。这意味着，如果你的模型是动态的，例如，改变依赖于输入数据的行为，出口将是不准确的。同样，跟踪可能只针对特定的输入大小是有效的（这就是为什么我们需要在跟踪明确的输入。）我们建议检查模型跟踪，并确保跟踪的运营商希望合理。如果模型包含像for循环，如果条件控制流， 跟踪为主 出口将展开的循环和if条件，导出一个静态的图形是完全一样的，因为这跑。如果你要导出动态控制流模型，您将需要使用 基于脚本的 出口国。 基于脚本的 意味着你正在尝试导出模型是[ ScriptModule HTG3。 ScriptModule 是在 TorchScript 核心数据结构，和 TorchScript 是Python语言，从PyTorch代码创建和序列优化的模型的子集。 我们允许混合跟踪和脚本。您可以撰写跟踪和脚本，以适应模型的一部分的特殊要求。结帐这个例子： import torch # Trace-based only class LoopModel(torch.nn.Module): def forward(self, x, y): for i in range(y): x = x + i return x model = LoopModel() dummy_input = torch.ones(2, 3, dtype=torch.long) loop_count = torch.tensor(5, dtype=torch.long) torch.onnx.export(model, (dummy_input, loop_count), 'loop.onnx', verbose=True) 随着 跟踪为主 出口商，我们得到的结果ONNX图其器展开for循环： graph(%0 : Long(2, 3), %1 : Long()): %2 : Tensor = onnx::Constant[value={1}]() %3 : Tensor = onnx::Add(%0, %2) %4 : Tensor = onnx::Constant[value={2}]() %5 : Tensor = onnx::Add(%3, %4) %6 : Tensor = onnx::Constant[value={3}]() %7 : Tensor = onnx::Add(%5, %6) %8 : Tensor = onnx::Constant[value={4}]() %9 : Tensor = onnx::Add(%7, %8) return (%9) 为了利用 基于脚本的 出口商捕捉动态环路，我们可以编写脚本的循环，并从正规nn.Module调用它： # Mixing tracing and scripting @torch.jit.script def loop(x, y): for i in range(int(y)): x = x + i return x class LoopModel2(torch.nn.Module): def forward(self, x, y): return loop(x, y) model = LoopModel2() dummy_input = torch.ones(2, 3, dtype=torch.long) loop_count = torch.tensor(5, dtype=torch.long) torch.onnx.export(model, (dummy_input, loop_count), 'loop.onnx', verbose=True, input_names=['input_data', 'loop_range']) 现在出口ONNX图变为： graph(%input_data : Long(2, 3), %loop_range : Long()): %2 : Long() = onnx::Constant[value={1}](), scope: LoopModel2/loop %3 : Tensor = onnx::Cast[to=9](%2) %4 : Long(2, 3) = onnx::Loop(%loop_range, %3, %input_data), scope: LoopModel2/loop # custom_loop.py:240:5 block0(%i.1 : Long(), %cond : bool, %x.6 : Long(2, 3)): %8 : Long(2, 3) = onnx::Add(%x.6, %i.1), scope: LoopModel2/loop # custom_loop.py:241:13 %9 : Tensor = onnx::Cast[to=9](%2) -> (%9, %8) return (%4) 动态控制流得到正确捕获。我们可以在不同的循环范围的后端验证。 import caffe2.python.onnx.backend as backend import numpy as np import onnx model = onnx.load('loop.onnx') rep = backend.prepare(model) outputs = rep.run((dummy_input.numpy(), np.array(9).astype(np.int64))) print(outputs[0]) #[[37 37 37] # [37 37 37]] import onnxruntime as ort ort_sess = ort.InferenceSession('loop.onnx') outputs = ort_sess.run(None, {'input_data': dummy_input.numpy(), 'loop_range': np.array(9).astype(np.int64)}) print(outputs) #[array([[37, 37, 37], # [37, 37, 37]], dtype=int64)] 局限性 张量就地如索引分配数据[索引] = NEW_DATA 目前不出口支撑。解决这种问题的一种方法是使用操作符散射，明确地更新原来的张量。 data = torch.zeros(3, 4) index = torch.tensor(1) new_data = torch.arange(4).to(torch.float32) Assigning to left hand side indexing is not supported in exporting. class InPlaceIndexedAssignment(torch.nn.Module): def forward(self, data, index, new_data): data[index] = new_data return data class InPlaceIndexedAssignmentONNX(torch.nn.Module): def forward(self, data, index, new_data): new_data = new_data.unsqueeze(0) index = index.expand(1, new_data.size(1)) data.scatter_(0, index, new_data) return data out = InPlaceIndexedAssignmentONNX()(data, index, new_data) torch.onnx.export(InPlaceIndexedAssignmentONNX(), (data, index, new_data), 'inplace_assign.onnx') caffe2 import caffe2.python.onnx.backend as backend import onnx onnx_model = onnx.load('inplace_assign.onnx') rep = backend.prepare(onnx_model) out_caffe2 = rep.run((torch.zeros(3, 4).numpy(), index.numpy(), new_data.numpy())) assert torch.all(torch.eq(out, torch.tensor(out_caffe2))) onnxruntime import onnxruntime sess = onnxruntime.InferenceSession('inplace_assign.onnx') out_ort = sess.run(None, { sess.get_inputs()[0].name: torch.zeros(3, 4).numpy(), sess.get_inputs()[1].name: index.numpy(), sess.get_inputs()[2].name: new_data.numpy(), }) assert torch.all(torch.eq(out, torch.tensor(out_ort))) 有没有在ONNX张量清单的概念。如果没有这个概念，它是非常困难的出口消耗或产生张量清单运营商，尤其是当张列表的长度在出口时并不知道。 x = torch.tensor([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]]) This is not exportable class Model(torch.nn.Module): def forward(self, x): return x.unbind(0) This is exportable. Note that in this example we know the split operator will always produce exactly three outputs, Thus we can export to ONNX without using tensor list. class AnotherModel(torch.nn.Module): def forward(self, x): return [torch.squeeze(out, 0) for out in torch.split(x, [1,1,1], dim=0)] PyTorch和ONNX后端（Caffe2，ONNXRuntime等）经常与某些数字差异运营商的实现。根据模型结构，这些差异可能是微不足道的，但他们也可能会导致行为的主要分歧（特别是未经训练的模型。）我们允许Caffe2直接调用运营商的Torch 实现，帮你抚平这些差异时的精度是非常重要的，并且还记录这些差异。 支持的运营商 下面的运营商的支持： BatchNorm ConstantPadNd CONV 退出 嵌入（不支持任何可选参数） FeatureDropout（不支持培训模式） 指数 MaxPool1d MaxPool2d MaxPool3d RNN ABS ACOS adaptive_avg_pool1d adaptive_avg_pool2d adaptive_avg_pool3d adaptive_max_pool1d 自适应max_pool2d adaptive_max_pool3d 添加（不支持非零的α） addmm 和 人气指数 argmax argmin ASIN 晒黑 avg_pool1d avg_pool2d avg_pool2d avg_pool3d 猫 小区 钳 clamp_max clamp_min CONCAT COS dim_arange DIV 退出 埃卢 EQ ERF EXP 扩大 expand_as 弄平 地板 充分 full_like 收集 通用电器 谷氨酸 GT hardtanh index_copy index_fill index_select instance_norm isnan layer_norm 乐 leaky_relu 日志 LOG2 log_sigmoid log_softmax logsumexp LT masked_fill 最大 意思 分 毫米 MUL 狭窄 NE NEG 非零 规范 那些 ones_like 要么 置换 pixel_shuffle POW prelu（输入通道之间共享单个重量不支持） 刺 兰特 randn randn_like 倒数 reflection_pad RELU 重复 replication_pad 重塑 reshape_as rrelu RSUB 分散 scatter_add 选择 九色鹿 乙状结肠 标志 罪 尺寸 切片 SOFTMAX（仅暗淡= -1支持） softplus 分裂 开方 挤 堆 子（不支持非零的α） 和 Ť 黄褐色 正切 （不支持非零阈值/非零值）的阈值 至 TOPK 颠倒 type_as 展开（有了ATEN-Caffe2集成的实验性支持） unsqueeze upsample_nearest1d upsample_nearest2d upsample_nearest3d 视图 哪里 零 zeros_like 上述设置操作员足以导出以下机型： AlexNet DCGAN DenseNet 盗梦空间（警告：这种模式是高度敏感的操作方式有变动） RESNET 超高分辨率 VGG word_language_model 为运营商添加支持 增加对运营商出口的支持力度是 提前使用[HTG1。为了实现这一目标，开发人员需要触摸PyTorch的源代码。请遵循从源代码安装PyTorch的[说明书HTG3。如果想要的操作是ONNX规范，它应该很容易增加对出口此类操作（添加操作员的符号功能）的支持。要确认操作是否规范与否，请检查[ ONNX操作员列表HTG5。 阿坦运营 如果运营商是ATEN运营商，这意味着你可以找到函数的Torch /中国证监会申报/ autograd /生成/ VariableType.h（在PyTorch生成的代码可安装DIR），应添加符号函数在torch/ onnx / symbolic_opset & LT ;版本& GT ;。PY，并按照列为以下说明： 定义torch/ onnx / symbolic_opset & LT符号函数;版本& GT ;。PY，例如torch/onnx/symbolic_opset9.py 。确保函数具有相同的名称VariableType.h定义的ATEN操作/功能。 第一个参数始终是出口ONNX图。参数名称必须完全匹配VariableType.h的名字，因为调度与关键字参数来完成。 参数顺序不一定匹配是什么VariableType.h，张量（输入）总是第一个，那么非张量参数。 在象征性的功能，如果操作员在ONNX已经标准化，我们只需要创建一个节点来表示ONNX操作者在图中。 如果输入参数是一个张量，但ONNX要求一个标量，我们必须明确地做转换。辅助函数_scalar可以标量张量转换成一个Python标量，并且_if_scalar_type_as可以将一个Python标量成PyTorch张量。 非宏正操作符 如果操作员是一个非ATEN运算符，符号函数具有在对应PyTorch Function类被添加。请阅读以下说明： 创建名为的符号函数的符号在相应的功能类。 第一个参数始终是出口ONNX图。 除了首先必须参数名完全匹配转发的名字。 输出元组大小必须的向前的输出相匹配。 在象征性的功能，如果操作员在ONNX已经标准化，我们只需要创建一个节点来表示ONNX操作者在图中。 象征性的功能应该在Python中实现。所有这些功能与Python的方法这是通过C ++实现互动 - Python绑定，但直观的界面，他们提供这个样子的： def operator/symbolic(g, *inputs): \"\"\" Modifies Graph (e.g., using \"op\"), adding the ONNX operations representing this PyTorch function, and returning a Value or tuple of Values specifying the ONNX outputs whose values correspond to the original PyTorch return values of the autograd Function (or None if an output is not supported by ONNX). Arguments: g (Graph): graph to write the ONNX representation into inputs (Value...): list of values representing the variables which contain the inputs for this function \"\"\" class Value(object): \"\"\"Represents an intermediate tensor value computed in ONNX.\"\"\" def type(self): \"\"\"Returns the Type of the value.\"\"\" class Type(object): def sizes(self): \"\"\"Returns a tuple of ints representing the shape of a tensor this describes.\"\"\" class Graph(object): def op(self, opname, *inputs, **attrs): \"\"\" Create an ONNX operator 'opname', taking 'args' as inputs and attributes 'kwargs' and add it as a node to the current graph, returning the value representing the single output of this operator (see the `outputs`keyword argument for multi-return nodes). The set of operators and the inputs/attributes they take is documented at https://github.com/onnx/onnx/blob/master/docs/Operators.md Arguments: opname (string): The ONNX operator name, e.g., `Abs`or `Add`. args (Value...): The inputs to the operator; usually provided as arguments to the `symbolic`definition. kwargs: The attributes of the ONNX operator, with keys named according to the following convention: `alpha_f`indicates the `alpha`attribute with type `f`. The valid type specifiers are `f`(float), `i`(int), `s`(string) or `t`(Tensor). An attribute specified with type float accepts either a single float, or a list of floats (e.g., you would say `dims_i`for a `dims`attribute that takes a list of integers). outputs (int, optional): The number of outputs this operator returns; by default an operator is assumed to return a single output. If `outputs`is greater than one, this functions returns a tuple of output `Value`, representing each output of the ONNX operator in positional. \"\"\" 所述ONNX曲线C ++定义在torch/ CSRC / JIT / ir.h。 下面是处理缺失符号函数为ELU操作者的例子。我们尝试导出模型，并看到错误消息如下： UserWarning: ONNX export failed on elu because torch.onnx.symbolic_opset9.elu does not exist RuntimeError: ONNX export failed: Couldn't export operator elu 因为PyTorch不支持导出埃卢操作导出失败。我们发现虚拟 张量 埃卢（常量 张量 [ - ]放; 输入， [HTG17标量 α， 布尔 就地） 常量 覆盖[ ]在VariableType.h。这意味着ELU是一个宏正操作符。我们检查 ONNX操作员列表，并确认恶露在ONNX标准化。我们将下列行添加到symbolic_opset9.py： def elu(g, input, alpha, inplace=False): return g.op(\"Elu\", input, alpha_f=_scalar(alpha)) 现在PyTorch能够输出埃卢运营商。 有在 symbolic_opset9.py 以上实例中， symbolic_opset10.py 。 指定运营商定义的接口是实验;冒险的用户应注意，这些API将在未来的接口可能会改变。 自定义操作符 在此之后教程扩展TorchScript用自定义的C ++运算符，您可以创建并注册在PyTorch自己的自定义OPS的实现。以下是如何这样的模型导出到ONNX： # Create custom symbolic function from torch.onnx.symbolic_helper import parse_args @parse_args('v', 'v', 'f', 'i') def symbolic_foo_forward(g, input1, input2, attr1, attr2): return g.op(\"Foo\", input1, input2, attr1_f=attr1, attr2_i=attr2) # Register custom symbolic function from torch.onnx import register_custom_op_symbolic register_custom_op_symbolic('custom_ops::foo_forward', symbolic_foo_forward, 9) class FooModel(torch.nn.Module): def __init__(self, attr1, attr2): super(FooModule, self).__init__() self.attr1 = attr1 self.attr2 = attr2 def forward(self, input1, input2): # Calling custom op return torch.ops.custom_ops.foo_forward(input1, input2, self.attr1, self.attr2) model = FooModel(attr1, attr2) torch.onnx.export(model, (dummy_input1, dummy_input2), 'model.onnx') 根据自定义操作，可以将其导出为一个或现有ONNX OPS的组合。您也可以将其导出为自运在ONNX为好。在这种情况下，你将需要相匹配的定制OPS实现，例如延长您所选择的后端 Caffe2定制OPS ， ONNXRuntime定制OPS 。 常见问题 问：我已出口我LSTM模式，但其输入的大小似乎是固定的？ 示踪剂记录在图中的示例输入形状。在情况下，模型应该接受动态形状的输入，你可以利用出口API参数 dynamic_axes [HTG1。 layer_count = 4 model = nn.LSTM(10, 20, num_layers=layer_count, bidirectional=True) model.eval() with torch.no_grad(): input = torch.randn(5, 3, 10) h0 = torch.randn(layer_count * 2, 3, 20) c0 = torch.randn(layer_count * 2, 3, 20) output, (hn, cn) = model(input, (h0, c0)) # default export torch.onnx.export(model, (input, (h0, c0)), 'lstm.onnx') onnx_model = onnx.load('lstm.onnx') # input shape [5, 3, 10] print(onnx_model.graph.input[0]) # export with `dynamic_axes` torch.onnx.export(model, (input, (h0, c0)), 'lstm.onnx', input_names=['input', 'h0', 'c0'], output_names=['output', 'hn', 'cn'], dynamic_axes={'input': {0: 'sequence'}, 'output': {0: 'sequence'}}) onnx_model = onnx.load('lstm.onnx') # input shape ['sequence', 3, 10] print(onnx_model.graph.input[0]) 问：如何与它的循环导出模型？ 请结算跟踪VS脚本[HTG1。 问：ONNX支持隐式数据类型标铸造？ > 没有，但出口商会尽量处理的那部分。标量被转换为在ONNX恒定张量。出口商会揣摩标量正确的数据类型。但是，对于它没有这样做的情况下，您将需要手动提供的数据类型信息。我们正在努力改善，使得手动更改不会在将来要求出口数据类型的传播。 class ImplicitCastType(torch.jit.ScriptModule): @torch.jit.script_method def forward(self, x): # Exporter knows x is float32, will export '2' as float32 as well. y = x + 2 # Without type propagation, exporter doesn't know the datatype of y. # Thus '3' is exported as int64 by default. return y + 3 # The following will export correctly. # return y + torch.tensor([3], dtype=torch.float32) x = torch.tensor([1.0], dtype=torch.float32) torch.onnx.export(ImplicitCastType(), x, 'models/implicit_cast.onnx', example_outputs=ImplicitCastType()(x)) 功能 torch.onnx.``export( model , args , f , export_params=True , verbose=False , training=False , input_names=None , output_names=None , aten=False , export_raw_ir=False , operator_export_type=None , opset_version=None , _retain_param_name=True , do_constant_folding=False , example_outputs=None , strip_doc_string=True , dynamic_axes=None )[source] 导出模型到ONNX格式。该出口国，一旦运行模型，以获得其执行一丝要导出;目前，它支持一组有限的动态模型（例如，RNNs）另见： onnx出口：PARAM模型：要导出的模型。 ：类型的模型：torch.nn.Module：PARAM ARGS：输入以 该模型，例如，使得模型（*参数）是该模型的有效调用。任何非张量参数将被硬编码到导出的模型;任何张量参数将成为导出的模型的输入，在它们出现在args的顺序。如果ARGS是张量，这等同于具有与该张量的1元元组称为它。 （注：传递关键字参数到模型目前不支持给我们留言，如果你需要它。） Parameters F - 一个类文件对象（必须实现的fileno返回文件描述符）或包含文件名的字符串。二进制的Protobuf将被写入该文件。 export_params （ 布尔 ， 默认真 ） - 如果指定，所有的参数将被导出。如果你要导出未经训练的模式设置为False。在这种情况下，如由model.state_dict（）中指定的输出模式将首先采取它的所有参数作为参数，排序。值（） 详细 （ 布尔 ， 默认为false ） - 如果指定，我们将打印出的调试说明跟踪被导出。 训练 （ 布尔 ， 默认为false ） - 导出模型训练模式。目前，ONNX是面向仅供推理模型导出，所以你一般不会需要将其设置为True。 input_names （ 字符串列表 ， 默认空列表 ） - 名称分配给图的输入节点，为了 output_names （ 字符串列表 ， 默认空列表 ） - 名称分配给图的输出节点，为了 ATEN （ 布尔 ， 默认假 ） - [已过时。使用operator_export_type]的模型导出ATEN模式。 ;版本& GT ;。PY导出为阿坦OPS如果使用宏正模式时，所有的OPS原稿symbolic_opset & LT出口通过的功能。 export_raw_ir （ 布尔 ， 默认假 ） - [已过时。使用operator_export_type]导出内部IR，而不是直接将其转换为ONNX OPS的。 operator_export_type （ 枚举 ， 默认OperatorExportTypes.ONNX ） - OperatorExportTypes.ONNX：所有OPS导出为普通ONNX欢声笑语。 OperatorExportTypes.ONNX_ATEN：所有OPS导出为阿滕欢声笑语。 OperatorExportTypes.ONNX_ATEN_FALLBACK：如果象征性的缺失， 依傍阿滕运算。 OperatorExportTypes.RAW：出口原料IR。 opset_version （ INT ， 默认为9 HTG9]） - 默认情况下，我们的模型导出到的opset所版本该onnx子模块。由于ONNX最新opset所下一个稳定版本之前可能演变，在默认情况下我们出口到一个稳定opset所版本。眼下，支持稳定opset所版本9. opset_version必须_onnx_master_opset或者其中的Torch / onnx / symbolic_helper.py定义_onnx_stable_opsets do_constant_folding （ 布尔 ， 默认假 ） - 如果为True，恒定折叠优化施加到出口过程中的模型。恒定折叠优化将取代一些具有所有常量输入，与预先计算的常数的节点OPS的。 example_outputs （ 张量 的元组， 默认无 ） - example_outputs必须导出ScriptModule或TorchScript功能时提供。 strip_doc_string （ 布尔 ， 默认真 ） - 如果为True，从导出的剥离字段“doc_string”模型，对堆栈跟踪哪些信息。 example_outputs - 正被导出的模型的示例输出。 dynamic_axes （ DICT & LT ;串 ， 字典 & LT ;蟒：INT ， 串 & GT ; & GT ; 或 字典 & LT ;串 ， 列表 （ INT ） & GT ; ， 默认空字典 ） - 一个字典，以指定的输入/输出的动态轴，使得： - KEY：输入和/或输出的名称 - 值：对于给定的密钥动态轴的指数的和潜在的名称将被用于导出动态轴。 （1）：在一般的值根据以下方式或二者的组合中的一个来定义。整数specifiying提供的输入的动态轴的列表。在这种情况下自动名称将被产生和导出过程中施加到所提供的输入/输出的动态轴。 OR（2）。内的字典，它指定在相应的输入/输出到期望出口期间这样的输入/输出的这种轴所施加的名字从动态轴的索引的映射。例。如果我们有用于输入和输出如下形状： 形状（INPUT_1）=（“B”，3，“W”，“H”）和形状（INPUT_2）=（“B”，4）和形状（输出）=（“B”，“d”，5） Then dynamic axes can be defined either as: (a). ONLY INDICES: dynamic_axes = {“INPUT_1”：[0，2，3]，“INPUT_2”：[0]，“输出”：[0，1]} 其中自动名称将用于导出动态轴来生成 (b). INDICES WITH CORRESPONDING NAMES: dynamic_axes = { 'INPUT_1'：{0： '批'，1： '宽度'，2： '高度'}， 'INPUT_2'：{0： '批'}， '输出'：{0： '批'， 1： '检测'} 其中提供的名称将被应用到导出动态轴 (c). MIXED MODE OF (a) and (b) dynamic_axes = {“INPUT_1”：[0，2，3]，“INPUT_2”：{0：”批”}，‘输出’：[0,1]} torch.onnx.``register_custom_op_symbolic( symbolic_name , symbolic_fn , opset_version )[source] torch.onnx.operators.``shape_as_tensor( x )[source] torch.onnx.``set_training( model , mode )[source] 上下文管理者临时设置“模式”到“模式”的训练模式，重置它，当我们退出与块。甲如果无操作模式是无。 torch.onnx.``is_in_onnx_export()[source] 检查它是否是在ONNX出口的中间。此功能在torch.onnx.export中旬返回True（）。 torch.onnx.export应与单个线程执行。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:19 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"torchvision/":{"url":"torchvision/","title":"torchvision","keywords":"","body":"torchvision 的 torchvision包由流行的数据集，模型体系结构，以及用于计算机视觉共同图像变换。 Package Reference torchvision.datasets MNIST 时装-MNIST KMNIST EMNIST QMNIST FakeData COCO LSUN ImageFolder DatasetFolder ImageNet CIFAR STL10 SVHN PhotoTour SBU 的Flickr VOC 都市风景 SBD USPS 动力学-400 HMDB51 UCF101 torchvision.io [HTG0视频 torchvision.models 分类 语义分割 对象检测，实例分割和Person关键点检测 [HTG0视频分类 torchvision.ops torchvision.transforms 上PIL图像变换 来变换的Torch 。*张量 转换变换 [HTG0】通用变换 功能变换 torchvision.utils torchvision.``get_image_backend()[source] 获取包的用于加载图像的名称 torchvision.``set_image_backend( backend )[source] 指定用于加载图像包。 Parameters 后端 （ 串 ） - 图像后端的名称。 {“PIL”，“accimage”}中的一个。的accimage软件包使用英特尔IPP库。它通常比PIL快，但不支持尽可能多的操作。 Next Previous ©版权所有2019年，Torch 贡献者。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-09-23 17:49:20 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}